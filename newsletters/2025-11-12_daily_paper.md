
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2025-11-12 论文日报

## 📊 今日论文统计
- 总论文数：15
- 热门领域：RL, GPT, LLM

## 📝 论文详情


### 1. 基于人类示范的计算机使用代理系统基础构建

**原文标题：** Grounding Computer Use Agents on Human Demonstrations

**摘要：**
构建可靠的计算机使用代理系统需要实现精准的基础关联：将自然语言指令与正确的屏幕元素准确对应。尽管网络和移动端交互已存在大规模数据集，但针对桌面环境的高质量资源仍然有限。为填补这一空白，我们推出GroundCUA——一个基于专家人类示范构建的大规模桌面基础关联数据集。该数据集涵盖12个类别下的87种应用程序，包含5.6万张屏幕截图，每个屏幕元素均经过精细标注，累计获得超过356万条人工验证的标注数据。基于这些示范，我们生成涵盖广泛现实任务场景的多样化指令，为模型训练提供高质量数据支撑。利用GroundCUA数据集，我们开发了GroundNext系列模型，可实现从指令到目标UI元素的精准映射。在30亿和70亿参数规模下，通过监督微调，GroundNext在五项基准测试中均达到最先进水平，且所需训练数据量不足先前工作的十分之一。强化学习后训练进一步提升了模型性能，在OSWorld基准测试中配合o3规划器进行智能体评估时，GroundNext取得了与使用更多数据训练的模型相当或更优的结果。这些发现证实了由专家驱动的高质量数据集在推进通用计算机使用代理系统发展中的关键作用。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07332) | [arXiv](https://arxiv.org/abs/2511.07332)



---

### 2. 小模型，大逻辑：多样性驱动优化激发VibeThinker-1.5B的大模型推理能力

**原文标题：** Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model
  Reasoning Ability in VibeThinker-1.5B

**摘要：**
本文通过提出VibeThinker-1.5B模型，挑战了当前普遍认为小模型天然缺乏强推理能力的共识。这个拥有15亿参数的稠密模型基于我们提出的频谱-信号原则（SSP）开发，该方案突破了当前通过扩大模型参数提升能力的主流范式（如DeepSeek R1的6710亿参数、Kimi k2的万亿级参数）。SSP框架首先采用两阶段多样性探索蒸馏（SFT）生成广谱解决方案，随后通过最大熵引导策略优化（RL）强化正确信号。在总训练成本仅7800美元的情况下，VibeThinker-1.5B展现出优于闭源模型Magistral Medium和Claude Opus 4的推理能力，并与开源模型GPT OSS-20B Medium表现相当。值得注意的是，在三个数学基准测试中，该模型以400倍小于DeepSeek R1的规模实现超越：AIME24（80.3 vs 79.8）、AIME25（74.4 vs 70.0）和HMMT25（50.4 vs 41.7）。相较于其基础模型（原成绩分别为6.7、4.3和0.6），这是质的飞跃。在LiveCodeBench V6测试中取得51.1分，优于Magistral Medium的50.3分及其基础模型的0分。这些发现证明小模型同样能实现媲美大模型的推理能力，大幅降低训练与推理成本，为推进AI研究的普惠化开辟了新路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06221) | [arXiv](https://arxiv.org/abs/2511.06221)



---

### 3. 对话系统中自适应多智能体响应优化机制研究

**原文标题：** Adaptive Multi-Agent Response Refinement in Conversational Systems

**摘要：**
大语言模型通过生成类人化响应在对话系统中展现出卓越成效，然而当涉及个性化需求或特定知识领域时，其表现仍存在局限。现实应用场景中依赖用户主动识别错误并请求重新生成响应显然不具可行性。针对此问题，可在返回响应前进行优化修正。现有研究方法主要集中于单一语言模型内部的响应优化，难以兼顾有效对话所需的多元维度。本研究提出基于多智能体框架的响应优化方案，通过为每个智能体分配特定维度的优化任务，重点针对对话质量至关重要的三个核心维度：事实准确性、个性化适配与逻辑连贯性。各智能体分别负责对应维度的审查与优化，并通过反馈融合机制提升整体响应质量。为强化智能体间的协同效能，我们引入动态通信策略——摒弃固定执行序列，根据查询需求自适应选择并协调最相关的智能体组合。在具有挑战性的对话数据集上的实验表明，本框架显著优于现有基线模型，尤其在涉及知识库与用户画像的复合任务中表现突出。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.08319) | [arXiv](https://arxiv.org/abs/2511.08319)



---

### 4. Wasm：构建结构化阿拉伯语交错多模态语料库的流程框架

**原文标题：** Wasm: A Pipeline for Constructing Structured Arabic Interleaved
  Multimodal Corpora

**摘要：**
大型语言模型（LLM）和大型多模态模型（LMM）的性能在很大程度上取决于其预训练数据集的质量与规模。最新研究表明，在图像与文本交错编排的自然文档上训练的大型多模态模型，通过利用先进的预训练模型强化语义对齐、图像序列一致性和文本连贯性，在广泛基准测试中表现优于仅基于图文对训练的模型。然而对于阿拉伯语而言，缺乏保持文档结构的高质量多模态数据集限制了该领域的发展。本文提出名为Wasm的处理流程，通过对Common Crawl数据集进行加工，构建了首个提供Markdown输出的阿拉伯语多模态数据集。与现有仅关注文本提取的阿拉伯语语料库不同，我们的方法在保持网页内容结构完整性的同时，兼顾纯文本与多模态预训练场景的灵活性。我们通过全面的对比分析，将本数据处理流程与现有主流数据集构建方法进行对比，既揭示了过滤策略的共性特征，也论证了特定设计决策的合理性。为促进后续研究，我们公开发布了具有代表性的数据集样本及完整的阿拉伯语多模态处理流程。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07080) | [arXiv](https://arxiv.org/abs/2511.07080)



---

### 5. KLASS：基于KL散度的掩码扩散模型快速推理方法

**原文标题：** KLASS: KL-Guided Fast Inference in Masked Diffusion Models

**摘要：**
掩码扩散模型在语言生成等多项任务中展现出卓越性能。然而受迭代优化机制制约，其推理过程常受限于缓慢且固定的采样速度。为解决此问题，我们提出"KL自适应稳定性采样"（KLASS），该方法通过利用词元级KL散度识别稳定高置信度预测，在无需额外模型训练的前提下实现高效采样。通过单次迭代中同步解掩多个词元，本方法在保证生成质量的同时显著提升推理速度。在推理基准测试中，KLASS相比标准贪心解码在保持性能优势的同时实现最高2.78倍的实际加速效果，在基于扩散的采样器中达到最优水平。我们进一步在文本、图像及分子生成等多领域验证KLASS的有效性，证明其可作为跨模型通用采样器广泛应用。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.05664) | [arXiv](https://arxiv.org/abs/2511.05664)



---

### 6. VideoSSR：视频自监督强化学习框架

**原文标题：** VideoSSR: Video Self-Supervised Reinforcement Learning

**摘要：**
可验证奖励强化学习（RLVR）显著提升了多模态大语言模型（MLLMs）的视频理解能力。然而，现有视频数据集的复杂度已难以匹配MLLMs的快速发展，而人工标注高质量新数据的成本依然居高不下。本研究探讨了一个关键问题：能否利用视频内蕴的丰富信息自生成高质量可验证训练数据？为此，我们提出三种自监督预训练任务：异常定位、目标计数与时序拼图，并构建视频内在理解基准（VIUBench）验证任务难度。实验表明当前最先进的MLLMs在这些任务上表现欠佳。基于这些预训练任务，我们构建了VideoSSR-30K数据集，提出新型视频自监督强化学习框架VideoSSR。在涵盖四大视频领域（通用视频问答、长视频问答、时序定位和复杂推理）的17个基准测试中，广泛实验表明VideoSSR能持续提升模型性能，平均改进幅度超5%。这些成果确立了VideoSSR作为推动MLLMs视频理解能力发展的基础框架。代码已开源：https://github.com/lcqysl/VideoSSR。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06281) | [arXiv](https://arxiv.org/abs/2511.06281)



---

### 7. 超越英语：基于大语言模型构建包容可扩展的多语言机器翻译系统

**原文标题：** Beyond English: Toward Inclusive and Scalable Multilingual Machine Translation with LLMs

**摘要：**
大语言模型显著推动了多语言机器翻译的发展，但广泛的语言覆盖、稳定的翻译质量以及英语中心化偏差仍是亟待解决的挑战。为解决这些问题，我们推出了LMT系列模型——一套以中英双语为核心的大规模多语言翻译系统，涵盖60种语言及234个翻译方向。在研发过程中，我们发现了一种被忽视的方向性退化现象：对称多语微调数据过度侧重反向翻译（其他语言至英语/中文），导致过多多对一映射并降低翻译质量。为此我们提出策略性降采样方法，通过简单而有效的技术手段缓解此退化现象。同时，我们设计了并行多语言提示机制，利用类型学相关的辅助语言增强跨语言迁移能力。通过严格的数据筛选和优化的适配策略，LMT在同等语言覆盖规模的模型中实现了最先进的性能，其中40亿参数模型（LMT-60-4B）显著超越了参数量更大的Aya-101-13B和NLLB-54B模型。我们发布四个规模版本（6亿/17亿/40亿/80亿）的LMT模型，旨在推动包容可扩展的高质量多语言机器翻译研究，并为该领域提供强有力的基准参考\href{https://github.com/NiuTrans/LMT{https://github.com/NiuTrans/LMT}}。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07003) | [arXiv](https://arxiv.org/abs/2511.07003)



---

### 8. 未竟之路：RLVR可证明偏离主方向的学习机制

**原文标题：** The Path Not Taken: RLVR Provably Learns Off the Principals

**摘要：**
可验证奖励强化学习（RLVR）能够可靠地提升大语言模型的推理性能，但其似乎仅修改了极少部分参数。我们重新审视这一悖论，发现稀疏性实为模型条件优化偏差的表象：对于固定预训练模型，参数更新始终集中于偏好参数区域，该现象在不同实验间高度一致，且对数据集和RL配方具有强不变性。我们通过三闸门理论机制性解释该动态：闸门I（KL锚点）施加KL约束的梯度更新；闸门II（模型几何）将更新步长引导至偏离主方向的低曲率、保谱子空间；闸门III（精度掩码）将非偏好区域的微观更新隐藏，使得偏离主方向的偏差呈现为稀疏性。我们随后验证该理论，并首次给出RLVR学习动态的参数级刻画：RLVR在权重空间中沿非主方向学习，通过最小化谱漂移、减少主空间旋转及实现非主方向更新对齐获得增益。相比之下，监督微调以主权重为目标，会扭曲频谱特征，其效果甚至滞后于RLVR。  

这些发现共同构成了首个针对RLVR训练动态的参数空间阐释，揭示了参数演化过程中的清晰规律。关键的是，我们证明RL运行在不同于监督微调的优化区域中，因此直接套用监督微调时代的参数高效微调方法存在缺陷——我们在先进稀疏微调及LoRA变体的案例研究中证实了这一点。本研究旨在为理解RLVR的白箱机制铺路，推动几何感知的RLVR原生算法设计，而非简单沿用监督微调时代的启发式方法。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.08567) | [arXiv](https://arxiv.org/abs/2511.08567)



---

### 9. 超越事实检索：基于生成式语义工作区的RAG情景记忆框架

**原文标题：** Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces

**摘要：**
大语言模型在长上下文推理中面临根本性挑战：许多文档超出其有限上下文窗口，而适配文本的性能随序列长度增加而下降，这需要通过外部记忆框架进行增强。当前解决方案从基于语义嵌入的检索演变为更复杂的结构化知识图谱表示，虽提升了意义构建与关联能力，但仅适用于事实检索，无法构建时空锚定的叙事表征以追踪情景事件中的实体。为弥补这一差距，我们提出生成式语义工作区——一种受神经科学启发的生成式记忆框架，能构建演化情境的结构化可解释表征，使大语言模型能够对动态角色、行为及时空语境进行推理。该框架包含将观测数据映射为中间语义结构的操作器，以及将这些结构整合至保障时序、空间与逻辑一致性的持久工作区的协调器。在包含10万至100万标记语料的情景记忆基准测试中，本框架相较现有基于RAG的基线模型性能提升达20%。此外，该框架具备高效特性，相比次优基线模型在查询时上下文标记数量减少51%，显著降低推理时间成本。更广泛而言，本框架为赋予大语言模型类人情景记忆提供了具体技术路径，为实现长周期推理的智能体奠定基础。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07587) | [arXiv](https://arxiv.org/abs/2511.07587)



---

### 10. DynaAct：动态动作空间下的大语言模型推理研究

**原文标题：** DynaAct: Large Language Model Reasoning with Dynamic Action Spaces

**摘要：**
在现代序列决策系统中，构建最优候选动作空间对提升推理效率至关重要。然而现有方法要么依赖缺乏可扩展性的人工定义动作空间，要么采用非结构化空间导致穷举搜索的计算成本过高。本文提出名为DynaAct的创新框架，通过自动构建紧凑动作空间来增强复杂问题解决场景中的序列推理能力。我们的方法首先通过大语言模型从涵盖多样化复杂推理问题的语料库中提取通用模式框架，以此估算完整动作空间的代理表征。随后构建一个子模函数，综合评估候选动作对当前状态的效用度及其多样性，并采用贪心算法选择最优候选集。在六个多样化标准基准上的大量实验表明，本方法在保持高效推理且未引入显著延迟的同时，显著提升了整体性能。代码实现已发布于https://github.com/zhaoxlpku/DynaAct。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.08043) | [arXiv](https://arxiv.org/abs/2511.08043)



---

### 11. [每瓦智能：衡量本地人工智能的智能能效]

**原文标题：** Intelligence per Watt: Measuring Intelligence Efficiency of Local AI

**摘要：**
当前大型语言模型的查询处理主要依赖集中式云基础设施中的前沿模型。快速增长的算力需求使该模式面临巨大压力，云服务商难以同步扩展基础设施规模。两项技术进展促使我们重新思考这一范式：小型语言模型（≤200亿活跃参数）已在多数任务中达到与前沿模型相媲美的性能，而本地加速器（如苹果M4 Max）能以交互级延迟运行这些模型。这引出一个关键问题：本地推理能否有效分流集中式基础设施的算力需求？解答该问题需从两个维度进行衡量：本地模型能否准确回答现实世界查询，以及能否在功耗受限设备（如笔记本电脑）上实现足够能效以具备实用性。我们提出“每瓦智能”这一指标——即任务准确率与单位功耗的比值，用于评估不同模型-加速器组合的本地推理能力与能效。通过对20余个前沿本地语言模型、8类加速器以及100万条真实世界单轮对话与推理查询（代表主流LLM流量）的大规模实证研究，我们逐条测量了准确率、能耗、延迟与功耗。研究揭示三大发现：首先，本地模型能准确回答88.7%的单轮对话与推理查询，准确率因领域而异；其次，2023至2025年间，每瓦智能指标提升5.3倍，本地查询覆盖率从23.2%升至71.3%；最后，运行相同模型时，本地加速器的每瓦智能指标较云加速器至少低1.4倍，显示巨大优化空间。这些发现证明本地推理能有效分流集中式基础设施需求，而每瓦智能可作为追踪该转型进程的关键指标。我们同步开源每瓦智能评测工具，为系统性能效基准测试提供支持。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07885) | [arXiv](https://arxiv.org/abs/2511.07885)



---

### 12. BiCA：基于引文感知困难负样本的生物医学稠密检索方法

**原文标题：** BiCA: Effective Biomedical Dense Retrieval with Citation-Aware Hard Negatives

**摘要：**
困难负样本对训练高效检索模型至关重要。传统困难负样本挖掘通常依赖交叉编码器或基于余弦距离等相似性度量的静态嵌入模型对文档排序。在生物医学和科学领域，由于源文档与困难负样本文档难以区分，使得困难负样本挖掘面临挑战。然而，被引文献天然与源文档具有上下文关联性且非重复文献，这使其成为理想的困难负样本。本研究提出BiCA：基于引文感知困难负样本的生物医学稠密检索方法，通过利用20,000篇PubMed文献中的引文链接进行困难负样本挖掘，以改进特定领域的小型稠密检索器。我们使用这些引文指导的负样本对GTE_small和GTE_Base模型进行微调，在BEIR基准的领域内和领域外任务中采用nDCG@10评估零样本稠密检索性能均取得稳定提升，并在LoTTE数据集的长尾主题任务中使用Success@5指标超越基线模型。研究结果揭示了利用文档链接结构生成高信息量负样本的潜力，仅需少量微调即可实现最优性能，为高数据效率的领域自适应提供了可行路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.08029) | [arXiv](https://arxiv.org/abs/2511.08029)



---

### 13. 软件开发中大型语言模型的平衡之道：从业者视角

**原文标题：** Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective

**摘要：**
背景：大型语言模型的出现可能引发软件开发领域的革命（例如流程自动化、劳动力转型）。尽管已有研究开始探讨LLM对软件开发的感知影响，但仍需通过实证研究来理解如何平衡使用LLM带来的正向与负向影响。目标：从软件开发者的视角，探究LLM如何影响软件开发及如何管理这些影响。方法：在2024年10月至2025年9月期间，我们通过三轮数据收集与分析，对22位软件从业者进行了访谈。采用社会技术扎根理论（STGT）对访谈参与者的反馈进行严谨分析。结果：我们识别出在个体、团队、组织和社会层面使用LLM的益处（如维持开发流程、改善开发者心智模型、促进创业精神）与弊端（如对开发者个性的负面影响、损害开发者声誉），并总结了LLM应用的最佳实践。结论：我们重点揭示了软件从业者、团队及组织在使用LLM时面临的权衡取舍。本研究结果对软件开发团队负责人和IT管理者评估LLM在其特定环境中的适用性具有重要参考价值。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06428) | [arXiv](https://arxiv.org/abs/2511.06428)



---

### 14. 基于对齐模型协作的多样性-质量协同优化方法

**原文标题：** Optimizing Diversity and Quality through Base-Aligned Model Collaboration

**摘要：**
对齐技术虽然显著提升了大语言模型的输出质量，却以牺牲多样性为代价，导致生成内容高度同质化。本研究提出基于对齐模型协作框架（BACo），该推理阶段令牌级模型协作框架通过动态融合基础大语言模型与其对齐版本，实现多样性-质量的协同优化。受Fei等人（2025）研究启发，BACo采用路由策略，基于下一令牌预测不确定度与预测内容的语义角色，逐令牌确定解码来源模型。现有提升多样性的方法（如重新训练、提示工程、多采样等）虽能增强多样性，但往往导致质量下降或需要高昂的解码/训练后成本。相比之下，BACo在单次推理中即可实现高质量与高多样性的协同提升，并具备强可控性。我们在三类开放生成任务中系统评估了路由策略族，通过13项涵盖多样性与质量的指标验证，BACo持续超越最先进的推理阶段基线方法。采用最优路由策略时，BACo在多样性-质量综合指标上实现21.3%的相对提升，人工评估结果也印证了这一改进。研究表明基础模型与对齐模型间的协作能有效优化并控制生成内容的多样性-质量平衡。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.05650) | [arXiv](https://arxiv.org/abs/2511.05650)



---

### 15. TimeSearch-R：基于自验证强化学习的自适应时序搜索技术实现长视频理解

**原文标题：** TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning

**摘要：**
时序搜索旨在根据给定查询从数万帧视频中定位最小相关帧集合，为长视频精准理解提供基础支撑。现有研究尝试逐步缩小搜索范围，但这类方法通常依赖人工设计的搜索流程，缺乏对最优搜索策略的端到端优化。本文提出TimeSearch-R框架，将时序搜索重构为文本-视频交错思考过程，通过强化学习将视频片段搜索无缝集成到推理链路中。然而，将群体相对策略优化等强化学习训练方法应用于视频推理会导致无监督的中间搜索决策，进而引发视频内容探索不足与逻辑推理不一致问题。为此，我们提出带完整性自验证的GRPO方法，通过收集交错推理过程中的视频帧，利用同一策略模型验证已搜索帧的充分性，从而提升视频推理的完整性。此外，我们构建了专用于GRPO-CSV的SFT冷启动与强化学习训练数据集，通过筛选时序依赖性弱的样本增强任务难度以提升时序搜索能力。大量实验表明，TimeSearch-R在Haystack-LVBench、Haystack-Ego4D等时序搜索基准，以及VideoMME、MLVU等长视频理解基准上均取得显著提升。特别值得注意的是，TimeSearch-R在LongVideoBench上创造了最新纪录，较基础模型Qwen2.5-VL提升4.1%，较先进视频推理模型Video-R1提升2.0%。代码已开源：https://github.com/Time-Search/TimeSearch-R。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.05489) | [arXiv](https://arxiv.org/abs/2511.05489)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2025-11-12_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)