
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2025-11-20 论文日报

## 📊 今日论文统计
- 总论文数：12
- 热门领域：RL

## 📝 论文详情


### 1. Kandinsky 5.0：面向图像与视频生成的基座模型系列

**原文标题：** Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation

**摘要：**
本报告介绍Kandinsky 5.0——一系列面向高分辨率图像与10秒视频合成的尖端基座模型。该框架包含三大核心模型组合：Kandinsky 5.0图像轻量版——包含60亿参数的图像生成模型系列；Kandinsky 5.0视频轻量版——快速轻量的20亿参数文生视频与图生视频模型；以及Kandinsky 5.0视频专业版——190亿参数的高品质视频生成模型。我们系统阐述了多阶段训练流程中的数据治理生命周期（涵盖收集、处理、筛选与聚类），该流程包含大规模预训练阶段，并融合了自监督微调（SFT）与基于强化学习（RL）的后训练等质量增强技术。同时，我们提出了创新的架构设计、训练方法与推理优化方案，使Kandinsky 5.0在人类评估中展现出高速生成能力与多任务的顶尖性能。作为大规模开源生成框架，Kandinsky 5.0充分发挥预训练及后续阶段的潜力，可适配多样化的生成应用场景。我们期待通过本报告及同步开源的核心代码与训练检查点，显著推动高质量生成模型在科研领域的发展与普及。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.14993) | [arXiv](https://arxiv.org/abs/2511.14993)



---

### 2. 基于视频的推理：通过迷宫求解任务首次评估视频模型的推理能力

**原文标题：** Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks

**摘要：**
视频模型在具有连贯运动动态的高保真视频生成领域已取得显著成功。类似于语言建模从文本生成到基于文本推理的发展历程，视频模型的进步促使我们思考：视频模型能否通过视频生成进行推理？与离散的文本语料相比，视频将推理锚定在明确的空间布局和时间连续性中，这使其成为空间推理的理想载体。本研究探索基于视频的推理范式，并推出VR-Bench——一个系统评估视频模型推理能力的综合基准。该基准以迷宫求解任务为基础，此类任务本质要求空间规划与多步推理能力，涵盖5种迷宫类型和多样化视觉风格，共包含7,920个程序化生成的视频。实证分析表明，监督微调能有效激发视频模型的推理能力。视频模型在推理过程中展现出更强的空间感知能力，其表现超越主流视觉语言模型，并在多样化场景、任务及复杂度层级中均具有良好的泛化性能。我们还发现测试时规模效应——推理阶段采用多样化采样可使推理可靠性提升10-20%。这些发现彰显了基于视频的推理方法在空间推理任务中独特的潜力和可扩展性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.15065) | [arXiv](https://arxiv.org/abs/2511.15065)



---

### 3. 优秀AI研究智能体需具备何种特质？探讨构思多样性的作用

**原文标题：** What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity

**摘要：**
AI研究智能体通过自动化机器学习模型的设计、实现与训练，为加速科学进步提供了可能。然而该领域仍处于发展初期，驱动智能体轨迹成败的关键因素尚未被完全理解。本文研究了构思多样性在智能体性能中发挥的作用。首先，我们分析了不同模型与智能体框架在MLE-bench（评估AI研究智能体的知名基准）上的运行轨迹。分析表明：不同模型与智能体框架会产生不同程度的构思多样性，且性能越优异的智能体往往展现出更高的构思多样性。进而，我们通过控制实验调节构思多样性程度，证明提高构思多样性可显著增强智能体性能。最后，我们突破MLE-bench基于奖牌评分的标准指标体系，通过附加评估指标验证了研究结论的稳健性——在不同智能体性能度量标准下，我们的发现依然成立。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.15593) | [arXiv](https://arxiv.org/abs/2511.15593)



---

### 4. VisPlay：基于图像自演进的多模态视觉语言模型

**原文标题：** VisPlay: Self-Evolving Vision-Language Models from Images

**摘要：**
强化学习为提升视觉语言模型在复杂推理任务中的性能提供了理论框架。然而现有强化学习方法通常依赖人工标注标签或任务特定启发式规则来定义可验证奖励，这两种方式均成本高昂且难以扩展。我们提出VisPlay——一种自演进强化学习框架，使视觉语言模型能够利用大量未标注图像数据自主提升推理能力。该框架以单一基础视觉语言模型为起点，将其分配至两个交互角色：图像条件提问器负责构建具有挑战性但可回答的视觉问题，多模态推理器则生成银标答案。通过群体相对策略优化算法对这两个角色进行联合训练，该算法融合多样性与难度奖励机制，以平衡生成问题的复杂程度与银标答案的质量。VisPlay在Qwen2.5-VL和MiMo-VL两大模型系列中均展现出良好的扩展性。在MM-Vet和MMMU等八个基准测试中，该框架在视觉推理、组合泛化及幻觉抑制方面均取得持续提升，为自演进多模态智能的发展提供了可扩展路径。项目页面详见：https://bruno686.github.io/VisPlay/

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.15661) | [arXiv](https://arxiv.org/abs/2511.15661)



---

### 5. 基于自动生成大规模数据集的指令引导胸部X光病灶分割

**原文标题：** Instruction-Guided Lesion Segmentation for Chest X-rays with Automatically Generated Large-Scale Dataset

**摘要：**
当前胸部X光病灶分割模型的应用受限于目标标签数量稀少及依赖冗长的专家级文本输入，这为实际应用带来了障碍。为解决这些局限性，我们提出了一种新范式：指令引导病灶分割，该范式旨在基于简单易用的用户指令分割多种病灶类型。在此范式下，我们通过全自动多模态流程构建了首个面向胸部X光病灶分割的大规模指令-答案数据集MIMIC-ILS，该流程能够根据胸部X光图像及其对应报告自动生成标注。MIMIC-ILS包含源自19.2万张图像和9.1万个独立分割掩码的110万条指令-答案对，涵盖七种主要病灶类型。为实证验证其效用，我们提出了基于MIMIC-ILS微调的视觉语言模型ROSALIA。该模型能够根据用户指令分割多种病灶并提供文本解释。在我们新提出的任务中，该模型实现了较高的分割精度与文本描述准确性，充分证明了我们流程的有效性，以及MIMIC-ILS作为像素级胸部X光病灶定位基础资源的重要价值。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.15186) | [arXiv](https://arxiv.org/abs/2511.15186)



---

### 6. ARC-Chapter：将小时级视频结构化构建为可导航章节与层级化摘要

**原文标题：** ARC-Chapter: Structuring Hour-Long Videos into Navigable Chapters and Hierarchical Summaries

**摘要：**
小时级长视频（如讲座、播客、纪录片）的激增强化了对高效内容结构化的需求。然而现有方法受限于小规模标注训练，其标注通常简短粗糙，难以泛化至长视频中的细微内容转换。我们提出ARC-Chapter——首个基于百万级长视频章节训练的大规模视频分章模型，其特点在于包含双语、时序锚定和层次化的章节标注。为实现这一目标，我们通过结构化流程构建了英汉双语章节数据集，将语音转录文本、场景文字和视觉描述统一整合为从简短标题到详细摘要的多层级标注。我们通过数据规模（数据量与标注强度）的扩展证明了明显的性能提升。此外，我们设计了名为GRACE的新型评估指标，该指标综合考量多对一的片段重叠度与语义相似性，能更好反映实际分章任务的灵活性。大量实验表明，ARC-Chapter以显著优势创下新性能纪录，F1分数较先前最佳方法提升14.0%，SODA分数提升11.3%。值得注意的是，ARC-Chapter展现出卓越的迁移学习能力，在YouCook2密集视频描述等下游任务中同样提升了现有最佳性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.14349) | [arXiv](https://arxiv.org/abs/2511.14349)



---

### 7. MHR：动量人体骨骼系统

**原文标题：** MHR: Momentum Human Rig

**摘要：**
本文提出MHR参数化人体模型，该模型融合了ATLAS架构的解耦骨骼/形态范式，并借鉴Momentum函数库构建了具有灵活性的现代骨骼绑定与姿态校正系统。该模型能够生成表现力丰富且符合解剖学原理的人体动画，支持非线性姿态校正，其设计可稳健集成于增强现实/虚拟现实及图形处理流程中。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.15586) | [arXiv](https://arxiv.org/abs/2511.15586)



---

### 8. FreeAskWorld：一种以人为中心的具身AI交互式闭环仿真平台

**原文标题：** FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI

**摘要：**
随着具身智能成为人工智能研究的核心前沿，仿真平台必须超越低层次物理交互，以捕捉复杂的人类中心社会行为。我们提出FreeAskWorld——一个融合大语言模型进行高层次行为规划与语义接地交互的仿真框架，其设计基于意图理论与社会认知理论。该框架支持可扩展、逼真的人机交互仿真，并包含专为多样化具身任务设计的模块化数据生成流程。为验证框架性能，我们将经典视觉语言导航任务扩展为交互增强的方位问询场景，使智能体能够主动寻求并解析导航指引。我们公开发布FreeAskWorld大规模基准数据集，包含重构环境、六类任务形态、16个核心物体类别、63,429帧标注样本及超过17小时的交互数据，为具身AI系统的训练与评估提供支持。通过对视觉语言导航模型和人类参与者进行开环与闭环设置的基准测试，实验结果表明：基于FreeAskWorld微调的模型显著优于原模型，在语义理解与交互能力方面均获得提升。这些发现印证了社会情境化仿真框架在推动具身AI系统实现高级规划与自然人机交互方面的有效性。特别需要指出的是，本研究揭示了交互本身可作为独立的信息模态这一重要特性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.13524) | [arXiv](https://arxiv.org/abs/2511.13524)



---

### 9. RoMa v2：更强大、更优质、更快速、更密集的特征匹配

**原文标题：** RoMa v2: Harder Better Faster Denser Feature Matching

**摘要：**
密集特征匹配旨在估计三维场景两幅图像间的所有对应关系，因其高精度与强鲁棒性已成为当前黄金标准。然而现有密集匹配器在诸多复杂现实场景中仍存在失效或性能不佳的问题，且高精度模型往往速度迟缓，限制了实际应用。本文通过一系列系统性改进多管齐下攻克这些缺陷，最终形成显著优化的模型。我们构建了新颖的匹配架构与损失函数，结合精心策划的多样化训练数据分布，使模型能够解决众多复杂匹配任务。通过解耦的“先匹配后优化”两阶段流程，我们进一步加速训练过程，同时借助定制CUDA内核显著降低优化阶段内存占用。此外，我们利用近期提出的DINOv3基础模型并融合多项创新洞见，有效提升模型鲁棒性与无偏性。在大量实验验证中，新型匹配器创造了最新技术标杆，其精度显著超越前代模型。代码已发布于https://github.com/Parskatt/romav2

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.15706) | [arXiv](https://arxiv.org/abs/2511.15706)



---

### 10. 生成式音乐人工智能与人类偏好的对齐：方法与挑战

**原文标题：** Aligning Generative Music AI with Human Preferences: Methods and Challenges

**摘要：**
尽管音乐生成式人工智能近期在保真度与风格多样性方面取得了显著进展，但由于其所采用的特定损失函数，这些系统往往难以契合人类细腻的审美偏好。本文主张将偏好对齐技术系统化应用于音乐生成领域，以弥合计算优化与人类音乐审美之间的根本鸿沟。基于包括MusicRL的大规模偏好学习、DiffRhythm+中基于扩散偏好多目标对齐框架、以及Text2midi-InferAlign等推理时优化技术在内的最新突破，我们深入探讨这些技术如何应对音乐特有的挑战：时序连贯性、和声一致性以及主观质量评估。我们指出了关键研究挑战，包括长篇幅作品的可扩展性、偏好建模可靠性等核心问题。展望未来，我们预见偏好对齐的音乐生成技术将在交互式作曲工具和个性化音乐服务中催生变革性应用。本研究呼吁持续开展跨学科合作，结合机器学习与音乐理论的前沿进展，共同构建真正服务于人类创作与体验需求的音乐人工智能系统。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.15038) | [arXiv](https://arxiv.org/abs/2511.15038)



---

### 11. 状态混合：面向多模态生成的令牌级动态路由机制

**原文标题：** Mixture of States: Routing Token-Level Dynamics for Multimodal Generation

**摘要：**
本文提出状态混合（MoS）——一种创新的多模态扩散模型融合范式，通过基于状态的灵活交互实现模态融合。该机制的核心在于可学习的令牌级路由模块，该模块能够根据去噪时间步长与输入内容，在多模态隐状态间建立动态交互关系，从而精确对齐令牌级特征与扩散轨迹。该路由模块采用稀疏化策略选取前k个隐状态，并配合ε-贪婪训练策略，以最小可学习参数和可忽略的计算开销实现上下文特征的高效选择。我们通过文本到图像生成（MoS-Image）与编辑任务（MoS-Editing）验证了该设计的有效性，相关成果达到业界最优水平。仅需30亿至50亿参数的模型即可匹配甚至超越参数量达4倍的大型对比模型。这些发现确立了MoS作为可扩展多模态扩散模型的灵活高效计算范式。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.12207) | [arXiv](https://arxiv.org/abs/2511.12207)



---

### 12. Medal S：面向医学分割的空间-文本提示模型

**原文标题：** Medal S: Spatio-Textual Prompt Model for Medical Segmentation

**摘要：**
本文提出Medal S医学分割基础模型，该模型在端到端可训练框架内支持原生分辨率空间提示与文本提示。相较于缺乏空间感知的纯文本方法，Medal S实现了体数据提示与文本嵌入的通道级对齐，有效缓解分辨率失配导致的定位偏差。通过保留完整三维上下文信息，该模型能并行处理多个原生分辨率掩码，显著提升多类别分割性能。轻量化三维卷积模块在双提示类型引导下实现精确体素空间优化，支持BiomedSegFM数据集中CT、MRI、PET、超声及显微影像等五种模态的243类分割任务。Medal S提供两种提示模式：纯文本模式下模型预测结果作为空间提示进行自主优化，无需人工干预；混合模式则融合人工标注以实现更高灵活性。在24类分割任务中，并行空间提示较顺序提示减少90%以上推理时间。针对目标-图像块比例失衡问题，我们提出动态重采样技术，扩展了SAT与nnU-Net的数据增强方法。此外，通过优化文本预处理流程、设计两阶段推理策略及后处理技术，显著提升了内存效率、精度与推理速度。在验证集五模态平均指标上，Medal S以DSC 75.44（对比69.83）、NSD 77.34（对比71.06）、F1 38.24（对比24.88）及DSC TP 65.46（对比46.97）全面超越SAT。该模型通过协调空间精度与语义文本指导，在多项医学分割任务中展现出较顺序提示方法更优异的效率与准确性。Medal S代码已开源：https://github.com/yinghemedical/Medal-S。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.13001) | [arXiv](https://arxiv.org/abs/2511.13001)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2025-11-20_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)