
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2025-11-11 论文日报

## 📊 今日论文统计
- 总论文数：30
- 热门领域：RL, LLM, Transformer, Diffusion

## 📝 论文详情


### 1. HaluMem：智能体记忆系统中的幻觉效应评估

**原文标题：** HaluMem: Evaluating Hallucinations in Memory Systems of Agents

**摘要：**
记忆系统是实现大语言模型与智能体长期学习及持续交互的核心组件。然而在记忆存储与检索过程中，这些系统常出现记忆幻觉现象，具体表现为虚构、错漏、冲突和缺失等问题。现有对记忆幻觉的评估主要采用端到端问答形式，难以定位幻觉产生的具体操作环节。为此，我们提出首个面向记忆系统的操作级幻觉评估基准HaluMem，通过定义记忆提取、记忆更新和记忆问答三项评估任务，系统揭示交互过程中不同操作阶段的幻觉行为。为支撑评估，我们构建了以用户为中心的多轮人机交互数据集HaluMem-Medium与HaluMem-Long，两者共包含约1.5万个记忆节点和3500道多类型问题，单用户平均对话轮次达1500轮与2600轮，上下文长度超100万token，可实现不同语境规模与任务复杂度下的幻觉评估。基于HaluMem的实证研究表明，现有记忆系统在提取与更新阶段易产生并积累幻觉，进而将误差传导至问答阶段。未来研究应致力于开发具有可解释性的约束化记忆操作机制，系统抑制幻觉并提升记忆可靠性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.03506) | [arXiv](https://arxiv.org/abs/2511.03506)



---

### 2. IterResearch：基于马尔可夫状态重构的长视野智能体范式再思考

**原文标题：** IterResearch: Rethinking Long-Horizon Agents via Markovian State
  Reconstruction

**摘要：**
深度研究智能体的最新进展通过对外部资源的动态推理，在自主知识构建方面展现出潜力。然而，现有方法依赖单上下文范式，将所有信息累积在持续扩展的上下文窗口中，导致上下文窒息与噪声污染，限制了其在长视野任务中的效能。我们提出IterResearch——一种创新的迭代式深度研究范式，将长视野研究重新定义为具有策略性工作空间重构的马尔可夫决策过程。通过将动态演进的研究报告作为记忆体并定期整合研究洞见，该方法能在任意探索深度下保持稳定的推理能力。我们进一步开发效率感知策略优化（EAPO），该强化学习框架通过几何奖励折现激励高效探索，并借助自适应降采样实现稳定的分布式训练。大量实验表明，IterResearch在六个基准测试中相较现有开源智能体平均提升14.5个百分点，显著缩小了与前沿私有系统的差距。值得注意的是，该范式展现出前所未有的交互扩展能力，可支持高达2048次交互且性能持续提升（从3.5%至42.5%），同时作为有效的提示策略，在长视野任务中较ReAct将前沿模型性能提升最高达19.2个百分点。这些发现确立了IterResearch作为长视野推理的通用解决方案，既可作为训练完成的智能体，也能作为前沿模型的提示范式。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07327) | [arXiv](https://arxiv.org/abs/2511.07327)



---

### 3. DRIVE：面向竞技性代码生成中可验证奖励强化学习的数据策管最佳实践

**原文标题：** DRIVE: Data Curation Best Practices for Reinforcement Learning with
  Verifiable Reward in Competitive Code Generation

**摘要：**
近期以推理为核心的大模型（如OpenAI o1、DeepSeek R1）推动了对可验证奖励强化学习（RLVR）的新一轮研究热潮。然而当前进展主要集中于数学领域（如AIME），竞技性编程代码生成领域探索不足，且数据策管所受关注远少于强化学习算法设计。本研究系统探讨了RLVR数据集（即强化学习提示）的构建方法，并提出在竞技性编程代码生成中实现卓越性能的实用训练技术。我们的流程始于基于强开源模型蒸馏得到的监督微调（SFT），并辅以通用型与推理密集型数据进行增强。强化学习阶段采用基于可执行测试用例的奖励机制，实施两阶段训练方案：首先使用组相对策略优化（GRPO）在大型均匀分布的竞技编程问题集上进行训练，每个提示生成8个推理轨迹，并设置相对较短的响应生成窗口（SFT阶段32K，本阶段24K），以扩大熵值并缓解重复与截断问题；随后执行预GRPO阶段：在精选的小规模高难度问题集上，采用每个提示64个推理轨迹的大规模采样预算，通过贯穿整个训练周期的硬聚焦课程学习策略持续保留最具挑战性的实例。我们在Qwen2.5-32B模型上实施该方法，并在LeetCode和Codeforces周赛上进行评估以避免数据泄露。最终模型在同等规模模型中达到最先进性能，与DeepSeek v3.1、豆包1.5思考版等领先系统表现相当。通过扩展性趋势分析，我们在内部大规模混合专家模型上观察到显著的强化学习扩展效应。本研究凝练出适用于竞技编程代码生成的RLVR数据策管、熵值扩展与课程设计的简明最佳实践。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06307) | [arXiv](https://arxiv.org/abs/2511.06307)



---

### 4. 《站台：面向人工智能驱动发现的开放世界环境》

**原文标题：** The Station: An Open-World Environment for AI-Driven Discovery

**摘要：**
本文提出“站台”（STATION）——一个模拟微型科研生态系统的开放世界多智能体环境。依托扩展上下文窗口，智能体可在站台中进行长期科研探索，包括研读同行论文、提出假设、提交代码、执行分析及发表成果。值得注意的是，该系统不存在中央协调机制——智能体可自主选择行为并在环境中构建独立研究叙事。实验表明，站台中的AI智能体在从数学到计算生物学乃至机器学习的多类基准测试中均达到最新最优性能，尤其在圆填充问题上显著超越AlphaEvolve。当智能体开展自主研究、进行同行互动并沿袭累积历史时，会涌现出丰富的叙事脉络。这些涌现叙事中自然衍生出创新方法，例如用于单细胞RNA测序批次整合的新型密度自适应算法。站台标志着在开放世界环境中通过涌现行为实现自主科学发现的重要突破，代表了超越刚性优化范式的新型研究范式。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06309) | [arXiv](https://arxiv.org/abs/2511.06309)



---

### 5. MVU-Eval：面向多模态大语言模型的多视频理解评估体系

**原文标题：** MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal
  LLMs

**摘要：**
多模态大语言模型（MLLMs）的出现扩展了人工智能在视觉模态的能力，然而现有评估基准仍局限于单视频理解，忽视了现实场景（如体育赛事分析与自动驾驶）中对多视频理解的关键需求。为填补这一重要空白，我们推出MVU-Eval——首个面向MLLMs的多视频理解综合评估基准。该基准通过1,824个精心构建的问答对（涵盖4,959个跨领域视频），系统评估八大核心能力，既包含基础感知任务，也涉及高阶推理任务。这些能力指标严格对标自动驾驶系统中的多传感器融合、多视角体育分析等实际应用场景。通过对前沿开源与闭源模型的大规模评估，我们揭示了当前MLLMs在处理多视频理解任务时存在的显著性能差距与局限性。本基准将公开发布以促进后续研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07250) | [arXiv](https://arxiv.org/abs/2511.07250)



---

### 6. 路由流形对齐提升混合专家大语言模型的泛化能力

**原文标题：** Routing Manifold Alignment Improves Generalization of Mixture-of-Experts
  LLMs

**摘要：**
稀疏混合专家模型因其能够在保持推理成本不变的前提下有效扩展模型能力，已被广泛应用于当前的大语言模型中。然而，在广泛下游任务上的评估表明，现有混合专家大语言模型中的路由模块普遍存在次优问题，导致其与最优路由方案存在显著性能差距（例如准确率相差10-20%）。本文证明，将路由权重流形与任务嵌入流形进行对齐，可有效缩小该差距并提升混合专家大语言模型的泛化性能。我们提出的"路由流形对齐方法"在训练目标中引入额外的流形正则项，仅需对路由模块进行轻量级微调（其余参数冻结）。具体而言，该正则化促使每个样本的路由权重在任务嵌入空间中趋近于其成功邻域样本（即路由权重能产生正确答案的样本）的权重分布。通过这种方式，面向相似任务的样本在各网络层会形成一致的专家选择模式。在不同样本间建立任务与专家的绑定关系，对提升模型泛化能力至关重要。此外，该方法还展现了将任务理解（通过嵌入模型实现）与解决方案生成（通过混合专家大语言模型实现）相统一的优势。实验中，我们使用该方法对OLMoE、DeepSeekMoE和Qwen3-MoE的路由模块进行微调。在多样化基准测试中的评估结果以及与基线模型的广泛对比表明，该方法带来了显著的性能提升。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07419) | [arXiv](https://arxiv.org/abs/2511.07419)



---

### 7. RedOne 2.0：社交网络服务中领域专用大语言模型后训练机制的重构

**原文标题：** RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social
  Networking Services

**摘要：**
作为人类互动与信息交换的关键媒介，社交网络服务（SNS）对大语言模型（LLM）提出了独特挑战：异构工作负载、快速演变的网络规范与俚语、以及引发显著分布偏移的多语言跨文化语料。监督微调（SFT）虽能实现模型专业化，但往往会引发分布内性能增益与分布外鲁棒性之间的“跷跷板效应”，这一矛盾在轻量化模型中尤为突出。为应对这些挑战，我们提出RedOne 2.0——采用渐进式强化学习优先的后训练范式，专为快速稳定适配SNS场景而设计。该流程包含三个阶段：（1）基于精选SNS语料的探索性学习，建立初始对齐并识别系统性缺陷；（2）针对性微调，对诊断出的能力缺口选择性应用SFT，同时掺入少量通用数据以缓解灾难性遗忘；（3）强化学习阶段，重新应用以SNS为核心信号的强化学习来巩固改进效果并协调多任务间的权衡关系。在涵盖三大类别的多样化任务测试中，我们40亿参数规模的模型相较70亿参数次优基线实现了平均2.41的性能提升。此外，RedOne 2.0相比基模型取得平均8.74的性能增幅，所需训练数据量较以SFT为核心的方法RedOne减少逾半，彰显出在紧凑规模下卓越的数据效率与训练稳定性。总体而言，RedOne 2.0为SNS场景中的领域专用大语言模型建立了具有竞争力的成本效益基准，在保持鲁棒性的同时持续推动能力边界拓展。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07070) | [arXiv](https://arxiv.org/abs/2511.07070)



---

### 8. SofT-GRPO：基于Gumbel重参数化软思考策略优化突破离散令牌大语言模型强化学习

**原文标题：** SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via
  Gumbel-Reparameterized Soft-Thinking Policy Optimization

**摘要：**
大语言模型的软思考推理范式在某些场景下能超越传统的离散令牌思维链推理，彰显其研究与应用价值。然而，尽管离散令牌思维链推理模式可通过群体相对策略优化等算法进行强化，将软思考模式与强化学习相结合仍面临挑战。这一困难源于向软思考令牌注入随机性及相应策略更新的复杂性，导致先前将软思考与GRPO结合的尝试通常表现不及离散令牌GRPO方法。为充分释放软思考潜力，本文提出新型策略优化算法SofT-GRPO，在软思考推理模式下强化大语言模型。该算法将Gumbel噪声注入逻辑值，采用Gumbel-Softmax技术避免软思考令牌超出预训练嵌入空间，并在策略梯度中运用重参数化技巧。我们在1.5B至7B参数的基础大语言模型上进行实验，结果表明：SofT-GRPO使软思考模型在Pass@1指标上略微超越离散令牌GRPO（平均准确率提升0.13%），同时在Pass@32指标上实现显著提升（平均准确率提升2.19%）。代码与权重文件已发布于https://github.com/zz1358m/SofT-GRPO-master。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06411) | [arXiv](https://arxiv.org/abs/2511.06411)



---

### 9. 基于置信度的推理：通过不确定性头部实现大语言模型推理步骤的高效验证

**原文标题：** Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps
  via Uncertainty Heads

**摘要：**
解决复杂任务通常需要大语言模型生成多步骤的长推理链。已有研究表明，对单个推理步骤的正确性进行验证能够进一步提升大语言模型在此类任务中的表现效率，并增强解决方案的可解释性。然而现有验证方法（如过程奖励模型）存在计算成本高昂、适用领域受限或需要大规模人工/模型生成标注等问题。为此，我们提出一种基于数据驱动不确定性评分的轻量级步骤级推理验证方案。通过训练基于Transformer的不确定性量化头部，利用冻结大语言模型的内部状态来估计其生成过程中推理步骤的不确定性。该方法完全自动化：目标标签可由更大规模语言模型（如DeepSeek R1）生成，或由原模型以自监督方式产生。不确定性头部在参数量不足1000万的情况下兼具高效性与轻量化特性。在数学推理、任务规划和常识问答等多个领域，其性能均可媲美甚至超越参数量达810倍的过程奖励模型。我们的研究结果表明，大语言模型的内部状态编码了其不确定性，可作为推理验证的可靠信号，为构建可扩展、可泛化的自省式大语言模型指明了可行方向。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06209) | [arXiv](https://arxiv.org/abs/2511.06209)



---

### 10. 基于物理世界模型的机器人学习

**原文标题：** Robot Learning from a Physical World Model

**摘要：**
本文提出PhysWorld框架，通过物理世界建模实现基于视频生成的机器人学习。当前视频生成模型能够根据语言指令和图像合成逼真的视觉演示，为机器人技术提供了强大却尚未充分开发的训练信号源。然而，直接将从生成视频中提取的像素运动映射到机器人会忽略物理规律，常导致操作失准。PhysWorld通过耦合视频生成与物理世界重建来解决这一局限。给定单张图像和任务指令，本方法既能生成任务条件视频，又能从视频中重建底层物理世界，同时通过基于对象的残差强化学习与物理世界模型相结合，将生成的视频运动转化为物理精确的动作。这种协同作用将隐式视觉指导转化为可物理执行的机器人轨迹，无需真实机器人数据采集即可实现零样本可泛化的机器人操作。在多样化现实任务上的实验表明，与现有方法相比，PhysWorld显著提升了操作精度。详情请访问项目网页：https://pointscoder.github.io/PhysWorld_Web/

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07416) | [arXiv](https://arxiv.org/abs/2511.07416)



---

### 11. 基于改进型循环结构的预训练语言模型深度思维教学方法

**原文标题：** Teaching Pretrained Language Models to Think Deeper with Retrofitted
  Recurrence

**摘要：**
深度循环语言模型的最新进展表明，循环结构能够将训练阶段的计算量与参数量同测试阶段的计算需求解耦。本研究探索如何将现有非循环预训练语言模型转化为深度循环模型。我们发现，通过采用渐进式循环训练课程，在训练过程中逐步增加模型有效深度，可在降低总体计算成本的同时保持模型性能。在数学领域的实验中，相较于直接对原始非循环语言模型进行后训练，将预训练模型转换为循环结构能在相同计算预算下获得更优的性能表现。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07384) | [arXiv](https://arxiv.org/abs/2511.07384)



---

### 12. NURBGen：基于大语言模型驱动的NURBS建模实现高保真文本到CAD生成

**原文标题：** NURBGen: High-Fidelity Text-to-CAD Generation through LLM-Driven NURBS
  Modeling

**摘要：**
从自然语言生成可编辑的3D CAD模型仍面临挑战，现有文本到CAD系统要么生成网格模型，要么依赖稀缺的设计历史数据。我们提出NURBGen——首个通过非均匀有理B样条（NURBS）直接根据文本生成高保真3D CAD模型的框架。为实现这一目标，我们微调大语言模型将自由格式文本转换为包含NURBS曲面参数（即控制点、节点向量、阶次和有理权重）的JSON表示，这些参数可通过Python直接转换为BRep格式。我们进一步提出混合表示法，将未修剪NURBS与解析图元相结合，以更稳健地处理修剪曲面和退化区域，同时降低标记复杂度。此外，我们推出partABC——这是ABC数据集的精选子集，包含独立CAD组件，并通过自动化标注流程添加了详细描述。经专家评估证实，NURBGen在多样化提示词上表现出卓越性能，在几何保真度与尺寸精度方面均超越现有方法。代码与数据集将公开发布。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06194) | [arXiv](https://arxiv.org/abs/2511.06194)



---

### 13. 长链接地思维：规模化提炼组合式视觉推理链条

**原文标题：** Long Grounded Thoughts: Distilling Compositional Visual Reasoning Chains at Scale

**摘要：**
当前多模态推理的进展主要依赖于未公开数据集与专有数据合成方案，这引发了对如何系统构建大规模以视觉为中心的推理数据集的开放性问题，尤其针对超越视觉数学范畴的任务。本研究提出新型推理数据生成框架，涵盖多样化技能与复杂度层级，生成超过100万条高质量合成视觉中心问题。该数据集同时包含偏好数据与指令提示，支持离线和在线强化学习。我们的合成框架分两阶段实施：(1)规模化扩展；(2)复杂度提升。通过融合视觉语言模型与推理大语言模型的两阶段处理流程，生成适用于视觉语言模型的思维链轨迹，捕捉前沿推理模型中丰富的多样化认知行为。值得注意的是，基于我们数据微调的Qwen2.5-VL-7B模型在所有评估的视觉中心基准测试中均超越开源基线模型，甚至在V* Bench、CV-Bench和MMStar-V上优于MiMo-VL-7B-RL等强效闭源模型。最令人惊讶的是，尽管完全以视觉为中心，我们的数据在纯文本推理（MMLU-Pro）和音频推理（MMAU）任务中展现出正向迁移能力。同样，在未包含视频或具身视觉数据的情况下，我们在单证据具身问答基准（NiEH）上观察到显著性能提升。最后，我们利用该数据系统分析了视觉语言模型的后训练流程。实证研究表明：(i)基于非线性推理轨迹的高质量数据监督微调是在线强化学习取得成效的关键；(ii)分阶段离线强化学习可匹配在线强化学习性能，同时降低计算需求；(iii)对高质量数据进行精细监督微调能显著提升跨领域、跨模态的迁移性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.05705) | [arXiv](https://arxiv.org/abs/2511.05705)



---

### 14. RLoop：基于迭代策略初始化的强化学习自改进框架

**原文标题：** RLoop: An Self-Improving Framework for Reinforcement Learning with
  Iterative Policy Initialization

**摘要：**
尽管可验证奖励的强化学习（RLVR）在训练大型推理模型方面具有强大能力，但其训练动态存在一个关键挑战：RL过拟合，即模型获得训练奖励却丧失泛化能力。我们的分析表明，这一现象由策略过度专门化及训练过程中产生的多样化解决方案的灾难性遗忘所驱动。标准优化方法会丢弃这些宝贵的跨步骤策略多样性。为解决此问题，我们提出RLoop——一个基于迭代策略初始化的自改进框架。RLoop将标准训练过程转化为良性循环：首先使用RL从给定策略探索解空间，随后筛选成功轨迹创建专家数据集。通过拒绝采样微调（RFT）利用该数据集优化初始策略，为下一轮迭代创建更优的起点。这种通过迭代重初始化的探索与利用循环，有效将瞬态策略变异转化为稳健的性能提升。实验表明，RLoop能显著缓解遗忘现象并提升泛化能力，相较于原始RL方法，平均准确率提高9%，pass@32指标提升超过15%。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.04285) | [arXiv](https://arxiv.org/abs/2511.04285)



---

### 15. DigiData：通用移动控制智能体的训练与评估框架

**原文标题：** DigiData: Training and Evaluating General-Purpose Mobile Control Agents

**摘要：**
具备用户界面控制能力的AI智能体有望彻底改变人类与数字设备的交互模式。为加速这一变革进程，两大基础要素不可或缺：一是能够支持智能体实现复杂且符合人类需求目标的高质量数据集，二是可供研究者与从业者快速提升智能体性能的稳健评估方法。本文提出DigiData——一个专为移动控制智能体训练设计的大规模、高质量、多模态数据集。与现有基于非结构化交互生成目标的数据集不同，DigiData通过系统性探索应用程序功能进行精心构建，从而具备更丰富的多样性及更高的目标复杂度。同时，我们推出DigiData-Bench基准测试平台，用于评估智能体在真实场景复杂任务中的表现。研究证实当前广泛采用的分步准确率指标难以可靠评估移动控制智能体，为此我们提出动态评估协议与AI驱动的评估方法作为严格的替代方案。本研究的成果将有力推动移动控制智能体发展，为构建更直观高效的人机交互模式奠定基础。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07413) | [arXiv](https://arxiv.org/abs/2511.07413)



---

### 16. MPJudge：音乐诱发绘画的感知评估研究

**原文标题：** MPJudge: Towards Perceptual Assessment of Music-Induced Paintings

**摘要：**
音乐诱发绘画是一种独特的艺术实践形式，指在音乐影响下创作视觉艺术作品。评估画作是否忠实反映其灵感来源的音乐，构成了一项具有挑战性的感知评估任务。现有方法主要依赖情感识别模型来评估音乐与绘画的相似性，但此类模型会引入显著噪声且忽略了情感之外的更广泛感知线索。为克服这些局限，我们提出了一种新颖的音乐诱发绘画评估框架，直接建模音乐与视觉艺术之间的感知连贯性。我们引入了MPD数据集——首个由领域专家基于感知连贯性标注的大规模音乐-绘画配对数据集。为更好处理模糊案例，我们进一步收集了成对偏好标注。基于该数据集，我们提出了MPJudge模型，通过基于调制的融合机制将音乐特征整合到视觉编码器中。为有效学习模糊案例，我们采用直接偏好优化方法进行训练。大量实验表明，我们的方法优于现有方法。定性结果进一步证明，我们的模型能更准确地识别绘画中与音乐相关的区域。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07137) | [arXiv](https://arxiv.org/abs/2511.07137)



---

### 17. Llama-Embed-Nemotron-8B：面向多语言与跨语言任务的通用文本嵌入模型

**原文标题：** Llama-Embed-Nemotron-8B: A Universal Text Embedding Model for
  Multilingual and Cross-Lingual Tasks

**摘要：**
本文推出llama-embed-nemotron-8b——一个开放权重的文本嵌入模型，截至2025年10月21日，该模型在多语言海量文本嵌入基准（MMTEB）排行榜上实现了最先进的性能。尽管现有模型展现出强劲性能，但其训练数据与方法论往往未完全公开。我们通过开发完全开源的模型来解决这一问题，公开其权重参数与详细消融实验，并计划发布精编训练数据集。该模型在所有核心嵌入任务（包括检索、分类与语义文本相似度STS）中均表现卓越，尤其在低资源语言和跨语言设置等具有挑战性的多语言场景中表现突出。这一顶尖性能得益于我们创新的数据组合策略：使用1,610万组查询-文档对，其中770万样本来自公共数据集，840万样本由各类开放权重大语言模型合成生成。我们的核心贡献包括通过系统消融实验分析了关键设计选择：对比损失实现的比较、合成数据生成策略的评估，以及模型融合的影响研究。llama-embed-nemotron-8b作为指令感知模型，支持用户自定义指令以增强特定应用场景的性能。这种顶尖性能、广泛适用性与用户驱动灵活性的结合，使其成为通用文本嵌入解决方案的理想选择。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07025) | [arXiv](https://arxiv.org/abs/2511.07025)



---

### 18. FLEX：基于经验前向学习的智能体持续进化框架

**原文标题：** FLEX: Continuous Agent Evolution via Forward Learning from Experience

**摘要：**
基于大语言模型的自主智能体在推理与问题解决领域实现了革命性突破，但其在训练完成后即保持静态，无法像智能生物那样在部署过程中通过经验积累实现持续成长。本文提出经验前向学习框架（FLEX），该梯度无关的学习范式使大语言模型智能体能够通过积累的经验实现持续进化。具体而言，FLEX通过持续反思与环境交互过程中的成功与失败案例，构建结构化经验库，从而培育可扩展、可传承的进化机制。在数学推理、化学逆合成及蛋白质适应性预测任务中，FLEX分别取得显著提升（AIME25基准提升23%，USPTO50k提升10%，ProteinGym提升14%）。研究进一步揭示了经验增长的显著缩放规律及跨智能体经验传承现象，标志着向可扩展、可传承的持续智能体进化迈出关键一步。项目页面：https://flex-gensi-thuair.github.io。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06449) | [arXiv](https://arxiv.org/abs/2511.06449)



---

### 19. 引领视觉-语言-动作模型未来发展的十大开放挑战

**原文标题：** 10 Open Challenges Steering the Future of Vision-Language-Action Models

**摘要：**
凭借其遵循自然语言指令的能力，视觉-语言-动作模型在具身人工智能领域日益普及，这得益于其前身——大语言模型和视觉语言模型取得的广泛成功。本文系统论述了VLA模型发展过程中的十大关键挑战：多模态融合、推理能力、数据构建、评估体系、跨机器人动作泛化、计算效率、全身协调、安全机制、智能体架构以及人机协作。同时，我们深入探讨了为实现这些突破性进展而涌现的四大技术趋势：空间关系理解、世界动态建模、后训练优化以及数据合成技术。通过以上探讨，我们希望引导研究界关注那些能加速VLA模型获得更广泛适用性的关键研究方向。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.05936) | [arXiv](https://arxiv.org/abs/2511.05936)



---

### 20. Ariadne：一个用于探索与拓展视觉语言模型推理边界的可控框架

**原文标题：** Ariadne: A Controllable Framework for Probing and Extending VLM
  Reasoning Boundaries

**摘要：**
尽管经过强化学习（RL）后训练的视觉语言模型（VLM）展现出卓越的通用推理能力，但其评估通常局限于语言主导型任务（如数学推理）。这引发了一个关键问题：对于基础VLM初始无法解决的视觉中心型空间任务，RL后训练是否能真正扩展其固有能力边界？为探究此问题，我们提出Ariadne框架——通过合成迷宫构建多步骤空间推理任务，其中任务难度（如路径长度、转弯次数）可精确调控。利用该可控环境，我们采用带验证奖励的强化学习（RLVR）在难度感知课程中训练VLM。令人惊讶的是，经过RLVR后训练的VLM在基础模型准确率为0%的问题集上实现了超过50%的准确率，证明我们的方法有效拓展了模型的初始能力边界。为评估实际应用潜力，我们在现实基准测试中进行了分布外（OOD）泛化评估。尽管仅使用合成迷宫样本进行训练，Ariadne在MapBench（如博物馆导航）和ReasonMap（地铁换乘任务）上分别实现了16%和24%的平均零样本性能提升。这些结果证实我们的方法不仅拓宽了模型的基础能力边界，还增强了其在现实空间任务中的泛化能力。需要说明的是，鉴于预训练数据的不透明性，本研究仅聚焦后训练阶段，我们期待此项工作能推动面向专业能力拓展的对齐方法研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.00710) | [arXiv](https://arxiv.org/abs/2511.00710)



---

### 21. DIMO：面向任意物体的多样化三维运动生成方法

**原文标题：** DIMO: Diverse 3D Motion Generation for Arbitrary Objects

**摘要：**
本文提出DIMO生成式方法，能够基于单张图像为任意物体生成多样化的三维运动。本方法的核心思想是利用训练完备的视频模型中蕴含的丰富先验知识，提取通用运动模式并将其嵌入至共享的低维潜空间。具体而言，我们首先生成具有多样化运动的同物体多段视频，随后将每种运动编码为潜向量，并通过训练共享运动解码器来学习以结构化紧凑运动表征（即神经关键点轨迹）所描述的运动分布。这些规范化的三维高斯模型由关键点驱动并进行融合，从而实现对几何形态与外观特征的建模。在基于已学习潜空间的推理阶段，我们可通过单次前向传播实时采样多样化三维运动，并支持三维运动插值与语言引导运动生成等多项创新应用。项目主页详见：https://linzhanm.github.io/dimo。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07409) | [arXiv](https://arxiv.org/abs/2511.07409)



---

### 22. RLVE：基于可验证自适应环境扩展语言模型强化学习规模的方法

**原文标题：** RLVE: Scaling Up Reinforcement Learning for Language Models with
  Adaptive Verifiable Environments

**摘要：**
本文提出基于可验证自适应环境（RLVE）的强化学习方法，通过采用可验证环境程序化生成问题并提供算法可验证奖励的机制，实现了语言模型强化学习规模的扩展。RLVE使每个可验证环境能够根据策略模型在训练过程中的能力表现，动态调整其问题难度分布。相比之下，静态数据分布在问题难度与策略能力不匹配时（过于简单或困难）往往会导致学习信号消失。为实现RLVE，我们开发了RLVE-Gym——一个通过人工环境工程精心构建的包含400个可验证环境的大规模训练套件。使用RLVE-Gym的实验表明，环境扩展（即增加训练环境集合）能持续提升模型的泛化推理能力。在RLVE-Gym全部400个环境中进行联合训练的RLVE方法，从当前最强的15亿参数推理语言模型出发，在六大推理基准测试中实现了3.37%的平均绝对性能提升。相比之下，延续该语言模型原有强化训练方案仅获得0.49%的平均绝对增益，尽管其计算消耗超过RLVE方法的三倍。我们已公开相关代码。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07317) | [arXiv](https://arxiv.org/abs/2511.07317)



---

### 23. 大语言模型具有情感感知能力吗？基于提示工程、检索机制与课程学习的情感识别方法研究

**原文标题：** Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and
  Curriculum Learning

**摘要：**
对话中的情感识别（ERC）是理解人类情感并实现自然人机交互的关键任务。尽管大语言模型（LLMs）近期在该领域展现出巨大潜力，但其捕捉显性情感与隐性情感内在联系的能力仍存在局限。我们提出了一种创新的ERC训练框架PRC-Emo，该框架融合提示工程、示例检索与课程学习三大模块，旨在探究LLMs能否有效感知对话语境中的情感波动。具体而言，我们基于显性与隐性情感线索设计了情感敏感型提示模板，以更精准地引导模型理解说话者的心理状态。我们构建了首个面向ERC的专用示例检索库，其中既包含广泛使用的数据集训练样本，也涵盖由LLMs生成并经人工校验的高质量对话实例。此外，我们将课程学习策略引入LoRA微调过程，通过量化同一说话者与不同说话者话语间的情感转移权重，为对话样本标注难度等级，并依此构建由易到难的训练序列。在IEMOCAP和MELD两个基准数据集上的实验结果表明，本方法取得了最新的最优性能，验证了所提方案在增强基于LLM的情感理解能力方面的有效性与泛化性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07061) | [arXiv](https://arxiv.org/abs/2511.07061)



---

### 24. SWE-fficiency：语言模型能否在真实工作负载下优化现实代码库？

**原文标题：** SWE-fficiency: Can Language Models Optimize Real-World Repositories on
  Real Workloads?

**摘要：**
优化大型软件仓库的性能需要代码推理与软件工程的专业能力，在保证程序正确性的同时降低运行耗时。然而现有基准测试多聚焦于“修复目标”而非“修复方法”。我们提出SWE-fficiency这一面向真实工作负载的仓库级性能优化评估基准，该测试集涵盖numpy、pandas、scipy等九个主流数据科学、机器学习及高性能计算仓库的498项任务：给定完整代码库与低速工作负载，智能体需解析代码语义、定位性能瓶颈及相关测试，并生成在通过相同单元测试的同时达到或超越专家级加速效果的补丁。为实现这种“如何修复”的评估，我们通过自动化流水线从GitHub拉取请求中采集性能优化编辑记录，结合关键词过滤、静态分析、覆盖率工具与执行验证，既确认专家加速基准又识别相关仓库单元测试。对前沿智能体的实证评估显示其表现显著欠佳：平均仅达到专家加速效果的0.15倍。智能体在定位优化机会、跨函数执行推理及保持编辑正确性方面存在明显不足。我们公开此基准测试及相关数据流水线，以推动自动化性能工程与长周期软件推理的研究进展。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06090) | [arXiv](https://arxiv.org/abs/2511.06090)



---

### 25. Diffusion-SDPO：扩散模型的安全直接偏好优化方法

**原文标题：** Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion
  Models

**摘要：**
文本到图像扩散模型虽能生成高质量图像，但其与人类偏好的对齐仍具挑战性。本文重新审视基于扩散的直接偏好优化方法，发现关键缺陷：扩大偏好间隔未必能提升生成质量。具体而言，标准Diffusion-DPO目标函数可能同时增加优胜分支与劣汰分支的重构误差。随着偏好间隔扩大，劣汰输出的退化可能严重到对优胜分支产生负面影响。为此，我们提出Diffusion-SDPO——一种安全更新机制，通过根据劣汰梯度与优胜梯度的对齐程度进行自适应缩放，实现对优胜分支的保护。一阶分析推导出的闭式缩放系数可确保在每步优化中优先输出的误差保持非递增。该方法结构简洁、模型无关，可广泛兼容现有DPO式对齐框架，且仅增加边际计算开销。在标准文本到图像基准测试中，Diffusion-SDPO在自动化偏好评估、美学指标及提示词对齐度量方面均持续优于现有偏好学习基线。代码已公开于：https://github.com/AIDC-AI/Diffusion-SDPO。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.03317) | [arXiv](https://arxiv.org/abs/2511.03317)



---

### 26. 千词成图：基于结构化描述的文本到图像生成增强方法

**原文标题：** Generating an Image From 1,000 Words: Enhancing Text-to-Image With
  Structured Captions

**摘要：**
文本到图像模型已从随意的创意工具迅速发展为专业级系统，实现了前所未有的图像质量与真实感。然而，大多数模型被训练用于将简短提示映射为细节图像，导致稀疏文本输入与丰富视觉输出之间产生落差。这种不匹配降低了可控性——模型往往随意补全缺失细节，偏向普通用户偏好，限制了专业应用的精确度。为解决这一局限，我们首次基于结构化长描述训练开源文本到图像模型，每个训练样本均标注有相同组的细粒度属性。该设计最大化表达覆盖度，并实现对视觉要素的解耦控制。为高效处理长描述，我们提出DimFusion融合机制，通过集成轻量级大语言模型的中间标记而不增加标记长度。同时提出文本瓶颈重建评估协议：通过评估真实图像在描述-生成循环中的重建质量，该协议可直接衡量可控性与表达力，即使在现有评估方法失效的超长描述场景下仍适用。最终，我们通过训练大规模模型FIBO验证贡献，在开源模型中实现了最先进的提示对齐效果。模型权重已公开于https://huggingface.co/briaai/FIBO

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06876) | [arXiv](https://arxiv.org/abs/2511.06876)



---

### 27. VADER：基于关系感知大语言模型的因果视频异常理解框架

**原文标题：** VADER: Towards Causal Video Anomaly Understanding with Relation-Aware
  Large Language Models

**摘要：**
视频异常理解旨在对视频中的异常事件提供详细阐释与语义解析，突破传统方法仅关注异常检测与定位的局限性。然而现有研究往往忽略物体间深层的因果关系与交互作用，而这些要素对于理解异常行为至关重要。本文提出VADER——一种基于大语言模型的视频异常理解框架，通过融合关键帧物体关系特征与视觉线索来增强视频异常认知。具体而言，VADER首先运用异常评分器计算逐帧异常分值，继而采用上下文感知采样策略捕捉异常事件的因果语境。通过关系特征提取器与对比关系编码器的协同作用，系统建模动态物体交互并生成紧凑的关系表征以供下游推理。这些视觉与关系线索与大语言模型集成后，可生成具有因果依据的详细描述，并支持稳健的异常相关问答。在多个真实场景视频异常理解基准测试上的实验表明，VADER在异常描述、解释与因果推理任务中均取得优异结果，推动了可解释视频异常分析研究的前沿发展。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07299) | [arXiv](https://arxiv.org/abs/2511.07299)



---

### 28. Omni-AVSR：基于大语言模型的统一多模态语音识别研究

**原文标题：** Omni-AVSR: Towards Unified Multimodal Speech Recognition with Large
  Language Models

**摘要：**
大语言模型近期在多模态语音识别领域取得显著进展，涵盖听觉语音识别、视觉语音识别与视听语音识别。然而现有基于大语言模型的方法通常独立处理各项任务，需训练独立模型导致计算与部署资源消耗增加，且未能充分利用跨任务协同潜力。这些方法还依赖固定速率的分词压缩机制，限制了精度与效率平衡的灵活性。这些局限性凸显了构建统一框架的必要性——既能支持多模态语音识别任务，又可实现弹性推理。为此，我们提出Omni-AVSR这一统一视听大语言模型，融合高效多粒度训练与参数有效性适配机制。具体而言，我们采用套娃表示学习范式实现多粒度视听数据的高效训练，显著降低固有训练资源消耗。此外，我们探索三种基于LoRA的主干网络适配策略，在共享性与任务特异性之间实现优化平衡。在LRS2和LRS3数据集上的实验表明，Omni-AVSR仅需训练单一模型即可达到与最先进基线模型相当或更优的准确率，同时大幅降低训练与部署资源消耗。该模型在噪声环境下保持稳健性能，我们通过分析模型规模扩展规律，为性能与效率的权衡关系提供了重要见解。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07253) | [arXiv](https://arxiv.org/abs/2511.07253)



---

### 29. LUT-LLM：基于FPGA内存计算的高效大语言模型推理框架

**原文标题：** LUT-LLM: Efficient Large Language Model Inference with Memory-based
  Computations on FPGAs

**摘要：**
大语言模型的快速发展推动了众多应用场景的进步，然而高效的单批次推理对于设备端智能仍然至关重要。尽管FPGA具有细粒度数据控制和高能效的特性，但近期GPU优化已缩小了其优势，尤其在基于算术运算的场景下。为突破此限制，我们利用FPGA丰富的片上存储资源，通过查表操作将LLM推理从算术计算转向内存计算。本文提出LUT-LLM——首个通过向量化内存操作实现十亿参数级LLM推理的FPGA加速器。我们的分析表明激活-权重协同量化是最有效的方案，其技术支撑包括：（1）带宽感知并行质心搜索算法；（2）高效的二维查表机制；（3）最小化数据缓存的时空混合架构。在AMD V80 FPGA平台对定制化Qwen 3 1.7B模型的实测表明，LUT-LLM相较AMD MI210实现延迟降低1.66倍，相比NVIDIA A100能效提升1.72倍，并可扩展至320亿参数模型，相较A100持续保持2.16倍的能效优势。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.06174) | [arXiv](https://arxiv.org/abs/2511.06174)



---

### 30. 强化学习提升大语言模型对层次化知识的遍历能力

**原文标题：** Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs

**摘要：**
传统观点认为强化学习（RL）虽能提升语言模型的推理与泛化能力，却会损害其记忆知识。我们通过实验发现，在纯粹的知识召回任务（尤其是需要遍历层次化结构知识的任务，如医学代码查询）中，经RL增强的模型持续优于基础模型及监督微调（SFT）模型，从而对这一观点提出挑战。我们推测这些增益并非源于新获取的数据，而是来自模型在参数空间内导航和搜索既有知识层次结构的程序性技能提升。为验证该假设，我们证明采用结构化提示（显式引导SFT模型进行层次遍历）可弥补大部分性能差距（在MedConceptsQA任务中将DeepSeek-V3/R1的差距从24个百分点缩减至7个百分点）。进一步研究发现，虽然提示策略能提升最终答案准确率，但RL增强模型在深度检索任务中仍保持更优的正确程序路径召回能力。最后，通过分层内部激活分析发现：尽管事实表征（如“代码57.95指代尿路感染”的激活模式）在SFT与RL模型间保持较高余弦相似度，但查询表征（如“代码57.95的含义”）却呈现显著分化，这表明RL主要改变了模型遍历知识的方式，而非知识表征本身。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.05933) | [arXiv](https://arxiv.org/abs/2511.05933)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2025-11-11_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)