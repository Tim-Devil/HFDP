
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-20 论文日报

## 📊 今日论文统计
- 总论文数：11
- 热门领域：LLM, RL, Vision, GPT

## 📝 论文详情


### 1. ABC-Bench：面向现实世界开发的智能体后端编码基准测试

**原文标题：** ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development

**摘要：**
大型语言模型（LLM）向自主智能体的演进，已将人工智能编码的范围从局部代码生成扩展至复杂、仓库级别及执行驱动的问题解决。然而，现有基准测试主要评估静态环境下的代码逻辑，忽视了现实工程中动态、全流程的需求，尤其是在需要严格环境配置与服务部署的后端开发领域。为填补这一空白，我们提出了ABC-Bench——一个专门设计用于在真实可执行工作流中评估智能体后端编码能力的基准测试。通过可扩展的自动化流程，我们从开源仓库中筛选出涵盖8种编程语言和19种框架的224项实际任务。与以往评估不同，ABC-Bench要求智能体管理从仓库探索到实例化容器化服务的完整开发生命周期，并通过外部端到端API测试。我们的大规模评估表明，即使是当前最先进的模型在这些整体性任务中也难以提供可靠性能，这凸显出现有模型能力与实际后端工程需求之间的显著差距。相关代码已开源：https://github.com/OpenMOSS/ABC-Bench。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11077) | [arXiv](https://arxiv.org/abs/2601.11077)



---

### 2. 多路思维：基于词元级分支与合并的推理方法

**原文标题：** Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge

**摘要：**
大语言模型通常通过思维链（CoT）策略更有效地解决复杂推理任务，但代价是生成长而低信息密度的词元序列。相比之下，人类常采用柔性推理方式，在每一步保持对多种可能后续步骤的概率分布。受此启发，我们提出多路思维机制——一种随机柔性推理方法，在每个思维步骤中采样K个候选词元，并将其嵌入向量聚合为单个连续的多路词元。该方法既保留了词汇嵌入先验和标准离散生成的采样动态特性，又能在多路扩展路径上形成可处理的概率分布。因此，多路轨迹可直接通过同策略强化学习进行优化。值得注意的是，多路思维具有自适应性：当模型置信度高时，多路词元近似离散化，其行为类似标准思维链；当模型不确定时，它能紧凑表征多个合理后续步骤，且不增加序列长度。在多项高难度数学推理基准测试中，从Pass@1到Pass@1024的评估范围内，多路思维机制始终优于强离散思维链及强化学习基线方法，同时生成更短的序列。代码与模型检查点已发布于https://github.com/GMLR-Penn/Multiplex-Thinking。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.08808) | [arXiv](https://arxiv.org/abs/2601.08808)



---

### 3. NAACL：面向RAG系统中大语言模型的噪声感知言语置信度校准

**原文标题：** NAACL: Noise-AwAre Verbal Confidence Calibration for LLMs in RAG Systems

**摘要：**
在关键事实领域部署大语言模型时，准确评估模型置信度至关重要。尽管检索增强生成技术被广泛采用以提升事实依据性，但RAG场景下的置信度校准机制仍未得到充分理解。本研究通过四个基准测试进行系统性分析，发现大语言模型因检索上下文噪声而表现出较差的校准性能。具体而言，矛盾或无关的证据往往会放大模型的错误确定性，导致严重的过度自信问题。为此，我们提出NAACL规则（噪声感知置信度校准规则），为噪声环境下的过度自信问题提供理论解决基础。进一步设计出NAACL噪声感知校准框架，该框架依据校准规则从约2000个HotpotQA示例中合成监督信号。通过基于该数据的监督微调，NAACL使模型具备内在的噪声感知能力，且无需依赖更强的教师模型。实验结果表明，NAACL带来显著提升：领域内ECE分数改善10.9%，跨领域改善8.0%。通过弥合检索噪声与言语校准之间的鸿沟，NAACL为构建既精确又具备认知可靠性的大语言模型开辟了新路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11004) | [arXiv](https://arxiv.org/abs/2601.11004)



---

### 4. Medical SAM3：一种用于通用提示驱动医学图像分割的基础模型

**原文标题：** Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation

**摘要：**
以SAM3为代表的可提示分割基础模型通过交互式和基于概念的提示机制展现出强大的泛化能力。然而，其在医学图像分割中的直接应用仍受限于严重的领域偏移、缺乏特权空间提示，以及需要理解复杂的解剖结构和三维体积信息。本文提出Medical SAM3，这是一种用于通用提示驱动医学图像分割的基础模型，通过对SAM3在大规模、异构的二维和三维医学影像数据集（包含配准的分割掩码和文本提示）上进行全面微调而获得。通过对原始SAM3的系统分析，我们观察到其在医学数据上的性能显著下降，其表面竞争力主要依赖于强几何先验（如基于真实标注的边界框）。这些发现促使我们超越单纯的提示工程，进行完整的模型适配。通过在涵盖10种医学影像模态的33个数据集上微调SAM3的模型参数，Medical SAM3获得了鲁棒的领域特定表征，同时保持了提示驱动的灵活性。跨器官、影像模态和维度的广泛实验表明，该模型取得了持续且显著的性能提升，尤其在具有语义模糊性、复杂形态和长程三维上下文特征的挑战性场景中表现突出。我们的研究结果确立了Medical SAM3作为医学影像领域通用、文本引导的分割基础模型，并强调了在严重领域偏移下实现鲁棒提示驱动分割时整体模型适配的重要性。代码和模型将在https://github.com/AIM-Research-Lab/Medical-SAM3 公开。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.10880) | [arXiv](https://arxiv.org/abs/2601.10880)



---

### 5. CoDance：一种用于鲁棒多主体动画的解绑-重绑范式

**原文标题：** CoDance: An Unbind-Rebind Paradigm for Robust Multi-Subject Animation

**摘要：**
受对鲁棒且灵活的多主体渲染需求的推动，角色图像动画在多个领域正变得日益重要。现有方法虽然在单人动画方面表现出色，但在处理任意数量的主体、多样的角色类型以及参考图像与驱动姿态之间的空间错位方面存在困难。我们将这些局限性归因于过于僵化的空间绑定，它强制要求姿态与参考图像之间严格的像素级对齐，以及无法将运动一致地重绑定到目标主体上。为应对这些挑战，我们提出了CoDance，一种新颖的解绑-重绑框架，能够在单一且可能存在错位的姿态序列条件下，对任意数量、类型及空间配置的主体进行动画生成。具体而言，解绑模块采用一种新颖的姿态偏移编码器，通过对姿态及其潜在特征引入随机扰动，打破姿态与参考图像之间僵化的空间绑定，从而迫使模型学习一种与位置无关的运动表示。为确保精确控制和主体关联，我们随后设计了重绑模块，利用文本提示的语义引导和主体掩码的空间引导，将学习到的运动定向到目标角色。此外，为促进全面评估，我们引入了一个新的多主体评测基准CoDanceBench。在CoDanceBench及现有数据集上进行的大量实验表明，CoDance实现了最先进的性能，并在不同主体和空间布局上展现出卓越的泛化能力。代码与权重将予以开源。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11096) | [arXiv](https://arxiv.org/abs/2601.11096)



---

### 6. 助手轴：定位与稳定语言模型的默认角色

**原文标题：** The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models

**摘要：**
大型语言模型能够呈现多种角色特征，但其通常默认表现为经过后期训练形成的“助手”身份。本研究通过提取与不同角色原型相对应的激活方向，探究了模型角色空间的结构。在多个不同模型中发现，该角色空间的主导成分是一个“助手轴”，它捕捉了模型在其默认助手模式下运行的程度。向助手方向引导会强化模型有益且无害的行为；而偏离该方向则会增强模型认同其他实体的倾向。此外，采用更极端的偏离值通常会诱发一种神秘而戏剧化的表达风格。研究发现该轴同样存在于预训练模型中，其主要促进顾问、教练等有益的人类角色原型，同时抑制精神性角色原型。沿助手轴测量偏离度可预测“角色漂移”现象——即模型偏离其典型角色特征，表现出有害或异常行为。研究发现角色漂移通常由两种对话情境驱动：要求模型对其运行过程进行元反思的对话，以及涉及情感脆弱用户的对话。实验表明，将激活值限制在助手轴的固定区域内，能够在此类场景中稳定模型行为，并能有效抵御基于角色对抗的越狱攻击。研究结果表明，后期训练虽将模型导向角色空间的特定区域，但仅以松散方式将其约束于此，这启示我们需要通过训练与引导策略的改进，使模型更深度地锚定于连贯的角色身份。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.10387) | [arXiv](https://arxiv.org/abs/2601.10387)



---

### 7. 虚假奖励悖论：从机制上理解RLVR如何激活大语言模型中的记忆捷径

**原文标题：** Spurious Rewards Paradox: Mechanistically Understanding How RLVR Activates Memorization Shortcuts in LLMs

**摘要：**
带可验证奖励的强化学习（RLVR）对于提升大语言模型的推理能力极为有效，然而近期证据表明，即使使用虚假或错误的奖励，Qwen 2.5等模型仍能取得显著性能提升。我们研究了这一现象，并识别出一个“困惑度悖论”：虚假的RLVR会引发一种分化，即答案标记的困惑度下降，而提示侧的连贯性却随之退化，这表明模型正在绕过推理过程，转而依赖记忆。通过使用路径修补、Logit透镜、JSD分析和神经微分方程等方法，我们揭示了一个促成此捷径的隐藏锚点-适配器电路。我们定位了位于中间层（L18-20）的一个功能锚点，它触发对记忆解决方案的检索；随后，位于更深层（L21+）的结构适配器会转换表征以适应该捷径信号。最后，我们证明，通过在该电路中缩放特定的MLP键，可以实现双向因果调控——人为地放大或抑制由数据污染驱动的性能表现。我们的研究结果为识别和缓解RLVR调优模型中的数据污染问题提供了一份机制性路线图。代码发布于 https://github.com/idwts/How-RLVR-Activates-Memorization-Shortcuts。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11061) | [arXiv](https://arxiv.org/abs/2601.11061)



---

### 8. YaPO：面向领域自适应的可学习稀疏激活导向向量

**原文标题：** YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation

**摘要：**
通过激活干预引导大语言模型已成为一种轻量化的对齐与个性化替代方案，无需进行微调。近期双向偏好优化研究证明，可通过直接偏好优化的方式从偏好数据中直接学习密集导向向量，从而实现对真实性、幻觉及安全行为的控制。然而，由于神经元的多语义特性，密集导向向量常会纠缠多个潜在因素，这限制了其在细粒度场景（如文化对齐）中的有效性与稳定性——此类场景需区分高度相关的价值观与行为（例如中东文化间的差异）。本文提出另一种策略优化方法，该方法无需参考模型，通过在稀疏自编码器的隐空间中学习稀疏导向向量。通过优化稀疏编码，YaPO能够生成解耦、可解释且高效的引导方向。实验表明，与密集导向基线方法相比，YaPO具有更快的收敛速度、更强的性能表现以及更优的训练稳定性。除文化对齐外，YaPO可泛化至一系列对齐相关行为，包括幻觉控制、财富追求、越狱防御及权力追求。值得注意的是，YaPO能够保持模型的通用知识能力，在MMLU基准测试中未出现可观测的性能下降。总体而言，我们的研究结果表明，YaPO为大语言模型的高效、稳定、细粒度对齐提供了通用方案，在可控性与领域自适应方面具有广泛的应用前景。相关代码与数据已公开于https://github.com/MBZUAI-Paris/YaPO。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.08441) | [arXiv](https://arxiv.org/abs/2601.08441)



---

### 9. PubMed-OCR：基于PubMed Central开放获取PDF的OCR标注数据集

**原文标题：** PubMed-OCR: PMC Open Access OCR Annotations

**摘要：**
PubMed-OCR是一个以光学字符识别（OCR）为核心的科学文献数据集，其内容源自PubMed Central开放获取的PDF文档。每页文献图像均通过Google Cloud Vision进行标注，并以紧凑的JSON格式发布，其中包含单词、行和段落级别的边界框坐标。该数据集涵盖20.95万篇文献（合计150万页，约13亿单词），支持布局感知建模、坐标定位问答以及依赖OCR的技术流程评估。本文分析了数据集的特性（如期刊覆盖范围与检测到的版面特征），并讨论了其局限性，包括对单一OCR引擎的依赖以及启发式行重建方法的不足。我们公开数据集与标注架构，以促进下游研究，并欢迎后续扩展工作。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11425) | [arXiv](https://arxiv.org/abs/2601.11425)



---

### 10. SIN-Bench：长上下文多模态科学交叉文献中的原生证据链追踪

**原文标题：** SIN-Bench: Tracing Native Evidence Chains in Long-Context Multimodal Scientific Interleaved Literature

**摘要：**
评估多模态大语言模型是否真正理解长篇科学论文仍具挑战性：仅依赖答案匹配的指标和合成的“大海捞针”测试往往奖励答案匹配，却未要求模型在文档中建立因果关联、证据可追溯的推理链条。我们提出“海洋寻鱼”范式，要求模型在原生科学文档中构建显式的跨模态证据链。为实现该范式，我们构建了SIN-Data——一个保留文本与图表原生交叉结构的科学交叉语料库。在此基础上，我们设计了SIN-Bench，包含四个渐进式任务：证据发现（SIN-Find）、假设验证（SIN-Verify）、基于证据的问答（SIN-QA）以及证据锚定式摘要生成（SIN-Summary）。我们进一步引入“无证据则不计分”原则，仅对基于可验证锚点的预测进行评分，并通过匹配度、相关性和逻辑性三个维度诊断证据质量。在八个多模态大语言模型上的实验表明，证据锚定是当前主要瓶颈：Gemini-3-pro取得了最佳平均综合得分（0.573），而GPT-5在SIN-QA答案准确率上最高（0.767），但在证据对齐的综合得分上表现欠佳，这揭示了答案正确性与可追溯证据支持之间的差距。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.10108) | [arXiv](https://arxiv.org/abs/2601.10108)



---

### 11. CLARE：通过自主适配器路由与扩展实现视觉-语言-动作模型的持续学习

**原文标题：** CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion

**摘要：**
为教导机器人完成复杂操作任务，当前普遍采用基于任务特定数据对预训练的视觉-语言-动作模型进行微调的方法。然而，由于该方案会更新现有表征，难以适用于机器人在现实世界中的长期运行场景——机器人必须在持续适应新任务与环境的同时，保持已习得的知识。现有机器人持续学习方法通常需要存储历史数据（样本示例），难以处理长任务序列，或依赖任务标识进行部署。为突破这些局限，我们提出CLARE：一种通用、参数高效的视觉-语言-动作模型无示例持续学习框架。CLARE通过在选定前馈层中引入轻量化模块化适配器，并依据层级特征相似性指导，仅在学习新任务时对必要模块进行自主扩展。在部署阶段，基于自编码器的路由机制无需任务标签即可动态激活最相关的适配器。通过在LIBERO基准测试中的大量实验，我们证明CLARE能在实现新任务高性能的同时避免对先前任务的灾难性遗忘，其表现显著优于基于样本示例的方法。代码与数据详见：https://tum-lsy.github.io/clare。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.09512) | [arXiv](https://arxiv.org/abs/2601.09512)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2026-01-20_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)