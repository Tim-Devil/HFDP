<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hugging Face 论文日报 - 2026-01-19</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
            padding: 20px;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 30px;
            font-size: 28px;
        }
        
        h1 img {
            vertical-align: middle;
            margin-right: 10px;
        }
        
        h2 {
            color: #34495e;
            margin-top: 40px;
            margin-bottom: 20px;
            font-size: 24px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }
        
        h3 {
            color: #2c3e50;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 20px;
        }
        
        p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        ul {
            margin-left: 20px;
            margin-bottom: 20px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        a {
            color: #3498db;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        strong {
            color: #2c3e50;
            font-weight: 600;
        }
        
        hr {
            border: none;
            border-top: 1px solid #e0e0e0;
            margin: 30px 0;
        }
        
        /* 关键修复:限制图片宽度 */
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        /* 确保图片容器也有宽度限制 */
        p img {
            max-width: 100%;
        }
        
        /* 论文详情区域样式 */
        .paper-section {
            background-color: #f9f9f9;
            padding: 20px;
            border-radius: 6px;
            margin-bottom: 20px;
        }
        
        /* 统计信息样式 */
        .stats {
            background-color: #e8f4f8;
            padding: 15px;
            border-radius: 6px;
            margin-bottom: 20px;
        }
        
        /* 响应式设计 */
        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 24px;
            }
            
            h2 {
                font-size: 20px;
            }
            
            h3 {
                font-size: 18px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1><img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-19 论文日报</h1>
<h2>📊 今日论文统计</h2>
<ul>
<li>总论文数：22</li>
<li>热门领域：RL, LLM, GPT, Transformer, NLP</li>
</ul>
<h2>📝 论文详情</h2>
<h3>1. 群体相对优势估计存在偏差</h3>
<p><strong>原文标题：</strong> Your Group-Relative Advantage Is Biased</p>
<p><strong>摘要：</strong>
基于验证器奖励的强化学习已成为推理任务中大语言模型后训练的主流方法，其中以GRPO及其变体为代表的群体方法得到广泛应用。这类方法依赖群体相对优势估计以避免学习评价函数，但其理论性质尚未得到充分研究。本文揭示了群体强化学习的一个根本问题：群体相对优势估计量相对于真实期望优势存在固有偏差。我们首次通过理论分析证明，该方法会系统性地低估困难提示的优势值，同时高估简单提示的优势值，导致探索与利用的失衡。为解决此问题，我们提出历史感知自适应难度加权方法——一种基于动态难度锚点与训练过程的自适应重加权方案，可调整优势估计值。在五个数学推理基准测试中的理论分析与实验结果表明，该方法融入GRPO及其变体后能持续提升模型性能。研究结果证实，修正偏差化的优势估计对实现稳健高效的RLVR训练具有关键意义。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.08521">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.08521">arXiv</a></p>
<hr />
<h3>2. 毒苹果效应：通过AI智能体技术扩展对中介市场的策略性操纵</h3>
<p><strong>原文标题：</strong> The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents</p>
<p><strong>摘要：</strong>
AI智能体融入经济市场从根本上改变了策略互动的格局。本文通过三个经典博弈论场景——议价（资源分配）、谈判（非对称信息交易）与劝说（策略性信息传递），系统研究了可用技术集扩展的经济影响。研究发现，单纯增加AI代理人的可选类型即可显著改变均衡收益与监管结果，这往往激励监管机构主动开发并发布新技术。相反，我们揭示了一种被称为“毒苹果”效应的策略现象：行为主体可能发布一项新技术（其自身与对手最终皆不采用），其唯一目的是操纵监管机构的市场设计选择以利己。这种策略性发布行为以牺牲对手方利益与监管公平目标为代价，提升了发布者的福利水平。本研究证明，静态监管框架易受技术扩展的操纵，亟需构建能够适应AI能力动态演进的市场设计机制。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.11496">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.11496">arXiv</a></p>
<hr />
<h3>3. 解锁隐性经验：从文本合成工具使用轨迹</h3>
<p><strong>原文标题：</strong> Unlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text</p>
<p><strong>摘要：</strong>
使大型语言模型（LLM）在多轮交互中有效利用工具，对于构建具备能力的自主智能体至关重要。然而，获取多样化且真实的多轮工具使用数据仍是一项重大挑战。本研究提出一种新颖的文本驱动范式。我们发现文本语料库天然包含丰富的多步骤问题解决经验，可作为多轮工具使用任务中尚未开发、可扩展且真实的数据源。基于此洞见，我们提出GEM——一种通过四阶段流程（相关性筛选、工作流与工具提取、轨迹锚定、复杂度优化）从文本语料库生成和提取多轮工具使用轨迹的数据合成框架。为降低计算成本，我们进一步通过监督微调训练了专用的轨迹合成模型，将复杂的生成流程蒸馏为高效的端到端轨迹生成器。实验表明，我们的GEM-32B模型在BFCL V3多轮基准测试中实现了16.5%的性能提升。该模型在部分领域（航空与零售）数据上超越了基于τ-bench领域内数据训练的模型性能，凸显了文本合成范式带来的卓越泛化能力。值得注意的是，我们的轨迹合成器在保持全流程生成质量的同时，显著降低了推理延迟与计算成本。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.10355">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.10355">arXiv</a></p>
<hr />
<h3>4. RubricHub：基于自动化由粗到细生成框架构建的全面且高区分度评估准则数据集</h3>
<p><strong>原文标题：</strong> RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation</p>
<p><strong>摘要：</strong>
可验证奖励强化学习（RLVR）在数学等推理密集型领域已取得显著进展。然而，由于缺乏真实基准，开放生成任务的优化仍面临挑战。基于评估准则的验证虽能提供结构化代理方案，但现有方法受限于可扩展性瓶颈与粗糙的评价标准，导致监督效果存在天花板效应。为此，我们提出一种自动化“由粗到细”的评估准则生成框架。该方法融合原则引导合成、多模型聚合与难度演进机制，能够生成全面且具有高区分度的评估标准，精准捕捉生成内容的细微差异。基于此框架，我们构建了RubricHub数据集——一个涵盖多领域的大规模数据集（约11万条）。我们通过包含基于准则的拒绝采样微调（RuFT）与强化学习（RuRL）的两阶段后训练流程验证其实用性。实验结果表明，RubricHub能显著提升模型性能：经过后训练的Qwen3-14B模型在HealthBench基准测试中达到69.3分，超越GPT-5等前沿闭源模型，取得当前最优性能。代码与数据即将开源发布。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.08430">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.08430">arXiv</a></p>
<hr />
<h3>5. 当个性化产生误导：理解并缓解个性化大语言模型中的幻觉现象</h3>
<p><strong>原文标题：</strong> When Personalization Misleads: Understanding and Mitigating Hallucinations in Personalized LLMs</p>
<p><strong>摘要：</strong>
个性化大语言模型通过适应用户个体特征以提升用户满意度，但个性化过程可能无意中扭曲事实推理。本文指出，当个性化大语言模型面对事实性查询时，会出现一种现象：模型倾向于生成符合用户历史偏好的答案，而非客观事实，从而导致由个性化引发的幻觉。这种幻觉会降低事实可靠性，并可能传播错误信念，其根源在于个性化表征与事实表征在模型内部的纠缠。为解决该问题，我们提出了一种轻量级的推理时方法——事实保持个性化导向，该方法能在保持个性化行为的同时，有效缓解由个性化引发的事实扭曲。此外，我们构建了首个面向个性化场景下事实性与个性化问答联合评估的基准测试集。在多种大语言模型架构与个性化方法上的实验表明，事实保持个性化导向方法能显著提升事实准确性，同时保持个性化性能。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.11000">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.11000">arXiv</a></p>
<hr />
<h3>6. ACoT-VLA：面向视觉-语言-动作模型的动作思维链</h3>
<p><strong>原文标题：</strong> ACoT-VLA: Action Chain-of-Thought for Vision-Language-Action Models</p>
<p><strong>摘要：</strong>
视觉-语言-动作模型已成为多样化操作任务中重要的通用机器人策略，传统上依赖通过视觉-语言模型嵌入将多模态输入直接转换为动作。近期研究引入了显式中间推理（如子任务预测的语言推理或目标图像合成的视觉推理）来指导动作生成。然而，这些中间推理往往具有间接性，且本质上难以传递精确动作执行所需的完整细粒度信息。我们认为，最有效的推理形式应直接在动作空间中进行推演。本文提出动作思维链范式，将推理过程构建为引导最终策略的粗粒度动作意图结构化序列。我们提出ACoT-VLA这一实现该范式的新型架构，具体引入两个互补组件：显式动作推理器和隐式动作推理器。前者通过粗粒度参考轨迹提供显式动作级推理步骤，后者从多模态输入的内部表征中提取潜在动作先验，共同构成动作思维链以约束下游动作头，实现具身化的策略学习。在真实环境与仿真环境中的大量实验表明，所提方法在LIBERO、LIBERO-Plus和VLABench基准上分别达到98.5%、84.1%和47.4%的性能表现，验证了其优越性。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.11404">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.11404">arXiv</a></p>
<hr />
<h3>7. BAPO：面向可靠智能搜索的边界感知策略优化</h3>
<p><strong>原文标题：</strong> BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search</p>
<p><strong>摘要：</strong>
基于强化学习的智能搜索使大语言模型能够通过动态规划和外部搜索解决复杂问题。尽管该方法通过大规模强化学习优化智能体策略显著提升了准确性，但我们发现其可靠性存在关键缺陷：这些智能体无法识别其推理边界，即使在证据不足或推理达到极限时也极少承认“我不知道”（IDK）。可靠性的缺失常导致看似合理但不可靠的答案，在许多实际应用场景中带来显著风险。为此，我们提出边界感知策略优化（BAPO），这是一种新颖的强化学习框架，旨在培养可靠的边界感知能力，同时不损害准确性。BAPO包含两个核心组件：（1）基于分组的边界感知奖励机制，仅在推理达到极限时鼓励模型给出IDK响应；（2）自适应奖励调节器，在早期探索阶段策略性地暂停该奖励，防止模型将IDK作为捷径进行利用。在四个基准测试上的大量实验表明，BAPO显著提升了智能搜索的整体可靠性。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.11037">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.11037">arXiv</a></p>
<hr />
<h3>8. FrankenMotion：基于部件的人体运动生成与组合</h3>
<p><strong>原文标题：</strong> FrankenMotion: Part-level Human Motion Generation and Composition</p>
<p><strong>摘要：</strong>
近年来，基于文本提示的人体运动生成取得了显著进展。然而，由于缺乏细粒度的部件级运动标注，现有方法主要依赖于序列级或动作级描述，这限制了对个体身体部位的可控性。本研究利用大语言模型的推理能力，构建了一个具有原子化、时序感知的部件级文本标注的高质量运动数据集。与以往仅提供固定时间段同步部件描述或仅依赖全局序列标签的数据集不同，我们的数据集以精细的时间分辨率捕捉了异步且语义独立的部件运动。基于此数据集，我们提出了一种基于扩散的部件感知运动生成框架，即FrankenMotion，其中每个身体部位由其自身具有时序结构的文本提示引导。据我们所知，这是首个提供原子化、时序感知的部件级运动标注，并实现空间（身体部位）与时间（原子动作）双重控制运动生成的研究。实验表明，FrankenMotion在适配并重训练于本设定下的所有基线模型中表现优异，且能够组合训练中未见的运动模式。我们的代码与数据集将在论文发表后公开。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.10909">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.10909">arXiv</a></p>
<hr />
<h3>9. 熵哨兵：基于解码熵迹对STEM领域大语言模型准确性的持续监控</h3>
<p><strong>原文标题：</strong> Entropy Sentinel: Continuous LLM Accuracy Monitoring from Decoding Entropy Traces in STEM</p>
<p><strong>摘要：</strong>
部署大语言模型面临两个相互关联的挑战：(1) 监控——在流量和领域发生漂移时评估模型在哪些方面表现不佳；(2) 改进——优先获取数据以弥补最大的性能差距。本研究检验了在领域偏移下，能否通过推理阶段的信号来估计分片层面的准确性。针对每个模型响应，我们基于最终层的下一个词元概率（来自top-k对数概率）计算输出熵分布曲线，并用十一个统计量进行概括。通过一个轻量级分类器预测单个实例的正确性，再对预测概率进行平均即可得到领域层面的准确性估计。我们在十个STEM推理基准测试上进行了评估，采用详尽的训练/测试组合（k取{1,2,3,4}；所有“10选k”组合），并覆盖六个系列的九种大语言模型（参数量3B-20B）。实验结果表明，该估计方法能够有效跟踪基准测试的保留准确率，多个模型在不同领域间呈现出近乎单调的排序关系。因此，输出熵分布曲线为可扩展的模型监控和数据采集目标确定提供了一个易于获取的有效信号。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.09001">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.09001">arXiv</a></p>
<hr />
<h3>10. 未来光流预测提升机器人控制与视频生成能力</h3>
<p><strong>原文标题：</strong> Future Optical Flow Prediction Improves Robot Control &amp; Video Generation</p>
<p><strong>摘要：</strong>
未来运动表征（如光流）在控制与生成任务中具有重要价值。然而，预测具有泛化能力的空间稠密运动表征仍是核心挑战，且从含噪声的真实世界数据中学习此类预测的研究尚不充分。本文提出FOFPred模型——一种基于语言条件的光流预测框架，其创新性地融合了视觉语言模型与扩散模型架构。该组合通过多模态推理能力与像素级生成保真度，实现了对未来运动的高质量预测。模型基于网络规模的人类活动数据进行训练，此类数据虽具有高度可扩展性但结构松散。为从含噪声的视频-文本数据中提取有效信号，我们采用关键的数据预处理技术，并依托强图像预训练的融合架构进行优化。训练完成的模型进一步扩展至控制与生成两大下游任务。在语言驱动场景下的机器人操作与视频生成实验表明，FOFPred具备跨领域泛化能力，验证了统一视觉语言-扩散架构的优越性，并证实了从多样化网络数据中进行可扩展学习对未来光流预测的重要价值。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.10781">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.10781">arXiv</a></p>
<hr />
<h3>11. ProFit：基于概率引导的标记选择在监督微调中利用高价值信号</h3>
<p><strong>原文标题：</strong> ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection</p>
<p><strong>摘要：</strong>
监督微调（SFT）是将大语言模型（LLM）与人类意图对齐的关键后训练策略。然而，传统SFT通常通过强制模型对齐单一参考答案而忽视语言的一对多本质，导致模型过度拟合非核心表达。尽管实证分析表明引入多参考答案可缓解此问题，但高昂的数据与计算成本要求策略转向：优先缓解单参考过拟合，而非追求代价高昂的答案多样性。为实现这一目标，本文揭示了标记概率与语义重要性之间的内在关联：高概率标记承载核心逻辑框架，而低概率标记多为可替换表达。基于此发现，我们提出ProFit方法，通过选择性掩码低概率标记以抑制表层过拟合。大量实验证实，ProFit在通用推理与数学基准测试中均稳定优于传统SFT基线方法。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.09195">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.09195">arXiv</a></p>
<hr />
<h3>12. ShapeR：基于随意采集数据的鲁棒条件式三维形状生成</h3>
<p><strong>原文标题：</strong> ShapeR: Robust Conditional 3D Shape Generation from Casual Captures</p>
<p><strong>摘要：</strong>
三维形状生成领域近期取得了显著进展，但现有方法大多依赖于干净、无遮挡且分割良好的输入数据，而现实场景中很少能满足这些条件。本文提出ShapeR，一种从随意采集序列中生成条件式三维物体形状的新方法。给定图像序列，我们利用现成的视觉-惯性SLAM系统、三维检测算法和视觉-语言模型，为每个物体提取稀疏SLAM点集、多视角位姿图像及机器生成描述文本。通过训练整流流变换器有效融合这些模态条件，最终生成高保真度的度量三维形状。为应对随意采集数据带来的挑战，我们采用多种技术手段：包括实时组合增强、涵盖物体与场景级数据集的渐进式训练方案，以及处理背景杂波的策略。此外，我们构建了包含7个真实场景中178个带几何标注的野外物体的新评估基准。实验表明，在该挑战性设定下，ShapeR显著优于现有方法，其倒角距离指标较当前最优技术提升2.7倍。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.11514">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.11514">arXiv</a></p>
<hr />
<h3>13. PhysRVG：面向视频生成模型的物理感知统一强化学习框架</h3>
<p><strong>原文标题：</strong> PhysRVG: Physics-Aware Unified Reinforcement Learning for Video Generative Models</p>
<p><strong>摘要：</strong>
物理原理是真实视觉仿真的基础，但在基于Transformer的视频生成中仍存在显著忽视。这一差距凸显了在渲染刚体运动（经典力学的核心原则）方面的关键局限性。尽管计算机图形学和基于物理的模拟器能够轻松运用牛顿公式模拟此类碰撞，现代预训练-微调范式却在像素级全局去噪过程中丢弃了物体刚性的概念。即使在训练后的模型优化过程中，完全正确的数学约束也被视为次优解（即条件），这从根本上限制了生成视频的物理真实感。基于这些考量，我们首次提出了一种面向视频生成模型的物理感知强化学习范式，该范式直接在高维空间中强制执行物理碰撞规则，确保物理知识被严格应用而非仅作为条件处理。随后，我们将此范式扩展为统一框架，称为模仿-发现循环（MDcycle），该框架在充分保留模型利用物理基础反馈能力的同时，支持大规模的模型微调。为验证本方法，我们构建了新的基准测试集PhysRVGBench，并通过广泛的定性与定量实验全面评估其有效性。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.11087">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.11087">arXiv</a></p>
<hr />
<h3>14. 推理模型生成思想社会</h3>
<p><strong>原文标题：</strong> Reasoning Models Generate Societies of Thought</p>
<p><strong>摘要：</strong>
大语言模型已在多个领域展现出卓越能力，但其复杂推理的内在机制尚未明晰。近期研究表明，推理模型在复杂认知任务上表现优于同等规模的指令微调模型，这通常归因于通过更长的思维链实现的扩展计算。本文发现，推理能力的提升不仅源于计算扩展，更源于模拟多智能体式交互——即构建“思想社会”——该系统通过具有差异化人格特质与领域专长的内部认知视角实现观点分化与辩论。通过对推理轨迹的定量分析与机制可解释性方法研究，我们发现DeepSeek-R1、QwQ-32B等推理模型比指令微调模型展现出更显著的视角多样性，在推理过程中会激活更广泛的异质性人格特征与专业特征间的冲突。这种多智能体结构具体表现为对话行为（包括问答、视角转换与矛盾观点调和）以及体现激烈交锋对话的社会情感角色，二者共同构成推理任务中的准确性优势。受控强化学习实验表明：当仅以推理准确性作为奖励时，基础模型会增强对话行为；而采用对话框架对模型进行微调，能比基础模型更快提升推理能力。这些发现表明，思想的社会化组织能有效促进解空间的探索。我们认为推理模型建立了与人类群体集体智能的计算平行机制——当多样性被系统化组织时，将催生更优越的问题解决能力，这为通过智能体组织利用群体智慧开辟了新路径。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.10825">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.10825">arXiv</a></p>
<hr />
<h3>15. PersonalAlign：基于长期用户中心化记录的个性化图形用户界面代理的层次化隐式意图对齐</h3>
<p><strong>原文标题：</strong> PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records</p>
<p><strong>摘要：</strong>
尽管图形用户界面代理在显式及完整指令下已展现出强大性能，但在实际部署中仍需与用户更复杂的隐式意图进行对齐。本研究提出面向个性化图形用户界面代理的层次化隐式意图对齐任务，该任务要求代理利用长期用户记录作为持续上下文，以解析模糊指令中被省略的用户偏好，并根据用户状态预测潜在操作习惯以提供主动协助。为推进该研究，我们构建了AndroidIntent基准测试集，旨在评估代理通过长期用户记录推理来解析模糊指令及提供主动建议的能力。我们从不同用户的2万条长期记录中标注了775项用户特定偏好和215项操作习惯用于评估。此外，我们提出层次化意图记忆代理，该代理通过持续更新的个人记忆库，以层次化方式组织用户偏好与操作习惯以实现个性化服务。最后，我们在AndroidIntent上评估了包括GPT-5、Qwen3-VL和UI-TARS在内的多种图形用户界面代理，实验结果表明层次化意图记忆代理在指令执行和主动协助性能上分别显著提升15.7%和7.3%。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.09636">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.09636">arXiv</a></p>
<hr />
<h3>16. 为Gemini构建生产就绪的探测模型</h3>
<p><strong>原文标题：</strong> Building Production-Ready Probes For Gemini</p>
<p><strong>摘要：</strong>
前沿语言模型的能力正在迅速提升，因此我们需要更强大的缓解措施来防止恶意行为者滥用日益强大的系统。先前研究表明，激活探测可能是一种有前景的滥用缓解技术，但我们发现一个关键挑战：探测模型在重要的生产环境分布变化下泛化能力不足。特别地，我们发现从短上下文输入转向长上下文输入时，现有探测架构表现不佳。为此，我们提出了几种能够应对长上下文分布变化的新型探测架构。</p>
<p>我们在网络攻击领域评估了这些探测模型，测试了它们对多轮对话、静态越狱攻击和自适应红队测试等生产相关场景变化的鲁棒性。结果表明，虽然多最大值方法能处理上下文长度问题，但实现广泛泛化仍需结合架构优化与多样化分布训练。此外，我们发现将探测模型与提示分类器结合，能凭借探测模型的计算效率优势，以较低成本实现最优准确率。</p>
<p>这些研究成果已成功应用于谷歌前沿语言模型Gemini的用户端实例中，实现了滥用缓解探测模型的部署。最后，我们通过AlphaEvolve在探测架构搜索和自适应红队测试自动化改进方面取得了初步积极成果，表明部分人工智能安全研究已具备自动化实现的可行性。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.11516">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.11516">arXiv</a></p>
<hr />
<h3>17. AgencyBench：在百万令牌现实场景中评测自主智能体的前沿能力</h3>
<p><strong>原文标题：</strong> AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts</p>
<p><strong>摘要：</strong>
基于大语言模型的自主智能体展现出多方面能力，能够对经济生产作出实质性贡献。然而，现有评测基准仍局限于单一智能体能力，未能捕捉长周期现实场景。此外，现实任务对人类参与反馈的依赖造成了可扩展性瓶颈，阻碍了自动化部署收集与评估。为弥补这一空白，我们推出AgencyBench——一个源自日常人工智能使用场景的综合评测基准，在32个现实场景中评估6项核心智能体能力，涵盖138项具有具体查询、交付标准和评分细则的任务。这些场景平均需要90次工具调用、100万令牌和数小时执行时间才能完成。为实现自动化评估，我们采用用户模拟智能体提供迭代反馈，并通过Docker沙箱进行基于视觉与功能评分细则的评估。实验表明，闭源模型显著优于开源模型（48.4% vs 32.1%）。进一步分析揭示了不同模型在资源效率、反馈驱动的自我修正以及特定工具使用偏好方面存在显著差异。最后，我们研究了智能体框架的影响，发现专有模型在其原生生态系统中表现更优（例如通过Claude-Agent-SDK运行的Claude-4.5-Opus），而开源模型则在不同执行框架中呈现独特的性能峰值，表明其存在针对特定框架的优化潜力。AgencyBench作为下一代智能体的关键测试平台，凸显了模型架构与智能体框架协同优化的必要性。我们相信这项工作为自主智能体的未来发展指明了方向，完整评测基准与评估工具包已发布于https://github.com/GAIR-NLP/AgencyBench。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.11044">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.11044">arXiv</a></p>
<hr />
<h3>18. 更多图像，更多问题？视觉语言模型失败模式的受控分析</h3>
<p><strong>原文标题：</strong> More Images, More Problems? A Controlled Analysis of VLM Failure Modes</p>
<p><strong>摘要：</strong>
大规模视觉语言模型（LVLMs）已展现出卓越的能力，但其在多图像理解与推理方面的熟练程度仍很大程度上未被探索。尽管现有基准测试已开始评估多图像模型，但对其核心弱点及其成因的全面分析仍然缺乏。本研究提出MIMIC（多图像模型洞察与挑战基准），这是一个旨在严格评估LVLMs多图像能力的新基准。借助MIMIC，我们进行了一系列诊断实验，揭示了普遍存在的问题：LVLMs往往无法跨图像整合信息，并且在同时追踪或关注多个概念时存在困难。为解决这些缺陷，我们提出了两种新颖的互补性改进方案。在数据层面，我们提出了一种程序化数据生成策略，能够将单图像标注组合成丰富且有针对性的多图像训练样本。在优化层面，我们分析了层级注意力模式，并推导出专为多图像输入设计的注意力掩码方案。实验结果表明，该方法显著提升了跨图像聚合能力，同时增强了现有多图像基准测试的性能，在多项任务中超越了先前的最先进水平。数据和代码将在https://github.com/anurag-198/MIMIC公开提供。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.07812">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.07812">arXiv</a></p>
<hr />
<h3>19. AstroReason-Bench：评估异构空间规划问题中的统一智能体规划能力</h3>
<p><strong>原文标题：</strong> AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems</p>
<p><strong>摘要：</strong>
智能体大语言模型（LLMs）的最新进展使其成为能够跨多种任务进行推理与行动的通用规划器。然而，现有智能体基准测试主要关注符号化或弱实体化环境，对其在物理约束的现实领域中的性能评估尚不充分。本文提出AstroReason-Bench，这是一个用于评估空间规划问题（SPP）中智能体规划能力的综合性基准测试集。空间规划问题是一类具有异构目标、严格物理约束和长周期决策特征的高风险问题。AstroReason-Bench整合了多种调度机制，包括地面站通信和敏捷对地观测，并提供统一的面向智能体的交互协议。通过对一系列先进的开源与闭源智能体LLM系统进行评估，我们发现当前智能体的表现显著逊于专用求解器，这揭示了现实约束下通用规划能力的关键局限。AstroReason-Bench为未来智能体研究提供了一个具有挑战性和诊断价值的测试平台。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.11354">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.11354">arXiv</a></p>
<hr />
<h3>20. 思维语言塑造大型语言模型的输出多样性</h3>
<p><strong>原文标题：</strong> Language of Thought Shapes Output Diversity in Large Language Models</p>
<p><strong>摘要：</strong>
输出多样性对大型语言模型至关重要，它是多元性与创造力的基础。本研究揭示，通过控制模型思考过程中使用的语言——即思维语言——能够为输出多样性提供新颖且结构化的来源。初步研究表明，不同思维语言在模型的思维空间中占据着不同区域。基于这一发现，我们研究了多语言思维下的两种重复采样策略——单语言采样与混合语言采样，并对所有输出（无论采用何种思维语言）进行英语控制的多样性评估。大量实验表明，将思维语言从英语切换至非英语语言能持续提升输出多样性，且存在明确稳定的正相关关系：思维空间中距离英语越远的语言带来的增益越大。我们进一步证明，通过组合效应聚合多种思维语言的样本可产生额外提升，而基于语言异质性的规模化采样能够拓展模型的多样性上限。最后，我们验证了这些发现在多元对齐场景中的实际价值，能够使大语言模型输出覆盖更广泛的文化知识与价值取向。代码已公开于：https://github.com/iNLP-Lab/Multilingual-LoT-Diversity。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.11227">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.11227">arXiv</a></p>
<hr />
<h3>21. 多模态推理数据策展的关键要素？来自DCVLR挑战赛的启示</h3>
<p><strong>原文标题：</strong> What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge</p>
<p><strong>摘要：</strong>
我们通过NeurIPS 2025视觉语言推理数据策展（DCVLR）挑战赛研究多模态推理的数据策展问题。该挑战赛通过固定模型与训练流程，聚焦于数据集选择机制的独立评估。我们基于沃尔顿多模态冷启动数据集构建的紧凑型策展数据在比赛中获得第一名。赛后消融实验表明，在已对齐的基础数据集上实施基于难度的样本选择是性能提升的核心驱动力。在固定训练方案下，扩大数据集规模并不能稳定提高平均准确率，其主要作用是降低训练结果的随机波动；而常用的多样性筛选与合成数据增强启发式方法不仅未能带来额外收益，反而常导致性能下降。这些结果表明DCVLR本质上属于饱和态评估范式，同时凸显了数据对齐与难度控制在高效多模态推理中的核心作用。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.10922">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.10922">arXiv</a></p>
<hr />
<h3>22. PhyRPR：免训练的物理约束视频生成方法</h3>
<p><strong>原文标题：</strong> PhyRPR: Training-Free Physics-Constrained Video Generation</p>
<p><strong>摘要：</strong>
当前基于扩散模型的视频生成方法虽能合成视觉上合理的视频，但往往难以满足物理约束。其核心原因在于现有方法多为单阶段范式：它们将高层物理理解与低层视觉合成相耦合，导致难以生成需要显式物理推理的内容。为突破这一局限，本文提出一种免训练的三阶段框架PhyRPR：物理推理（PhyReason）—物理规划（PhyPlan）—物理优化（PhyRefine），该框架实现了物理理解与视觉合成的解耦。具体而言，PhyReason阶段采用多模态大模型进行物理状态推理，并借助图像生成器合成关键帧；PhyPlan阶段通过确定性方法生成可控的粗粒度运动骨架；PhyRefine阶段通过隐空间融合策略将运动骨架注入扩散采样过程，在保持规划动力学特征的同时优化外观表现。这种分阶段设计使生成过程具备显式的物理可控性。在物理约束条件下的广泛实验表明，本方法能持续提升生成内容的物理合理性与运动可控性。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.09255">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.09255">arXiv</a></p>
<hr />
<h2>🔍 关键词云图</h2>
<p><img alt="关键词云图" src="../images/keywords_wordcloud.png" /></p>
<h2>📈 近期论文趋势</h2>
<p><img alt="论文趋势" src="../images/daily_papers.png" /></p>
<h2>🎙️ 语音播报</h2>
<ul>
<li><a href="../audio/2026-01-19_daily_papers.mp3">收听今日论文解读</a></li>
</ul>
<h2>📱 订阅渠道</h2>
<ul>
<li>GitHub: <a href="https://github.com/2404589803/hf-daily-paper-newsletter-chinese">hf-daily-paper-newsletter-chinese</a></li>
</ul>
    </div>
</body>
</html>