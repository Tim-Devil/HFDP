
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-12 论文日报

## 📊 今日论文统计
- 总论文数：31
- 热门领域：GPT, LLM, NLP, RL, Transformer

## 📝 论文详情


### 1. 基于地图的思考：用于地理定位的强化并行地图增强智能体

**原文标题：** Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization

**摘要：**
图像地理定位任务旨在利用视觉线索预测图像在地球上任意位置的拍摄地点。现有的大型视觉语言模型方法虽然利用了世界知识、思维链推理和智能体能力，但忽视了人类常用的一种策略——使用地图。在本研究中，我们首先赋予模型“基于地图思考”的能力，并将其构建为地图内智能体循环框架。为此，我们开发了一种两阶段优化方案，包括智能体强化学习阶段和并行测试时扩展阶段。强化学习增强了模型的智能体能力以提高采样效率，而并行测试时扩展使模型能够在最终预测前探索多条候选路径，这对地理定位至关重要。为了在最新真实场景图像上评估我们的方法，我们进一步提出了MAPBench——一个完全由真实世界图像构成的综合性地理定位训练与评估基准。实验结果表明，我们的方法在多数指标上优于现有开源和闭源模型，特别是在与具备谷歌搜索/地图增强模式的Gemini-3-Pro对比时，将Acc@500m指标从8.0%提升至22.1%。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05432) | [arXiv](https://arxiv.org/abs/2601.05432)



---

### 2. MMFormalizer：面向真实场景的多模态自动形式化方法

**原文标题：** MMFormalizer: Multimodal Autoformalization in the Wild

**摘要：**
自动形式化旨在将自然语言描述的数学内容转化为形式化语句以支持机器推理，但在真实物理世界中面临根本性挑战——物理问题常需从视觉元素推断隐藏约束（如质量或能量），这体现了问题的多模态本质。为此，我们提出MMFormalizer，通过将自适应实体锚定与真实世界的数学及物理领域实体相结合，将自动形式化的范畴从纯文本扩展至多模态场景。该系统通过递归锚定与公理组合，从感知锚定的基本单元递归构建形式化命题，其自适应递归终止机制确保每个抽象概念均获得视觉证据支持，并锚定于维度或公理基础之上。我们在新构建的基准测试集PhyX-AF上评估MMFormalizer，该数据集包含从MathVerse、PhyX、合成几何与解析几何中精选的115个样本，涵盖多样化的多模态自动形式化任务。实验结果表明，GPT-5与Gemini-3-Pro等前沿模型在编译准确率与语义准确率上表现最佳，其中GPT-5在物理推理任务中尤为突出，而几何领域仍是当前最具挑战性的方向。总体而言，MMFormalizer为统一的多模态自动形式化提供了可扩展框架，有效连接了感知与形式化推理。据我们所知，这是首个能够处理经典力学（源自哈密顿量体系）、相对论、量子力学及热力学的多模态自动形式化方法。更多细节详见项目页面：MMFormalizer.github.io

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03017) | [arXiv](https://arxiv.org/abs/2601.03017)



---

### 3. CaricatureGS：基于高斯曲率的三维高斯泼溅人脸夸张化方法

**原文标题：** CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature

**摘要：**
本文提出了一种兼具照片级真实感与可控性的三维人脸夸张化框架。我们首先采用基于本征高斯曲率的表面夸张技术，但发现其与纹理结合时易产生过度平滑的渲染效果。为解决此问题，我们引入近期被证实能生成逼真自由视角虚拟形象的三维高斯泼溅技术。基于多视角图像序列，我们提取FLAME网格模型，求解曲率加权泊松方程，获得其夸张化形态。然而直接对高斯分布进行形变会导致效果不佳，因此我们通过局部仿射变换将每帧图像扭曲至其对应的二维夸张表征，合成了伪真实夸张图像。随后设计了一种交替使用真实数据与合成数据监督的训练方案，使单一高斯集合能够同时表征自然与夸张形态的虚拟形象。该方案提升了保真度，支持局部编辑，并允许对夸张强度进行连续控制。为实现实时形变，我们引入了原始表面与夸张表面之间的高效插值方法，并通过分析证明该方法与闭式解存在有界偏差。在定量与定性评估中，本方法均优于现有工作，能够生成具有照片级真实感且几何可控的夸张虚拟形象。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03319) | [arXiv](https://arxiv.org/abs/2601.03319)



---

### 4. 思维分子结构：长链推理拓扑映射研究

**原文标题：** The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning

**摘要：**
大语言模型在模仿人类或非长链推理模型时，常难以习得有效的长链推理能力。为探究此问题，本研究提出可学习的长链推理轨迹在统一视域下具有稳定的类分子结构，该结构由三种相互作用构成：深度推理（类共价键作用）、自我反思（类氢键作用）与自我探索（类范德华作用）。对蒸馏轨迹的分析表明，此类结构源于长链推理微调过程，而非关键词模仿。我们提出"有效语义异构体"概念，证明仅促进熵快速收敛的键合作用能支撑稳定的长链推理学习，而结构竞争会损害训练效果。基于这些发现，我们开发了Mole-Syn方法——一种基于分布转移图的引导合成技术，可有效构建长链推理结构，在多项基准测试中显著提升模型性能与强化学习稳定性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06002) | [arXiv](https://arxiv.org/abs/2601.06002)



---

### 5. 证据链构建：基于引证感知评分奖励的深度搜索智能体鲁棒强化学习

**原文标题：** Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards

**摘要：**
强化学习已成为提升基于大语言模型的深度搜索智能体性能的关键技术。然而，现有方法主要依赖二元结果奖励，无法有效评估智能体推理过程的全面性与事实依据，常导致捷径利用和事实幻觉等不良行为。为突破这些局限，我们提出引证感知评分奖励框架——一种面向深度搜索智能体的细粒度奖励机制，强调推理的全面性、事实依据性和证据连贯性。该框架将复杂问题分解为可验证的单步评分项，要求智能体通过显式识别隐含实体、提供准确引证支撑，并构建连接预测答案的完整证据链来满足这些评分标准。我们进一步提出引证感知分组相对策略优化算法，该算法融合引证感知评分奖励与结果奖励，用于训练鲁棒的深度搜索智能体。实验表明，在多个深度搜索基准测试中，该算法均稳定优于基于标准结果奖励的强化学习基线方法。分析结果验证了该算法能有效抑制捷径利用行为，促进全面且基于证据的推理过程，并在开放式深度研究任务中展现出强大的泛化能力。相关代码与数据已公开于https://github.com/THUDM/CaRR。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06021) | [arXiv](https://arxiv.org/abs/2601.06021)



---

### 6. EnvScaler：基于程序化合成的LLM智能体工具交互环境扩展框架

**原文标题：** EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis

**摘要：**
大语言模型（LLM）被期望训练为能够在各类现实环境中作为智能体执行任务，但这一过程依赖于丰富多样的工具交互沙箱环境。然而，真实系统的访问往往受限；LLM模拟的环境容易产生幻觉与不一致性；而人工构建的沙箱则难以扩展。本文提出EnvScaler，一种通过程序化合成实现可扩展工具交互环境的自动化框架。EnvScaler包含两个核心组件：首先，SkelBuilder通过主题挖掘、逻辑建模与质量评估构建多样化的环境骨架；随后，ScenGenerator为每个环境生成多任务场景及基于规则的轨迹验证函数。借助EnvScaler，我们合成了191个环境及约7,000个场景，并将其应用于Qwen3系列模型的监督微调（SFT）与强化学习（RL）训练。在三个基准测试上的实验结果表明，EnvScaler显著提升了LLM在涉及多轮次、多工具交互的复杂环境中解决任务的能力。代码与数据已开源：https://github.com/RUC-NLPIR/EnvScaler。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05808) | [arXiv](https://arxiv.org/abs/2601.05808)



---

### 7. Qwen3-VL-Embedding 与 Qwen3-VL-Reranker：一种用于前沿多模态检索与排序的统一框架

**原文标题：** Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking

**摘要：**
本报告介绍了 Qwen3-VL-Embedding 与 Qwen3-VL-Reranker 模型系列，它们是基于 Qwen3-VL 基础模型构建的 Qwen 家族最新扩展。二者共同提供了一个端到端的高精度多模态搜索流程，通过将文本、图像、文档图像及视频等多种模态映射到一个统一的表示空间中实现。Qwen3-VL-Embedding 模型采用多阶段训练范式，从大规模对比预训练逐步推进到重排序模型蒸馏，以生成语义丰富的高维向量。该模型支持嵌套表示学习，可实现灵活的嵌入维度，并能处理长达 32k 词元的输入。作为补充，Qwen3-VL-Reranker 采用具有交叉注意力机制的交叉编码器架构，对查询-文档对进行细粒度相关性估计。两个模型系列均继承了 Qwen3-VL 的多语言能力，支持超过 30 种语言，并以 2B 和 8B 参数规模发布，以适应多样化的部署需求。实证评估表明，Qwen3-VL-Embedding 系列在多种多模态嵌入评估基准上均取得了领先性能。具体而言，Qwen3-VL-Embedding-8B 在 MMEB-V2 基准上获得 77.8 的综合得分，在所有模型中位列第一（截至 2025 年 1 月 8 日）。本报告详细阐述了该系列的架构设计、训练方法及实际能力，并展示了其在图像-文本检索、视觉问答、视频-文本匹配等多种多模态检索任务上的有效性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04720) | [arXiv](https://arxiv.org/abs/2601.04720)



---

### 8. 能否在执行前预测机器学习智能体的行为？

**原文标题：** Can We Predict Before Executing Machine Learning Agents?

**摘要：**
自主机器学习智能体已彻底改变科学发现范式，但其仍受限于“生成-执行-反馈”的传统框架。现有方法因严格依赖高成本的物理执行来验证假设，面临严重的“执行瓶颈”问题。受世界模型启发，本研究通过内化执行先验知识，以即时预测推理替代昂贵的运行时验证，从而突破物理约束。我们在此工作中形式化定义了“数据驱动的解决方案偏好”任务，并构建了包含18,438组对比对的完整语料库。实验表明，大语言模型在获得“已验证数据分析报告”的提示后展现出显著的预测能力，准确率达61.5%且置信度校准稳健。最终，我们将该框架实例化为FOREAGENT智能体，采用“预测-验证”循环机制，在收敛速度提升6倍的同时，其性能超越基于执行的基线方法6%。代码与数据集将于近期在https://github.com/zjunlp/predict-before-execute公开。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05930) | [arXiv](https://arxiv.org/abs/2601.05930)



---

### 9. AgentOCR：通过光学自压缩重构智能体历史

**原文标题：** AgentOCR: Reimagining Agent History via Optical Self-Compression

**摘要：**
大型语言模型的最新进展使得基于多轮交互轨迹进行强化学习的智能体系统成为可能，但实际部署受限于快速增长的文本历史记录，这些记录会大幅增加令牌开销和内存占用。本文提出AgentOCR框架，该框架通过将累积的观察-行动历史表示为紧凑的渲染图像，利用视觉令牌更高的信息密度。为实现多轮交互的可扩展性，AgentOCR提出分段光学缓存机制。该机制通过将历史分解为可哈希的片段并维护视觉缓存，消除了冗余的重复渲染。除固定渲染外，AgentOCR引入智能体自压缩机制，使智能体主动输出压缩率，并通过压缩感知奖励进行训练，从而自适应地平衡任务成功率与令牌效率。我们在ALFWorld和基于搜索的问答等具有挑战性的智能体基准测试上进行了广泛实验。结果显示，AgentOCR在显著降低令牌消耗（>50%）的同时，保持了基于文本的智能体95%以上的性能，实现了稳定的令牌与内存效率。进一步分析验证了分段光学缓存带来20倍的渲染加速效果，以及自压缩机制有效的策略平衡能力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04786) | [arXiv](https://arxiv.org/abs/2601.04786)



---

### 10. 领域偏移下偏好调优泛化性与多样性的实证研究

**原文标题：** An Empirical Study on Preference Tuning Generalization and Diversity Under Domain Shift

**摘要：**
偏好调优通过优化显式偏好信号（而非仅依赖似然性），使预训练语言模型与人类在质量、实用性或安全性方面的判断标准对齐。已有研究表明，当在训练领域外进行评估时，偏好调优会降低模型性能并削弱其实用性。然而，适应性策略在多大程度上能够缓解这种领域偏移的影响尚未得到充分探索。为应对这一挑战，本研究对领域偏移下的对齐泛化问题进行了全面系统的考察。我们在文本摘要和问答实用性任务中，比较了五种主流对齐目标以及从源领域到目标领域的多种适应性策略（包括目标领域监督微调与伪标注方法）。研究结果表明，不同对齐目标在领域偏移下的泛化表现存在系统性差异。我们进一步证明，基于伪标注的适应性策略能够显著减轻领域偏移导致的性能退化。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05882) | [arXiv](https://arxiv.org/abs/2601.05882)



---

### 11. VideoAR：基于下一帧与尺度预测的自回归视频生成模型

**原文标题：** VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction

**摘要：**
当前视频生成领域的研究进展主要由扩散模型和流匹配模型主导，这些模型虽能生成高质量结果，但计算成本高昂且难以扩展。本研究提出VideoAR，首个结合多尺度下一帧预测与自回归建模的大规模视觉自回归视频生成框架。VideoAR通过将帧内自回归建模与因果性下一帧预测相结合，并辅以能高效编码时空动态的三维多尺度分词器，实现了空间与时间依赖关系的解耦。为提升长时一致性，我们提出了多尺度时序旋转位置编码、跨帧误差校正和随机帧掩码技术，共同抑制误差传播并增强时序连贯性。我们的多阶段预训练流程通过逐步提升分辨率和时长，实现了空间与时间学习的渐进对齐。实验表明，VideoAR在自回归模型中取得了最先进的性能：在UCF-101数据集上将FVD指标从99.5提升至88.6，同时减少超过10倍的推理步数，并获得81.74的VBench评分——该成绩可与规模大一个数量级的扩散模型相媲美。这些结果证明VideoAR显著缩小了自回归范式与扩散范式之间的性能差距，为未来视频生成研究提供了可扩展、高效且时序一致的基础框架。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05966) | [arXiv](https://arxiv.org/abs/2601.05966)



---

### 12. 自信的幻觉？通过邻域一致性诊断大语言模型的真实性

**原文标题：** Illusions of Confidence? Diagnosing LLM Truthfulness via Neighborhood Consistency

**摘要：**
随着大语言模型在现实场景中的部署日益广泛，仅关注回答正确性已显不足。可靠的部署要求模型在上下文扰动下保持真实的信念。现有评估主要依赖点状置信度指标（如自一致性），这可能掩盖信念的脆弱性。研究表明，即使是具有完美自一致性的回答事实，在轻微上下文干扰下也可能迅速崩溃。为弥补这一缺陷，我们提出邻域一致性信念——一种评估概念邻域内响应连贯性的信念稳健性结构化度量方法。为验证该方法的有效性，我们设计了新的认知压力测试协议，用于探测上下文干扰下的输出稳定性。在多类大语言模型上的实验表明，具有高邻域一致性信念的数据在抗干扰性方面表现更为稳健。最后，我们提出结构感知训练方法，通过优化上下文不变的信念结构，将长尾知识的脆弱性降低约30%。代码发布于https://github.com/zjunlp/belief。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05905) | [arXiv](https://arxiv.org/abs/2601.05905)



---

### 13. 目标力：教授视频模型实现物理条件化目标

**原文标题：** Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals

**摘要：**
视频生成领域的最新进展使得能够开发出可为机器人技术和规划任务模拟潜在未来的“世界模型”。然而，为这些模型指定精确目标仍具挑战性：文本指令通常过于抽象而难以捕捉物理细节，而目标图像对于动态任务往往难以指定。为此，我们提出“目标力”这一新颖框架，允许用户通过明确的力向量和中间动力学过程来定义目标，从而模拟人类对物理任务的思维模式。我们在精心构建的合成因果基元数据集（如弹性碰撞和多米诺骨牌倾倒）上训练视频生成模型，使其学会在时空维度上传递力的作用。尽管仅基于简单物理数据进行训练，我们的模型在复杂现实场景（包括工具操控和多物体因果链）中展现出卓越的零样本泛化能力。研究结果表明，通过将视频生成建立在基础物理交互之上，模型能够演化为隐式神经物理模拟器，实现无需依赖外部引擎的精确物理感知规划。相关数据集、代码、模型权重及交互式视频演示已发布于项目页面。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05848) | [arXiv](https://arxiv.org/abs/2601.05848)



---

### 14. BizFinBench.v2：一个面向专家级金融能力对齐的统一双模式双语基准

**原文标题：** BizFinBench.v2: A Unified Dual-Mode Bilingual Benchmark for Expert-Level Financial Capability Alignment

**摘要：**
大语言模型经历了快速演进，已成为金融运营智能化的关键技术。然而，现有基准常受限于依赖模拟或通用样本、聚焦单一离线静态场景等缺陷，导致其无法契合金融服务对真实性与实时响应的要求，造成基准表现与实际运营效能间的显著差距。为此，我们推出BizFinBench.v2，这是首个基于中美股市真实业务数据并融合在线评估的大规模评测基准。通过对金融平台真实用户查询进行聚类分析，我们在四大核心业务场景下构建了八项基础任务与两项在线任务，共计29,578组专家级问答对。实验结果显示，ChatGPT-5在主任务中取得61.5%的突出准确率，但与金融专家仍存在明显差距；在线任务中DeepSeek-R1的表现优于所有其他商用大语言模型。错误分析进一步揭示了现有模型在真实金融业务场景中的具体能力缺陷。BizFinBench.v2突破了当前基准的局限性，实现了对大语言模型金融能力的业务级解构，为评估大语言模型在金融领域广泛部署的效能提供了精准依据。数据与代码已公开于https://github.com/HiThink-Research/BizFinBench.v2。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06401) | [arXiv](https://arxiv.org/abs/2601.06401)



---

### 15. Orient Anything V2：统一朝向与旋转理解

**原文标题：** Orient Anything V2: Unifying Orientation and Rotation Understanding

**摘要：**
本研究提出Orient Anything V2，这是一个增强型基础模型，用于从单张或成对图像中统一理解物体的三维朝向与旋转。该模型在Orient Anything V1（通过单一独特正面定义朝向）的基础上进行扩展，能够处理具有不同旋转对称性的物体，并直接估计相对旋转。这些改进得益于四项关键创新：1）通过生成模型合成可扩展的三维资产，确保广泛的类别覆盖与均衡的数据分布；2）一种高效的模型在环标注系统，能够鲁棒地识别每个物体0到N个有效正面；3）一种对称感知的周期性分布拟合目标，可捕捉所有可能的正面朝向，有效建模物体的旋转对称性；4）一种直接预测物体相对旋转的多帧架构。大量实验表明，Orient Anything V2在11个广泛使用的基准测试中，于朝向估计、六自由度姿态估计和物体对称性识别任务上均实现了零样本性能的领先水平。该模型展现出强大的泛化能力，显著拓宽了朝向估计在多种下游任务中的适用性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05573) | [arXiv](https://arxiv.org/abs/2601.05573)



---

### 16. 同一论断，不同判断：多语言金融虚假信息检测中情境诱导偏见的基准研究

**原文标题：** Same Claim, Different Judgment: Benchmarking Scenario-Induced Bias in Multilingual Financial Misinformation Detection

**摘要：**
大语言模型已广泛应用于金融领域的各个方面。由于训练数据主要来源于人类撰写的语料库，大语言模型可能继承一系列人类偏见。行为偏见可能导致决策的不稳定性和不确定性，尤其是在处理金融信息时。然而，现有关于大语言模型偏见的研究主要集中于直接提问或简化的通用场景，对复杂的现实金融环境以及高风险、情境敏感的多语言金融虚假信息检测任务的考量有限。本研究提出MFMDScen——一个用于评估大语言模型在多语言金融虚假信息检测任务中跨不同经济场景行为偏见的综合基准。通过与金融专家合作，我们构建了三类复杂金融场景：（1）基于角色与人格特质的场景；（2）基于角色与地域背景的场景；（3）融合族群与宗教信仰的角色场景。我们进一步开发了涵盖英语、中文、希腊语和孟加拉语的多语言金融虚假信息数据集。通过将这些场景与虚假信息论断相结合，MFMDScen实现了对22个主流大语言模型的系统性评估。研究结果表明，显著的行为偏见在商业模型和开源模型中持续存在。本项目资源发布于https://github.com/lzw108/FMD。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05403) | [arXiv](https://arxiv.org/abs/2601.05403)



---

### 17. AnyDepth：简化深度估计

**原文标题：** AnyDepth: Depth Estimation Made Easy

**摘要：**
单目深度估计旨在从二维图像中恢复三维场景的深度信息。近期研究虽取得显著进展，但其对大规模数据集和复杂解码器的依赖限制了效率与泛化能力。本文提出一种轻量级且以数据为中心的零样本单目深度估计框架。首先采用DINOv3作为视觉编码器以获取高质量密集特征；其次，针对DPT结构复杂性的固有缺陷，设计了基于紧凑Transformer架构的简易深度变换解码器（SDT）。相较于DPT，该解码器采用单路径特征融合与上采样流程，显著降低了跨尺度特征融合的计算开销，在减少约85%-89%参数量的同时实现了更高精度。此外，提出基于质量的数据筛选策略，通过滤除低质量样本在缩减数据集规模的同时提升整体训练质量。在五个基准数据集上的大量实验表明，本框架在精度上超越DPT。本研究凸显了平衡模型设计与数据质量对于实现高效可泛化零样本深度估计的重要性。代码：https://github.com/AIGeeksGroup/AnyDepth。项目网站：https://aigeeksgroup.github.io/AnyDepth。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.02760) | [arXiv](https://arxiv.org/abs/2601.02760)



---

### 18. SmartSearch：面向搜索代理的过程奖励引导式查询优化框架

**原文标题：** SmartSearch: Process Reward-Guided Query Refinement for Search Agents

**摘要：**
基于大语言模型的搜索代理通过整合信息检索能力，在解决知识密集型问题方面展现出巨大潜力。现有研究主要聚焦于优化搜索代理的推理范式，但推理过程中中间搜索查询的质量问题尚未得到充分重视。这导致生成的查询往往不够精确，进而引发非预期的检索结果，最终制约搜索代理的整体效能。为缓解这一问题，我们提出SmartSearch框架，其核心机制包括：（1）过程奖励机制：通过双层级信用评估对每个中间搜索查询的质量提供细粒度监督；（2）查询优化机制：通过选择性优化低质量搜索查询，并基于优化结果重新生成后续搜索轮次，从而提升查询生成质量。为使搜索代理能够在过程奖励引导下逐步内化查询质量改进能力，我们设计了三阶段课程学习框架，引导代理依次经历模仿、对齐与泛化三个阶段。实验结果表明，SmartSearch在各项基准测试中均优于现有基线方法，定量分析进一步验证了其在搜索效率与查询质量方面的显著提升。代码已开源：https://github.com/MYVAE/SmartSearch。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04888) | [arXiv](https://arxiv.org/abs/2601.04888)



---

### 19. 检索增强大语言模型中的过度搜索现象研究

**原文标题：** Over-Searching in Search-Augmented Large Language Models

**摘要：**
检索增强大语言模型通过整合外部检索机制，在知识密集型任务中表现卓越。然而，这类模型常出现过度搜索现象——即使检索无助于提升回答质量，仍不必要地调用搜索工具，这不仅导致计算效率低下，还可能因引入无关上下文而产生事实幻觉。本研究从查询类型、模型类别、检索条件及多轮对话等多个维度系统评估了过度搜索现象。研究发现：（1）检索通常能提升可回答查询的答案准确率，但会削弱模型对不可回答问题的拒答能力；（2）过度搜索现象在复杂推理模型和深度研究系统中更为显著，其程度受噪声检索影响而加剧，并在多轮对话中随轮次增加而累积；（3）检索证据的构成至关重要，负面证据的存在能有效提升模型的拒答能力。为量化过度搜索，本文提出"单位正确性所需标记数"评估指标，用以衡量检索增强大语言模型的性能-成本权衡关系。最后，我们探索了查询层面与检索层面的缓解策略，并发布OverSearchQA数据集以推动高效检索增强大语言模型的持续研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05503) | [arXiv](https://arxiv.org/abs/2601.05503)



---

### 20. DR-LoRA：面向专家混合模型适配的动态秩LoRA方法

**原文标题：** DR-LoRA: Dynamic Rank LoRA for Mixture-of-Experts Adaptation

**摘要：**
专家混合模型已成为扩展大语言模型的主流范式。参数高效微调技术（如LoRA）被广泛用于将预训练的MoE大语言模型适配至下游任务。然而，现有方法为所有专家分配相同的LoRA秩，忽视了MoE大语言模型内在的功能专化特性。这种均匀分配导致资源错配：任务相关专家参数配置不足，而相关性较低的专家却获得冗余参数。本文提出动态秩LoRA框架DR-LoRA，该框架能根据任务特定需求在微调过程中动态调整专家LoRA秩。DR-LoRA采用专家显著性评分机制，综合专家路由频率与LoRA秩重要性来量化各专家对额外容量的需求。具有较高显著性评分的专家将优先进行秩扩展，从而自动形成适应目标任务的异构秩分布。在多基准测试上的实验表明，在相同参数预算下，DR-LoRA始终优于标准LoRA及静态分配策略，通过更高效的参数利用实现了更优越的任务性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04823) | [arXiv](https://arxiv.org/abs/2601.04823)



---

### 21. 记忆至关重要：以事件为中心的记忆作为智能体搜索与推理的逻辑图谱

**原文标题：** Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning

**摘要：**
大型语言模型正日益被部署为能够推理、规划并与环境交互的智能体。为有效适应长周期任务场景，此类智能体的关键能力在于具备一种能够保存、组织并检索过往经验以支持下游决策的记忆机制。然而，现有方法大多以扁平化方式组织存储记忆，并依赖简单的基于相似度的检索技术。即使引入结构化记忆，现有方法仍难以显式捕捉经验或记忆单元间的逻辑关联。此外，记忆访问过程往往与已构建的结构脱节，仍依赖于浅层语义检索，导致智能体无法对长周期依赖关系进行逻辑推理。本研究提出CompassMem——一个受事件分割理论启发的、以事件为中心的记忆框架。该框架通过将经验渐进分割为事件并以显式逻辑关系进行连接，将记忆组织为事件图谱。该图谱作为逻辑导航地图，使智能体能够超越表层检索，在记忆空间中进行结构化、目标导向的导航，逐步汇聚有价值记忆以支持长周期推理。在LoCoMo与NarrativeQA数据集上的实验表明，CompassMem在多种骨干模型中均能持续提升检索与推理性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04726) | [arXiv](https://arxiv.org/abs/2601.04726)



---

### 22. GenCtrl——生成模型的形式化可控性工具包

**原文标题：** GenCtrl -- A Formal Controllability Toolkit for Generative Models

**摘要：**
随着生成模型日益普及，对生成过程进行细粒度控制的需求变得至关重要。然而，尽管从提示工程到微调的各种受控生成方法不断涌现，一个根本性问题仍未得到解答：这些模型本身是否真正可控？本研究提出了一个理论框架来形式化地回答这一问题。通过将人机交互建模为控制过程，我们提出了一种新颖算法，用于在对话场景中估计模型的可控集合。值得注意的是，我们基于样本复杂度给出了估计误差的形式化保证：我们推导出可控集合估计的概率近似正确边界，这些边界具有分布无关性，除输出有界性外无需任何假设，且适用于任何黑盒非线性控制系统（即任意生成模型）。我们在对话过程控制的不同任务上对理论框架进行了实证验证，涵盖语言模型和文本到图像生成场景。实验结果表明，模型可控性具有出人意料的脆弱性，且高度依赖实验设置。这凸显了进行严格可控性分析的必要性，应将研究重点从单纯尝试控制转向首先理解其根本性局限。

---

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05637) | [arXiv](https://arxiv.org/abs/2601.05637)



---

### 23. TCAndon-Router：面向多智能体协作的自适应推理路由机制

**原文标题：** TCAndon-Router: Adaptive Reasoning Router for Multi-Agent Collaboration

**摘要：**
多智能体系统已成为构建高性能智能应用的重要范式。在这些系统中，负责决定由哪些专家智能体处理给定查询的路由机制对整体性能起着关键作用。现有的路由策略主要分为两类：性能路由（通过在不同规模的模型间平衡延迟与成本）和任务路由（将查询分配给特定领域的专家以提高准确性）。在实际企业应用中，任务路由更为适用；然而，现有方法大多依赖静态的单标签决策机制，这带来了两大局限：（一）难以在业务领域扩展时无缝集成新的智能体；（二）因智能体能力重叠导致的路由冲突，最终降低了系统的准确性与鲁棒性。为应对这些挑战，本文提出TCAndon-Router（TCAR）：一种面向多智能体协作的自适应推理路由机制。与传统路由机制不同，TCAR支持动态接入智能体，并首先生成自然语言推理链，再预测能够处理查询的候选智能体集合。此外，我们设计了协作执行流程：被选中的智能体独立生成响应，随后由专用的优化智能体进行聚合与精炼，最终形成单一高质量响应。在公开数据集和企业实际数据上的实验表明，TCAR显著提升了路由准确性，减少了路由冲突，并在模糊场景中保持鲁棒性。我们已在https://huggingface.co/tencent/TCAndon-Router发布TCAR，以支持未来可解释与协作式多智能体路由的相关研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04544) | [arXiv](https://arxiv.org/abs/2601.04544)



---

### 24. 将反馈提炼为记忆即工具

**原文标题：** Distilling Feedback into Memory-as-a-Tool

**摘要：**
本文提出一种框架，通过基于文件的记忆系统与智能体控制的工具调用，将瞬时性批判转化为可检索的指导原则，从而分摊推理时逻辑分析的计算成本。我们在Rubric Feedback Bench（一种基于评分标准学习的新型数据集）上对该方法进行评估。实验表明，增强后的大型语言模型能快速达到测试时优化流程的性能水平，同时显著降低推理成本。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05960) | [arXiv](https://arxiv.org/abs/2601.05960)



---

### 25. TowerMind：面向大语言模型智能体的塔防游戏学习环境与基准测试平台

**原文标题：** TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents

**摘要：**
大语言模型（LLMs）近期取得的突破性进展，使其成为构建智能体的潜力范式，其中长期规划与决策能力正逐渐成为适应多样化场景与任务的核心通用能力。实时策略（RTS）游戏是评估这两项能力的理想测试平台，因其固有的游戏机制要求同时具备宏观层面的战略规划能力与微观层面的战术适应及动作执行能力。然而，现有的基于RTS游戏的环境往往存在计算需求较高或缺乏文本观察支持的问题，这限制了大语言模型在RTS游戏评估中的应用。为此，我们提出了TowerMind——一个基于RTS游戏子类塔防（TD）游戏的新型环境。TowerMind保留了RTS游戏评估大语言模型的关键优势，同时具备低计算需求和多模态观察空间，包括基于像素的图像、文本描述以及结构化游戏状态表示。此外，TowerMind支持模型幻觉评估，并提供了高度的可定制性。我们设计了五个基准关卡，用于评估多种广泛使用的大语言模型在不同多模态输入设置下的表现。实验结果显示，大语言模型在能力与幻觉维度上均与人类专家存在明显的性能差距。实验进一步揭示了大语言模型行为的关键局限，例如规划验证不足、决策缺乏多终局性以及动作使用效率低下。我们还评估了两种经典强化学习算法：Ape-X DQN和PPO。通过提供轻量级、多模态的设计，TowerMind补充了现有基于RTS游戏的环境体系，并为人工智能智能体领域引入了新的基准测试标准。项目源代码已在GitHub（https://github.com/tb6147877/TowerMind）上公开。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05899) | [arXiv](https://arxiv.org/abs/2601.05899)



---

### 26. Router-Suggest：视觉对话中多模态自动补全的动态路由方法

**原文标题：** Router-Suggest: Dynamic Routing for Multimodal Auto-Completion in Visually-Grounded Dialogs

**摘要：**
实时多模态自动补全对于数字助手、聊天机器人、设计工具及医疗咨询等依赖共享视觉情境的用户输入场景至关重要。本文提出多模态自动补全任务，该任务基于部分已输入文本及视觉线索实时预测对话中的后续字符。与传统纯文本自动补全不同，多模态自动补全将预测建立在多模态语境中，从而更精准捕捉用户意图。为支持该任务研究，我们基于MMDialog与ImageChat构建了基准数据集。通过将前沿视觉语言模型与强文本基线模型进行对比评估，本文揭示了模型在准确性与效率间的权衡关系。我们提出Router-Suggest路由框架，该框架可根据对话语境动态选择文本模型或视觉语言模型，并设计了适用于资源受限环境的轻量化变体。实验表明，Router-Suggest较性能最优的视觉语言模型实现了2.3倍至10倍的加速效果。用户研究证实，在多轮对话场景中，视觉语言模型在用户满意度方面显著优于文本模型，特别是在节省用户输入成本与提升补全质量方面表现突出。这些发现强调了多模态语境在自动补全系统中的必要性，为构建更智能、更具用户感知能力的辅助系统提供了新方向。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05851) | [arXiv](https://arxiv.org/abs/2601.05851)



---

### 27. ViTNT-FIQA：基于视觉Transformer的无训练人脸图像质量评估方法

**原文标题：** ViTNT-FIQA: Training-Free Face Image Quality Assessment with Vision Transformers

**摘要：**
人脸图像质量评估（FIQA）对于构建可靠的人脸识别系统至关重要。现有方法主要仅利用最终层的特征表示，而无训练方法通常需要多次前向传播或反向传播过程。本文提出ViTNT-FIQA，一种无需训练的方法，通过度量中间层视觉Transformer（ViT）模块间图像块嵌入演化的稳定性来评估质量。我们发现高质量人脸图像在跨模块间呈现稳定的特征优化轨迹，而质量退化图像则表现出不稳定的特征变换。该方法通过计算连续Transformer模块间L2归一化图像块嵌入的欧氏距离，并将其聚合为图像级质量分数。我们在具有可控退化等级的质量标注合成数据集上实证验证了这种相关性。与现有无训练方法不同，ViTNT-FIQA仅需单次前向传播，无需反向传播或模型结构修改。通过在八个基准数据集（LFW、AgeDB-30、CFP-FP、CALFW、Adience、CPLFW、XQLFW、IJB-C）上的广泛实验表明，ViTNT-FIQA在保持计算效率、可直接应用于任何预训练ViT人脸识别模型的同时，达到了与最先进方法相竞争的性能水平。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05741) | [arXiv](https://arxiv.org/abs/2601.05741)



---

### 28. IIB-LPO：基于迭代信息瓶颈的潜在策略优化

**原文标题：** IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck

**摘要：**
近期，面向大语言模型推理的可验证奖励强化学习虽取得进展，却始终受限于一个持续存在的挑战：探索坍缩。随机推演的语义同质性常使模型陷入狭窄且过度优化的行为模式。现有方法虽利用策略熵鼓励探索，却存在固有局限：全局熵正则化易受奖励黑客攻击，可能导致无意义的冗长输出；而局部基于令牌的选择性更新则受预训练模型强归纳偏置的制约。为此，我们提出基于迭代信息瓶颈的潜在策略优化方法，该创新方法将探索机制从令牌分布的统计扰动转向推理轨迹的拓扑分岔。IIB-LPO在高熵状态触发潜在分岔以多样化推理路径，并运用信息瓶颈原理同时作为轨迹过滤器与自奖励机制，确保探索过程既简洁又信息丰富。在四个数学推理基准测试上的实证结果表明，IIB-LPO实现了最先进的性能，在准确率上超越现有方法最高达5.3%，在多样性指标上提升最高达7.4%。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05870) | [arXiv](https://arxiv.org/abs/2601.05870)



---

### 29. Afri-MCQA：面向非洲语言的多模态文化问答基准

**原文标题：** Afri-MCQA: Multimodal Cultural Question Answering for African Languages

**摘要：**
非洲拥有全球超过三分之一的语言，但在人工智能研究中仍处于代表性不足的状态。本文提出Afri-MCQA，这是首个覆盖12个国家、15种非洲语言、包含7.5万组问答对的多语言文化问答基准。该基准提供文本与语音模态的英语-非洲语言平行问答对，所有数据均由母语者创建。基于Afri-MCQA对大语言模型（LLMs）的评估表明，开源模型在各类文化场景中表现欠佳，当以母语或语音形式进行开放式视觉问答时，准确率接近零。为评估语言能力，我们设计了控制实验以区分文化知识与语言能力的影响，观察到模型在非洲母语与英语的文本及语音任务上均存在显著性能差距。这些发现凸显了发展语音优先方法、文化导向预训练以及跨语言文化迁移的必要性。为支持更具包容性的非洲语言多模态人工智能发展，我们已在HuggingFace平台（https://huggingface.co/datasets/Atnafu/Afri-MCQA）以学术许可协议或CC BY-NC 4.0协议开源Afri-MCQA数据集。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05699) | [arXiv](https://arxiv.org/abs/2601.05699)



---

### 30. 角色悖论：医学角色作为临床语言模型中的行为先验

**原文标题：** The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models

**摘要：**
角色调节可视为大型语言模型（LLM）的一种行为先验，通常被认为能以单调方式赋予专业能力并提升安全性。然而，其对高风险临床决策的影响仍缺乏深入探究。本研究系统评估了临床LLM中基于角色的控制机制，通过考察专业角色（如急诊科医师、护士）与交互风格（果敢型vs.谨慎型）如何影响不同模型在医疗任务中的行为表现。我们采用多维评估方法，从任务准确性、校准度和安全相关风险行为三个维度，对临床分诊与患者安全任务进行性能评估。研究发现存在系统性、情境依赖且非单调的影响效应：医学角色能提升危重症护理任务的表现，使准确性与校准度最高提升约20%，但在初级诊疗场景中却会导致相当程度的性能下降。交互风格虽能调节风险倾向与敏感度，但其效果高度依赖模型特性。尽管在安全关键案例中，聚合的LLM评估结果倾向于医学角色优于非医学角色，但人类临床医生在安全合规性方面仅呈现中等一致性（平均科恩κ系数=0.43），且对其推理质量的回答表现出极低置信度（95.9%的回应缺乏把握）。本研究揭示：角色作为行为先验会引发情境依赖的权衡效应，而非安全性与专业能力的可靠保证。代码已发布于https://github.com/rsinghlab/Persona_Paradox。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05376) | [arXiv](https://arxiv.org/abs/2601.05376)



---

### 31. 面向安全与伦理人工智能的法律对齐

**原文标题：** Legal Alignment for Safe and Ethical AI

**摘要：**
人工智能对齐包含两大核心问题：一是规范性问题，即明确人工智能系统应如何行动；二是技术性问题，即确保人工智能系统符合这些规范。迄今为止，人工智能对齐研究普遍忽视了一个应对这些问题的重要知识来源与实践领域：法律。本文旨在填补这一空白，探讨如何运用法律规则、原则及方法来应对对齐问题，并为设计安全、合乎伦理的人工智能系统提供理论依据。这一新兴领域——法律对齐——聚焦三个研究方向：（1）设计符合合法制度与程序所制定之法律规则内容的人工智能系统；（2）借鉴法律解释方法以指导人工智能系统的推理与决策过程；（3）运用法律概念作为应对人工智能系统可靠性、信任与合作挑战的结构性蓝图。这些研究方向衍生出新的概念性、实证性与制度性问题，包括探究特定人工智能系统应遵循的具体法律体系、建立评估机制以检验其在真实场景中的合规性，以及构建支持法律对齐实践实施的治理框架。解决这些问题需要融合法学、计算机科学等多学科专业知识，为相关领域学者提供了协同设计更优人工智能系统的合作契机。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04175) | [arXiv](https://arxiv.org/abs/2601.04175)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2026-01-12_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)