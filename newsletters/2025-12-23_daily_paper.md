
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2025-12-23 论文日报

## 📊 今日论文统计
- 总论文数：24
- 热门领域：GPT, RL, LLM

## 📝 论文详情


### 1. DataFlow：以数据为中心的人工智能时代下，由大语言模型驱动的统一数据准备与工作流自动化框架

**原文标题：** DataFlow: An LLM-Driven Framework for Unified Data Preparation and Workflow Automation in the Era of Data-Centric AI

**摘要：**
大语言模型对高质量数据需求的快速增长，使得对可扩展、可靠且语义丰富的数据准备流程的需求日益迫切。然而，当前实践仍主要由临时脚本和松散定义的工作流主导，这些方法缺乏原则性的抽象，阻碍了可复现性，并且对模型在环数据生成的支持有限。为应对这些挑战，我们提出了DataFlow，一个统一且可扩展的、由大语言模型驱动的数据准备框架。DataFlow采用系统级抽象设计，支持模块化、可复用和可组合的数据转换，并提供了一个类似PyTorch风格的流程构建API，用于构建可调试和可优化的数据流。该框架包含近200个可复用算子以及六个覆盖文本、数学推理、代码、Text-to-SQL、智能体RAG和大规模知识提取的通用领域流程。为进一步提升易用性，我们引入了DataFlow-Agent，它能够通过算子合成、流程规划和迭代验证，自动将自然语言描述转换为可执行流程。在六个代表性用例中，DataFlow持续提升了下游大语言模型的性能。我们的数学、代码和文本流程表现优于人工精选数据集和专门的合成基线，在Text-to-SQL任务上相比SynSQL实现了高达+3%的执行准确率提升，在代码基准测试中平均提升达+7%，并在MATH、GSM8K和AIME基准上取得了1-3个百分点的增益。此外，由DataFlow生成的统一万样本数据集使基础模型能够超越在百万级Infinity-Instruct数据上训练的同类模型。这些结果表明，DataFlow为可靠、可复现和可扩展的大语言模型数据准备提供了一个实用且高性能的基础，并为未来以数据为中心的人工智能发展奠定了系统级的基石。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.16676) | [arXiv](https://arxiv.org/abs/2512.16676)



---

### 2. 棱镜假说：通过统一自编码协调语义与像素表示

**原文标题：** The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding

**摘要：**
跨模态的深度表征本质上是相互交织的。本文系统分析了多种语义编码器与像素编码器的频谱特性。研究发现，编码器的特征频谱与其功能角色之间存在一种极具启发性却鲜被探索的对应关系：语义编码器主要捕获编码抽象含义的低频成分，而像素编码器额外保留了传达细粒度细节的高频信息。这一启发式发现为理解编码器行为与其底层频谱结构的关系提供了统一视角。我们将其定义为“棱镜假说”——每种数据模态都可被视为现实世界在共享特征频谱上的投影，正如棱镜分光原理所示。基于此洞见，我们提出了统一自编码模型，该模型通过创新的频带调制器协调语义结构与像素细节，使二者能够无缝共存。在ImageNet和MS-COCO基准上的大量实验表明，我们的UAE模型能够以先进性能将语义抽象与像素级保真度有效统一至单一潜在空间中。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19693) | [arXiv](https://arxiv.org/abs/2512.19693)



---

### 3. 面向教学视频编辑的区域约束上下文生成方法

**原文标题：** Region-Constraint In-Context Generation for Instructional Video Editing

**摘要：**
上下文生成范式近期在教学图像编辑领域展现出卓越的数据效率与合成质量。然而，将此类上下文学习机制应用于基于指令的视频编辑并非易事。若未明确指定编辑区域，生成结果易出现编辑区域定位偏差，且在去噪过程中编辑区与非编辑区的特征标记易产生相互干扰。为解决上述问题，本文提出ReCo——一种创新的教学视频编辑范式，该范式在上下文生成过程中深入探索编辑区与非编辑区之间的约束建模机制。技术层面，ReCo采用宽度维度拼接源视频与目标视频进行联合去噪。为校准视频扩散学习过程，ReCo创新性地引入两种正则化项：潜在空间正则化与注意力正则化，分别作用于单步反向去噪的潜在特征与注意力图谱。前者通过增强源视频与目标视频间编辑区域的潜在特征差异，同时缩小非编辑区域的差异，从而强化对编辑区域的精准修改并抑制非编辑区域的异常内容生成；后者通过抑制编辑区域特征标记对源视频对应区域标记的注意力权重，有效降低目标视频新对象生成过程中的特征干扰。此外，我们构建了大规模高质量视频编辑数据集ReCo-Data，包含50万条指令-视频配对样本，为模型训练提供有力支撑。在四大主流指令式视频编辑任务上的大量实验验证了本方法的优越性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.17650) | [arXiv](https://arxiv.org/abs/2512.17650)



---

### 4. QuCo-RAG：基于预训练语料库不确定性量化的动态检索增强生成

**原文标题：** QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation

**摘要：**
动态检索增强生成通过在生成过程中自适应地决定何时进行检索，以缓解大语言模型中的幻觉问题。然而，现有方法依赖于模型内部信号（如对数概率、熵），这些信号本质上是不可靠的，因为大语言模型通常校准不佳，且常在错误输出中表现出高置信度。我们提出QuCo-RAG方法，将评估依据从主观置信度转向基于预训练数据计算的客观统计量。该方法通过两个阶段量化不确定性：（1）在生成前，我们识别指示长尾知识缺口的低频实体；（2）在生成过程中，我们验证实体在预训练语料库中的共现情况，零共现通常意味着幻觉风险。两个阶段均利用Infini-gram技术对超过4万亿词元的语料进行毫秒级延迟查询，当不确定性较高时触发检索。在多跳问答基准测试中，实验表明QuCo-RAG在使用OLMo-2模型时相比最先进基线实现了5-12个点的精确匹配度提升，并能有效迁移至预训练数据未公开的模型（如Llama、Qwen、GPT），最高提升精确匹配度14个点。在生物医学问答领域的泛化测试进一步验证了该范式的鲁棒性。这些结果表明，基于语料库的验证为动态检索增强生成提供了一种原则性、实际模型无关的范式。我们的代码已公开于https://github.com/ZhishanQ/QuCo-RAG。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19134) | [arXiv](https://arxiv.org/abs/2512.19134)



---

### 5. 无限单应性作为相机控制视频生成的鲁棒条件约束

**原文标题：** Infinite-Homography as Robust Conditioning for Camera-Controlled Video Generation

**摘要：**
视频扩散模型的最新进展激发了动态场景相机控制新视角视频生成领域的广泛关注，其目标是为创作者提供后期制作中的电影级摄像机控制能力。相机控制视频生成的核心挑战在于确保生成内容对指定相机位姿的忠实性，同时保持视角一致性，并基于有限观测推断被遮挡的几何结构。现有方法主要通过两种途径应对该挑战：在轨迹-视频配对数据集上训练轨迹条件视频生成模型，或从输入视频估计深度以沿目标轨迹重投影并生成未投影区域。然而，现有方法难以生成既忠实于相机位姿又具备高质量的视频，主要原因有二：（1）基于重投影的方法极易受深度估计误差影响；（2）现有数据集中相机轨迹的多样性有限，制约了学习模型的泛化能力。为解决这些局限性，本文提出InfCam——一种无需深度估计、具有高姿态忠实度的相机控制视频到视频生成框架。该框架集成两个关键组件：（1）无限单应性变换，将三维相机旋转直接编码至视频扩散模型的二维隐空间，通过基于该无噪声旋转信息的条件约束，以端到端训练方式预测残差视差项，从而实现高精度的相机位姿忠实度；（2）数据增强流程，将现有合成多视角数据集转化为具有多样化轨迹与焦距的视频序列。实验结果表明，InfCam在相机位姿准确性与视觉保真度方面均优于基线方法，并能从合成数据良好泛化至真实场景数据。项目页面链接：https://emjay73.github.io/InfCam/

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.17040) | [arXiv](https://arxiv.org/abs/2512.17040)



---

### 6. 大语言模型能否评估学生困境？基于能力模拟的人机难度对齐在试题难度预测中的应用

**原文标题：** Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction

**摘要：**
试题（问题或任务）难度的准确估计对教育评估至关重要，但面临冷启动问题。尽管大语言模型展现出超越人类的问题解决能力，但其是否能感知人类学习者的认知困境仍是一个开放性问题。本研究通过对医学知识和数学推理等多个领域的20余个模型进行大规模实证分析，探讨人机难度对齐问题。研究发现存在系统性错位现象：扩大模型规模并不能可靠提升对齐效果；模型并未与人类认知对齐，而是趋同于机器共识。研究观察到，高性能模型往往难以准确估计题目难度，即使被明确要求模拟特定能力水平，模型仍难以复现学生能力受限的认知状态。此外，模型存在显著的内省能力缺失，无法预测自身认知局限。这些结果表明，通用问题解决能力并不等同于对人类认知困境的理解，凸显出现有模型在自动化难度预测应用中的挑战。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.18880) | [arXiv](https://arxiv.org/abs/2512.18880)



---

### 7. WorldWarp：基于异步视频扩散的三维几何传播框架

**原文标题：** WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion

**摘要：**
生成长序列且几何一致的视频面临一个根本性困境：几何一致性要求像素空间严格遵循三维结构，而当前最先进的生成模型在相机条件化的隐空间中运行最为高效。这种脱节导致现有方法在处理遮挡区域和复杂相机轨迹时存在困难。为弥合这一差距，本文提出WorldWarp框架，该框架将三维结构锚点与二维生成优化器相结合。为实现几何基础，WorldWarp通过高斯溅射（3DGS）技术维护在线三维几何缓存。通过将历史内容显式变形至新视角，该缓存充当结构支架，确保每一新帧都遵循先验几何关系。然而，静态变形不可避免地会因遮挡产生空洞与伪影。我们通过设计面向“填充-修正”目标的时空扩散（ST-Diff）模型来解决此问题。本研究的核心创新在于时空动态噪声调度机制：空白区域接受完整噪声以触发内容生成，而变形区域接受部分噪声以实现细节优化。通过每一步动态更新三维缓存，WorldWarp实现了视频片段间的跨帧一致性。实验表明，该框架通过三维逻辑引导结构生成、扩散逻辑完善纹理细节，达到了当前最优的生成保真度。项目页面：https://hyokong.github.io/worldwarp-page/。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19678) | [arXiv](https://arxiv.org/abs/2512.19678)



---

### 8. LoGoPlanner：基于度量感知视觉几何的定位支撑导航策略

**原文标题：** LoGoPlanner: Localization Grounded Navigation Policy with Metric-aware Visual Geometry

**摘要：**
在非结构化环境中进行轨迹规划是移动机器人的一项基础且具有挑战性的能力。传统的模块化流程存在延迟问题，并且在感知、定位、建图与规划模块间易产生级联误差。近期端到端学习方法将原始视觉观测直接映射为控制信号或轨迹，有望在开放世界场景中实现更高的性能与效率。然而，现有大多数端到端方法仍依赖独立的定位模块，这些模块需借助精确的传感器外参标定进行自身状态估计，从而限制了其在不同实体与环境间的泛化能力。本文提出LoGoPlanner，一种基于定位的端到端导航框架，通过以下方式突破上述局限：（1）微调长时程视觉几何主干网络，使其预测结果基于绝对度量尺度，从而为精确定位提供隐式状态估计；（2）从历史观测中重建周围场景几何结构，为可靠避障提供密集、细粒度的环境感知；（3）将策略学习建立于上述辅助任务引导的隐式几何信息之上，从而减少误差传播。我们在仿真与真实场景中对LoGoPlanner进行评估，其完全端到端的设计有效降低了累积误差，同时度量感知的几何记忆增强了规划一致性与避障能力，相比具备理想定位的基线方法性能提升超过27.3%，并在不同实体与环境中展现出强大的泛化能力。代码与模型已在项目页面https://steinate.github.io/logoplanner.github.io/公开。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19629) | [arXiv](https://arxiv.org/abs/2512.19629)



---

### 9. UCoder：基于大语言模型内部探测的无监督代码生成方法

**原文标题：** UCoder: Unsupervised Code Generation by Internal Probing of Large Language Models

**摘要：**
大语言模型在代码生成任务中展现出卓越能力，但其效果严重依赖带有大量标注数据（如问答对）或无标注数据集（如代码片段）的监督训练，这些数据通常成本高昂且难以大规模获取。为突破这一限制，本文提出IPC方法，这是一种无监督框架，通过大语言模型的内部探测实现代码生成，无需任何外部语料（包括无标注代码片段）。我们引入问题空间探测、测试理解探测、解决方案空间探测以及知识巩固与强化机制，以挖掘大语言模型中存在的内部知识与置信度模式。进一步地，IPC通过自洽性机制与基于表示的质量评估来筛选可靠代码候选，用以训练UCoder（基于无监督学习的代码生成模型）。我们在多个代码基准测试中验证了所提方法，结果表明无监督方法能够达到与监督方法相竞争的性能，同时显著降低对标注数据和计算资源的依赖。分析实验表明，模型内部状态蕴含丰富的代码质量与正确性信号，有效利用这些信号能够为代码生成任务实现高效的无监督学习，为资源受限场景下训练代码大语言模型开辟了新方向。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.17385) | [arXiv](https://arxiv.org/abs/2512.17385)



---

### 10. GenEnv：大语言模型智能体与环境模拟器间的难度对齐协同进化

**原文标题：** GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators

**摘要：**
训练高性能大语言模型智能体的关键瓶颈在于现实世界交互数据的高成本与静态特性。为此，我们提出GenEnv框架，通过在智能体与可扩展的生成式环境模拟器之间建立难度对齐的协同进化博弈来解决这一问题。与传统基于静态数据集进化的方法不同，GenEnv实现了数据动态演化：模拟器作为动态课程策略，持续生成与智能体“最近发展区”精准匹配的任务。这一过程由简洁高效的α-课程奖励机制引导，确保任务难度与智能体当前能力对齐。我们在API-Bank、ALFWorld、BFCL、Bamboogle和TravelPlanner五个基准测试上评估GenEnv。实验表明，该框架在7B基线模型上最高可提升智能体性能40.3%，其平均表现达到或超越了更大规模模型的水平。与基于Gemini 2.5 Pro的离线数据增强方法相比，GenEnv仅需三分之一的数据量即可实现更优性能。通过从静态监督转向自适应模拟，GenEnv为扩展智能体能力提供了一条高效的数据利用路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19682) | [arXiv](https://arxiv.org/abs/2512.19682)



---

### 11. StoryMem：基于记忆机制的多镜头长视频叙事生成

**原文标题：** StoryMem: Multi-shot Long Video Storytelling with Memory

**摘要：**
视觉叙事任务要求生成具备电影级画质与长程一致性的多镜头视频。受人类记忆机制启发，我们提出StoryMem范式，将长视频叙事任务重构为基于显式视觉记忆的迭代式镜头合成过程，从而将预训练的单镜头视频扩散模型转化为多镜头叙事生成器。该范式通过创新的记忆到视频（M2V）架构实现，该架构维护着由历史生成镜头关键帧构成的紧凑动态记忆库。存储的记忆通过潜在空间拼接与负向RoPE偏移技术注入单镜头视频扩散模型，仅需LoRA微调即可完成适配。结合语义关键帧选择策略与美学偏好过滤机制，进一步保障了生成过程中记忆信息的高效性与稳定性。此外，该框架天然支持平滑镜头转场与定制化叙事生成应用。为推进评估标准化，我们构建了ST-Bench——一个面向多镜头视频叙事的多样化评测基准。大量实验表明，StoryMem在保持高美学质量与提示词遵循度的同时，相比现有方法实现了更优的跨镜头一致性，标志着向连贯分钟级视频叙事生成迈出了重要一步。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19539) | [arXiv](https://arxiv.org/abs/2512.19539)



---

### 12. LoPA：基于前瞻并行解码的大规模扩散语言模型推理加速

**原文标题：** LoPA: Scaling dLLM Inference via Lookahead Parallel Decoding

**摘要：**
扩散大语言模型（dLLMs）已展现出高速推理的重要潜力。然而，当前基于置信度的解码策略受限于并行度不足，通常每个前向传播仅能生成1-3个词元（TPF）。本研究首次发现dLLM推理的并行度对词元填充顺序（TFO）具有高度敏感性。为此，我们提出无需训练、即插即用的前瞻并行解码算法LoPA，通过优化TFO实现推理加速。LoPA通过并行分支同步探索不同候选TFO，并依据分支置信度筛选出最具未来并行潜力的顺序。将LoPA应用于当前最先进的D2F模型后，解码效率获得显著提升：在GSM8K数据集上，D2F-Dream模型的TPF提升至10.1，同时保持优于Dream基准模型的性能。为支撑此突破性并行规模，我们进一步开发了具备分支并行特性的多设备推理系统，在多GPU部署环境下实现了1073.9 tokens/s的单样本吞吐量。代码已开源：https://github.com/zhijie-group/LoPA。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.16229) | [arXiv](https://arxiv.org/abs/2512.16229)



---

### 13. MobileWorld：在智能体-用户交互及MCP增强环境中的自主移动智能体基准测试

**原文标题：** MobileWorld: Benchmarking Autonomous Mobile Agents in Agent-User Interactive, and MCP-Augmented Environments

**摘要：**
在现有的在线移动使用基准测试中，AndroidWorld因其可复现的环境与确定性评估已成为主流基准；然而，近期智能体成功率超过90%的现象表明该基准已趋饱和，亟需更具挑战性的新基准。此外，该环境缺失电子商务与企业通讯等关键应用类别，且未能体现用户指令模糊、工具混合使用等真实移动使用场景特征。为弥补这一差距，我们提出MobileWorld——一个显著更具挑战性且能更好反映真实移动使用场景的基准测试，涵盖20个应用程序中的201项任务，同时保持与AndroidWorld同等的可复现评估水平。MobileWorld的挑战性主要体现在两方面：其一，它强调跨应用交互的长周期任务——与AndroidWorld相比，MobileWorld平均需要近两倍的任务完成步骤（27.8步对14.3步），且包含更多跨应用任务（62.2%对9.5%）；其二，MobileWorld突破标准图形界面操作范畴，引入智能体-用户交互及MCP增强任务等新型任务类别。为确保评估可靠性，我们提供基于快照的容器化环境与精确功能验证机制，包括后端数据库检查与任务回调接口。我们进一步开发了具有扩展动作空间的规划-执行智能体框架，以支持用户交互及MCP调用。实验结果显示，相较于AndroidWorld，各类方法性能均出现显著下降：最佳智能体框架与端到端模型的成功率分别为51.7%和20.9%。分析表明，现有模型在用户交互与MCP调用方面存在明显不足，这为构建更鲁棒的下一代移动智能技术提供了战略发展路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19432) | [arXiv](https://arxiv.org/abs/2512.19432)



---

### 14. 推理调色板：通过潜在情境化调控推理以实现（视觉）语言模型的可控探索

**原文标题：** Reasoning Palette: Modulating Reasoning via Latent Contextualization for Controllable Exploration for (V)LMs

**摘要：**
探索能力深刻影响着大型（视觉）语言模型的推理时性能与强化学习训练效果，因为随机采样常产生冗余的推理路径且缺乏高层级多样性。本文提出“推理调色板”——一种新颖的潜在调制框架，通过引入随机潜在变量实现策略性情境化，在词元生成前引导模型的内部规划。该潜在情境通过变分自编码器从问题-答案对的平均池化嵌入中推断得出，每个采样潜在变量可能编码独特的推理情境。在推理阶段，采样的潜在变量被解码为可学习的词元前缀并附加至输入提示前，从而调控模型的内部推理轨迹。通过这种方式，模型在输出生成前对推理策略进行内部采样，进而塑造整个响应序列的风格与结构。简短的监督微调预热阶段使模型能够适应这种潜在条件调节。在强化学习优化中，推理调色板通过按需注入多样化推理模式促进结构化探索，显著提升探索效率与持续学习能力。在多个推理基准测试上的实验表明，本方法能实现对（视觉）语言模型策略行为的可解释与可控调节，相比标准强化学习方法取得持续的性能提升。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.17206) | [arXiv](https://arxiv.org/abs/2512.17206)



---

### 15. 是否存在优于高斯分布的源分布？图像流匹配中源分布的探索

**原文标题：** Is There a Better Source Distribution than Gaussian? Exploring Source Distributions for Image Flow Matching

**摘要：**
流匹配作为一种强大的生成建模方法，其源分布的选择具有灵活性。尽管高斯分布被广泛使用，但在高维数据生成中潜在更优的替代方案仍鲜有探索。本文提出了一种新颖的二维模拟方法，在可解释的二维设置中捕捉高维几何特性，使我们能够分析训练过程中流匹配的学习动态。基于此分析，我们得出关于流匹配行为的若干关键发现：（1）密度近似可能因模态差异而降低性能；（2）方向对齐在过度集中时会出现路径纠缠问题；（3）高斯分布的全向覆盖能确保稳健学习；（4）范数失准会产生显著学习成本。基于这些发现，我们提出一个结合范数对齐训练与方向剪枝采样的实用框架。该方法既保持了稳定流学习所必需的全向监督鲁棒性，又在推理阶段消除了数据稀疏区域的初始化需求。值得注意的是，我们的剪枝策略可应用于任何使用高斯源分布训练的流匹配模型，无需重新训练即可获得即时性能提升。实证评估表明，该方法在生成质量和采样效率上均取得持续改进。我们的研究为源分布设计提供了实用见解与指导原则，并提出了一种可直接应用于改进现有流匹配模型的技术。代码已开源：https://github.com/kwanseokk/SourceFM。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.18184) | [arXiv](https://arxiv.org/abs/2512.18184)



---

### 16. Real2Edit2Real：通过三维控制界面生成机器人演示数据

**原文标题：** Real2Edit2Real: Generating Robotic Demonstrations via a 3D Control Interface

**摘要：**
机器人学习的最新进展得益于大规模数据集和强大的视觉运动策略架构，但策略的鲁棒性仍受限于收集多样化演示数据的高昂成本，尤其是在操作任务的空间泛化方面。为减少重复性数据采集，本文提出Real2Edit2Real框架，该框架通过三维控制界面将三维可编辑性与二维视觉数据相结合，从而生成新的演示数据。我们的方法首先利用度量尺度三维重建模型，从多视角RGB观测中重建场景几何结构。基于重建的几何结构，我们在点云上进行深度可靠的三维编辑以生成新的操作轨迹，同时对机器人位姿进行几何校正以恢复物理一致的深度信息，这为合成新演示提供了可靠条件。最后，我们提出一种以深度为主要控制信号的多条件视频生成模型，结合动作图、边缘图和射线图，合成空间增强的多视角操作视频。在四个真实世界操作任务上的实验表明，仅使用1-5个原始演示生成数据训练的策略，其性能可达到甚至超越使用50个真实世界演示训练的策略，数据效率提升高达10-50倍。此外，在高度和纹理编辑方面的实验结果证明了该框架的灵活性和可扩展性，表明其具备成为统一数据生成框架的潜力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19402) | [arXiv](https://arxiv.org/abs/2512.19402)



---

### 17. 能否核对无误？风险投资领域自主法律智能体的发展路径

**原文标题：** Does It Tie Out? Towards Autonomous Legal Agents in Venture Capital

**摘要：**
在完成风险投资融资轮次前，律师需开展包括股权结构表核验在内的尽职调查工作——即通过大量底层法律文件验证每项证券（如股份、期权、认股权证）及发行条款（如归属时间表、加速触发条件、转让限制）的合规性。尽管大语言模型在法律基准测试中持续进步，但诸如股权结构核验这类专业化法律工作流程，即使对现有强智能体系统而言仍难以实现。该任务需要多文档推理能力、严格的证据可追溯性以及确定性输出，而现有技术方案尚无法稳定满足这些要求。本文将股权结构核验界定为法律人工智能的现实基准测试案例，系统分析与比较现有智能体系统的表现，并提出一种面向核验自动化的世界模型架构——该架构更广泛地可作为应用型法律智能的基础框架。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.18658) | [arXiv](https://arxiv.org/abs/2512.18658)



---

### 18. CASA：通过自注意力实现跨模态注意力的高效视觉语言融合

**原文标题：** CASA: Cross-Attention via Self-Attention for Efficient Vision-Language Fusion

**摘要：**
视觉语言模型通常通过将预训练视觉编码器提取的图像标记插入语言模型的文本流中进行训练。这种方法允许文本与图像信息在模型内部充分交互，但在处理高分辨率图像、长对话或流式视频时，会带来极高的内存和计算成本。采用跨注意力机制的视觉语言模型是标记插入方法的高效替代方案，但其性能存在明显差距，尤其在涉及细粒度视觉细节的任务中。我们发现，提升此类模型性能的关键在于在专用的跨注意力层中同时实现局部文本到文本的交互。基于此，我们提出CASA（通过自注意力实现跨模态注意力），这是一种简单高效的范式。该范式在常见图像理解基准测试中显著缩小了与全标记插入方法的性能差距，同时在处理流式视频描述等长上下文多模态任务时，保持了与跨注意力模型相同的可扩展性。示例与代码请访问项目页面：https://kyutai.org/casa。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19535) | [arXiv](https://arxiv.org/abs/2512.19535)



---

### 19. MatSpray：将二维材料世界知识融合至三维几何结构

**原文标题：** MatSpray: Fusing 2D Material World Knowledge on 3D Geometry

**摘要：**
在游戏和电影产业中，手动建模材料参数与三维几何结构是一项耗时但至关重要的任务。尽管三维重建技术的最新进展已能实现对场景几何结构与外观的精确近似，但由于缺乏精确且空间变化的材料参数，这些方法在重光照场景中往往表现不足。与此同时，基于二维图像操作的扩散模型在预测基于物理的渲染（PBR）属性（如反照率、粗糙度与金属度）方面展现出强大性能。然而，将这些二维材质贴图迁移至重建的三维几何结构上仍面临重大挑战。本文提出一种融合新型学习方法与投影技术的框架，将二维材料数据整合至三维几何结构中。我们首先通过高斯泼溅技术重建场景几何结构，并利用扩散模型从输入图像生成反照率、粗糙度与金属度的二维贴图。任何能够将图像或视频转换为PBR材质的现有扩散模型均可应用于此流程。随后，通过优化基于图像的损失函数或借助高斯光线追踪直接将材料参数投影至高斯体素，将预测结果进一步整合至三维表征中。为提升细节精度与多视角一致性，我们进一步引入轻量级神经优化步骤（神经融合器），该模块以光线追踪材料特征为输入，生成精细化调整参数。实验结果表明，所提方法在量化指标与视觉真实感方面均优于现有技术，能够从重建场景中生成更精确、可重光照且具有照片级真实感的渲染结果，显著提升了内容生产流程中资产创建工作的真实感与效率。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.18314) | [arXiv](https://arxiv.org/abs/2512.18314)



---

### 20. 部件识别：三维部件分割与命名

**原文标题：** Name That Part: 3D Part Segmentation and Naming

**摘要：**
本文研究语义化三维部件分割问题，即如何将物体分解为具有明确语义的部件。尽管现有数据集包含部件标注，但不同数据集间的定义标准不一致，限制了模型的鲁棒性训练。先前方法仅能生成未标注的分解结果或检索缺乏完整形状标注的单一部件。我们提出ALIGN-Parts方法，将部件命名构建为直接集合对齐任务。该方法将三维形状分解为部件单元——隐式三维部件表征，并通过二分图匹配与部件描述进行关联。我们融合了三维部件场的几何特征、多视角视觉特征的外观信息，以及语言模型生成的功能描述所包含的语义知识。通过文本对齐损失函数，部件单元与文本共享嵌入空间，在数据充足的条件下可实现理论上的开放词汇匹配。我们提出的高效、新颖的单次三维部件分割与命名方法，可应用于多项下游任务，包括作为可扩展的标注引擎。由于本模型支持对任意描述的零样本匹配，并对已知类别提供置信度校准预测，经人工验证后我们构建了统一的本体框架，整合了PartNet、3DCoMPaT++和Find3D数据集，涵盖1,794个独立三维部件。同时展示了新构建的Tex-Parts数据集案例，并针对命名三维部件分割任务提出了两项创新评估指标。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.18003) | [arXiv](https://arxiv.org/abs/2512.18003)



---

### 21. 从形式语言与自然语言视角理解大语言模型的三段论推理能力

**原文标题：** Understanding Syllogistic Reasoning in LLMs from Formal and Natural Language Perspectives

**摘要：**
本研究从逻辑学与自然语言双重视角探讨大语言模型的三段论推理能力。在此过程中，我们深入考察大语言模型的基础推理机制及其研究发展趋势。为支撑研究，我们选取了14个大型语言模型，分别从符号推理与自然语言理解两个维度系统检验其三段论推理表现。研究结果表明，虽然此类推理能力并非所有大语言模型普遍具备的涌现特性，但部分模型在符号推理任务中展现的完美性能促使我们思考：大语言模型是否正逐渐演化为形式化推理机制，而非精确复现人类推理的微妙特征。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.12620) | [arXiv](https://arxiv.org/abs/2512.12620)



---

### 22. Over++：面向图层交互效果的生成式视频合成

**原文标题：** Over++: Generative Video Compositing for Layer Interaction Effects

**摘要：**
在专业视频合成工作流程中，艺术家需要手动创建前景主体与背景图层之间的环境交互效果，例如阴影、反射、扬尘与飞溅等。现有视频生成模型难以在添加此类效果的同时保持输入视频内容，而当前视频修复方法要么需要逐帧的高成本掩码标注，要么会产生不符合物理规律的结果。本文提出增强合成这一新任务，其目标是在保持原始场景的前提下，根据文本提示与输入视频图层合成逼真的半透明环境效果。针对该任务，我们提出Over++视频特效生成框架，该框架无需对相机位姿、场景静止性或深度监督进行预设。我们构建了专为此任务设计的配对特效数据集，并提出保留文本驱动编辑能力的非配对增强策略。本方法还支持可选掩码控制与关键帧引导，且无需密集标注。尽管在有限数据上训练，Over++仍能生成多样化且逼真的环境效果，并在特效生成与场景保持两方面均优于现有基线方法。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19661) | [arXiv](https://arxiv.org/abs/2512.19661)



---

### 23. 基于脑电轴的阅读与调控大语言模型状态方法

**原文标题：** Brain-Grounded Axes for Reading and Steering LLM States

**摘要：**
现有大语言模型（LLM）可解释性方法通常从文本监督中推导方向向量，但此类方法往往缺乏外部实体基础。本研究提出以人脑活动作为坐标系（而非训练信号）来读取和调控LLM内部状态。基于SMN4Lang脑磁图数据集，我们构建了词级相位锁定值（PLV）模式的脑图谱，并通过独立成分分析提取潜在坐标轴。使用独立词典和基于命名实体识别的标签验证坐标轴有效性（词性/对数词频作为基准检验），随后训练轻量适配器将LLM隐藏状态映射至这些脑电轴，且无需微调LLM。沿脑电轴方向调控模型时，在TinyLlama中间层发现稳健的词汇轴（与词频相关），该效应在困惑度匹配控制实验中依然存在；脑电轴与文本探针对比显示，脑电轴在更低困惑度下产生更大的对数词频偏移。功能/内容轴（第13轴）在TinyLlama、Qwen2-0.5B和GPT-2中呈现一致的调控效果，并获得困惑度匹配的文本层面佐证。TinyLlama第4层的效应显著但不稳定，故将其视为次要发现（见附录）。当使用无GPT嵌入变化特征的图谱或word2vec嵌入重建图谱时，坐标轴结构保持稳定（匹配轴间|r|=0.64-0.95），降低了循环论证风险。探索性功能磁共振锚定实验提示嵌入变化与对数词频可能存在潜在对应关系，但该效应对血流动力学建模假设敏感，仅作为群体层面证据。这些研究结果支持一种新型交互范式：基于神经生理学的坐标轴为LLM行为提供了可解释且可控的调控路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19399) | [arXiv](https://arxiv.org/abs/2512.19399)



---

### 24. SecureCode v2.0：用于训练安全感知代码生成模型的生产级数据集

**原文标题：** SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models

**摘要：**
AI助手在45%的安全相关场景中会产生易受攻击的代码，从而大规模地将漏洞引入生产系统。然而，现有的安全编码数据集存在不足：它们缺乏实际事件基础，无法满足现代训练所需的规模，并且缺少开发者在生产部署中所需的操作安全上下文。我们提出了SecureCode v2.0，这是一个包含1,215个通过结构验证和专家安全审查的、以安全为中心的编码示例的生产级数据集。每个示例均关联到具有CVE参考的实际记录安全事件，提供易受攻击和安全两种实现方式，展示具体攻击方法，并包含纵深防御的操作指南。该数据集涵盖11个漏洞类别（完整的OWASP Top 10:2025加上AI/ML安全威胁）和11种编程语言（Python、JavaScript、Java、Go、PHP、C#、TypeScript、Ruby、Rust、Kotlin以及用于基础设施即代码的YAML）。

我们的质量保证框架确保所有示例均基于真实事件。每个示例包含SIEM集成策略、基础设施加固建议（Docker、AppArmor、WAF配置）以及使用语言适配框架的测试方法。数据集采用四轮对话结构模拟真实的开发者-AI交互过程，从基础实现逐步升级到高级安全考量与纵深防御指导。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.18542) | [arXiv](https://arxiv.org/abs/2512.18542)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2025-12-23_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)