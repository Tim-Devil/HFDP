<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hugging Face 论文日报 - 2026-01-29</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
            padding: 20px;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 30px;
            font-size: 28px;
        }
        
        h1 img {
            vertical-align: middle;
            margin-right: 10px;
        }
        
        h2 {
            color: #34495e;
            margin-top: 40px;
            margin-bottom: 20px;
            font-size: 24px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }
        
        h3 {
            color: #2c3e50;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 20px;
        }
        
        p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        ul {
            margin-left: 20px;
            margin-bottom: 20px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        a {
            color: #3498db;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        strong {
            color: #2c3e50;
            font-weight: 600;
        }
        
        hr {
            border: none;
            border-top: 1px solid #e0e0e0;
            margin: 30px 0;
        }
        
        /* 关键修复:限制图片宽度 */
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        /* 确保图片容器也有宽度限制 */
        p img {
            max-width: 100%;
        }
        
        /* 论文详情区域样式 */
        .paper-section {
            background-color: #f9f9f9;
            padding: 20px;
            border-radius: 6px;
            margin-bottom: 20px;
        }
        
        /* 统计信息样式 */
        .stats {
            background-color: #e8f4f8;
            padding: 15px;
            border-radius: 6px;
            margin-bottom: 20px;
        }
        
        /* 响应式设计 */
        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 24px;
            }
            
            h2 {
                font-size: 20px;
            }
            
            h3 {
                font-size: 18px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1><img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-29 论文日报</h1>
<h2>📊 今日论文统计</h2>
<ul>
<li>总论文数：22</li>
<li>热门领域：RL, LLM, GPT, Transformer</li>
</ul>
<h2>📝 论文详情</h2>
<h3>1. 越难越好：通过难度感知GRPO与多角度问题重构提升数学推理能力</h3>
<p><strong>原文标题：</strong> Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation</p>
<p><strong>摘要：</strong>
基于可验证奖励的强化学习（RLVR）为增强大模型的数学推理能力提供了一种稳健机制。然而，我们发现现有方法在算法和数据层面均存在对更具挑战性问题系统性重视不足的问题，尽管这类问题对于提升未充分发展的能力至关重要。算法层面，广泛使用的组相对策略优化（GRPO）存在一种隐性失衡：对于更难的问题，策略更新的幅度反而更小。数据层面，现有的增强方法主要通过改写问题来增加多样性，未能系统性地提升问题的内在难度。为解决这些问题，我们提出了一个双轮驱动的MathForge框架，旨在从算法和数据两个维度共同聚焦更难的问题，以提升数学推理能力。该框架包含难度感知组策略优化（DGPO）算法与多角度问题重构（MQR）策略。具体而言，DGPO首先通过难度平衡的组优势估计纠正GRPO中的隐性失衡，并进一步通过难度感知的问题级加权机制优先处理更难的问题。同时，MQR从多个角度重构问题，在保持原标准答案不变的前提下提升问题难度。总体而言，MathForge形成了一个协同增强的闭环：MQR拓展了数据边界，而DGPO则能高效地从增强数据中学习。大量实验表明，MathForge在多种数学推理任务上均显著优于现有方法。代码及增强数据均已公开于 https://github.com/AMAP-ML/MathForge。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20614">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20614">arXiv</a></p>
<hr />
<h3>2. 开源世界模型的演进</h3>
<p><strong>原文标题：</strong> Advancing Open-source World Models</p>
<p><strong>摘要：</strong>
本文介绍LingBot-World，一款基于视频生成技术开发的开源世界模拟器。作为顶尖的世界模型，LingBot-World具备以下特性：（1）在广泛环境中保持高保真度与强健的动态表现力，涵盖写实场景、科学情境、卡通风格等多种类型；（2）实现分钟级时序预测能力，同时保持长期上下文一致性，即具备“长时记忆”特性；（3）支持实时交互功能，在以每秒16帧生成时延低于1秒。我们公开提供代码与模型资源，旨在缩小开源与闭源技术之间的差距。我们相信此次开源将推动内容创作、游戏开发、机器人学习等领域的实际应用，为研究社区注入创新动力。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20540">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20540">arXiv</a></p>
<hr />
<h3>3. Innovator-VL：面向科学发现的多模态大语言模型</h3>
<p><strong>原文标题：</strong> Innovator-VL: A Multimodal Large Language Model for Scientific Discovery</p>
<p><strong>摘要：</strong>
本文提出Innovator-VL，一个面向科学领域的多模态大语言模型，旨在提升跨学科科学理解与推理能力，同时在通用视觉任务上保持优异性能。与当前依赖海量领域预训练与不透明技术流程的趋势不同，本研究证明，通过原则性的训练设计与透明化的方法体系，能够在显著降低数据需求的前提下实现强大的科学智能。（i）首先，我们提供了一套完全透明、端到端可复现的训练流程，涵盖数据收集、清洗、预处理、监督微调、强化学习及评估环节，并附有详细的优化方案，便于学界系统性地扩展研究。（ii）其次，Innovator-VL展现出显著的数据效率，仅使用不足五百万条精选样本（无需大规模预训练）即在多项科学任务中取得具有竞争力的性能。这些结果表明，通过原则性数据筛选而非盲目扩大规模，同样可以实现有效的推理能力。（iii）再次，该模型表现出强大的泛化能力，在通用视觉、多模态推理及科学基准测试中均达到先进水平，说明科学对齐能力可融入统一模型而不损害其通用性能。我们的实践表明，即使不依赖大规模数据，也能构建高效、可复现、高性能的科学多模态模型，为未来研究提供了实用基础。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.19325">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.19325">arXiv</a></p>
<hr />
<h3>4. DeepSeek-OCR 2：视觉因果流</h3>
<p><strong>原文标题：</strong> DeepSeek-OCR 2: Visual Causal Flow</p>
<p><strong>摘要：</strong>
本文提出DeepSeek-OCR 2模型，旨在探究一种新型编码器——DeepEncoder V2——能否根据图像语义动态重排视觉标记的可行性。传统视觉语言模型在处理图像时，始终以固定的光栅扫描顺序（从左上方至右下方）和静态位置编码将视觉标记输入大语言模型。然而，这种处理方式与人类视觉感知机制相悖，后者遵循由内在逻辑结构驱动的灵活且语义连贯的扫描模式。特别是在处理复杂版式图像时，人类视觉系统展现出基于因果关系的序列化处理特性。受此认知机制启发，DeepEncoder V2被设计为具备因果推理能力的编码器，使其在基于大语言模型的内容解析前能够智能地重排视觉标记。本研究探索了一种新颖范式：是否可以通过两级级联的一维因果推理结构有效实现二维图像理解，从而提供一种有望实现真正二维推理的全新架构方案。代码与模型权重已公开于http://github.com/deepseek-ai/DeepSeek-OCR-2。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20552">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20552">arXiv</a></p>
<hr />
<h3>5. Spark：基于动态分支的长时程智能体学习策略感知探索框架</h3>
<p><strong>原文标题：</strong> Spark: Strategic Policy-Aware Exploration via Dynamic Branching for Long-Horizon Agentic Learning</p>
<p><strong>摘要：</strong>
强化学习已赋能大语言模型成为智能体，但在有限资源下训练其执行长时程任务仍面临挑战，主要源于高质量轨迹的稀缺性。现有方法通常通过扩大轨迹采样规模并在中间步骤中平均分配计算资源，这种模式本质上会在平凡步骤中浪费大量计算资源，且无法保证样本质量。为此，我们提出Spark（基于关键状态动态分支的策略感知探索框架），该创新框架通过在关键决策状态选择性分支以实现资源高效的探索。我们的核心思路是在关键决策点激活自适应分支探索机制，以探测潜在的高价值轨迹，从而实现以采样质量优先而非盲目覆盖的精准资源分配。该设计利用智能体内在的决策信号降低对人类先验知识的依赖，使智能体能够自主扩展探索范围并实现更强的泛化能力。在多样化任务（如具身规划）上的实验表明，Spark能以显著更少的训练样本获得更高的成功率，即使在未见场景中也展现出鲁棒的泛化性能。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20209">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20209">arXiv</a></p>
<hr />
<h3>6. AACR-Bench：基于全仓库级上下文的自动代码评审评估基准</h3>
<p><strong>原文标题：</strong> AACR-Bench: Evaluating Automatic Code Review with Holistic Repository-Level Context</p>
<p><strong>摘要：</strong>
高质量的评估基准对于在自动代码评审（ACR）中部署大语言模型（LLMs）至关重要。然而，现有基准存在两个关键局限：首先，在仓库级上下文中缺乏多语言支持，限制了评估结果的普适性；其次，依赖从原始拉取请求（PR）评论中提取的嘈杂且不完整的真实数据，制约了问题检测的范围。为应对这些挑战，我们提出了AACR-Bench——一个提供跨编程语言完整跨文件上下文的综合性基准。与传统数据集不同，AACR-Bench采用“AI辅助、专家验证”的标注流程，能够发现原始PR中常被忽略的潜在缺陷，从而使缺陷覆盖率提升285%。基于AACR-Bench对主流LLMs进行的广泛评估表明，由于数据局限性，以往的评估可能误判或仅部分捕捉了模型能力。本研究为ACR评估建立了更严谨的标准，并为基于LLM的ACR提供了新的见解，即：上下文的粒度/层级以及检索方法的选择会显著影响ACR性能，且这种影响因LLM类型、编程语言以及LLM使用范式（例如是否采用智能体架构）而异。我们的评估集代码、数据及其他相关资源已公开于https://github.com/alibaba/aacr-bench。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.19494">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.19494">arXiv</a></p>
<hr />
<h3>7. 语言模型中的线性表征在对话过程中可能发生显著变化</h3>
<p><strong>原文标题：</strong> Linear representations in language models can change dramatically over a conversation</p>
<p><strong>摘要：</strong>
语言模型表征通常包含与高层概念相对应的线性方向。本研究探讨这些表征的动态特性：在（模拟）对话语境中，这些维度上的表征如何演变。我们发现线性表征在对话过程中可能发生显著变化：例如，对话初期被表征为事实的信息可能在对话结束时被表征为非事实，反之亦然。这种变化具有内容依赖性：对话相关信息可能发生改变，而通用信息通常保持稳定。即使对于能够将事实性与表层响应模式解耦的维度，这些变化依然稳健，且在不同模型架构和模型层中均有体现。此类表征变化无需依赖策略性对话——即使回放由完全不同的模型编写的对话脚本也能产生类似变化。然而，若仅将科幻故事作为明确标注的上下文背景，其适应效应则显著减弱。我们还证明，沿着特定表征方向进行引导在对话不同阶段可能产生截然不同的效果。这些结果与以下观点相符：表征的演变可能是模型响应对话所提示的特定角色而产生的适应性变化。本研究发现可能对可解释性与引导技术构成挑战——具体而言，静态的特征/方向解释方法，或假设特定特征范围始终对应特定真实值的探测方法，都可能产生误导性结论。然而，这类表征动态特性也为理解模型如何适应语境开辟了令人振奋的新研究方向。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20834">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20834">arXiv</a></p>
<hr />
<h3>8. 基于自蒸馏的强化学习</h3>
<p><strong>原文标题：</strong> Reinforcement Learning via Self-Distillation</p>
<p><strong>摘要：</strong>
大型语言模型日益在代码和数学等可验证领域通过强化学习进行后训练。然而，当前基于可验证奖励的强化学习方法仅从每次尝试的标量结果奖励中学习，形成了严重的信用分配瓶颈。许多可验证环境实际能提供丰富的文本反馈（如运行时错误或评估意见），以解释尝试失败的原因。我们将此场景形式化为具有丰富反馈的强化学习，并提出自蒸馏策略优化方法，该方法能够将标记化反馈转化为密集学习信号，无需依赖外部教师或显式奖励模型。SDPO将基于反馈调节的当前模型视为自教师，并将其反馈感知的下一标记预测蒸馏回策略中。通过这种方式，SDPO利用模型在上下文中回溯识别自身错误的能力。在科学推理、工具使用以及LiveCodeBench v6的竞争性编程任务中，SDPO相较于强RLVR基线方法显著提升了样本效率和最终准确率。值得注意的是，在仅返回标量反馈的标准RLVR环境中，SDPO通过将成功轨迹作为失败尝试的隐式反馈，同样超越了基线方法。最后，在测试阶段对单个问题应用SDPO可加速困难二元奖励任务的探索过程，以仅需三分之一尝试次数即可达到与k最优采样或多轮对话相同的发现概率。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20802">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20802">arXiv</a></p>
<hr />
<h3>9. SERA：软验证高效代码库智能体</h3>
<p><strong>原文标题：</strong> SERA: Soft-Verified Efficient Repository Agents</p>
<p><strong>摘要：</strong>
开源权重编码智能体相较于闭源系统应具备一项根本优势：它们能够针对私有代码库进行专业化定制，将特定仓库信息直接编码至权重中。然而训练成本与复杂性使得这一优势长期停留于理论层面。我们证明其实用化现已可行。本文提出软验证高效代码库智能体（SERA），这是一种高效的编码智能体训练方法，能够快速、低成本地创建针对私有代码库的专业化智能体。仅通过监督微调（SFT），SERA即在完全开源（开放数据、方法、代码）模型中取得最先进的成果，同时达到如Devstral-Small-2等前沿开源权重模型的性能水平。SERA模型的创建成本比强化学习方法降低26倍，比现有合成数据方法降低57倍即可达到同等性能。我们提出的软验证生成（SVG）方法能够从单一代码库生成数千条训练轨迹。结合成本效益优势，该方法实现了对私有代码库的专业化适配。除仓库专业化应用外，我们将SVG扩展至更大规模的代码库集合，生成超过20万条合成训练轨迹。基于该数据集，我们深入分析了编码智能体训练的缩放规律、消融实验及混杂因素。总体而言，我们相信这项工作将极大加速开源编码智能体的研究进程，并彰显可适配私有代码库的开源模型优势。我们将SERA作为Ai2开源编码智能体系列的首个模型公开发布，同时开放全部代码、数据及Claude Code集成方案，以支持研究社区的发展。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20789">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20789">arXiv</a></p>
<hr />
<h3>10. VERGE：可验证大语言模型推理的形式化精炼与引导引擎</h3>
<p><strong>原文标题：</strong> VERGE: Formal Refinement and Guidance Engine for Verifiable LLM Reasoning</p>
<p><strong>摘要：</strong>
尽管大语言模型（LLM）具备流畅的语法生成能力，但在高风险领域中确保其逻辑正确性仍是一项根本性挑战。本文提出一种神经符号框架，将LLM与可满足性模理论（SMT）求解器相结合，通过迭代精炼生成可验证引导的答案。该方法将LLM输出分解为原子主张，将其自动形式化为⼀阶逻辑表达式，并利用自动定理证明技术验证其逻辑一致性。我们引入三项关键创新：（1）通过形式语义等价性检验实现多模型共识，确保候选答案间的逻辑层面对齐，消除表层形式指标的语法偏差；（2）语义路由机制，将不同类型的主张导向适配的验证策略：逻辑主张使用符号求解器，常识推理则采用LLM集成验证；（3）基于最小修正子集（MCS）的精确逻辑错误定位技术，精确定位需要修订的主张子集，将二元失败信号转化为可操作的反馈。本框架根据主张的逻辑状态进行分类，并将多重验证信号聚合为具有方差惩罚的统一评分。系统利用结构化反馈迭代优化答案，直至满足接受标准或达到收敛状态。这种混合方法在可行处提供形式化保证，在其他场景采用共识验证，从而推进可信人工智能的发展。基于GPT-OSS-120B模型的实验表明，在一系列推理基准测试中，VERGE在收敛时的平均性能较单次推理方法提升18.7%。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20055">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20055">arXiv</a></p>
<hr />
<h3>11. OmegaUse：构建面向自主任务执行的通用图形用户界面智能体</h3>
<p><strong>原文标题：</strong> OmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Execution</p>
<p><strong>摘要：</strong>
图形用户界面（GUI）智能体在赋能基础模型完成现实世界任务方面展现出巨大潜力，有望彻底改变人机交互模式并提升人类生产效率。本报告提出OmegaUse——一个支持跨移动端与桌面端平台自主任务执行的通用GUI智能体模型，涵盖计算机使用与手机操作两大场景。构建高效的GUI智能体模型依赖于两大要素：（1）高质量数据与（2）有效的训练方法。为此，我们设计了精密的数椐构建流程与解耦式训练范式。在数据构建方面，我们整合了严格筛选的开源数据集，并提出一种创新的自动合成框架，通过自底向上的自主探索与自顶向下的分类体系引导生成相结合的方式，创造高保真合成数据。在训练方法上，为充分发挥数据价值，我们采用两阶段策略：首先通过监督微调建立基础交互语法，继而采用分组相对策略优化算法提升空间定位与序列规划能力。为平衡计算效率与智能体推理能力，OmegaUse基于混合专家架构构建。为评估离线环境下的跨终端能力，我们推出OS-Nav基准测试套件，涵盖多操作系统场景：面向中文安卓移动环境的ChiM-Nav，以及聚焦Ubuntu系统日常桌面交互的Ubu-Nav。大量实验表明，OmegaUse在现有GUI基准测试中表现卓越，在ScreenSpot-V2上达到96.3%的最先进水平，在AndroidControl上获得79.1%的领先步骤成功率。在OS-Nav测试中，OmegaUse同样表现强劲，于ChiM-Nav达到74.24%的步骤成功率，在Ubu-Nav上取得55.9%的平均成功率。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20380">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20380">arXiv</a></p>
<hr />
<h3>12. 面向大语言模型推理的群体分布鲁棒优化驱动强化学习</h3>
<p><strong>原文标题：</strong> Group Distributionally Robust Optimization-Driven Reinforcement Learning for LLM Reasoning</p>
<p><strong>摘要：</strong>
大语言模型推理能力的近期进展日益依赖于训练后损失函数与对齐策略的优化。然而，现有强化学习范式（如群体相对策略优化）仍受限于静态均匀性约束：采用均匀提示采样策略并为每个提示分配固定次数的推理展开。面对异构、重尾分布的推理数据，这种机制会产生结构性低效问题——在已掌握模式上浪费计算资源，同时对困难问题的长尾部分训练不足。为此，我们提出多对抗者群体分布鲁棒优化框架，这是一个以优化为核心的新型框架，通过动态调整训练分布突破均匀推理模型的限制。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.19280">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.19280">arXiv</a></p>
<hr />
<h3>13. RIR-Mega-Speech：一个包含全面声学元数据与可复现评估的混响语音语料库</h3>
<p><strong>原文标题：</strong> RIR-Mega-Speech: A Reverberant Speech Corpus with Comprehensive Acoustic Metadata and Reproducible Evaluation</p>
<p><strong>摘要：</strong>
尽管针对混响语音的研究已持续数十年，但由于多数语料库缺乏逐文件的声学标注或仅提供有限的复现文档，不同方法间的比较仍存在困难。本文提出RIR-Mega-Speech语料库，该语料库通过将LibriSpeech语音与RIR-Mega集合中约5,000条模拟房间脉冲响应进行卷积生成，总时长约117.5小时。每个文件均包含根据源脉冲响应通过明确定义、可复现流程计算得到的RT60、直达声与混响声能量比（DRR）以及清晰度指数（C_{50}）。我们同时提供了用于重建数据集和复现所有评估结果的脚本。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.19949">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.19949">arXiv</a></p>
<hr />
<h3>14. UPLiFT：基于局部注意力机制的高效像素密集特征上采样方法</h3>
<p><strong>原文标题：</strong> UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders</p>
<p><strong>摘要：</strong>
任务无关的特征上采样领域已成为一个前景广阔的研究方向，旨在从预训练的视觉骨干网络中高效生成更密集的特征。这类方法通过学习将低分辨率特征映射至高分辨率版本，能够以较低成本实现密集特征提取。早期研究多采用迭代上采样策略，而近期工作则转向基于交叉注意力的方法，但后者可能面临与待上采样骨干网络相似的计算效率扩展问题。本研究证明，迭代上采样方法仍可与基于交叉注意力的方法相竞争，且能以更低推理成本实现最优性能。我们提出UPLiFT——一种通用像素级轻量化特征转换架构，并设计高效的局部注意力算子以克服传统迭代特征上采样方法的局限。该算子采用完全局部化的注意力池化公式，实验表明局部注意力机制能使UPLiFT在上采样过程中保持特征稳定性，以低于现有像素密集特征上采样器的推理成本达到最优性能。此外，我们将UPLiFT应用于生成式下游任务，结果显示其在VAE特征上采样方面与当前最优的耦合流匹配模型具有相当性能。总体而言，UPLiFT为生成密集特征提供了一种通用且高效的解决方案。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.17950">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.17950">arXiv</a></p>
<hr />
<h3>15. 基于失败前缀条件化的饱和问题推理模型训练</h3>
<p><strong>原文标题：</strong> Training Reasoning Models on Saturated Problems via Failure-Prefix Conditioning</p>
<p><strong>摘要：</strong>
可验证奖励强化学习（RLVR）显著提升了大型语言模型（LLMs）的推理能力，但随着问题趋于饱和，训练常陷入停滞。我们发现核心挑战在于信息性失败的可及性较差：学习信号虽存在，但在标准推演中极少出现。为解决此问题，我们提出失败前缀条件化方法——一种从饱和问题中学习的简单有效策略。该方法并非从原始问题开始，而是通过将训练条件化于从罕见错误推理轨迹中提取的前缀，重新分配探索范围，从而使模型暴露于易失败状态。实验表明，失败前缀条件化带来的性能提升相当于在中等难度问题上训练的效果，同时保持了较高的标记效率。此外，我们分析了模型的鲁棒性，发现该方法能降低模型在误导性失败前缀下的性能衰减，尽管对早期正确推理的遵循程度有轻微折衷。最后，我们证明在训练中动态更新失败前缀的迭代策略，能在性能平台期后实现额外增益。总体而言，本研究结果表明失败前缀条件化为在饱和问题上延续RLVR训练提供了有效路径。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20829">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20829">arXiv</a></p>
<hr />
<h3>16. GDCNet：基于生成式差异对比的多模态讽刺检测网络</h3>
<p><strong>原文标题：</strong> GDCNet: Generative Discrepancy Comparison Network for Multimodal Sarcasm Detection</p>
<p><strong>摘要：</strong>
多模态讽刺检测旨在通过建模跨模态语义不一致性来识别图文对中的讽刺表达。现有方法通常利用跨模态嵌入失配来检测不一致性，但当视觉与文本内容关联松散或语义间接时效果受限。尽管近期研究借助大语言模型生成讽刺线索，但生成结果的固有多样性和主观性常引入噪声。为应对这些局限，本文提出生成式差异对比网络。该框架通过使用多模态大语言模型生成的描述性、事实性图像标题作为稳定语义锚点，以捕捉跨模态冲突。具体而言，GDCNet计算生成的目标描述与原始文本之间的语义及情感差异，同时评估视觉-文本保真度。这些差异特征通过门控模块与视觉、文本表征融合，实现模态贡献的自适应平衡。在多模态讽刺检测基准上的大量实验表明，GDCNet在准确性与鲁棒性方面均显著优于现有方法，在MMSD2.0基准上取得了最先进的性能。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20618">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20618">arXiv</a></p>
<hr />
<h3>17. 人工智能如何影响技能形成</h3>
<p><strong>原文标题：</strong> How AI Impacts Skill Formation</p>
<p><strong>摘要：</strong>
人工智能辅助在各专业领域显著提升了生产力，尤其对于新手工作者而言。然而，这种辅助如何影响有效监督人工智能所需技能的发展仍不明确。新手工作者若过度依赖人工智能来完成不熟悉的任务，可能会在此过程中损害自身技能的习得。我们通过随机实验研究了开发人员在使用和未使用人工智能辅助的情况下，如何掌握新的异步编程库。研究发现，人工智能的使用会损害概念理解、代码阅读和调试能力，且平均而言并未带来显著的效率提升。完全委托编码任务的参与者虽显示出一定的生产力改善，但这是以牺牲对编程库的学习为代价的。我们识别出六种不同的人工智能交互模式，其中三种涉及认知参与，即使在参与者接受人工智能辅助的情况下也能保持学习效果。我们的研究结果表明，人工智能增强的生产力并非通往能力的捷径，在将人工智能辅助引入工作流程时应审慎考虑，以保护技能形成——尤其是在安全关键领域。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20245">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20245">arXiv</a></p>
<hr />
<h3>18. SE-DiCoW：自注册的说话人日志条件化Whisper模型</h3>
<p><strong>原文标题：</strong> SE-DiCoW: Self-Enrolled Diarization-Conditioned Whisper</p>
<p><strong>摘要：</strong>
在多说话人环境中实现说话人归属的自动语音识别（ASR）仍然是一项重大挑战。尽管部分方法在特定领域微调后能取得优异性能，但鲜有系统能在跨域数据集上表现出良好的泛化能力。我们先前提出的说话人日志条件化Whisper模型（DiCoW）利用说话人日志输出作为条件信息，通过极少量微调即展现出强大的多语言与多领域性能。本文针对DiCoW的一个关键局限进行改进：静默-目标-非目标-重叠（STNO）掩码中存在歧义性——当两个或多个说话人完全重叠时，即使其转写内容不同，模型接收的条件信息仍可能近乎相同。我们提出SE-DiCoW（自注册的说话人日志条件化Whisper模型），该模型通过说话人日志输出来定位对话中目标说话人最活跃的任意片段作为注册段，并借助交叉注意力机制将注册段作为固定条件信息注入每个编码器层。我们进一步通过改进数据分割策略、模型初始化方法和数据增强技术对DiCoW进行优化。这些改进共同带来了显著性能提升：在EMMA MT-ASR基准测试中，SE-DiCoW相较于原始DiCoW模型将宏观平均tcpWER相对降低了52.4%。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.19194">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.19194">arXiv</a></p>
<hr />
<h3>19. FP8-RL：一种实用且稳定的低精度大语言模型强化学习技术栈</h3>
<p><strong>原文标题：</strong> FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning</p>
<p><strong>摘要：</strong>
大语言模型（LLM）的强化学习（RL）正日益受限于生成过程（rollout），其中长输出序列导致注意力机制与KV缓存内存成为端到端步骤时间的主要瓶颈。FP8格式通过降低生成过程中的计算成本与内存流量，为加速强化学习提供了有效途径，但将其应用于强化学习却面临独特的工程与算法挑战：策略权重每一步均会更新（需要重复量化并与推理引擎进行权重同步），且低精度生成过程可能偏离训练器预设的高精度策略，导致训练-推理失配及潜在的不稳定性。本报告提出了一种实用的大语言模型强化学习FP8生成技术栈，该技术栈在veRL生态系统中实现，支持常见训练后端（如FSDP/Megatron-LM）与推理引擎（如vLLM/SGLang）。我们（i）采用分块FP8量化技术实现FP8 W8A8线性层生成；（ii）将FP8扩展至KV缓存，通过逐步QKV缩放因子重校准消除长上下文内存瓶颈；（iii）利用基于重要性采样的生成校正方法（词元级TIS/MIS变体）缓解训练-推理失配。在稠密模型与混合专家模型上的实验表明，这些技术可使生成吞吐量提升高达44%，同时保持与BF16基线相当的学习性能。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.18150">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.18150">arXiv</a></p>
<hr />
<h3>20. 角色提示作为审视大语言模型社会推理的透镜</h3>
<p><strong>原文标题：</strong> Persona Prompting as a Lens on LLM Social Reasoning</p>
<p><strong>摘要：</strong>
在仇恨言论检测等社会敏感性任务中，大语言模型（LLMs）生成解释的质量对于用户信任和模型对齐等因素至关重要。尽管角色提示（PP）作为一种引导模型进行用户定制生成的方法正被日益广泛使用，但其对模型推理过程的影响仍未得到充分探究。本研究探讨了当模型基于不同模拟人口统计角色时，其生成的推理依据如何变化。通过使用带有词级推理标注的数据集，我们测量了模型与不同人口统计群体人工标注的一致性，并评估了PP对模型偏见和人类对齐的影响。我们在三种大语言模型上的评估结果揭示了三个关键发现：（1）PP在最主观的任务（仇恨言论检测）中提升了分类性能，但降低了推理依据的质量；（2）模拟角色未能与其真实世界对应的人口统计群体对齐，且高跨角色一致性表明模型对显著引导具有抵抗性；（3）无论是否使用PP，模型均表现出稳定的人口统计偏见，并存在强烈过度标记内容为有害的倾向。我们的研究揭示了一个关键权衡：虽然PP能提升社会敏感性任务的分类性能，但这往往以牺牲推理质量为代价，且无法缓解深层偏见，这警示我们在应用中需保持审慎。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20757">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20757">arXiv</a></p>
<hr />
<h3>21. SketchDynamics：探索自由手绘草图在动画生成中的动态意图表达</h3>
<p><strong>原文标题：</strong> SketchDynamics: Exploring Free-Form Sketches for Dynamic Intent Expression in Animation Generation</p>
<p><strong>摘要：</strong>
手绘草图提供了一种直观的方式来表达动画创作中的动态意图（即元素如何随时间与空间变化），这使其成为自动化内容生成的天然媒介。然而，现有方法通常将草图限制于固定的指令标记或预定义的视觉形式，忽视了其自由形式的本质以及人在意图塑造中的核心作用。为解决这一问题，我们提出了一种交互范式：用户通过自由手绘草图向视觉-语言模型传达动态意图，并在此以草图故事板到动态图形的工作流程进行实例化。我们实现了一个交互界面，并通过一项包含24名参与者的三阶段研究对其进行了改进。研究展示了草图如何以最少的输入传达运动信息，其固有的模糊性如何需要用户参与以进行澄清，以及草图如何能够视觉化地引导视频优化。我们的研究结果揭示了草图与人工智能交互在弥合意图与结果之间差距方面的潜力，并论证了其在三维动画与视频生成中的适用性。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20622">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20622">arXiv</a></p>
<hr />
<h3>22. Shallow-π：基于流式视觉语言动作模型的知识蒸馏方法</h3>
<p><strong>原文标题：</strong> Shallow-π: Knowledge Distillation for Flow-based VLAs</p>
<p><strong>摘要：</strong>
机器人实时部署需求的日益增长，对视觉-语言-动作（VLA）模型提出了快速设备端推理的要求。在现有VLA研究中，效率优化主要集中于令牌级别（如视觉令牌剪枝），而对Transformer层级的系统性压缩关注有限。据我们所知，基于流式架构的VLA模型在知识蒸馏框架下的深度压缩尚未得到探索。本研究提出Shallow-π——一种系统化的知识蒸馏框架，通过大幅削减VLM主干网络与流式动作头的Transformer层数，将模型从18层压缩至6层。在标准操作基准测试中，Shallow-π在成功率下降不足1%的前提下实现了两倍以上的推理加速，确立了压缩VLA模型的性能新标杆。关键的是，我们在Jetson Orin与Jetson Thor嵌入式平台上，通过多机器人系统（包括人形机器人平台）在复杂动态操作场景中的工业级实测验证了该方法的有效性。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.20262">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.20262">arXiv</a></p>
<hr />
<h2>🔍 关键词云图</h2>
<p><img alt="关键词云图" src="../images/keywords_wordcloud.png" /></p>
<h2>📈 近期论文趋势</h2>
<p><img alt="论文趋势" src="../images/daily_papers.png" /></p>
<h2>🎙️ 语音播报</h2>
<ul>
<li><a href="../audio/2026-01-29_daily_papers.mp3">收听今日论文解读</a></li>
</ul>
<h2>📱 订阅渠道</h2>
<ul>
<li>GitHub: <a href="https://github.com/2404589803/hf-daily-paper-newsletter-chinese">hf-daily-paper-newsletter-chinese</a></li>
</ul>
    </div>
</body>
</html>