
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-05 论文日报

## 📊 今日论文统计
- 总论文数：15
- 热门领域：LLM, RL, GPT

## 📝 论文详情


### 1. Youtu-Agent：通过自动化生成与混合策略优化提升智能体生产力

**原文标题：** Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization

**摘要：**
现有的大语言模型（LLM）智能体框架面临两大挑战：高昂的配置成本与静态的能力局限。构建高质量智能体通常需要在工具集成与提示工程上投入大量人工，而已部署的智能体难以适应动态环境，往往需要昂贵的微调。为解决这些问题，我们提出了Youtu-Agent，一个面向LLM智能体自动化生成与持续演进的模块化框架。Youtu-Agent采用结构化配置系统，将执行环境、工具集与上下文管理解耦，支持灵活复用与自动化合成。我们引入了两种生成范式：面向标准任务的工作流模式，以及面向复杂、非标准需求的元智能体模式，能够自动生成工具代码、提示词与配置。此外，Youtu-Agent建立了一套混合策略优化系统：（1）智能体实践模块，使智能体能够通过上下文优化积累经验、提升性能，无需参数更新；（2）智能体强化学习模块，与分布式训练框架集成，支持以端到端、大规模方式对任意Youtu-Agent进行可扩展且稳定的强化学习。实验表明，Youtu-Agent在WebWalkerQA（71.47%）和GAIA（72.8%）基准上使用开放权重模型达到了最先进的性能。我们的自动化生成流程实现了超过81%的工具合成成功率，而实践模块在AIME 2024/2025上的性能分别提升了+2.7%与+5.4%。此外，我们的智能体强化学习训练在7B参数LLM上实现了40%的加速，且性能稳定提升，在数学与通用/多跳问答基准上，分别将编码/推理与搜索能力最高提升了35%和21%。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.24615) | [arXiv](https://arxiv.org/abs/2512.24615)



---

### 2. NeoVerse：基于真实世界单目视频增强的4D世界模型

**原文标题：** NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos

**摘要：**
本文提出NeoVerse，一种多功能4D世界模型，能够实现4D重建、新轨迹视频生成及丰富的下游应用。我们首先指出当前4D世界建模方法普遍存在的可扩展性局限，其根源在于依赖昂贵且专业的多视角4D数据或繁琐的训练预处理流程。相比之下，NeoVerse基于核心设计理念，使完整流程能够灵活适配多样化的真实世界单目视频。具体而言，NeoVerse具备无需姿态估计的前馈式4D重建、在线单目退化模式模拟等高度协同的技术特性。这些设计使NeoVerse在跨领域应用中展现出卓越的泛化能力与多功能性。同时，该模型在标准重建与生成基准测试中取得了最先进的性能表现。项目页面详见：https://neoverse-4d.github.io

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.00393) | [arXiv](https://arxiv.org/abs/2601.00393)



---

### 3. Avatar Forcing：面向自然对话的实时交互式头部虚拟形象生成

**原文标题：** Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation

**摘要：**
说话头部生成技术旨在从静态肖像中创建逼真的虚拟形象，以支持虚拟交流与内容创作。然而，现有模型尚无法传递真正交互式沟通的体验，其生成结果多为单向响应，缺乏情感互动。为实现真正交互式的虚拟形象，我们指出两大关键挑战：在因果约束下实现实时运动生成，以及在不依赖额外标注数据的情况下学习富有表现力且生动的反应。为应对这些挑战，我们提出Avatar Forcing——一种基于扩散强迫机制的交互式头部虚拟形象生成新框架。该设计使虚拟形象能够以低延迟处理实时多模态输入（包括用户音频与动作），即时响应言语与非言语线索（如语音、点头、笑声等）。此外，我们引入一种直接偏好优化方法，通过丢弃用户条件构建合成负样本，实现无需标注的表现力交互学习。实验结果表明，本框架支持低延迟（约500毫秒）实时交互，相比基线模型加速6.8倍，并能生成具有反应力与表现力的虚拟形象动作，在超过80%的对比评估中优于基线方法。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.00664) | [arXiv](https://arxiv.org/abs/2601.00664)



---

### 4. 驯服幻觉：通过反事实视频生成提升多模态大语言模型的视频理解能力

**原文标题：** Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation

**摘要：**
多模态大语言模型（MLLMs）在视频理解领域取得了显著进展。然而，它们存在一个关键缺陷：过度依赖语言先验，这可能导致视觉信息失真的幻觉现象，尤其是在处理违背常识的反事实视频时。这一局限性源于文本与视频数据之间的内在不平衡，且由于收集和标注反事实数据成本高昂，该问题难以解决。为此，我们提出了DualityForge，一种新颖的反事实数据合成框架，该框架利用可控的、基于扩散模型的视频编辑技术，将真实世界视频转化为反事实场景。通过将结构化上下文信息嵌入视频编辑和问答生成过程，该框架能够自动生成高质量的问答对以及用于对比训练的原始-编辑视频对。基于此，我们构建了DualityVidQA，一个旨在减少MLLM幻觉的大规模视频数据集。此外，为充分利用配对数据的对比特性，我们提出了Duality-Normalized Advantage Training（DNA-Train），一种两阶段的监督微调-强化学习训练机制，其中强化学习阶段应用了配对间的ℓ₁优势归一化，从而实现更稳定高效的政策优化。在DualityVidQA-Test上的实验表明，我们的方法显著降低了模型在反事实视频上的幻觉，相比Qwen2.5-VL-7B基线实现了24.0%的相对提升。此外，我们的方法在幻觉评估和通用基准测试中均取得了显著进步，显示出强大的泛化能力。我们将开源数据集和代码。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.24271) | [arXiv](https://arxiv.org/abs/2512.24271)



---

### 5. SenseNova-MARS：基于强化学习的多模态智能体推理与搜索框架

**原文标题：** SenseNova-MARS: Empowering Multimodal Agentic Reasoning and Search via Reinforcement Learning

**摘要：**
尽管视觉-语言模型（VLMs）能够通过智能体推理解决复杂任务，但其能力仍主要局限于文本导向的思维链或孤立工具调用。这些模型未能展现出类人的熟练度，无法将动态工具操作与连续推理无缝交织，尤其是在需要协调使用搜索、图像裁剪等外部工具的知识密集型与视觉复杂场景中。本研究提出SenseNova-MARS，一种基于强化学习（RL）的新型多模态智能体推理与搜索框架，旨在赋予VLMs交织式视觉推理与工具使用能力。具体而言，SenseNova-MARS动态整合图像搜索、文本搜索与图像裁剪工具，以应对细粒度、知识密集型的视觉理解挑战。在强化学习阶段，我们提出批量归一化分组序列策略优化（BN-GSPO）算法，以提升训练稳定性并增强模型调用工具与有效推理的能力。为全面评估智能体VLMs在复杂视觉任务上的表现，我们构建了HR-MMSearch基准测试集——首个由高分辨率图像构成、包含知识密集型与搜索驱动问题的搜索导向基准。实验表明，SenseNova-MARS在开源搜索与细粒度图像理解基准上取得了最先进的性能。具体而言，在搜索导向基准测试中，SenseNova-MARS-8B在MMSearch上获得67.84分，在HR-MMSearch上获得41.64分，超越了Gemini-3-Flash、GPT-5等专有模型。SenseNova-MARS通过提供高效稳健的工具使用能力，为智能体VLMs的发展迈出了重要一步。为促进该领域进一步研究，我们将公开全部代码、模型与数据集。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.24330) | [arXiv](https://arxiv.org/abs/2512.24330)



---

### 6. AdaGaR：面向动态场景重建的自适应Gabor表示方法

**原文标题：** AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction

**摘要：**
从单目视频重建动态三维场景需要同时捕获高频外观细节与时间连续运动。现有基于单一高斯基元的方法受限于其低通滤波特性，而标准Gabor函数存在能量不稳定问题。此外，时间连续性约束的缺失常导致插值过程中的运动伪影。本文提出AdaGaR统一框架，在显式动态场景建模中同时解决频率自适应性与时间连续性问题。我们引入自适应Gabor表示方法，通过可学习频率权重与自适应能量补偿扩展高斯函数，以平衡细节捕获与稳定性。针对时间连续性，采用结合时间曲率正则化的三次Hermite样条来确保平滑运动演化。通过融合深度估计、点跟踪与前景掩码的自适应初始化机制，在训练初期建立稳定的点云分布。在Tap-Vid DAVIS数据集上的实验表明，该方法取得了最优性能（PSNR 35.49、SSIM 0.9433、LPIPS 0.0723），并在帧插值、深度一致性、视频编辑与立体视图合成等任务中展现出强大泛化能力。项目页面：https://jiewenchan.github.io/AdaGaR/

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.00796) | [arXiv](https://arxiv.org/abs/2601.00796)



---

### 7. 深度增量学习

**原文标题：** Deep Delta Learning

**摘要：**
深度残差网络的有效性本质上基于恒等快捷连接机制。虽然该机制有效缓解了梯度消失问题，但它对特征变换施加了严格的加性归纳偏置，从而限制了网络建模复杂状态转移的能力。本文提出深度增量学习（DDL）这一新型架构，通过使用可学习的、数据依赖的几何变换对恒等快捷连接进行调制，从而推广了标准残差连接。该变换被称为增量算子，由反射方向向量k(X)和门控标量β(X)参数化，构成单位矩阵的秩-1扰动。我们对该算子进行谱分析，证明门控β(X)能够实现恒等映射、正交投影与几何反射之间的动态插值。进一步地，我们将残差更新重构为同步秩-1注入，其中门控作为动态步长，同时控制旧信息的擦除与新特征的写入。这种统一设计使网络能够显式控制其逐层转移算子的谱空间，在保持门控残差架构稳定训练特性的同时，实现对复杂非单调动态过程的建模。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.00417) | [arXiv](https://arxiv.org/abs/2601.00417)



---

### 8. 嵌套学习：深度学习架构的幻觉

**原文标题：** Nested Learning: The Illusion of Deep Learning Architectures

**摘要：**
尽管近年来取得了显著进展，特别是在语言模型开发领域，但关于此类模型如何实现持续学习/记忆、自我改进及寻找有效解决方案等根本性挑战与未解问题依然存在。本文提出一种称为嵌套学习（NL）的新学习范式，该范式通过一组具有独立上下文流的嵌套式、多层级和/或并行优化问题来连贯地表征机器学习模型。通过NL视角分析，现有深度学习方法通过压缩自身上下文流从数据中学习，而上下文学习能力在大模型中自然涌现。NL提出了一种设计理念：通过构建更多层级来开发更具表达力的学习算法，从而实现高阶上下文学习，并有望解锁有效的持续学习能力。我们通过三项核心贡献论证NL的价值：（1）表达性优化器：研究表明，已知的基于梯度的优化器（如Adam、带动量的SGD等）本质上是旨在通过梯度下降压缩梯度信息的关联记忆模块。基于此洞见，我们提出了具有深度记忆和/或更强学习规则的其他高表达力优化器；（2）自修正学习模块：利用NL对学习算法的深刻理解，我们构建了一种通过学习自身更新算法来实现自我修正的序列模型；（3）连续记忆系统：提出了一种超越传统长/短期记忆框架的新型记忆系统表述。将自修正序列模型与连续记忆系统相结合，我们开发出名为“Hope”的持续学习模块，在语言建模、知识融合、小样本泛化任务、持续学习及长上下文推理任务中展现出卓越性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.24695) | [arXiv](https://arxiv.org/abs/2512.24695)



---

### 9. 推理与创造力的权衡：迈向创造力驱动的问题解决

**原文标题：** The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving

**摘要：**
当前最先进的大语言模型（LLM）流程依赖于自举推理循环：通过采样多样化的思维链并强化得分最高的路径，主要优化正确性。本文分析了这种设计选择如何导致模型在推理路径上的分布崩溃，从而削减语义熵并削弱创造性问题解决能力。为解析这一失效机制，我们提出了分布化创造性推理（DCR）——一种统一的变分目标框架，将训练过程建模为在解轨迹概率测度上的梯度流。STaR、GRPO、DPO以及熵奖励等现有方法均可视为该损失函数的特例。该框架得出三项核心成果：（一）多样性衰减定理，阐释了基于正确性的目标如何导致STaR、GRPO和DPO产生不同模式的多样性衰减；（二）确保收敛至稳定且多样化策略的设计方案，有效防止分布崩溃；（三）可在实践中实现的简洁可行方案。DCR由此为同时保持正确性与创造性的大语言模型提供了首个原则性方法。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.00747) | [arXiv](https://arxiv.org/abs/2601.00747)



---

### 10. 通过方向解耦对齐在扩散强化学习中抑制偏好模式坍塌

**原文标题：** Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning

**摘要：**
近期研究表明，通过人类反馈强化学习技术，文本到图像扩散模型与人类偏好的对齐已取得显著进展。然而，现有方法虽然在自动化奖励指标上获得高分，却常导致偏好模式坍塌——这是一种特定形式的奖励破解现象，表现为模型收敛于狭窄的高分输出模式（例如单一风格图像或普遍过曝的图像），严重损害了生成多样性。本研究首次系统界定并量化了这一现象，提出专用于测量偏好模式坍塌程度的新基准DivGenBench。我们认为这种坍塌是由奖励模型固有偏差的过度优化所驱动的。基于此分析，我们提出方向解耦对齐框架，该框架通过方向性修正奖励信号来缓解偏好模式坍塌。具体而言，我们的方法首先在冻结模型参数的状态下，于奖励模型的嵌入空间中学习方向修正量，随后在优化过程中将此修正应用于奖励信号，从而防止模型坍缩至特定模式以保持多样性。通过结合质量与多样性的定性分析与定量指标的综合评估表明，方向解耦对齐框架在实现与人类偏好的对齐方面具有显著优势。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.24146) | [arXiv](https://arxiv.org/abs/2512.24146)



---

### 11. 多样性还是精确性？深度解析下一词元预测

**原文标题：** Diversity or Precision? A Deep Dive into Next Token Prediction

**摘要：**
近期研究表明，强化学习（RL）能显著提升大语言模型（LLM）的推理能力。然而，此类强化学习训练的有效性关键取决于预训练模型的词元输出分布所定义的探索空间。本文重新审视标准交叉熵损失，将其解释为应用于单步决策过程的策略梯度优化的一个特例。为系统研究预训练分布如何塑造后续强化学习的探索潜力，我们提出一种广义预训练目标，将同策略强化学习原理适配至监督学习框架。通过将下一词元预测构建为随机决策过程，我们引入一种显式平衡多样性与精确性的奖励塑造策略。该方法采用正向奖励缩放因子控制对真实标注词元的概率集中度，并引入排名感知机制对高排名与低排名负样本词元进行非对称处理。这使我们能够重塑预训练的词元输出分布，探究如何为强化学习提供更有利的探索空间，最终提升端到端推理性能。与“更高分布熵有助于有效探索”的直觉相反，我们发现施加以精确性为导向的先验分布能为强化学习提供更优越的探索空间。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.22955) | [arXiv](https://arxiv.org/abs/2512.22955)



---

### 12. 快速权重乘积键记忆

**原文标题：** Fast-weight Product Key Memory

**摘要：**
现代语言模型中的序列建模层通常面临存储容量与计算效率之间的权衡。Softmax注意力机制虽能提供无界存储，却需付出二次方计算的昂贵代价；线性变体虽计算高效，但其存储容量有限且固定。本文提出快速权重乘积键记忆（FwPKM），该新型架构通过将稀疏的乘积键记忆从静态模块转化为动态的“快速权重”情景记忆，有效解决了这一矛盾。与乘积键记忆不同，FwPKM在训练和推理阶段均通过局部块级梯度下降动态更新参数，使模型能够快速记忆并检索输入序列中的新键值对。实验表明，FwPKM作为一种高效的情景记忆模块，能够与标准模型的语义记忆形成互补，在长上下文数据集上显著降低困惑度。值得注意的是，在“大海捞针”评估中，FwPKM仅使用4K词元序列训练即可泛化至128K词元的长上下文场景。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.00671) | [arXiv](https://arxiv.org/abs/2601.00671)



---

### 13. InfoSynth：面向大语言模型的信息引导式基准测试合成方法

**原文标题：** InfoSynth: Information-Guided Benchmark Synthesis for LLMs

**摘要：**
大语言模型在推理与代码生成方面已展现出显著进步，然而高效创建用于评估这些能力的新基准测试仍面临挑战。传统的基准构建依赖人工完成，这一过程成本高昂且耗时。此外，现有基准测试常会污染大语言模型的训练数据，因此需要新颖且多样化的基准以准确评估其真实能力。本研究提出InfoSynth，一种基于信息论原理自动生成与评估推理基准的新框架。我们提出基于KL散度与熵的度量指标，无需依赖高成本的模型评估即可量化基准的新颖性与多样性。基于此框架，我们开发了一套端到端流程，通过遗传算法与迭代式代码反馈，从种子数据集中合成稳健的Python编程问题。该方法在97%的情况下能为新问题生成准确的测试用例与解决方案，且合成基准相较于原始种子数据集持续表现出更高的新颖性与多样性。此外，我们的算法提供了一种控制生成问题新颖性/多样性与难度的方法。InfoSynth为构建高质量、新颖且多样化的大语言模型基准测试提供了一个可扩展、可自我验证的完整流程。项目页面：https://ishirgarg.github.io/infosynth_web/

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.00575) | [arXiv](https://arxiv.org/abs/2601.00575)



---

### 14. MorphAny3D：释放结构化隐空间在三维形变中的潜力

**原文标题：** MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing

**摘要：**
三维形变技术因难以生成语义一致且时序平滑的变形序列而持续面临挑战，在跨类别形变任务中尤为突出。本文提出MorphAny3D——一种基于结构化隐空间表征的无训练框架，可实现高质量三维形变。我们的核心发现是：通过在三维生成器的注意力机制中智能融合源目标对象的SLAT特征，能够自然生成符合物理规律的形变序列。为此，我们设计了形变交叉注意力模块，通过融合源目标特征保持结构连贯性；并提出时序融合自注意力模块，通过引入相邻帧特征增强时序一致性。此外，我们采用方向校正策略以缓解形变过程中的姿态歧义问题。大量实验表明，本方法生成的形变序列达到当前最优水平，即使在极具挑战性的跨类别形变任务中亦表现出色。MorphAny3D进一步支持解耦形变与三维风格迁移等高级应用，并可推广至其他基于SLAT的生成模型。项目主页：https://xiaokunsun.github.io/MorphAny3D.github.io/。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.00204) | [arXiv](https://arxiv.org/abs/2601.00204)



---

### 15. 我们能否信任AI的解释？思维链推理中系统性隐瞒的证据

**原文标题：** Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning

**摘要：**
当人工智能系统逐步解释其推理过程时，从业者通常认为这些解释揭示了实际影响AI答案的因素。我们通过将提示信息嵌入问题并测量模型是否提及这些信息来验证这一假设。在对11个主流AI模型超过9000个测试案例的研究中，我们发现了一个令人担忧的模式：模型几乎从不主动提及提示信息，但当被直接询问时，它们会承认注意到了这些提示。这表明模型能够识别关键信息却选择不报告。告知模型其行为正在被监控并无改善效果。强制模型报告提示信息虽然有效，但会导致其在无提示时误报，并降低回答准确率。我们还发现，迎合用户偏好的提示尤其危险——模型最常遵循这类提示却最少报告其影响。这些发现表明，仅观察AI的推理过程不足以发现其隐藏的影响因素。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.00830) | [arXiv](https://arxiv.org/abs/2601.00830)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2026-01-05_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)