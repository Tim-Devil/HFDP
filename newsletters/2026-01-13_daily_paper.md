
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-13 论文日报

## 📊 今日论文统计
- 总论文数：42
- 热门领域：LLM, Vision, GPT, Transformer, RL, Audio

## 📝 论文详情


### 1. 观看、推理与检索：面向开放网络的智能体视频推理深度研究基准

**原文标题：** Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning

**摘要：**
在现实世界的视频问答场景中，视频通常仅提供局部视觉线索，而可验证的答案广泛分布于开放网络中；因此模型需要联合执行跨帧线索提取、迭代检索以及基于多跳推理的验证。为填补这一空白，我们构建了首个视频深度研究基准VideoDR。VideoDR以视频条件化的开放域视频问答为核心，要求进行跨帧视觉锚点提取、交互式网络检索以及对视频-网络联合证据的多跳推理；通过严格的人工标注与质量控制，我们获得了涵盖六个语义领域的高质量视频深度研究样本。我们在工作流范式与智能体范式下评估了多个闭源与开源多模态大语言模型，结果表明智能体范式并非始终优于工作流范式：其优势取决于模型在长检索链中保持初始视频锚点的能力。进一步分析指出，目标漂移与长程一致性是核心瓶颈。综上所述，VideoDR为研究开放网络环境下的视频智能体提供了系统性基准，并揭示了下一代视频深度研究智能体面临的关键挑战。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06943) | [arXiv](https://arxiv.org/abs/2601.06943)



---

### 2. BabyVision：超越语言的视觉推理能力研究

**原文标题：** BabyVision: Visual Reasoning Beyond Language

**摘要：**
人类在掌握语言能力之前便已发展出核心视觉技能，而当前的多模态大语言模型（MLLMs）仍严重依赖语言先验知识以弥补其薄弱的视觉理解能力。我们发现一个重要事实：即使面对三岁幼儿也能轻松解决的基础视觉任务，最先进的多模态大语言模型仍持续表现失败。为系统探究这一差距，我们提出BabyVision基准测试，旨在评估多模态大语言模型独立于语言知识的核心视觉能力。该基准涵盖四大关键类别，包含22个子类共388项任务。实证结果与人工评估表明，主流多模态大语言模型的表现显著低于人类基线水平。其中Gemini3-Pro-Preview得分仅为49.7，落后于六岁儿童水平，与成人平均分94.1存在巨大差距。这些结果揭示，尽管当前多模态大语言模型在知识密集型评估中表现优异，其仍缺乏基础视觉原语能力。BabyVision研究的进展标志着向人类水平视觉感知与推理能力迈出的重要一步。我们同时通过提出BabyVision-Gen生成模型与自动评估工具包探索视觉推理任务的解决方案。相关代码与基准数据已发布于https://github.com/UniPat-AI/BabyVision以供复现研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06521) | [arXiv](https://arxiv.org/abs/2601.06521)



---

### 3. PaCoRe：通过并行协同推理学习扩展测试时计算

**原文标题：** PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning

**摘要：**
本文提出并行协同推理（PaCoRe），一种旨在克服当代语言模型核心局限的训练与推理框架：即模型无法在固定上下文窗口下，将测试时计算（TTC）规模显著扩展至超越顺序推理的范畴。PaCoRe摒弃了传统的顺序推理范式，通过在多轮消息传递架构协调下的大规模并行探索来驱动测试时计算。每一轮并行启动多个推理轨迹，将其发现压缩为上下文受限的消息，并综合这些消息以指导下一轮推理，最终生成答案。通过基于结果的大规模端到端强化学习训练，模型掌握了PaCoRe所需的信息综合能力，并能够将有效测试时计算扩展至数百万令牌量级，同时不突破上下文限制。该方法在多个领域均带来显著性能提升，尤其在数学推理方面超越了前沿系统：一个80亿参数的模型在HMMT 2025数据集上达到94.5%的准确率，通过将有效测试时计算扩展至约两百万令牌，超越了GPT-5的93.2%表现。我们开源了模型检查点、训练数据及完整推理流程，以加速后续研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05593) | [arXiv](https://arxiv.org/abs/2601.05593)



---

### 4. MHLA：通过令牌级多头机制恢复线性注意力的表达能力

**原文标题：** MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head

**摘要：**
尽管Transformer架构在许多领域占据主导地位，但其二次复杂度的自注意力机制限制了其在大规模应用中的使用。线性注意力提供了一种高效的替代方案，但其直接应用往往会导致性能下降。现有改进方法通常通过引入额外模块（如深度可分离卷积）重新引入计算开销，违背了提升效率的初衷。本文指出这些方法存在一个关键缺陷：全局上下文坍缩，即模型丧失表征多样性。为解决这一问题，我们提出了多头线性注意力机制（MHLA），该机制通过在令牌维度上划分多头并分别计算注意力，有效保持了表征多样性。我们证明MHLA在保持线性复杂度的同时，能够恢复softmax注意力的大部分表达能力，并在多个领域验证了其有效性：在相同时间复杂度下，ImageNet分类任务提升3.6%，自然语言处理任务提升6.3%，图像生成任务提升12.6%，视频生成任务提升41%。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07832) | [arXiv](https://arxiv.org/abs/2601.07832)



---

### 5. X-Coder：通过全合成任务、解决方案与测试推进竞技编程能力

**原文标题：** X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests

**摘要：**
竞技编程因其密集的推理需求与高逻辑复杂性，对代码大语言模型提出了巨大挑战。然而，当前代码大语言模型仍严重依赖现实世界数据，这限制了其可扩展性。本文探索了一种全合成方法：使用完全生成的任务、解决方案与测试用例训练代码大语言模型，从而在不依赖现实数据的情况下增强代码推理能力。为此，我们基于特征合成技术提出了一种名为SynthSmith的新型数据合成流程。SynthSmith展现出生成多样化、高难度任务以及已验证解决方案与测试的强大潜力，同时支持监督微调与强化学习。基于所提出的合成监督微调与强化学习数据集，我们推出了X-Coder模型系列，该系列在LiveCodeBench v5上达到62.9 avg@8的显著通过率，在v6上达到55.8，尽管仅拥有70亿参数，其表现仍优于DeepCoder-14B-Preview与AReal-boba2-14B。深入分析表明，缩放定律在我们的合成数据集上依然成立，并进一步探讨了哪些维度对扩展更有效。我们通过详细的消融实验与分析，深入揭示了以代码为中心的强化学习机制，并阐明了影响性能的关键因素。研究结果表明，扩展高质量合成数据并采用分阶段训练策略能显著推进代码推理能力，同时减少对现实世界编程数据的依赖。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06953) | [arXiv](https://arxiv.org/abs/2601.06953)



---

### 6. GlimpRouter：基于思维单词元瞥见的协同推理高效框架

**原文标题：** GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts

**摘要：**
大型推理模型通过显式生成多步思维链获得了卓越性能，但该能力会带来显著的推理延迟与计算成本。协同推理通过将计算任务在轻量模型与大型模型间进行选择性分配，提供了具有前景的解决方案，但核心挑战依然存在：如何判断推理步骤何时需要大型模型的强大能力，何时可交由轻量模型高效处理。现有路由策略或依赖局部词元概率，或采用事后验证机制，均会引入显著的推理开销。本研究提出一种新颖的步进式协同视角：推理步骤的难度可通过其首个词元进行推断。受大型推理模型中“顿悟时刻”现象的启发，我们发现初始词元的熵值可作为步骤难度的有效预测指标。基于此洞见，我们提出了GlimpRouter——一种无需训练的步进式协同推理框架。该框架使用轻量模型仅生成每个推理步骤的首个词元，仅当初始词元熵值超过阈值时才将当前步骤路由至大型模型。在多基准测试上的实验表明，该方法在保持准确性的同时显著降低了推理延迟。例如在AIME25基准上，GlimpRouter相较于独立大型模型在准确率提升10.7%的同时，推理延迟降低了25.9%。这些结果表明了一种简洁而有效的推理机制：基于思维片段的瞥见而非完整步骤评估来分配计算资源。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05110) | [arXiv](https://arxiv.org/abs/2601.05110)



---

### 7. 迷失于噪声：推理模型如何受上下文干扰项影响而失效

**原文标题：** Lost in the Noise: How Reasoning Models Fail with Contextual Distractors

**摘要：**
推理模型与智能体人工智能系统的最新进展，使得对多样化外部信息的依赖日益增强。然而，这种转变引入了本质上充满噪声的输入上下文，而当前经过净化的基准测试未能捕捉这一现实。我们提出了NoisyBench，这是一个综合性基准，系统性地评估了模型在RAG、推理、对齐和工具使用等11个数据集上，面对随机文档、无关对话历史和困难负样本干扰等多种噪声类型时的鲁棒性。我们的评估显示，在面对上下文干扰项时，最先进的模型性能会出现高达80%的灾难性下降。关键的是，我们发现智能体工作流常因过度信任带噪声的工具输出而放大这些错误，并且干扰项即使在没有对抗意图的情况下也可能引发突发性失准。我们发现，提示工程、上下文工程、监督微调以及仅基于结果奖励的强化学习均无法确保鲁棒性；相比之下，我们提出的**理性感知奖励机制**通过激励模型识别噪声中有用信息，显著增强了其抗干扰能力。最后，我们揭示了一种逆向缩放趋势：在噪声环境中，增加测试时计算量反而导致性能下降，并通过注意力可视化证明模型会过度关注干扰标记。这些发现为构建下一代鲁棒且具备强推理能力的智能体提供了重要洞见。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07226) | [arXiv](https://arxiv.org/abs/2601.07226)



---

### 8. OS-Symphony：一种面向鲁棒通用计算机使用智能体的整体框架

**原文标题：** OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent

**摘要：**
尽管视觉语言模型（VLMs）显著推动了计算机使用智能体（CUAs）的发展，但现有框架在长流程工作流的鲁棒性和新领域泛化能力方面仍面临挑战。这些局限主要源于对历史视觉上下文管理缺乏细粒度控制，以及缺少视觉感知的教程检索机制。为弥补上述不足，本文提出OS-Symphony整体框架，其核心协调器整合了两项关键创新以实现鲁棒自动化：（1）反思记忆智能体——采用里程碑驱动的长期记忆机制实现轨迹级自我修正，有效缓解长流程任务中的视觉上下文丢失问题；（2）多功能工具智能体——配备多模态搜索器，通过SeeAct范式在基于浏览器的沙箱环境中合成实时视觉对齐教程，从而解决未知场景中的保真度问题。实验结果表明，OS-Symphony在不同规模模型上均实现显著性能提升，在三大在线基准测试中创下最新最优记录，其中在OSWorld基准上达到65.84%的卓越表现。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07779) | [arXiv](https://arxiv.org/abs/2601.07779)



---

### 9. 超越硬掩码：扩散语言模型的渐进式词元演化

**原文标题：** Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models

**摘要：**
扩散语言模型通过迭代优化实现并行解码，为语言建模提供了一种前景广阔的替代方案。然而，现有扩散语言模型大多依赖硬二值掩码和离散词元分配机制，这限制了早期决策的修正能力，且未能充分利用中间概率表示。本文提出EvoToken-DLM——一种创新的基于扩散的语言建模方法，通过演化的软词元分布替代传统硬二值掩码。该模型实现了从掩码状态到离散输出的渐进式过渡，支持可修正的解码过程。为有效支撑这种演化机制，我们引入连续轨迹监督方法，使训练目标与迭代概率更新过程保持一致。在多个基准测试上的实验表明，EvoToken-DLM始终取得卓越性能，显著优于现有基于扩散和掩码的扩散语言模型基线。项目主页：https://aim-uofa.github.io/EvoTokenDLM。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07351) | [arXiv](https://arxiv.org/abs/2601.07351)



---

### 10. 可控记忆使用：长期人机交互中的锚定与创新平衡

**原文标题：** Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction

**摘要：**
随着基于大语言模型的智能体日益广泛地应用于长期交互场景，累积记忆对于实现个性化服务和保持风格一致性至关重要。然而，现有系统大多采用“全有或全无”的记忆使用策略：若完全纳入历史相关信息可能导致“记忆锚定”现象，使智能体受困于过往交互模式；而完全排除记忆则会造成信息利用不足与重要交互历史的丢失。本研究证明，智能体对记忆的依赖程度可被建模为显式且用户可控的维度。我们首先提出记忆依赖性的行为度量指标，用以量化历史交互对当前输出的影响程度。继而提出可调控记忆智能体框架SteeM，该框架允许用户动态调节记忆依赖强度——从促进创新的“全新启动”模式到严格遵循交互历史的“高保真”模式。跨场景实验表明，相较于传统提示方法与刚性记忆掩码策略，本方法能持续生成更精细、更有效的控制机制，为个性化人机协作提供优化解决方案。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05107) | [arXiv](https://arxiv.org/abs/2601.05107)



---

### 11. DrivingGen：自动驾驶生成式视频世界模型综合基准

**原文标题：** DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving

**摘要：**
作为世界模型的一种形式，视频生成模型已成为人工智能领域最令人兴奋的前沿方向之一，其通过建模复杂场景的时间演化，使智能体具备预测未来的能力。在自动驾驶领域，这一愿景催生了驾驶世界模型：这类生成式模拟器能够推演自车与其他交通参与者的未来状态，从而实现可扩展的仿真、极端场景的安全测试以及丰富的合成数据生成。然而，尽管相关研究快速增长，该领域仍缺乏严谨的基准来衡量进展并指导研究方向。现有评估方法存在明显局限：通用视频指标忽略了安全关键的成像因素；轨迹合理性鲜少被量化；时间一致性与智能体层级一致性未被充分考量；基于自车条件的可控性亦遭忽视。此外，当前数据集未能覆盖现实部署所需的多变场景条件。为弥补这些不足，我们提出了DrivingGen——首个面向生成式驾驶世界模型的综合基准。DrivingGen整合了从驾驶数据集和互联网规模视频源中精选的多样化评估数据集，涵盖不同天气、昼夜时段、地理区域及复杂驾驶场景，并配套一套全新评估指标，从视觉真实感、轨迹合理性、时间连贯性和可控性四个维度进行联合评估。通过对14个前沿模型的基准测试，我们发现了明显的性能权衡：通用模型视觉表现更优但违背物理规律，而驾驶专用模型能真实捕捉运动模式却在视觉质量上存在不足。DrivingGen提供了一个统一的评估框架，旨在推动可靠、可控、可部署的驾驶世界模型发展，为可扩展仿真、路径规划及数据驱动决策提供支持。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.01528) | [arXiv](https://arxiv.org/abs/2601.01528)



---

### 12. MegaFlow：面向智能体时代的大规模分布式编排系统

**原文标题：** MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era

**摘要：**
交互式与自主人工智能系统的快速发展标志着我们正迈入智能体时代。在软件工程、计算机操作等复杂智能体任务上训练与评估智能体，不仅需要高效的模型计算能力，更依赖于能够协调海量智能体-环境交互的复杂基础设施。然而，当前尚无开源基础设施能有效支持此类复杂智能体任务的大规模训练与评估。为应对这一挑战，本文提出MegaFlow——一个面向智能体-环境工作负载的大规模分布式编排系统，可实现高效的任务调度、资源分配与细粒度任务管理。MegaFlow将智能体训练基础设施抽象为三个通过统一接口交互的独立服务（模型服务、智能体服务与环境服务），支持在不同智能体-环境配置中实现独立扩展与灵活的资源分配。在实际部署的智能体训练场景中，MegaFlow成功协调了数万个并发智能体任务，在保持系统高稳定性的同时实现了高效的资源利用率。通过支持如此大规模的智能体训练，MegaFlow填补了新兴智能体人工智能领域的关键基础设施空白。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07526) | [arXiv](https://arxiv.org/abs/2601.07526)



---

### 13. 通过解耦表征对齐增强潜在扩散模型

**原文标题：** Boosting Latent Diffusion Models via Disentangled Representation Alignment

**摘要：**
潜在扩散模型通过在压缩的潜在空间中操作生成高质量图像，该空间通常通过变分自编码器等图像标记器获得。为构建更利于生成的变分自编码器，近期研究探索利用视觉基础模型作为变分自编码器的表征对齐目标，这与潜在扩散模型常用的方法相呼应。尽管这种方法带来了一定的性能提升，但对变分自编码器和潜在扩散模型使用相同的对齐目标，忽略了两者根本不同的表征需求。我们认为，潜在扩散模型受益于保留高层语义概念的潜在表示，而变分自编码器则应擅长语义解耦，能够以结构化方式编码属性级信息。为此，我们提出语义解耦变分自编码器，通过将其潜在空间与预训练视觉基础模型的语义层次对齐，显式优化解耦表征学习。该方法采用非线性映射网络转换变分自编码器潜在表示，使其与视觉基础模型对齐，从而弥合属性级解耦与高层语义之间的鸿沟，为变分自编码器学习提供有效指导。我们通过在属性预测任务上的线性探针评估语义解耦效果，证明其与生成性能提升存在强相关性。最终，基于语义解耦变分自编码器训练的流式变换器实验表明：该编码器显著加速训练过程，在ImageNet 256×256数据集上使用/不使用无分类器引导时，分别达到1.21和1.75的最新FID指标。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05823) | [arXiv](https://arxiv.org/abs/2601.05823)



---

### 14. 用户未尽之言：欠明确查询对视觉语言模型的限制

**原文标题：** What Users Leave Unsaid: Under-Specified Queries Limit Vision-Language Models

**摘要：**
当前的视觉语言基准测试主要采用结构清晰、提示明确的规范化问题。然而，真实用户查询往往具有非正式性和欠明确性。用户通常会省略大量背景信息，依赖图像传递语境。本文提出HAERAE-Vision基准数据集，该数据集收集自韩国网络社区的653个真实视觉问题（从8.6万候选问题中筛选保留0.76%），每个问题均配有明确改写版本，共形成1,306个查询变体。通过对39个视觉语言模型的评估发现，即使是前沿模型（GPT-5、Gemini 2.5 Pro）在原始查询上的准确率也不足50%。关键发现表明，仅通过查询明确化处理即可带来8至22个百分点的性能提升，其中较小模型获益最为显著。进一步研究显示，即使结合网络搜索，欠明确查询的表现仍逊于未使用搜索的明确查询，这揭示出现有检索技术无法弥补用户省略的语境信息。我们的研究证明，视觉语言模型面临的主要困难很大程度上源于自然查询的欠明确特性，而非模型能力本身，这凸显出基准测试评估与实际应用部署之间存在关键差距。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06165) | [arXiv](https://arxiv.org/abs/2601.06165)



---

### 15. ET-Agent：通过行为校准激励高效工具集成推理智能体

**原文标题：** ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration

**摘要：**
大型语言模型（LLMs）可通过采用工具集成推理范式突破其参数知识限制。然而，现有基于LLM的智能体训练框架通常侧重于答案准确性，而忽视了对行为模式的针对性对齐，导致智能体在TIR任务中常出现低效行为，例如冗余或不足的工具调用。如何在校准TIR任务执行过程中的错误行为模式、进而探索高效轨迹，仍是一个开放性问题。本文提出ET-Agent训练框架，通过自我演进数据飞轮与行为校准训练两个协同视角校准智能体的工具使用行为。具体而言，我们引入自演进数据飞轮机制生成增强数据，用于微调LLM以提升其探索能力。在此基础上，我们构建了双阶段行为校准训练框架，旨在逐步将错误行为模式校准至最优行为。深入的实验验证了该框架在正确性、效率、推理简洁性和工具执行准确性等多维度的优越性。ET-Agent框架为TIR领域研究提供了实践性见解，代码开源地址：https://github.com/asilverlight/ET-Agent

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06860) | [arXiv](https://arxiv.org/abs/2601.06860)



---

### 16. Dr. Zero：无需训练数据的自进化搜索智能体

**原文标题：** Dr. Zero: Self-Evolving Search Agents without Training Data

**摘要：**
随着高质量数据日益难以获取，无数据自进化已成为一种前景广阔的研究范式。该方法使大语言模型能够自主生成并解决复杂问题，从而提升其推理能力。然而，多轮搜索智能体在无数据自进化中面临挑战，主要受限于问题多样性不足以及多步推理与工具调用所需的大量计算资源。本研究提出Dr. Zero框架，使搜索智能体能够在完全无需训练数据的情况下实现高效自进化。具体而言，我们设计了一种自进化反馈循环：提案器生成多样化问题用于训练基于同一基础模型初始化的求解器，而求解器的进化反过来激励提案器产生难度递增且可解决的任务，从而形成自动化课程以同步优化两个智能体。为提升训练效率，我们进一步提出跳数分组相对策略优化方法。该方法通过聚类结构相似的问题构建组级基线，有效减少评估单个查询难度与可解性时的采样开销，进而不牺牲性能或稳定性的前提下显著降低求解器训练的计算需求。大量实验结果表明，无数据训练的Dr. Zero框架在性能上达到甚至超越全监督搜索智能体，证明复杂推理与搜索能力可仅通过自进化机制实现。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07055) | [arXiv](https://arxiv.org/abs/2601.07055)



---

### 17. 先见森林后见树：基于潜在叠加的高效视觉推理方法

**原文标题：** Forest Before Trees: Latent Superposition for Efficient Visual Reasoning

**摘要：**
尽管思维链技术赋予大型视觉语言模型多步推理能力，但显式文本推理过程存在信息带宽瓶颈，连续视觉细节在离散化标记过程中易被丢失。近期潜在推理方法试图解决这一挑战，却常因僵化的自回归目标而陷入过早的语义坍缩。本文提出Laser新范式，通过动态窗口对齐学习重构视觉推理过程。该方法摒弃逐点预测的强制约束，使潜在状态与动态变化的未来语义有效窗口对齐。这种机制构建了"先森林后树木"的认知层级，使模型能够在聚焦局部细节前保持全局特征的概率叠加态。关键创新在于，Laser通过可解码轨迹保持可解释性，同时借助自优化叠加机制稳定无约束学习过程。在6个基准测试上的大量实验表明，Laser在潜在推理方法中达到最先进性能，较强势基线Monet平均提升5.03%。值得注意的是，该方法在实现性能增益的同时具备极高效率，推理标记量减少97%以上，并展现出对分布外领域强大的泛化能力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06803) | [arXiv](https://arxiv.org/abs/2601.06803)



---

### 18. TourPlanner：一种融合约束门控强化学习的竞争性共识框架用于旅行规划

**原文标题：** TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning

**摘要：**
旅行规划是一个复杂的决策过程，需要综合多维度信息以构建行程方案。然而，现有旅行规划方法面临若干挑战：（1）在保持高召回率的同时筛选候选兴趣点；（2）单一推理路径限制了旅行规划在可行解空间内的探索能力；（3）同时优化硬约束与软约束仍是重大难题。为应对这些挑战，我们提出TourPlanner——一个融合多路径推理与约束门控强化学习的综合框架。具体而言，我们首先引入个性化召回与空间优化流程，构建具有空间感知的候选兴趣点集合。随后，我们提出竞争性共识思维链这一多路径推理范式，以增强对可行解空间的探索能力。为进一步优化规划方案，我们在强化学习阶段集成基于Sigmoid函数的门控机制，该机制仅在硬约束满足后动态优先处理软约束的达成。在旅行规划基准测试上的实验结果表明，TourPlanner实现了最先进的性能，在方案可行性与用户偏好契合度方面均显著超越现有方法。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04698) | [arXiv](https://arxiv.org/abs/2601.04698)



---

### 19. OpenTinker：智能体强化学习中的关注点分离

**原文标题：** OpenTinker: Separating Concerns in Agentic Reinforcement Learning

**摘要：**
本文介绍OpenTinker，这是一个围绕算法设计、执行以及智能体-环境交互的关注点分离而构建的大型语言模型（LLM）智能体强化学习（RL）基础设施。OpenTinker摒弃了单一、端到端的强化学习流程，将智能体学习系统分解为具有明确定义抽象边界的轻量级、可组合组件。用户负责定义智能体、环境及交互协议，而推理与训练任务则交由托管执行运行时处理。OpenTinker引入了一个集中式调度器，用于在共享资源上管理训练与推理工作负载，包括基于LoRA和全参数的强化学习、监督微调以及推理任务。我们进一步探讨了将OpenTinker扩展至多智能体训练的设计原则。最后，我们通过一系列强化学习应用案例，展示了该框架在实际智能体学习场景中的有效性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07376) | [arXiv](https://arxiv.org/abs/2601.07376)



---

### 20. 大语言模型的决策是否忠实于其口头置信度？

**原文标题：** Are LLM Decisions Faithful to Verbal Confidence?

**摘要：**
大语言模型（LLMs）能够生成令人惊讶的、关于其自身不确定性的复杂估计。然而，这种表达出的置信度在多大程度上与模型的推理、知识或决策过程相关联，目前尚不明确。为探究此问题，我们引入了RiskEval框架：该框架旨在评估模型是否会根据不同的错误惩罚调整其弃权策略。我们对多个前沿模型的评估揭示了一个关键分离现象：模型在表达口头置信度时并不具备成本意识，在高惩罚条件下决定是否参与或弃权时也缺乏策略性响应。即使极端惩罚使得频繁弃权成为数学上的最优策略，模型也几乎从不弃权，从而导致效用崩溃。这表明，经过校准的口头置信度分数可能不足以构建可信且可解释的人工智能系统，因为当前模型缺乏将不确定性信号转化为最优且风险敏感决策的策略性能力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07767) | [arXiv](https://arxiv.org/abs/2601.07767)



---

### 21. 结构化情景事件记忆

**原文标题：** Structured Episodic Event Memory

**摘要：**
当前大型语言模型中的记忆方法主要依赖静态检索增强生成技术，该方法往往导致检索结果分散，难以捕捉复杂推理所需的结构化依赖关系。对于自主智能体而言，这种被动扁平的架构缺乏对长期交互动态关联特性进行建模所需的认知组织能力。为此，我们提出结构化情景事件记忆框架，该分层架构通过图记忆层处理关系性事实，并与动态情景记忆层协同实现叙事演进。基于认知框架理论，本框架将交互流转化为以前溯指针锚定的结构化情景事件框架。此外，我们引入智能体关联融合机制与反向溯源扩展方法，从碎片化证据中重构连贯的叙事语境。在LoCoMo与LongMemEval基准测试中的实验结果表明，该框架显著超越基线模型，使智能体能够保持卓越的叙事连贯性与逻辑一致性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06411) | [arXiv](https://arxiv.org/abs/2601.06411)



---

### 22. e5-omni：面向全模态嵌入的显式跨模态对齐方法

**原文标题：** e5-omni: Explicit Cross-modal Alignment for Omni-modal Embeddings

**摘要：**
现代信息系统通常涉及多种类型的项目，例如文本查询、图像、视频片段或音频片段。这推动了全模态嵌入模型的发展，旨在将异构模态映射到共享空间中以进行直接比较。然而，当前大多数全模态嵌入方法仍严重依赖于从预训练视觉-语言模型（VLM）主干中继承的隐式对齐机制。在实践中，这引发了三个常见问题：（1）相似度对数具有模态依赖的锐度，导致评分尺度不一致；（2）混合模态批次造成困难度分布不均衡，使得批内负样本随时间推移效果减弱，许多负样本迅速变得无关紧要，对梯度贡献甚微；（3）跨模态嵌入呈现不匹配的一阶和二阶统计特征，导致排序稳定性下降。为解决这些问题，我们提出e5-omni——一种轻量级的显式对齐方案，可将现成的VLM适配为鲁棒的全模态嵌入模型。e5-omni包含三个简单组件：（1）模态感知温度校准，用于对齐相似度尺度；（2）具有去偏控制的可控负样本课程学习，专注于混淆性负样本同时减少假负样本的影响；（3）协方差正则化的批白化处理，以更好地匹配共享嵌入空间中的跨模态几何结构。在MMEB-V2和AudioCaps数据集上的实验表明，该方法相较于强双模态与全模态基线模型均取得稳定提升，且该方案能良好迁移至其他VLM主干网络。模型检查点已发布于https://huggingface.co/Haon-Chen/e5-omni-7B。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03666) | [arXiv](https://arxiv.org/abs/2601.03666)



---

### 23. “TODO: 修复Gemini造成的混乱”：理解生成式人工智能引发的自承技术债务

**原文标题：** "TODO: Fix the Mess Gemini Created": Towards Understanding GenAI-Induced Self-Admitted Technical Debt

**摘要：**
随着ChatGPT、Copilot、Claude和Gemini等大型语言模型（LLMs）逐渐融入软件开发工作流，开发者在代码注释中越来越多地留下人工智能参与的痕迹。其中，部分注释明确承认了生成式人工智能的使用以及技术缺陷的存在。通过分析来自公开Python和JavaScript的GitHub仓库（2022年11月至2025年7月）的6,540条涉及LLM的代码注释，我们识别出81条同时自承技术债务（SATD）的案例。开发者最常描述推迟测试、不完整适配以及对AI生成代码的理解有限，这表明人工智能辅助既影响了技术债务出现的时间，也影响了其产生的原因。我们提出“生成式人工智能引发的自承技术债务”（GIST）这一概念框架，用以描述开发者在使用AI生成代码时，同时明确表达对其行为或正确性存在不确定性的重复性案例。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07786) | [arXiv](https://arxiv.org/abs/2601.07786)



---

### 24. ShowUI-Aloha：人类示范驱动的图形用户界面智能体

**原文标题：** ShowUI-Aloha: Human-Taught GUI Agent

**摘要：**
图形用户界面（GUI）是人机交互的核心，然而自动化复杂的GUI任务仍是自主智能体面临的主要挑战，这很大程度上源于缺乏可扩展的高质量训练数据。虽然人类操作录屏提供了丰富的数据源，但这些记录通常冗长、非结构化且缺乏标注，使得智能体难以从中有效学习。为此，我们提出了ShowUI-Aloha——一个完整的处理流程，能够将桌面环境中非结构化的真实人类屏幕录像转化为结构化、可执行的任务序列。该框架包含四个核心组件：记录器负责捕获屏幕视频及精确的用户交互（如鼠标点击、键盘输入和滚动操作）；学习器通过语义理解原始交互行为与视觉上下文，将其转化为描述性自然语言标注；规划器通过解析示范记录、维护任务状态，并基于上下文推理动态生成下一步高层动作计划；执行器则在操作系统层面忠实执行这些动作计划，通过安全检查与实时反馈机制实现精确点击、拖拽、文本输入及窗口操作。这些组件共同构成了一个可扩展的真实人类数据采集与解析方案，为构建能够通过观察人类行为进行高效学习的通用GUI智能体提供了可行路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07181) | [arXiv](https://arxiv.org/abs/2601.07181)



---

### 25. 编码化伏笔-照应文本生成

**原文标题：** Codified Foreshadowing-Payoff Text Generation

**摘要：**
伏笔与照应是普遍存在的叙事手法，作者通过其在故事早期引入承诺，并通过具体可观察的结果予以解决。然而，尽管故事生成技术取得了进展，大语言模型在连接此类长程叙事依赖关系时仍常显乏力，即便在必要语境存在的情况下，也往往让“契科夫的枪”未能击发。现有评估方法大多忽视了这种结构性缺陷，侧重于表层连贯性而非叙事铺垫的逻辑实现。本文提出编码化伏笔-照应生成框架，该创新框架通过照应实现的视角重构叙事质量评估体系。针对大语言模型难以直观把握伏笔事件“触发机制”的现状，CFPG将叙事连续性转化为一系列可执行的因果谓词。通过从BookSum语料库中挖掘并编码“伏笔-触发-照应”三元组，我们提供了结构化监督机制，确保伏笔承诺不仅被提及，更能在时间与逻辑层面得到兑现。实验表明，CFPG在照应准确度与叙事一致性方面显著优于标准提示基线方法。我们的研究结果表明，对叙事机制进行显式编码对于推动大语言模型从表层流畅性迈向真正的叙事能力至关重要。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07033) | [arXiv](https://arxiv.org/abs/2601.07033)



---

### 26. Sci-Reasoning：解码人工智能创新模式的数据集

**原文标题：** Sci-Reasoning: A Dataset Decoding AI Innovation Patterns

**摘要：**
尽管人工智能创新正加速发展，但突破背后的智力过程——研究者如何识别研究空白、整合先前工作并产生洞见——仍鲜为人知。科学推理结构化数据的缺乏，阻碍了对人工智能研究智能体的系统性分析与开发。本文介绍Sci-Reasoning，这是首个捕捉高质量人工智能研究背后智力综合过程的数据集。通过采用社区验证的质量信号以及基于大语言模型加速、人工验证的流程，我们追踪了NeurIPS、ICML和ICLR（2023-2025年）中Oral与Spotlight论文的关键前驱工作，并以结构化形式阐明了具体的推理关联。我们的分析识别出15种不同的思维模式，其中三种主导策略占比达52.7%：空白驱动重构（24.2%）、跨领域综合（18.0%）与表征转换（10.5%）。最具影响力的创新路径往往融合多种模式：空白驱动重构+表征转换、跨领域综合+表征转换，以及空白驱动重构+跨领域综合。本数据集支持对科学进展的量化研究，并为训练下一代人工智能研究智能体提供了结构化推理轨迹。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04577) | [arXiv](https://arxiv.org/abs/2601.04577)



---

### 27. 大语言模型在持续预训练中如何学习概念？

**原文标题：** How Do Large Language Models Learn Concepts During Continual Pre-Training?

**摘要：**
人类主要通过概念（如“狗”）来理解世界，这些抽象的心理表征构建了感知、推理和学习的基础。然而，大语言模型在持续预训练过程中如何获取、保留和遗忘此类概念，目前仍缺乏深入理解。本研究探讨了单个概念的获取与遗忘机制，以及多个概念之间如何通过干扰和协同产生交互。我们将这些行为动态与模型内部的“概念回路”（即与特定概念相关的计算子图）联系起来，并引入图度量指标来刻画回路结构。分析结果表明：（1）大语言模型的概念回路能够提供具有统计显著性的概念学习与遗忘信号；（2）在持续预训练过程中，概念回路呈现阶段性时序模式，即早期增强、随后逐渐减弱并趋于稳定；（3）学习增益较大的概念在后续训练中往往表现出更强的遗忘现象；（4）语义相似的概念比弱相关概念产生更显著的干扰效应；（5）不同概念知识的可迁移性存在差异，部分概念能显著促进其他概念的学习。综上，本研究从回路层面揭示了概念学习的动态特征，为设计更具可解释性与鲁棒性的概念感知训练策略提供了理论依据。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03570) | [arXiv](https://arxiv.org/abs/2601.03570)



---

### 28. 论后训练中监督微调与强化学习的不可解耦性

**原文标题：** On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training

**摘要：**
大语言模型的后训练通常交替进行监督微调（SFT）与强化学习（RL）。这两种方法具有不同目标：SFT旨在最小化模型输出与专家响应之间的交叉熵损失，而RL则致力于最大化来自人类偏好或基于规则的验证器所衍生的奖励信号。现代推理模型已广泛采用交替进行SFT与RL训练的做法。然而，二者能否解耦尚未有理论阐释。我们证明无论以何种顺序均无法实现解耦：（1）先SFT后RL的耦合：在SFT最优性条件下，RL会增加SFT损失；（2）先RL后SFT的耦合：SFT会降低RL已获得的奖励。基于Qwen3-0.6B的实验证实了预测的性能退化现象，验证了在后训练中若分离SFT与RL，则无法保持先前已达到的性能水平。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07389) | [arXiv](https://arxiv.org/abs/2601.07389)



---

### 29. 文本推理能否提升多模态大语言模型在细粒度视觉分类中的性能？

**原文标题：** Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?

**摘要：**
多模态大语言模型（MLLMs）展现出强大的通用能力，但在细粒度视觉分类（FGVC）这一核心感知任务上仍面临挑战。FGVC需要细微的视觉辨别能力，对众多现实应用至关重要。在数学和代码等复杂任务中，提升性能的常用策略是思维链（CoT）推理。然而，先前多项研究表明，CoT实际上可能损害视觉感知任务的性能。这些研究虽从相对局限的视角探讨了该问题，但尚未揭示CoT降低感知密集型任务性能的根本原因。本文通过零样本评估与多种训练范式的视角，系统性地重新审视了CoT在FGVC中的作用。在不同实验设置中，我们发现一个核心悖论：CoT导致的性能下降主要受推理长度驱动，即更长的文本推理会持续降低分类准确率。我们将此现象称为“思维成本”。基于这一发现，我们做出两项关键贡献：（1）提出\alg方法——一种简单通用的即插即用式多奖励优化归一化方法，可平衡异构奖励信号；（2）提出ReFine-RFT框架，该框架结合集成奖励与\alg方法，在约束推理长度的同时提供密集的以准确率为导向的反馈。大量实验验证了我们发现的普适性及所提ReFine-RFT框架的有效性，该框架在多项FGVC基准测试中达到了最先进的性能。代码与模型已开源：https://github.com/jiezhu23/ReFine-RFT{项目链接}。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06993) | [arXiv](https://arxiv.org/abs/2601.06993)



---

### 30. RealMem：面向现实世界记忆驱动交互的大语言模型评测基准

**原文标题：** RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction

**摘要：**
随着大语言模型从静态对话接口演变为自主通用智能体，有效的记忆机制对于保障长期行为一致性至关重要。然而，现有评测基准主要集中于日常对话或任务导向型对话，未能涵盖智能体必须追踪动态目标的**"长期项目导向型"**交互场景。为填补这一空白，我们提出了首个基于真实项目场景构建的评测基准**RealMem**。该基准涵盖十一个场景下的两千余组跨会话对话，采用自然用户查询进行性能评估。我们设计了一套融合项目基础构建、多智能体对话生成以及记忆与进度管理的综合流程，以模拟记忆的动态演化过程。实验表明，现有记忆系统在管理现实项目固有的长期状态与动态上下文依赖方面面临显著挑战。相关代码与数据集已发布于[https://github.com/AvatarMemory/RealMemBench](https://github.com/AvatarMemory/RealMemBench)。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06966) | [arXiv](https://arxiv.org/abs/2601.06966)



---

### 31. SketchJudge：基于多模态大语言模型的手绘图表评分诊断基准

**原文标题：** SketchJudge: A Diagnostic Benchmark for Grading Hand-drawn Diagrams with Multimodal Large Language Models

**摘要：**
尽管多模态大语言模型（MLLMs）在视觉理解方面取得了显著进展，但在处理人类手绘草图的无结构性和模糊性时仍面临挑战。这一局限在视觉评分这一尚未充分探索的任务中尤为突出——模型不仅需要解决问题，还需诊断手绘图表中的错误。此类诊断能力依赖于复杂的结构、语义及元认知推理。为弥补这一不足，我们提出了SketchJudge，这是一个专为评估MLLMs作为手绘STEM（科学、技术、工程、数学）图表评分者而设计的新型基准。SketchJudge涵盖几何、物理、图表和流程图四个领域的1,015份手绘学生作答样本，包含多样化的风格差异和明确的错误类型。基于SketchJudge的评估表明，即使先进的MLLMs仍显著落后于人类水平，验证了该基准在揭示符号与噪声语境下当前视觉-语言对齐机制脆弱性方面的有效性。所有数据、代码及评估脚本均已公开，访问地址为：https://github.com/yuhangsu82/SketchJudge。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06944) | [arXiv](https://arxiv.org/abs/2601.06944)



---

### 32. 大语言模型微调中的人工纠缠现象研究

**原文标题：** Artificial Entanglement in the Fine-Tuning of Large Language Models

**摘要：**
大语言模型（LLMs）可通过仅修改少量可训练参数的参数高效微调（PEFT）方法适配新任务，其中低秩更新是常用策略。本研究采用量子信息视角解析其有效性机制：低秩参数化天然对应低维矩阵乘积态（MPS）表示，从而可通过纠缠熵量化参数结构特征。据此我们提出并度量“人工纠缠”——即人工神经网络（特指大语言模型）参数体系的纠缠熵。我们以1B和8B规模的LLaMA模型在Tulu3与OpenThoughts3数据集上的训练为实验基础，对比研究了典型低秩适应（LoRA）PEFT方法与全参数微调（FFT），发现：（1）LoRA中查询与值投影矩阵更新呈现具有中心抑制特征的体积律内部人工纠缠（称为“纠缠谷”），其对超参数敏感且与FFT模式显著不同；（2）注意力矩阵中表征空间内词元关联的外部人工纠缠遵循带对数修正的面积律，对LoRA超参数及训练步数保持稳健。借鉴黑洞物理中的无毛定理，我们提出：虽然LoRA与FFT产生相异的内部纠缠特征，但此类差异未在注意力输出中显现，这种“无毛”特性可能是低秩更新有效的内在原因。我们进一步基于随机矩阵理论提供理论支撑，并将分析拓展至MPS适应PEFT方法，发现其具有定性相似的行为特征。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06788) | [arXiv](https://arxiv.org/abs/2601.06788)



---

### 33. FinForge：半合成金融基准生成框架

**原文标题：** FinForge: Semi-Synthetic Financial Benchmark Generation

**摘要：**
在金融等专业且高风险的领域中评估语言模型仍面临重大挑战，主要原因是缺乏公开、高质量且领域特定的数据集。现有的通用基准虽覆盖广泛，但缺乏评估语言模型在实际金融推理能力（既需概念理解又需定量严谨性）所需的深度与领域保真度。为填补这一空白，我们提出了FinForge——一个可扩展的半合成流程，通过专家指导的数据策展与基于语言模型的可控合成相结合，构建金融专用评估基准。FinForge整合了来自权威金融源的手动与程序化语料构建，并利用Gemini 2.5 Flash进行结构化问题生成与验证。为验证该流程的有效性，我们发布了FinForge-5k基准快照，包含超过5,000个人工验证的问答对，涵盖11个金融子领域；其源自从10万份已验证文档（总计1.43亿词元）中精选的语料库。基于FinForge-5k对前沿开源与闭源模型的评估显示，模型在金融推理能力上存在显著差异，领先模型的准确率接近80%。这些发现凸显了该框架在诊断当前模型局限、指导未来金融领域能力改进方面的实用价值。所有代码与数据已公开于https://github.com/gtfintechlab/FinForge。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06747) | [arXiv](https://arxiv.org/abs/2601.06747)



---

### 34. Gecko：一种高效处理任意长度序列的固有神经架构

**原文标题：** Gecko: An Efficient Neural Architecture Inherently Processing Sequences with Arbitrary Lengths

**摘要：**
设计一种能够高效且固有地处理任意长度序列数据的统一神经网络，是序列建模领域一个核心且具有挑战性的问题。Transformer架构中的设计选择，包括二次复杂度与较弱的长度外推能力，限制了其向长序列扩展的能力。本研究提出Gecko神经架构，该架构继承了Mega和Megalodon（采用门控注意力的指数移动平均）的设计思路，并进一步引入多项技术组件以增强其长程依赖捕获能力，包括时间步衰减归一化、滑动分块注意力机制以及自适应工作记忆。在70亿参数规模、2万亿训练标记量的控制性预训练实验中，与Llama2和Megalodon进行对比，Gecko展现出更优的效率和长上下文扩展性。Gecko取得了1.68的训练损失，显著优于Llama2-7B（1.75）和Megalodon-7B（1.70），并接近Llama2-13B（1.67）的水平。值得注意的是，在不依赖任何上下文扩展技术的情况下，Gecko展现出固有的长上下文处理与检索能力，能够稳定处理长达400万标记的序列，并从超出其注意力窗口4倍长度的上下文中检索信息。代码地址：https://github.com/XuezheMax/gecko-llm

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06463) | [arXiv](https://arxiv.org/abs/2601.06463)



---

### 35. 推理扩展能否提升推理忠实度？——关于自洽性权衡的多模型分析

**原文标题：** Does Inference Scaling Improve Reasoning Faithfulness? A Multi-Model Analysis of Self-Consistency Tradeoffs

**摘要：**
自洽性已成为提升大语言模型在推理任务上准确性的常用技术。该方法思路简明：生成多条推理路径，通过多数投票选择最常见答案。尽管这种方法能稳定提升准确率，但其增益是否真正反映推理质量的改善仍不明确。本文探究了一个此前未被研究的基础问题：推理扩展能否提升推理忠实度？

我们在100道GSM8K数学推理问题上，对四种前沿模型（GPT-5.2、Claude Opus 4.5、Gemini-3-flash-preview和DeepSeek-v3.2）展开了全面实证研究。通过自助置信区间、配对比较的麦克尼马尔检验及科恩d效应值等量化分析方法，我们严谨评估了扩展推理的影响。研究结果揭示了模型间的显著差异，对关于自洽性的普遍假设提出了挑战。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06423) | [arXiv](https://arxiv.org/abs/2601.06423)



---

### 36. FlyPose：面向无人机视角下鲁棒人体姿态估计的研究

**原文标题：** FlyPose: Towards Robust Human Pose Estimation From Aerial Views

**摘要：**
无人机正日益频繁地部署于人类活动密集的场景中，例如包裹配送、交通监控、灾害响应和基础设施巡检。为确保在此类人机共融环境中的安全可靠运行，需要从空中视角准确感知人体姿态与行为。这种视角因图像分辨率低、拍摄角度陡峭以及（自）遮挡等问题，对现有方法提出了严峻挑战，尤其在需要实时可行模型的应用场景中。本研究训练并部署了FlyPose——一种面向航拍图像的轻量级自上而下人体姿态估计流程。通过多数据集联合训练，我们在Manipal-UAV、VisDrone、HIT-UAV及自建数据集的测试集上实现了人体检测平均精度6.8 mAP的提升。针对二维人体姿态估计任务，我们在极具挑战性的UAV-Human数据集上取得了16.3 mAP的精度提升。FlyPose在Jetson Orin AGX开发套件上的推理延迟（含预处理）约为20毫秒，并在飞行实验中成功部署于四旋翼无人机平台。同时，我们开源了FlyPose-104数据集——一个规模较小但极具挑战性的航拍人体姿态估计数据集，包含从困难航拍视角手工标注的样本：https://github.com/farooqhassaan/FlyPose。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05747) | [arXiv](https://arxiv.org/abs/2601.05747)



---

### 37. 系统日志严重性分类任务中轻量级语言模型与轻量级推理语言模型的基准测试

**原文标题：** Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification

**摘要：**
系统日志对于监控和诊断现代计算基础设施至关重要，但其规模与复杂性要求可靠高效的自动化解析。由于严重性级别是系统日志消息中预定义的元数据，仅让模型对其进行分类的独立实用价值有限，难以揭示模型理解系统日志的深层能力。我们认为，将严重性分类视为探究运行时日志理解能力的基准测试，而非最终任务，能提供更多信息。基于Linux生产服务器的真实journalctl数据，我们在零样本、少样本及检索增强生成（RAG）提示下评估了九种轻量级语言模型（SLM）与轻量级推理语言模型（SRLM）。结果显示出明显的性能分层：Qwen3-4B在RAG设置下达到最高准确率95.64%，而Gemma3-1B在少样本提示下准确率仅为20.25%，结合RAG后提升至85.28%。值得注意的是，微型的Qwen3-0.6B在无检索时表现较弱，但借助RAG准确率达到88.12%。相比之下，包括Qwen3-1.7B和DeepSeek-R1-Distill-Qwen-1.5B在内的多款SRLM在与RAG结合时性能显著下降。效率测试进一步区分了模型性能：多数Gemma和Llama变体能在每条日志1.2秒内完成推理，而Phi-4-Mini-Reasoning的单条日志推理时间超过228秒，准确率却低于10%。这些发现表明：（1）架构设计，（2）训练目标，以及（3）在严格输出约束下整合检索上下文的能力共同决定了模型表现。通过聚焦轻量可部署模型，本基准测试契合数字孪生（DT）系统的实时性需求，并证明严重性分类可作为评估模型能力与实时部署可行性的观察窗口，对根本原因分析（RCA）及更广泛的DT集成具有启示意义。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07790) | [arXiv](https://arxiv.org/abs/2601.07790)



---

### 38. 随机混沌：为何确定性推断扼杀人工智能认知，而分布变异性是其生命之源

**原文标题：** Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artifical Cognition

**摘要：**
确定性推断是经典软件中一种令人安心的理想状态：相同程序在相同输入下应始终产生相同输出。随着大语言模型进入实际部署阶段，这一理念被全盘引入推断架构。思维机器实验室近期研究详细分析了LLM推断中的非确定性，展示了批不变内核与确定性注意力机制如何强制实现比特级完全一致的输出，并将确定性推断定位为可复现性与企业级可靠性的前提。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07239) | [arXiv](https://arxiv.org/abs/2601.07239)



---

### 39. 3D CoCa v2：结合测试时搜索的可泛化空间智能对比学习框架

**原文标题：** 3D CoCa v2: Contrastive Learners with Test-Time Search for Generalizable Spatial Intelligence

**摘要：**
空间智能指在三维环境中感知、推理并描述物体及其关系的能力，是具身感知与场景理解的基础。三维场景描述旨在用自然语言描述三维场景，但由于点云的稀疏性与不规则性，以及现有描述模型在室内外等差异显著场景中存在的弱 grounding 问题和有限分布外泛化能力，该任务仍面临挑战。为解决这一问题，我们提出 3D CoCa v2——一种可泛化的三维场景描述框架，该框架将对比式视觉-语言学习与三维描述生成相统一，并通过无需更新模型参数的测试时搜索进一步提升鲁棒性。3D CoCa v2 基于冻结的 CLIP 语义先验、感知几何信息的空间感知三维场景编码器，以及通过对比学习与描述生成目标联合优化的多模态解码器构建，无需依赖外部检测器或人工提案。在推理阶段，测试时搜索生成多样化的描述候选，并基于紧凑场景摘要进行奖励引导的选择。实验表明，本方法在 ScanRefer 数据集上 CIDEr@0.5IoU 指标提升 1.50，在 Nr3D 数据集上提升 1.61，在 TOD3Cap 的零样本分布外评估中 CIDEr@0.25 指标提升 3.8。代码将发布于 https://github.com/AIGeeksGroup/3DCoCav2。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06496) | [arXiv](https://arxiv.org/abs/2601.06496)



---

### 40. 论口语语言模型评估中全局词元困惑度的谬误

**原文标题：** On the Fallacy of Global Token Perplexity in Spoken Language Model Evaluation

**摘要：**
基于大规模原始音频预训练的生成式口语语言模型能够在保持说话者身份与情感特征等属性的同时，生成符合语境的语音延续内容，已成为口语对话系统的基石模型。在现有文献中，这类模型常采用"全局词元困惑度"进行评估——该方法直接将文本困惑度公式应用于语音词元。然而，这种评估方式忽视了语音与文本模态间的本质差异，可能导致对语音特性的低估。本研究提出一系列基于似然估计与生成质量的评估方法，以替代简单的全局词元困惑度指标。实验证明，所提出的评估方法能更真实地反映感知生成质量，其与人工评定的平均意见得分（MOS）之间展现出更强的相关性。在新指标评估体系下，口语语言模型的性能对比格局发生重构：最佳模型与人类表现上限之间的差距显著缩小。这些结果表明，采用恰当的评估方法对于准确衡量口语语言建模的发展进程具有至关重要的意义。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06329) | [arXiv](https://arxiv.org/abs/2601.06329)



---

### 41. 水涨船高：基于机器翻译质量估计的习语奖励机制提升整体翻译质量

**原文标题：** A Rising Tide Lifts All Boats: MTQE Rewards for Idioms Improve General Translation Quality

**摘要：**
非组合性表达（如习语、谚语和隐喻）对神经机器翻译系统构成显著挑战，因其含义无法仅通过单个词汇推导得出。这类表达承载着丰富的文化内涵，兼具比喻义与字面义，导致准确翻译难度较高。鉴于现有模型在组合性文本翻译中表现良好，本研究探索采用机器翻译质量估计模型作为奖励函数，通过GRPO式微调训练模型以提升习语翻译能力。基于汉语和印地语习语数据集的实验表明：模型习语翻译能力提升约14个百分点，通用非习语翻译能力隐性提升约8个百分点，跨语言翻译能力（单语言训练、跨语言评估）提升约6个百分点。本研究量化了非组合性表达的翻译差距，为开发具有更强跨文化及比喻语言理解能力的大语言模型提供了理论依据。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06307) | [arXiv](https://arxiv.org/abs/2601.06307)



---

### 42. SPINAL——神经对齐层中的缩放律与偏好整合

**原文标题：** SPINAL -- Scaling-law and Preference Integration in Neural Alignment Layers

**摘要：**
直接偏好优化（DPO）是一种基于原则且可扩展的方法，可作为RLHF的替代方案，用于根据成对偏好对齐大语言模型。然而，其内部几何特征尚未得到充分刻画，这限制了对模型的审计、检查点比较以及故障预测。本文提出SPINAL（神经对齐层中的缩放律与偏好整合），这是一种通过逐层追踪局部结构变化来度量对齐过程如何重塑各层表征的诊断方法。在不同模型系列中，DPO会产生一种集中于最后解码器块（通常为第21至30层）的逐层校准效应，偏好梯度在此处对下一词元分布产生最直接影响。SPINAL将每个检查点编码为基于（层索引、收缩分数、传输分数）的深度轨迹。收缩分数概括了层谱尾部的衰减速度（小模态消失的快慢），数值越高表明表征向更少有效方向的收缩越强；传输分数则通过有界重叠度量概括相邻层间词元分布的偏移程度，数值越低表明表征空间的步进更短、更平滑。对齐后的检查点显示出收缩分数在深层骤升、传输分数平稳下降的特征，与策略分布的收紧和稳定相一致；而未对齐模型则呈现出更高曲率、更高熵值及几何不连贯的深度轨迹。总体而言，对齐过程具有几何局部性：最终层编码了最主要的偏好诱导修正。SPINAL将这种局部性转化为实用的审计信号，可量化对齐集中发生的层位、其表现强度以及在训练过程中开始失稳的时机。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06238) | [arXiv](https://arxiv.org/abs/2601.06238)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2026-01-13_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)