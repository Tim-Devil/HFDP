
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-13 论文日报

## 📊 今日论文统计
- 总论文数：42
- 热门领域：LLM, Vision, GPT, Transformer, RL, Audio

## 📝 论文详情


### 1. 观看、推理与搜索：面向智能体视频推理的开放网络视频深度研究基准

**原文标题：** Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning

**摘要：**
在真实世界视频问答场景中，视频通常仅提供局部视觉线索，而可验证答案广泛分布于开放网络；模型因此需要联合执行跨帧线索提取、迭代检索以及基于多跳推理的验证。为弥合这一差距，我们构建了首个视频深度研究基准VideoDR。该基准以视频条件开放域视频问答为核心，要求进行跨帧视觉锚点提取、交互式网络检索，以及对视频-网络联合证据的多跳推理；通过严格的人工标注与质量控制，我们获得了涵盖六个语义领域的高质量视频深度研究样本。我们分别在流程式与智能体式两种范式下评估了多个闭源与开源多模态大语言模型，结果表明智能体范式并非始终优于流程式范式：其性能提升取决于模型在长检索链中保持初始视频锚点的能力。进一步分析指出，目标漂移与长程一致性是核心瓶颈。综上所述，VideoDR为开放网络环境下的视频智能体研究提供了系统性基准，并揭示了新一代视频深度研究智能体面临的关键挑战。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06943) | [arXiv](https://arxiv.org/abs/2601.06943)



---

### 2. BabyVision：超越语言的视觉推理能力研究

**原文标题：** BabyVision: Visual Reasoning Beyond Language

**摘要：**
人类在掌握语言之前便已发展出核心视觉能力，而当代多模态大语言模型（MLLMs）仍严重依赖语言先验知识来弥补其薄弱的视觉理解能力。我们发现一个重要事实：当前最先进的MLLMs在人类（甚至三岁儿童）可轻松解决的基础视觉任务上持续表现不佳。为系统探究这一差距，我们提出了BabyVision基准测试，旨在独立于语言知识评估MLLMs的核心视觉能力。BabyVision涵盖广泛任务类型，包含四大关键类别下的22个子类共388项测试项目。实证结果与人工评估表明，主流MLLMs的表现显著低于人类基线水平。其中Gemini3-Pro-Preview仅获49.7分，落后于六岁儿童水平，与成人平均94.1分存在巨大差距。这些结果揭示，尽管当前MLLMs在知识密集型评估中表现优异，但仍缺乏基础视觉认知能力。BabyVision的进展标志着向人类水平视觉感知与推理能力迈出了重要一步。我们还通过提出BabyVision-Gen与自动评估工具包，探索利用生成模型解决视觉推理问题。相关代码与基准数据已发布于https://github.com/UniPat-AI/BabyVision以供复现研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06521) | [arXiv](https://arxiv.org/abs/2601.06521)



---

### 3. PaCoRe：通过并行协同推理实现测试时计算规模化的学习方法

**原文标题：** PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning

**摘要：**
本文提出并行协同推理（PaCoRe），一种旨在解决当代语言模型核心局限的训练与推理框架：模型无法在固定上下文窗口限制下，将测试时计算（TTC）规模显著扩展至超越序列推理的范畴。PaCoRe摒弃传统序列化范式，通过基于消息传递架构的多轮协调机制，驱动测试时计算实现大规模并行探索。每一轮并行启动多条推理轨迹，将其发现压缩至上下文受限的消息中，并综合这些消息以指导下一轮推理，最终生成答案。通过基于结果的大规模端到端强化学习训练，模型掌握了PaCoRe所需的信息综合能力，能够将有效测试时计算扩展至数百万token量级，同时不突破上下文长度限制。该方法在多个领域均带来显著性能提升，尤其在数学推理领域超越了前沿系统：一个80亿参数的模型在HMMT 2025测试中达到94.5%的准确率，通过将有效测试时计算扩展至约两百万token，超越了GPT-5的93.2%表现。我们开源了模型检查点、训练数据及完整推理流程，以加速后续研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05593) | [arXiv](https://arxiv.org/abs/2601.05593)



---

### 4. MHLA：通过令牌级多头机制恢复线性注意力的表达能力

**原文标题：** MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head

**摘要：**
尽管Transformer架构在众多领域占据主导地位，但其二次复杂度的自注意力机制限制了其在大规模场景中的应用。线性注意力提供了一种高效的替代方案，但其直接应用往往导致性能下降。现有改进方法通常通过引入额外模块（如深度可分离卷积）重新引入计算开销，这违背了设计初衷。本文指出这些方法存在一个关键缺陷：全局上下文坍缩，即模型丧失表征多样性。为解决此问题，我们提出多头线性注意力机制（MHLA），通过在令牌维度划分的注意力头内计算注意力以保持多样性。我们证明MHLA在维持线性复杂度的同时，能够恢复softmax注意力的大部分表达能力，并在多个领域验证其有效性：在相同时间复杂度下，ImageNet分类任务提升3.6%，自然语言处理任务提升6.3%，图像生成任务提升12.6%，视频生成任务提升41%。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07832) | [arXiv](https://arxiv.org/abs/2601.07832)



---

### 5. X-Coder：基于全合成任务、解决方案与测试的竞争性编程推进研究

**原文标题：** X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests

**摘要：**
竞争性编程因其密集的推理需求与高逻辑复杂度，对代码大语言模型提出了巨大挑战。然而，当前代码大语言模型仍严重依赖现实世界数据，这限制了其可扩展性。本文探索了一种全合成方法：通过完全生成的任务、解决方案与测试用例训练代码大语言模型，从而在不依赖现实数据的情况下增强代码推理能力。为此，我们基于特征合成技术提出了一种名为SynthSmith的新型数据合成流程。SynthSmith展现出生成多样化、高难度任务以及已验证解决方案与测试用例的强大潜力，同时支持监督微调与强化学习。基于所提出的合成监督微调与强化学习数据集，我们推出了X-Coder模型系列。该系列模型在LiveCodeBench v5上达到62.9 avg@8的显著通过率，在v6上达到55.8，仅以70亿参数即超越了DeepCoder-14B-Preview与AReal-boba2-14B模型。深入分析表明，缩放定律在我们的合成数据集上依然成立，并进一步探索了哪些维度对扩展更有效。我们通过详细的消融实验与分析，深入探讨了以代码为中心的强化学习机制，并揭示了影响性能的关键因素。研究结果表明，扩展高质量合成数据并采用分阶段训练策略能显著推进代码推理能力的发展，同时减少对现实世界编程数据的依赖。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06953) | [arXiv](https://arxiv.org/abs/2601.06953)



---

### 6. GlimpRouter：通过思维一瞥实现高效协同推理

**原文标题：** GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts

**摘要：**
大型推理模型通过显式生成多步思维链取得了卓越性能，但这种能力会带来显著的推理延迟和计算成本。协同推理通过在轻量级模型与大型模型之间选择性分配工作提供了有前景的解决方案，然而一个根本性挑战仍然存在：如何判断推理步骤何时需要大型模型的能力，何时可交由小型模型高效处理。现有路由策略要么依赖局部词元概率，要么采用事后验证机制，均会引入显著的推理开销。本研究提出一种新颖的逐步骤协同视角：推理步骤的难度可通过其首个词元进行推断。受大型推理模型中“顿悟时刻”现象的启发，我们发现初始词元的熵值可作为步骤难度的强预测指标。基于此洞见，我们提出了GlimpRouter——一种无需训练的逐步骤协同推理框架。该框架使用轻量级模型仅生成每个推理步骤的首个词元，仅当初始词元熵值超过阈值时才将步骤路由至大型模型。在多个基准测试上的实验表明，该方法在保持准确性的同时显著降低了推理延迟。例如在AIME25基准上，相较于独立大型模型，GlimpRouter在降低25.9%推理延迟的同时实现了10.7%的准确率提升。这些结果表明了一种简单而有效的推理机制：基于思维片段的“一瞥”而非完整步骤评估来分配计算资源。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05110) | [arXiv](https://arxiv.org/abs/2601.05110)



---

### 7. 迷失于噪声之中：推理模型如何在上下文干扰项下失效

**原文标题：** Lost in the Noise: How Reasoning Models Fail with Contextual Distractors

**摘要：**
推理模型与智能体人工智能系统的最新进展，导致了对多样化外部信息的日益依赖。然而，这种转变引入了本质上充满噪声的输入上下文，而当前经过净化的基准测试未能捕捉这一现实。我们提出了NoisyBench，这是一个综合性基准，系统性地评估了模型在RAG、推理、对齐和工具使用任务中，针对包括随机文档、无关聊天历史和困难负例干扰项在内的多种噪声类型，在11个数据集上的鲁棒性。我们的评估显示，在面对上下文干扰项时，最先进的模型性能会出现高达80%的灾难性下降。关键的是，我们发现智能体工作流常常因过度信任有噪声的工具输出而放大这些错误，并且干扰项即使没有对抗意图也可能引发突发的错位行为。我们发现，提示工程、上下文工程、监督微调以及仅基于结果奖励的强化学习均无法确保鲁棒性；相比之下，我们提出的**理性感知奖励**通过激励模型识别噪声中有用的信息，显著增强了其抗干扰能力。最后，我们揭示了一种逆向缩放趋势，即增加测试时的计算量反而导致在噪声环境下的性能更差，并通过注意力可视化证明模型会不成比例地关注干扰项标记，这为构建下一代鲁棒且具备推理能力的智能体提供了至关重要的见解。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07226) | [arXiv](https://arxiv.org/abs/2601.07226)



---

### 8. OS-Symphony：一种面向鲁棒通用计算机使用智能体的整体框架

**原文标题：** OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent

**摘要：**
尽管视觉语言模型（VLMs）显著推动了计算机使用智能体（CUAs）的发展，但现有框架在长流程工作流的鲁棒性和新领域泛化能力方面仍面临挑战。这些局限主要源于对历史视觉上下文管理缺乏细粒度控制，以及缺少视觉感知的教程检索机制。为弥补这些不足，本文提出OS-Symphony整体框架，其核心协调器整合了两项关键创新以实现鲁棒自动化：（1）反思记忆智能体，利用里程碑驱动的长期记忆实现轨迹级自我修正，有效缓解长流程任务中的视觉上下文丢失问题；（2）多功能工具智能体，配备采用SeeAct范式的多模态检索器，可在基于浏览器的沙箱环境中导航并合成实时视觉对齐教程，从而解决未知场景中的保真度问题。实验结果表明，OS-Symphony在不同规模模型上均实现显著性能提升，在三个在线基准测试中创下最新最优记录，其中在OSWorld基准上达到65.84%的显著成效。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07779) | [arXiv](https://arxiv.org/abs/2601.07779)



---

### 9. 超越硬掩码：扩散语言模型的渐进式词元演化

**原文标题：** Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models

**摘要：**
扩散语言模型通过迭代优化实现并行解码，为语言建模提供了一种前景广阔的替代方案。然而，现有扩散语言模型大多依赖硬二元掩码和离散词元分配机制，这限制了早期决策的可修正性，且未能充分利用中间概率表示。本文提出EvoToken-DLM——一种基于扩散机制的新型语言建模方法，该方法通过演化的软词元分布替代硬二元掩码。EvoToken-DLM实现了从掩码状态到离散输出的渐进式过渡，支持可修正的解码过程。为有效支撑这种演化机制，我们引入连续轨迹监督方法，使训练目标与迭代概率更新过程保持对齐。在多个基准测试上的广泛实验表明，EvoToken-DLM始终取得卓越性能，显著优于现有基于扩散和掩码的扩散语言模型基线。项目主页：https://aim-uofa.github.io/EvoTokenDLM。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07351) | [arXiv](https://arxiv.org/abs/2601.07351)



---

### 10. 可控记忆使用：长期人机交互中的锚定与创新平衡

**原文标题：** Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction

**摘要：**
随着基于大语言模型的智能体在长期交互中的应用日益广泛，累积记忆对于实现个性化服务和保持风格一致性至关重要。然而，现有系统大多采用“全有或全无”的记忆使用策略：若完全纳入过往相关信息，可能导致“记忆锚定”现象，使智能体受困于历史交互模式；而完全排除记忆则会造成信息利用不足及重要交互历史的丢失。本文提出可将智能体对记忆的依赖程度建模为显式且用户可控的维度。我们首先引入记忆依赖性的行为度量指标，用以量化历史交互对当前输出的影响程度。进而提出可调控记忆智能体框架SteeM，该框架允许用户动态调节记忆依赖强度——从促进创新的“全新启动”模式到严格遵循交互历史的“高保真”模式。多场景实验表明，该方法在个性化人机协作中始终优于传统提示策略与刚性记忆屏蔽方案，能够实现更精细有效的交互控制。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05107) | [arXiv](https://arxiv.org/abs/2601.05107)



---

### 11. DrivingGen：自动驾驶生成式视频世界模型的综合基准测试

**原文标题：** DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving

**摘要：**
作为世界模型的一种形式，视频生成模型已成为人工智能领域最激动人心的前沿方向之一，其通过建模复杂场景的时间演化，使智能体具备预测未来的能力。在自动驾驶领域，这一愿景催生了驾驶世界模型：这类生成式模拟器能够推演自车与其他交通参与者的未来状态，从而实现可扩展的仿真、极端场景的安全测试以及丰富的合成数据生成。然而，尽管相关研究快速增长，该领域仍缺乏严谨的基准测试来衡量进展并指引重点方向。现有评估方法存在明显局限：通用视频指标忽略了安全关键的成像因素；轨迹合理性鲜少被量化；时间一致性与智能体层级一致性未被重视；基于自车条件的可控性亦遭忽视。此外，当前数据集未能覆盖现实部署所需的多变场景条件。为弥补这些不足，我们提出了DrivingGen——首个面向生成式驾驶世界模型的综合基准测试。DrivingGen整合了从驾驶数据集和互联网规模视频源中精选的多样化评估数据集，涵盖不同天气、昼夜时段、地理区域及复杂驾驶场景，并配套一套全新评估指标，从视觉真实感、轨迹合理性、时间连贯性和可控性四个维度进行联合评估。通过对14个前沿模型的基准测试，我们揭示了明确的权衡关系：通用模型视觉表现更佳但违背物理规律，而驾驶专用模型能真实捕捉运动模式却在视觉质量上存在不足。DrivingGen提供了一个统一的评估框架，旨在推动可靠、可控、可部署的驾驶世界模型发展，为可扩展仿真、路径规划与数据驱动决策提供支撑。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.01528) | [arXiv](https://arxiv.org/abs/2601.01528)



---

### 12. MegaFlow：面向智能体时代的大规模分布式编排系统

**原文标题：** MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era

**摘要：**
交互式与自主人工智能系统的快速发展标志着我们正迈入智能体时代。在软件工程、计算机操作等复杂智能体任务上训练与评估智能体，不仅需要高效的模型计算能力，更依赖于能够协调海量智能体-环境交互的复杂基础设施。然而，当前尚无开源基础设施能有效支持此类复杂智能体任务的大规模训练与评估。为应对这一挑战，本文提出MegaFlow——一个面向智能体-环境工作负载的大规模分布式编排系统，可实现高效的任务调度、资源分配与细粒度任务管理。MegaFlow将智能体训练基础设施抽象为三个通过统一接口交互的独立服务（模型服务、智能体服务与环境服务），支持在不同智能体-环境配置中实现独立扩展与灵活资源分配。在实际部署的智能体训练场景中，MegaFlow成功协调了数万个并发智能体任务，在保持系统高稳定性的同时实现了高效的资源利用率。通过赋能如此大规模的智能体训练，MegaFlow填补了新兴智能体人工智能领域的关键基础设施空白。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07526) | [arXiv](https://arxiv.org/abs/2601.07526)



---

### 13. 通过解耦表征对齐增强潜在扩散模型

**原文标题：** Boosting Latent Diffusion Models via Disentangled Representation Alignment

**摘要：**
潜在扩散模型通过在压缩的潜在空间中操作来生成高质量图像，该空间通常通过变分自编码器等图像标记器获得。为构建更利于生成的VAE，近期研究探索利用视觉基础模型作为VAE的表征对齐目标，这与LDM常用的对齐策略相呼应。尽管这种方法带来了一定的性能提升，但为VAE和LDM使用相同的对齐目标忽略了两者根本不同的表征需求。我们认为，LDM受益于保留高层语义概念的潜在表示，而VAE应擅长语义解耦，能够以结构化方式编码属性级信息。为此，我们提出语义解耦VAE，通过将其潜在空间与预训练VFM的语义层次对齐，显式优化解耦表征学习。该方法采用非线性映射网络转换VAE潜在表示，使其与VFM对齐，从而弥合属性级解耦与高层语义之间的鸿沟，为VAE学习提供有效指导。我们通过属性预测任务的线性探针评估语义解耦效果，证明其与生成性能提升存在强相关性。最终，基于Send-VAE训练了基于流的Transformer模型SiT；实验表明Send-VAE显著加速训练过程，在ImageNet 256×256数据集上使用/不使用无分类器引导时分别达到1.21和1.75的当前最优FID指标。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05823) | [arXiv](https://arxiv.org/abs/2601.05823)



---

### 14. 用户未尽之言：欠明确查询对视觉语言模型的限制

**原文标题：** What Users Leave Unsaid: Under-Specified Queries Limit Vision-Language Models

**摘要：**
当前的视觉语言基准测试主要包含结构清晰、提示明确的问题。然而，真实用户的查询往往是非正式且欠明确的。用户通常会省略大量信息，依赖图像来传递上下文。我们提出了HAERAE-Vision基准，该基准包含来自韩国在线社区的653个真实视觉问题（从8.6万个候选问题中筛选保留0.76%），每个问题均配有一个明确的重写版本，共生成1,306个查询变体。通过对39个视觉语言模型进行评估，我们发现即使是当前最先进的模型（如GPT-5、Gemini 2.5 Pro）在原始查询上的准确率也不足50%。关键的是，仅通过查询明确化处理，模型性能即可提升8至22个百分点，且较小模型受益最为显著。我们进一步证明，即使结合网络搜索，欠明确查询的表现仍不及未经搜索的明确查询，这表明当前检索技术无法弥补用户省略的信息。我们的研究结果表明，视觉语言模型面临的大部分困难源于自然查询的欠明确性，而非模型能力本身，这凸显了基准评估与实际应用之间存在的重要差距。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06165) | [arXiv](https://arxiv.org/abs/2601.06165)



---

### 15. ET-Agent：通过行为校准激励高效工具集成推理智能体

**原文标题：** ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration

**摘要：**
大型语言模型（LLM）能够通过采用工具集成推理（TIR）范式来扩展其参数知识边界。然而，现有基于LLM的智能体训练框架通常侧重于答案的准确性，而忽视了对行为模式的针对性对齐。因此，智能体在执行TIR任务时常常表现出低效行为，例如冗余或不足的工具调用。如何在校准TIR任务执行过程中的错误行为模式，从而探索有效轨迹，仍是一个开放性问题。本文提出ET-Agent，这是一个通过两个协同视角——自演进数据飞轮与行为校准训练——来校准智能体工具使用行为的训练框架。具体而言，我们引入自演进数据飞轮以生成增强数据，用于微调LLM以提升其探索能力。在此基础上，我们实现了一个两阶段的行为校准训练框架，旨在逐步将错误行为模式校准至最优行为。进一步的深入实验证实了该方法在多个维度上的优越性，包括正确性、效率、推理简洁性和工具执行准确性。我们的ET-Agent框架为TIR领域的研究提供了实践启示。代码可在https://github.com/asilverlight/ET-Agent获取。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06860) | [arXiv](https://arxiv.org/abs/2601.06860)



---

### 16. Dr. Zero：无需训练数据的自进化搜索智能体

**原文标题：** Dr. Zero: Self-Evolving Search Agents without Training Data

**摘要：**
随着高质量数据日益难以获取，无数据自进化已成为一种前景广阔的研究范式。该方法使大型语言模型能够自主生成并解决复杂问题，从而提升其推理能力。然而，多轮搜索智能体在无数据自进化中面临挑战，主要受限于问题多样性不足以及多步推理与工具调用所需的大量计算资源。本研究提出Dr. Zero框架，使搜索智能体能够在完全无需训练数据的情况下实现高效自进化。具体而言，我们设计了自进化反馈循环机制：由提议者生成多样化问题用于训练基于同一基础模型初始化的求解器。随着求解器能力的进化，它会激励提议者产生难度递增且可解决的任务，从而形成自动化课程学习体系以同步优化两个智能体。为提升训练效率，我们进一步提出跳步分组相对策略优化方法。该方法通过聚类结构相似的问题构建组级基线，有效降低了评估单个查询难度与可解性所需的采样开销。因此，HRPO在保持性能与稳定性的同时，显著减少了求解器训练的计算需求。大量实验结果表明，无数据训练的Dr. Zero在性能上达到甚至超越了全监督训练的搜索智能体，证明了复杂推理与搜索能力可仅通过自进化机制实现涌现。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07055) | [arXiv](https://arxiv.org/abs/2601.07055)



---

### 17. 先见森林后见树：基于潜在叠加的高效视觉推理方法

**原文标题：** Forest Before Trees: Latent Superposition for Efficient Visual Reasoning

**摘要：**
尽管思维链技术赋予大型视觉语言模型多步推理能力，但显式文本推理过程存在信息带宽瓶颈——连续的视觉细节在离散化标记处理过程中被丢失。近期潜在推理方法试图解决这一挑战，却常因僵化的自回归目标而陷入过早的语义坍缩。本文提出Laser新范式，通过动态窗口对齐学习重构视觉推理过程。该方法摒弃逐点预测的强制约束，使潜在状态与未来语义的动态有效窗口对齐。这种机制构建了“先森林后树木”的认知层级，使模型在聚焦局部细节前能够保持全局特征的概率叠加态。关键创新在于，Laser通过可解码轨迹保持可解释性，同时借助自优化叠加机制稳定无约束学习过程。在6个基准测试上的实验表明，Laser在潜在推理方法中达到最先进性能，较强势基线Monet平均提升5.03%。值得注意的是，该方法在实现性能增益的同时具备极高效率，推理标记量减少97%以上，并展现出对分布外领域强大的泛化能力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06803) | [arXiv](https://arxiv.org/abs/2601.06803)



---

### 18. TourPlanner：一种基于约束门控强化学习的竞争共识式旅行规划框架

**原文标题：** TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning

**摘要：**
旅行规划是一个复杂的决策过程，需要综合多维度信息以构建行程方案。然而，现有旅行规划方法面临多重挑战：（1）在保持高召回率的同时筛选候选兴趣点；（2）单一推理路径限制了旅行规划在可行解空间中的探索能力；（3）同时优化硬约束与软约束仍是重大难题。为应对这些挑战，我们提出TourPlanner——一个融合多路径推理与约束门控强化学习的综合框架。具体而言，我们首先设计个性化召回与空间优化流程，构建具有空间感知的候选兴趣点集合。随后提出竞争共识思维链多路径推理范式，增强对可行解空间的探索能力。为进一步优化规划方案，我们在强化学习阶段引入基于Sigmoid函数的门控机制，该机制仅在硬约束满足后动态调整对软约束的优先满足程度。在旅行规划基准测试上的实验结果表明，TourPlanner实现了最先进的性能，在方案可行性与用户偏好契合度方面均显著超越现有方法。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04698) | [arXiv](https://arxiv.org/abs/2601.04698)



---

### 19. OpenTinker：智能体强化学习中的关注点分离

**原文标题：** OpenTinker: Separating Concerns in Agentic Reinforcement Learning

**摘要：**
本文介绍OpenTinker，这是一个围绕算法设计、执行以及智能体-环境交互的关注点分离而构建的大型语言模型（LLM）智能体强化学习（RL）基础设施。OpenTinker摒弃了单一、端到端的强化学习流程，将智能体学习系统分解为具有明确定义抽象边界的轻量级可组合组件。用户负责定义智能体、环境及交互协议，而推理与训练任务则交由托管执行运行时处理。OpenTinker引入了一个集中式调度器，用于在共享资源上管理训练与推理工作负载，包括基于LoRA和全参数的强化学习、监督微调以及推理任务。我们进一步探讨了将OpenTinker扩展至多智能体训练的设计原则。最后，我们通过一系列强化学习应用案例，展示了该框架在实际智能体学习场景中的有效性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07376) | [arXiv](https://arxiv.org/abs/2601.07376)



---

### 20. 大语言模型的决策是否忠实于其口头置信度？

**原文标题：** Are LLM Decisions Faithful to Verbal Confidence?

**摘要：**
大语言模型（LLMs）能够生成令人惊讶的、关于其自身不确定性的复杂估计。然而，这种表达出的置信度在多大程度上与模型的推理、知识或决策过程相关联，目前尚不清楚。为了检验这一点，我们引入了RiskEval框架：该框架旨在评估模型是否会根据不同的错误惩罚调整其弃权策略。我们对多个前沿模型的评估揭示了一个关键的分裂现象：模型在表达其口头置信度时并不具备成本意识，在高惩罚条件下决定是否参与或弃权时也缺乏策略性响应。即使极端惩罚使得频繁弃权成为数学上的最优策略，模型也几乎从不选择弃权，从而导致效用崩溃。这表明，经过校准的口头置信度分数可能不足以构建可信且可解释的人工智能系统，因为当前模型缺乏将不确定性信号转化为最优且风险敏感决策的策略能动性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07767) | [arXiv](https://arxiv.org/abs/2601.07767)



---

### 21. 结构化情景事件记忆

**原文标题：** Structured Episodic Event Memory

**摘要：**
当前大型语言模型（LLM）中的记忆方法主要依赖于静态检索增强生成（RAG），这种方式常导致检索结果分散，难以捕捉复杂推理所需的结构化依赖关系。对于自主智能体而言，这种被动且扁平化的架构缺乏必要的认知组织能力，无法有效建模长期交互中动态且关联的特性。为此，我们提出结构化情景事件记忆（SEEM）——一种分层框架，通过将关系性事实的图记忆层与叙事推进的动态情景记忆层相协同，构建起融合的记忆体系。该框架基于认知框架理论，将交互流转化为以前溯指针为锚点的结构化情景事件框架（EEF）。此外，我们引入了自主关联融合机制与反向溯源扩展（RPE）方法，以从碎片化证据中重建连贯的叙事语境。在LoCoMo与LongMemEval基准测试上的实验结果表明，SEEM显著优于现有基线方法，能够使智能体保持更优的叙事连贯性与逻辑一致性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06411) | [arXiv](https://arxiv.org/abs/2601.06411)



---

### 22. e5-omni：面向全模态嵌入的显式跨模态对齐方法

**原文标题：** e5-omni: Explicit Cross-modal Alignment for Omni-modal Embeddings

**摘要：**
现代信息系统常涉及多种类型的项目，例如文本查询、图像、视频片段或音频片段。这推动了全模态嵌入模型的发展，旨在将异构模态映射到共享空间中以进行直接比较。然而，当前大多数全模态嵌入方法仍严重依赖于从预训练视觉语言模型（VLM）骨干中继承的隐式对齐机制。实践中，这导致三个常见问题：（i）相似度对数具有模态依赖的锐度，使得评分缺乏一致尺度；（ii）混合模态批次造成不平衡的困难度分布，导致批内负样本随时间推移效果减弱，许多负样本迅速变得无关紧要，对梯度贡献甚微；（iii）跨模态嵌入呈现不匹配的一阶与二阶统计量，降低了排序稳定性。为解决这些问题，我们提出e5-omni——一种轻量级的显式对齐方案，可将现成的VLM适配为鲁棒的全模态嵌入模型。e5-omni整合了三个简单组件：（1）通过模态感知温度校准对齐相似度尺度；（2）采用带去偏控制的可控负样本课程学习，聚焦于混淆性负样本同时降低假负样本的影响；（3）结合协方差正则化的批白化处理，以更好地匹配共享嵌入空间中的跨模态几何结构。在MMEB-V2和AudioCaps数据集上的实验表明，该方法相较于强双模态与全模态基线模型均取得稳定提升，且该方案能良好迁移至其他VLM骨干网络。模型检查点已发布于https://huggingface.co/Haon-Chen/e5-omni-7B。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03666) | [arXiv](https://arxiv.org/abs/2601.03666)



---

### 23. "TODO：修复Gemini制造的混乱"：理解生成式人工智能引发的自认技术债务

**原文标题：** "TODO: Fix the Mess Gemini Created": Towards Understanding GenAI-Induced Self-Admitted Technical Debt

**摘要：**
随着ChatGPT、Copilot、Claude和Gemini等大型语言模型（LLMs）被集成到软件开发工作流程中，开发者越来越多地在代码注释中留下人工智能参与的痕迹。其中，部分注释明确承认了生成式人工智能的使用以及技术缺陷的存在。通过分析来自公共Python和JavaScript的GitHub仓库（2022年11月至2025年7月）的6,540条涉及LLM的代码注释，我们识别出其中81条同时自认了技术债务（SATD）。开发者最常描述的是推迟测试、不完整的适配以及对AI生成代码的有限理解，这表明人工智能辅助既影响了技术债务出现的时间，也影响了其产生的原因。我们提出"生成式人工智能引发的自认技术债务（GIST）"这一概念框架，用以描述开发者在使用AI生成代码时，同时明确表达对其行为或正确性存在不确定性的重复性案例。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07786) | [arXiv](https://arxiv.org/abs/2601.07786)



---

### 24. ShowUI-Aloha：人类示范驱动的图形用户界面智能体

**原文标题：** ShowUI-Aloha: Human-Taught GUI Agent

**摘要：**
图形用户界面（GUI）是人机交互的核心，但自动化复杂GUI任务仍是自主智能体面临的主要挑战，其根本原因在于缺乏可扩展的高质量训练数据。尽管人类操作录像是丰富的数据来源，但这些记录通常冗长、非结构化且缺乏标注，导致智能体难以从中有效学习。为解决这一问题，我们提出了ShowUI-Aloha——一个完整的处理流程，能够将桌面环境中非结构化、真实场景的人类屏幕录像转化为结构化、可执行的任务序列。该框架包含四个核心组件：记录器负责捕获屏幕视频及精确的用户交互（如鼠标点击、键盘输入和滚动操作）；学习器通过语义解析原始交互行为与视觉上下文，将其转化为描述性自然语言标注；规划器读取解析后的示范数据，维护任务状态，并基于上下文推理动态生成下一步高层动作计划；执行器则在操作系统层面忠实执行这些动作计划，通过安全检查与实时反馈机制实现精确点击、拖拽、文本输入及窗口操作。这些组件共同构成了采集与解析真实人类操作数据的可扩展解决方案，为构建能够通过观察人类行为进行高效学习的通用GUI智能体提供了可行路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07181) | [arXiv](https://arxiv.org/abs/2601.07181)



---

### 25. 编码化伏笔-照应文本生成

**原文标题：** Codified Foreshadowing-Payoff Text Generation

**摘要：**
伏笔与照应是普遍存在的叙事手法，作者通过其在故事早期埋设承诺，并通过具体可观测的结果予以解决。然而，尽管故事生成技术已取得进展，大语言模型在连接此类长程叙事依赖时仍常显不足，即便在必要语境存在的情况下，也往往让“契科夫的枪”未能击发。现有评估方法大多忽视了这种结构性缺陷，侧重于表层连贯性而非叙事铺垫的逻辑实现。本文提出编码化伏笔-照应生成框架，该创新框架通过照应实现的视角重构叙事质量评估体系。针对大语言模型难以直观把握伏笔事件“触发机制”的问题，本框架将叙事连续性转化为一组可执行的因果谓词。通过从BookSum语料库中挖掘并编码“伏笔-触发-照应”三元组，我们提供了结构化监督机制，确保伏笔承诺不仅被提及，更能在时间与逻辑层面得到兑现。实验表明，该框架在照应准确度与叙事一致性方面显著优于标准提示基线方法。我们的研究结果表明，对叙事机制进行显式编码对于推动大语言模型从表层流畅性迈向真正的叙事能力至关重要。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07033) | [arXiv](https://arxiv.org/abs/2601.07033)



---

### 26. Sci-Reasoning：解码人工智能创新模式的数据集

**原文标题：** Sci-Reasoning: A Dataset Decoding AI Innovation Patterns

**摘要：**
尽管人工智能创新加速发展，但突破背后的智力过程——研究者如何识别研究空白、综合前人工作并产生洞见——仍鲜为人知。科学推理结构化数据的缺乏，阻碍了对人工智能研究智能体的系统性分析与开发。本文介绍 Sci-Reasoning，这是首个捕捉高质量人工智能研究背后智力综合过程的数据集。通过采用社区验证的质量信号以及基于大语言模型加速、人工验证的流程，我们追踪了 NeurIPS、ICML 与 ICLR（2023–2025）中 Oral 与 Spotlight 论文的关键前驱工作，并以结构化形式阐明其具体的推理关联。我们的分析识别出 15 种不同的思维模式，其中三种主导策略占比达 52.7%：空白驱动重构（24.2%）、跨领域综合（18.0%）与表征转换（10.5%）。最具影响力的创新路径往往融合多种模式：空白驱动重构 + 表征转换、跨领域综合 + 表征转换，以及空白驱动重构 + 跨领域综合。本数据集支持对科学进展的量化研究，并为训练下一代人工智能研究智能体提供了结构化的推理轨迹。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04577) | [arXiv](https://arxiv.org/abs/2601.04577)



---

### 27. 大规模语言模型在持续预训练中如何学习概念？

**原文标题：** How Do Large Language Models Learn Concepts During Continual Pre-Training?

**摘要：**
人类主要通过概念（例如“狗”）来理解世界，这些抽象的心理表征构建了感知、推理和学习的基础。然而，大规模语言模型（LLMs）在持续预训练过程中如何获取、保留和遗忘此类概念，目前仍缺乏深入理解。本研究探讨了单个概念如何被习得与遗忘，以及多个概念之间如何通过干扰和协同作用相互影响。我们将这些行为动态与LLMs内部的“概念回路”（即与特定概念相关的计算子图）联系起来，并引入图度量指标来刻画回路结构。分析结果表明：（1）LLMs的概念回路能够提供具有统计显著性的概念学习与遗忘信号；（2）在持续预训练过程中，概念回路呈现阶段性时序模式，表现为早期增强、随后逐渐减弱并趋于稳定；（3）学习增益较大的概念在后续训练中往往表现出更强的遗忘效应；（4）语义相近的概念比弱相关概念引发更显著的干扰；（5）不同概念知识的可迁移性存在差异，部分概念能显著促进其他概念的学习。综合而言，本研究从回路层面揭示了概念学习的动态机制，为设计更具可解释性和鲁棒性的概念感知训练策略提供了理论依据。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03570) | [arXiv](https://arxiv.org/abs/2601.03570)



---

### 28. 论后训练中监督微调与强化学习的不可解耦性

**原文标题：** On the Non-decoupling of Supervised Fine-tuning and Reinforcement Learning in Post-training

**摘要：**
大语言模型的后训练通常交替进行监督微调与强化学习。这两种方法具有不同目标：监督微调旨在最小化模型输出与专家响应之间的交叉熵损失，而强化学习则致力于最大化基于人类偏好或规则验证器生成的奖励信号。现代推理模型已广泛采用交替进行监督微调与强化学习的训练范式。然而，关于二者能否解耦的理论研究尚属空白。我们证明两种顺序的解耦均不可行：（1）先监督微调后强化学习的耦合：在监督微调最优性条件下，强化学习会增大监督微调损失；（2）先强化学习后监督微调的耦合：监督微调会降低强化学习已获得的奖励。基于Qwen3-0.6B的实验证实了理论预测的性能退化现象，验证了在后训练过程中若分离监督微调与强化学习，则无法保持先前已达成的性能水平。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07389) | [arXiv](https://arxiv.org/abs/2601.07389)



---

### 29. 文本推理能否提升多模态大语言模型在细粒度视觉分类中的性能？

**原文标题：** Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?

**摘要：**
多模态大语言模型（MLLMs）展现出强大的通用能力，但在细粒度视觉分类（FGVC）这一核心感知任务上仍面临挑战。FGVC要求细微的视觉辨别能力，对众多现实应用至关重要。在数学、编程等复杂任务中，提升性能的常用策略是思维链（CoT）推理。然而，先前多项研究表明，CoT实际上可能损害视觉感知任务的性能。这些研究虽从相对局限的视角探讨了该问题，但未阐明CoT为何会降低以感知为主导的任务性能。本文通过零样本评估与多种训练范式的系统性再检验，深入探究了CoT在FGVC中的作用。在不同实验设置中，我们揭示了一个核心矛盾：CoT导致的性能下降主要受推理长度驱动，即更长的文本推理会持续降低分类准确率。我们将此现象称为“思考代价”。基于这一发现，我们做出两项关键贡献：（1）提出\alg方法——一种简单通用的即插即用式多奖励优化归一化方法，可平衡异构奖励信号；（2）提出ReFine-RFT框架，该框架结合集成奖励与\alg方法，在约束推理长度的同时提供密集的、以准确率为导向的反馈。大量实验验证了我们发现的可靠性及所提ReFine-RFT框架的有效性，该框架在多个FGVC基准测试中取得了最先进的性能。代码与模型已开源：https://github.com/jiezhu23/ReFine-RFT{项目链接}。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06993) | [arXiv](https://arxiv.org/abs/2601.06993)



---

### 30. RealMem：面向现实世界记忆驱动交互的大语言模型基准测试

**原文标题：** RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction

**摘要：**
随着大语言模型从静态对话接口演变为自主通用智能体，有效的记忆机制对于保障长期行为一致性至关重要。然而，现有基准测试主要集中于日常对话或任务导向型对话，未能涵盖智能体必须追踪动态目标的**"长期项目导向型"**交互场景。为填补这一空白，我们提出了首个基于真实项目场景的基准测试框架**RealMem**。该框架涵盖十一种项目场景下的2000余组跨会话对话，采用自然用户查询进行评估。我们设计了一套融合项目基础构建、多智能体对话生成以及记忆与进度管理的综合流程，以模拟记忆的动态演化过程。实验表明，现有记忆系统在处理现实项目固有的长期状态维护与动态上下文依赖方面面临显著挑战。相关代码与数据集已在[https://github.com/AvatarMemory/RealMemBench](https://github.com/AvatarMemory/RealMemBench)开源。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06966) | [arXiv](https://arxiv.org/abs/2601.06966)



---

### 31. SketchJudge：基于多模态大语言模型的手绘图表分级诊断基准

**原文标题：** SketchJudge: A Diagnostic Benchmark for Grading Hand-drawn Diagrams with Multimodal Large Language Models

**摘要：**
尽管多模态大语言模型在视觉理解方面取得了显著进展，但在处理人类手绘草图中非结构化与模糊性特征时仍面临挑战。这一局限在视觉分级这一尚未充分探索的任务中尤为突出，该任务要求模型不仅解决问题，还需诊断手绘图表中的错误。此类诊断能力依赖于复杂的结构、语义及元认知推理。为填补这一空白，我们提出了SketchJudge——一个专门用于评估多模态大语言模型作为手绘STEM图表分级器的新型基准。SketchJudge涵盖几何、物理、图表和流程图四大领域共1,015份手绘学生作答样本，包含多样化的风格变体与典型错误类型。基于SketchJudge的评估表明，即使先进的多模态大语言模型仍显著落后于人类水平，验证了该基准在揭示符号化及噪声环境下当前视觉-语言对齐机制脆弱性方面的有效性。所有数据、代码与评估脚本已公开于https://github.com/yuhangsu82/SketchJudge。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06944) | [arXiv](https://arxiv.org/abs/2601.06944)



---

### 32. 大语言模型微调中的人工纠缠现象研究

**原文标题：** Artificial Entanglement in the Fine-Tuning of Large Language Models

**摘要：**
大语言模型（LLMs）可通过仅修改少量可训练参数的参数高效微调（PEFT）方法适配新任务，这类方法通常采用低秩更新策略。本研究从量子信息视角出发解析其有效性机制。在此视角下，低秩参数化天然对应于低维矩阵乘积态（MPS）表示，从而支持基于纠缠的参数结构表征。据此，我们提出并度量了“人工纠缠”——定义为人工神经网络（特指大语言模型）参数体系的纠缠熵。我们首先以在Tulu3和OpenThoughts3数据集上训练的1B和8B规模LLaMA模型为对象，研究了代表性低秩适应（LoRA）PEFT方法与全参数微调（FFT）方法，发现：（i）LoRA中查询与值投影矩阵更新过程的内部人工纠缠遵循具有中心抑制特征的体积律（称为“纠缠谷”），该现象对超参数敏感且与FFT模式存在显著差异；（ii）注意力矩阵中表征语义单元相关性的外部人工纠缠遵循带对数修正的面积律，对LoRA超参数及训练步数保持稳健。借鉴黑洞物理中的无毛定理，我们提出：虽然LoRA与FFT会引发不同的内部纠缠特征，但这些差异并未体现在注意力输出中，这种“无毛”特性可能是低秩更新有效的内在原因。我们进一步基于随机矩阵理论提供了理论支撑，并将分析拓展至MPS适应PEFT方法，发现其展现出定性相似的行为规律。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06788) | [arXiv](https://arxiv.org/abs/2601.06788)



---

### 33. FinForge：半合成金融基准生成框架

**原文标题：** FinForge: Semi-Synthetic Financial Benchmark Generation

**摘要：**
在金融等专业性强、风险高的领域中评估语言模型仍面临重大挑战，主要原因在于缺乏公开、高质量且领域特定的数据集。现有的通用基准虽覆盖广泛，但缺乏评估语言模型在实际金融推理能力（既需概念理解又需定量严谨性）所需的深度与领域保真度。为填补这一空白，我们提出了FinForge——一个可扩展的半合成流程，通过专家引导的数据策展与基于语言模型的受控合成相结合，构建金融专用评估基准。FinForge融合了来自权威金融资料的手动与程序化语料构建，并利用Gemini 2.5 Flash进行结构化问题生成与验证。为验证该流程的有效性，我们构建了FinForge-5k基准快照，包含来自10万份经审核文档（总计1.43亿词元）的11个金融子领域超过5000个人工验证问答对。基于FinForge-5k对当前领先的开源与闭源模型进行评估，结果显示各模型在金融推理能力上存在显著差异，最优模型的准确率接近80%。这些发现凸显了该框架在诊断现有模型局限、指导未来金融领域能力改进方面的实用价值。所有代码与数据已公开于https://github.com/gtfintechlab/FinForge。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06747) | [arXiv](https://arxiv.org/abs/2601.06747)



---

### 34. Gecko：一种能高效处理任意长度序列的神经架构

**原文标题：** Gecko: An Efficient Neural Architecture Inherently Processing Sequences with Arbitrary Lengths

**摘要：**
设计一种能够高效且本质地处理任意长度序列数据的统一神经网络，是序列建模领域一个核心且具有挑战性的问题。Transformer架构中的设计选择，包括二次计算复杂度和较弱的长序列外推能力，限制了其向长序列扩展的能力。本研究提出Gecko神经架构，它继承了Mega和Megalodon的设计思想（采用带门控注意力的指数移动平均机制），并进一步引入了多项技术组件以增强其捕获长程依赖的能力，包括时间步衰减归一化、滑动分块注意力机制和自适应工作记忆。在与Llama2和Megalodon进行的70亿参数、2万亿训练标记规模的受控预训练对比中，Gecko展现出更优的效率和长上下文扩展能力。Gecko取得了1.68的训练损失，显著优于Llama2-7B（1.75）和Megalodon-7B（1.70），并接近Llama2-13B（1.67）的水平。值得注意的是，在不依赖任何上下文扩展技术的情况下，Gecko展现出固有的长上下文处理与检索能力，能够稳定处理长达400万标记的序列，并能从超出其注意力窗口长度4倍的上下文中检索信息。代码地址：https://github.com/XuezheMax/gecko-llm

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06463) | [arXiv](https://arxiv.org/abs/2601.06463)



---

### 35. 推理规模扩展能否提升推理忠实度？关于自洽性权衡的多模型分析

**原文标题：** Does Inference Scaling Improve Reasoning Faithfulness? A Multi-Model Analysis of Self-Consistency Tradeoffs

**摘要：**
自洽性已成为提升大语言模型在推理任务上准确性的常用技术。该方法思路直接：生成多条推理路径并通过多数投票选择最常见答案。虽然这能可靠地提升准确率，但尚不清楚这种提升是否反映了推理质量的真实改进。我们探究了一个此前未被研究的基础性问题：推理规模扩展能否提升推理忠实度？

我们在100道GSM8K数学推理问题上对四种前沿模型（GPT-5.2、Claude Opus 4.5、Gemini-3-flash-preview和DeepSeek-v3.2）进行了全面实证研究。通过自助置信区间、配对比较的麦克尼马尔检验及科恩d效应值等量化分析方法，我们严谨评估了扩展效应。研究结果揭示了模型间的显著差异，对关于自洽性的普遍假设提出了挑战。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06423) | [arXiv](https://arxiv.org/abs/2601.06423)



---

### 36. FlyPose：面向航拍视角下鲁棒人体姿态估计的研究

**原文标题：** FlyPose: Towards Robust Human Pose Estimation From Aerial Views

**摘要：**
无人机正日益频繁地部署于人类活动密集的场景中，例如包裹配送、交通监控、灾害响应和基础设施巡检。为确保此类人机共存环境下的安全可靠运行，需要从航拍视角精确感知人体姿态与行为。这一视角因图像分辨率低、拍摄角度陡峭及（自）遮挡等问题，对现有方法构成显著挑战，尤其在需要实时可行模型的应用场景中。本文训练并部署了FlyPose——一种面向航拍图像的轻量级自上而下人体姿态估计框架。通过多数据集联合训练，我们在Manipal-UAV、VisDrone、HIT-UAV及自建数据集的测试集上实现了人体检测平均精度提升6.8 mAP。针对二维人体姿态估计任务，在具有挑战性的UAV-Human数据集上取得了16.3 mAP的性能提升。FlyPose在Jetson Orin AGX开发套件上的推理延迟（含预处理）约为20毫秒，并已在四旋翼无人机飞行实验中完成机载部署。同时，我们公开了FlyPose-104数据集——一个规模较小但极具挑战性的航拍人体姿态估计数据集，包含从困难航拍视角手动标注的样本：https://github.com/farooqhassaan/FlyPose。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.05747) | [arXiv](https://arxiv.org/abs/2601.05747)



---

### 37. 系统日志严重性分类任务中轻量级语言模型与轻量级推理语言模型的基准测试

**原文标题：** Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification

**摘要：**
系统日志对于监控与诊断现代计算基础设施至关重要，但其规模与复杂性要求可靠且高效的自动化解析。由于严重性级别是系统日志消息中预定义的元数据，仅让模型对其进行分类的独立实用价值有限，难以反映模型理解系统日志的深层能力。我们认为，将严重性分类视为探究运行时日志理解能力的基准测试，而非最终任务，能提供更丰富的信息。基于从Linux生产服务器采集的真实journalctl数据，我们在零样本、少样本及检索增强生成提示策略下评估了九种轻量级语言模型与轻量级推理语言模型。结果显示明显的性能分层：Qwen3-4B在检索增强生成条件下达到最高准确率95.64%，而Gemma3-1B在少样本提示下准确率仅为20.25%，通过检索增强生成提升至85.28%。值得注意的是，微型模型Qwen3-0.6B在无检索时表现较弱，但仍实现了88.12%的准确率。相反，包括Qwen3-1.7B与DeepSeek-R1-Distill-Qwen-1.5B在内的多款轻量级推理语言模型在结合检索增强生成后性能显著下降。效率测量进一步区分了模型性能：多数Gemma与Llama变体可在单条日志1.2秒内完成推理，而Phi-4-Mini-Reasoning的单条日志推理时间超过228秒，准确率却不足10%。这些发现表明：（1）架构设计，（2）训练目标，以及（3）在严格输出约束下整合检索上下文的能力共同决定了模型表现。通过聚焦轻量化可部署模型，本基准测试契合数字孪生系统的实时性需求，并证明严重性分类可作为评估模型能力与实时部署可行性的观察窗口，对根本原因分析与更广泛的数字孪生集成具有重要参考价值。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07790) | [arXiv](https://arxiv.org/abs/2601.07790)



---

### 38. 随机混沌：为何确定性推断扼杀人工智能认知，而分布变异性是其生命之源

**原文标题：** Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artifical Cognition

**摘要：**
确定性推断是经典软件中一种令人安心的理想状态：同一程序在相同输入下应始终产生相同输出。随着大语言模型进入实际部署阶段，这一理念被全盘引入推断技术栈。思维机器实验室近期研究详细分析了LLM推断中的非确定性，展示了批次不变内核与确定性注意力机制如何强制实现比特级完全相同的输出，并将确定性推断定位为可复现性和企业可靠性的前提。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07239) | [arXiv](https://arxiv.org/abs/2601.07239)



---

### 39. 3D CoCa v2：结合测试时搜索的可泛化空间智能对比学习框架

**原文标题：** 3D CoCa v2: Contrastive Learners with Test-Time Search for Generalizable Spatial Intelligence

**摘要：**
空间智能指在三维环境中感知、推理并描述物体及其相互关系的能力，是具身感知与场景理解的基础。三维描述任务旨在用自然语言描述三维场景，但由于点云的稀疏性与不规则性，以及现有描述模型在室内外等差异显著场景中存在弱 grounding 问题与有限的分布外泛化能力，该任务仍面临挑战。为解决这一问题，我们提出 3D CoCa v2——一种可泛化的三维描述框架，该框架将对比式视觉-语言学习与三维描述生成相统一，并通过无需更新模型参数的测试时搜索进一步提升鲁棒性。3D CoCa v2 基于冻结的 CLIP 语义先验、感知几何的空间化三维场景编码器，以及通过对比与描述目标联合优化的多模态解码器构建，无需依赖外部检测器或人工设计提案。在推理阶段，测试时搜索生成多样化的描述候选句，并基于紧凑场景摘要进行奖励引导的选择。实验表明，本方法在 ScanRefer 数据集上 CIDEr@0.5IoU 指标提升 1.50，在 Nr3D 数据集上提升 1.61，在 TOD3Cap 的零样本分布外评估中 CIDEr@0.25 指标提升 3.8。代码将在 https://github.com/AIGeeksGroup/3DCoCav2 发布。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06496) | [arXiv](https://arxiv.org/abs/2601.06496)



---

### 40. 论口语模型评估中全局词元困惑度的谬误

**原文标题：** On the Fallacy of Global Token Perplexity in Spoken Language Model Evaluation

**摘要：**
基于大规模原始音频预训练的生成式口语模型能够延续语音提示并生成合适内容，同时保持说话者身份、情感等属性，可作为口语对话的基础模型。在现有文献中，这些模型常采用"全局词元困惑度"进行评估，该方法直接将文本困惑度公式应用于语音词元。然而，这种做法忽视了语音与文本模态间的本质差异，可能导致对语音特性的低估。本研究提出一系列基于似然估计与生成能力的评估方法，以替代朴素的全局词元困惑度指标。实验证明，所提出的评估方式能更真实地反映感知生成质量，其与人工评定的平均意见得分（MOS）呈现更强的相关性。在新指标评估下，口语模型的性能对比格局发生重构：最佳模型与人类表现上限之间的差距显著缩小。这些结果表明，采用恰当的评估方法对于准确衡量口语建模研究进展具有关键意义。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06329) | [arXiv](https://arxiv.org/abs/2601.06329)



---

### 41. 水涨船高：基于机器翻译质量评估的成语奖励机制提升整体翻译质量

**原文标题：** A Rising Tide Lifts All Boats: MTQE Rewards for Idioms Improve General Translation Quality

**摘要：**
非组合性表达（如成语、谚语和隐喻）对神经机器翻译系统构成显著挑战，因为其含义无法仅通过单个词汇推导得出。这类表达承载着丰富的文化内涵，兼具比喻义与字面义，导致准确翻译尤为困难。鉴于现有模型在组合性文本翻译上表现良好，本研究探索采用基于机器翻译质量评估模型的GRPO式微调方法，将其作为奖励函数来训练模型以提升成语翻译能力。通过使用汉语和印地语成语数据集进行实验，我们发现模型的成语翻译能力提升约14个百分点，非成语类通用文本的翻译能力隐性提升约8个百分点，跨语言翻译能力（单语言训练，多语言评估）提升约6个百分点。本研究量化了非组合性文本的翻译差距，并为开发具有更强跨文化及比喻语言理解能力的大语言模型提供了理论参考。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06307) | [arXiv](https://arxiv.org/abs/2601.06307)



---

### 42. SPINAL——神经对齐层中的缩放律与偏好整合

**原文标题：** SPINAL -- Scaling-law and Preference Integration in Neural Alignment Layers

**摘要：**
直接偏好优化（DPO）是一种基于原则、可扩展的替代方法，用于通过成对偏好对齐大型语言模型，以替代基于人类反馈的强化学习（RLHF）。然而，其内部几何特征仍未被充分刻画，这限制了对模型的审计、检查点比较以及故障预测。我们提出SPINAL（神经对齐层中的缩放律与偏好整合），这是一种通过逐层追踪局部结构变化来度量对齐过程如何重塑各层表征的诊断方法。在不同模型系列中，DPO会产生一种集中于最后解码器块（通常为第21至30层）的逐层校准效应，偏好梯度在此处对接续词元分布产生最直接的影响。SPINAL将每个检查点编码为基于（层索引、收缩分数、传输分数）的深度轨迹。收缩分数概括了层谱尾部的衰减速度（小模态消失的快慢）；更高的值表示向更少有效方向的收缩更强。传输分数通过有界重叠度量概括了相邻层间词元分布的偏移程度；更低的值表示在表征空间中步长更短、更平滑。对齐后的检查点显示出收缩性在深层急剧上升，同时传输性平滑下降，这与策略质量的收紧和稳定相一致；而未对齐模型则呈现出更高曲率、更高熵值以及几何不一致的深度路径。总体而言，对齐在几何上是局部化的：最终层编码了主要的偏好诱导修正。SPINAL将这种局部化转化为实用的审计信号，能够量化对齐集中何处、其表现强度如何，以及在训练过程中何时开始失稳。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.06238) | [arXiv](https://arxiv.org/abs/2601.06238)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2026-01-13_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)