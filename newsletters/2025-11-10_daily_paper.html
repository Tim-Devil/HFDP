<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hugging Face 论文日报 - 2025-11-10</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
            padding: 20px;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 30px;
            font-size: 28px;
        }
        
        h1 img {
            vertical-align: middle;
            margin-right: 10px;
        }
        
        h2 {
            color: #34495e;
            margin-top: 40px;
            margin-bottom: 20px;
            font-size: 24px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }
        
        h3 {
            color: #2c3e50;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 20px;
        }
        
        p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        ul {
            margin-left: 20px;
            margin-bottom: 20px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        a {
            color: #3498db;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        strong {
            color: #2c3e50;
            font-weight: 600;
        }
        
        hr {
            border: none;
            border-top: 1px solid #e0e0e0;
            margin: 30px 0;
        }
        
        /* 关键修复:限制图片宽度 */
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        /* 确保图片容器也有宽度限制 */
        p img {
            max-width: 100%;
        }
        
        /* 论文详情区域样式 */
        .paper-section {
            background-color: #f9f9f9;
            padding: 20px;
            border-radius: 6px;
            margin-bottom: 20px;
        }
        
        /* 统计信息样式 */
        .stats {
            background-color: #e8f4f8;
            padding: 15px;
            border-radius: 6px;
            margin-bottom: 20px;
        }
        
        /* 响应式设计 */
        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 24px;
            }
            
            h2 {
                font-size: 20px;
            }
            
            h3 {
                font-size: 18px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1><img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2025-11-10 论文日报</h1>
<h2>📊 今日论文统计</h2>
<ul>
<li>总论文数：10</li>
<li>热门领域：GPT</li>
</ul>
<h2>📝 论文详情</h2>
<h3>1. 过于良善难以为恶：大语言模型在反派角色扮演中的失效研究</h3>
<p><strong>原文标题：</strong> Too Good to be Bad: On the Failure of LLMs to Role-Play Villains</p>
<p><strong>摘要：</strong>
大语言模型正日益承担包括虚构角色模拟在内的创造性生成任务。然而，其塑造非亲社会性对抗人格的能力仍待深入探究。我们提出假设：现代大语言模型的安全对齐机制与真实扮演道德模糊或反派角色的任务存在根本性冲突。为验证此假设，我们引入道德角色扮演基准测试，该数据集采用四级道德对齐量表并包含平衡测试集以进行严格评估。我们要求前沿大语言模型扮演从道德典范到纯粹反派的多维角色。大规模评估显示，随着角色道德水平的降低，角色扮演保真度呈现持续单调下降趋势。研究发现模型在处理与安全原则直接对立的特质时表现最为困难，如"欺诈性"和"操纵性"特征，往往将复杂的恶意表现为浅层的攻击行为。此外，我们证明通用聊天机器人能力无法有效预测反派扮演水平，高度安全对齐的模型在此方面表现尤为不佳。本研究首次系统论证了这一关键局限，揭示了模型安全性与创作保真度之间的本质矛盾。我们提出的基准测试与研究发现在开发更精细化、情境感知的对齐方法方面具有开创性意义。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2511.04962">HuggingFace</a> | <a href="https://arxiv.org/abs/2511.04962">arXiv</a></p>
<hr />
<h3>2. DeepEyesV2：迈向具身化多模态智能体模型</h3>
<p><strong>原文标题：</strong> DeepEyesV2: Toward Agentic Multimodal Model</p>
<p><strong>摘要：</strong>
具身化多模态模型不仅需要理解文本与图像，还应能主动调用外部工具（如代码执行环境与网络搜索），并将这些操作融入推理过程。本研究提出DeepEyesV2模型，从数据构建、训练方法和模型评估三个维度系统探讨如何构建具身化多模态模型。我们发现单纯使用强化学习难以形成稳定的工具使用行为，这一现象促使我们设计了两阶段训练流程：通过冷启动阶段建立工具使用模式，再经由强化学习阶段优化工具调用策略。我们构建了兼具多样性与适度挑战性的训练数据集，特别纳入了工具使用具有显著效益的实例。同时提出RealX-Bench综合评估基准，该基准专为评估需要融合感知、搜索与推理能力的真实世界多模态推理任务而设计。在RealX-Bench及其他代表性基准上的实验表明，DeepEyesV2在真实场景理解、数学推理和搜索密集型任务中均表现优异。值得注意的是，该模型展现出任务自适应的工具调用特性：在感知任务中倾向使用图像操作，在推理任务中偏好数值计算。强化学习进一步促成了复杂工具组合能力，使模型能根据情境选择性调用工具。本研究期望为学界开发具身化多模态模型提供建设性指导。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2511.05271">HuggingFace</a> | <a href="https://arxiv.org/abs/2511.05271">arXiv</a></p>
<hr />
<h3>3. 视觉空间调优</h3>
<p><strong>原文标题：</strong> Visual Spatial Tuning</p>
<p><strong>摘要：</strong>
从视觉输入中捕捉空间关系是实现类人通用智能的基石。先前研究多通过引入额外专家编码器来增强视觉语言模型的空间感知能力，但这种方法不仅带来额外开销，往往还会损害模型的通用能力。为在通用架构中增强空间能力，我们提出视觉空间调优（VST）这一综合框架，旨在培育具备从空间感知到推理的类人视觉空间能力的视觉语言模型。我们首先通过构建包含410万样本的大规模数据集VST-P来增强视觉语言模型的空间感知能力，该数据集涵盖单视图、多图像和视频三大类别的19项空间技能。继而提出VST-R数据集，包含13.5万经过精心设计的样本，用于指导模型进行空间推理。特别采用渐进式训练流程：先通过监督微调建立基础空间知识，再通过强化学习进一步提升空间推理能力。在保持通用能力不受影响的前提下，所提出的VST框架在多个空间基准测试中持续取得最优结果，包括在MMSI-Bench达到34.8%的准确率，在VSIBench达到61.2%的准确率。研究表明，通过本文提出的空间调优范式可显著增强视觉-语言-行动模型，为开发更具物理现实基础的人工智能开辟了新路径。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2511.05491">HuggingFace</a> | <a href="https://arxiv.org/abs/2511.05491">arXiv</a></p>
<hr />
<h3>4. VeriCoT：基于逻辑一致性检验的神经符号思维链验证方法</h3>
<p><strong>原文标题：</strong> VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical
  Consistency Checks</p>
<p><strong>摘要：</strong>
大型语言模型能够通过思维链进行多步推理，但其无法可靠地验证自身逻辑。即使获得正确答案，底层推理过程仍可能存在缺陷，这在高风险场景中会削弱可信度。为缓解该问题，我们提出VeriCoT——一种从思维链推理中提取并验证形式逻辑论证的神经符号方法。该方法将思维链的每个推理步骤形式化为一阶逻辑，并识别使论证植根于源语境、常识知识或先前推理步骤的前提条件。符号化表征支持自动化求解器验证逻辑有效性，而自然语言前提则允许人类和系统识别未经验证或存在谬误的推理步骤。在ProofWriter、LegalBench和BioASQ数据集上的实验表明，VeriCoT能有效识别缺陷推理，并成为最终答案正确性的强预测指标。我们进一步利用VeriCoT的验证信号实现：（1）推理时自反思机制，（2）基于VeriCoT蒸馏数据集的监督微调，以及（3）采用带验证导向配对奖励的直接偏好优化进行偏好微调，从而持续提升推理的有效性与准确性。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2511.04662">HuggingFace</a> | <a href="https://arxiv.org/abs/2511.04662">arXiv</a></p>
<hr />
<h3>5. 稠密运动描述生成</h3>
<p><strong>原文标题：</strong> Dense Motion Captioning</p>
<p><strong>摘要：</strong>
当前三维人体运动与语言融合的研究主要集中于文本到动作的生成任务，而对运动理解任务的探索相对不足。本文提出稠密运动描述生成这一新型任务，旨在对三维人体运动序列中的动作进行时序定位与描述。现有数据集在提供精细时序标注方面存在不足，且主要由包含少量动作的短序列构成。为克服这些局限，我们构建了复杂运动数据集CompMo——首个具有精确时间边界标注的大规模复杂运动序列数据集。通过精心设计的数据生成流程，CompMo包含60,000个运动序列，每个序列由至少2个至多10个动作组合而成，并配有精确的时序范围标注。我们进一步提出DEMO模型，该模型将大语言模型与轻量级运动适配器相结合，通过训练实现具有时序锚点的稠密描述生成。实验结果表明，DEMO在CompMo数据集及适配基准测试中显著优于现有方法，为三维运动理解与描述领域的后续研究建立了坚实的基准。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2511.05369">HuggingFace</a> | <a href="https://arxiv.org/abs/2511.05369">arXiv</a></p>
<hr />
<h3>6. 通过优化文本嵌入减轻大型视觉语言模型中的幻觉现象</h3>
<p><strong>原文标题：</strong> Towards Mitigating Hallucinations in Large Vision-Language Models by
  Refining Textual Embeddings</p>
<p><strong>摘要：</strong>
本研究揭示了主流大型视觉语言模型架构中存在的固有偏差——过度偏向语言模态，这主要源于当前普遍将视觉嵌入简单附加至输入文本序列的做法。为应对此问题，我们提出一种简单而有效的解决方案：通过整合平均池化视觉特征来优化文本嵌入。该方法在公认基准测试中显著提升了视觉基础能力，并有效降低了幻觉现象。虽然平均池化为视觉信息融合提供了简洁、鲁棒且高效的实现路径，但我们认为更复杂的融合机制有望进一步提升视觉基础与跨模态对齐效果。鉴于本研究的核心目标在于揭示模态失衡及其对幻觉现象的影响机制，并论证通过视觉信息优化文本嵌入可有效缓解该问题，我们将更先进的融合策略探索留待后续研究。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2511.05017">HuggingFace</a> | <a href="https://arxiv.org/abs/2511.05017">arXiv</a></p>
<hr />
<h3>7. 动态环境中的实时推理智能体</h3>
<p><strong>原文标题：</strong> Real-Time Reasoning Agents in Evolving Environments</p>
<p><strong>摘要：</strong>
现实世界中的智能体不仅需要做出符合逻辑的判断，更需保证决策的时效性。这要求智能体持续感知动态环境：在推理过程尚未完成时，危险可能突然显现，机遇可能转瞬即逝，其他智能体也在同步行动。尽管语言模型推理技术已取得长足进步，现有方法仍未能充分考虑这种动态特性。我们提出将实时推理作为动态环境中智能体研究的新范式，并构建实时推理验证平台予以实证。我们研究了语言模型在智能体中的两种部署范式：（1）反应式智能体——采用有限计算资源的语言模型实现快速响应；（2）规划式智能体——允许扩展推理计算以处理复杂问题。实验表明，即使最先进的模型在两种范式中都难以同时保证逻辑严谨性与决策及时性。为此，我们提出AgileThinker框架，通过协同运用两种推理范式突破此局限。随着任务难度和时间压力的提升，AgileThinker始终优于单一推理范式的智能体，有效实现了推理深度与响应延迟的平衡。本研究将实时推理确立为开发实用智能体的关键测试基准，为时间约束下人工智能系统的研究奠定基础，指明了实现实时能力智能体的发展路径。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2511.04898">HuggingFace</a> | <a href="https://arxiv.org/abs/2511.04898">arXiv</a></p>
<hr />
<h3>8. 大海捞针式越狱攻击</h3>
<p><strong>原文标题：</strong> Jailbreaking in the Haystack</p>
<p><strong>摘要：</strong>
长上下文语言模型的最新进展已实现百万级令牌的输入处理能力，显著扩展了其在计算机使用代理等复杂任务中的应用范围。然而，这种扩展上下文对模型安全性的影响尚不明确。为填补这一研究空白，我们提出NINJA（"大海捞针"越狱攻击的简称），该方法通过将模型生成的良性内容附加至恶意用户目标之后，实现对对齐语言模型的越狱。我们方法的关键在于发现恶意目标在上下文中的位置对模型安全性具有重要影响。在标准安全基准测试HarmBench上的实验表明，NINJA显著提升了包括LLaMA、Qwen、Mistral和Gemini在内的前沿开源与专有模型的攻击成功率。与现有越狱方法不同，本方法具有低资源消耗、强可迁移性和低可检测性的特点。更重要的是，我们证明NINJA具备计算最优性——在固定计算预算下，增加上下文长度比增加N次最优越狱尝试次数更具效能。这些发现表明，即便是良性长上下文——当辅以精心设计的目标定位时——也会在现代语言模型中引发根本性安全漏洞。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2511.04707">HuggingFace</a> | <a href="https://arxiv.org/abs/2511.04707">arXiv</a></p>
<hr />
<h3>9. HAFixAgent：具备历史感知的自动化程序修复智能体</h3>
<p><strong>原文标题：</strong> HAFixAgent: History-Aware Automated Program Repair Agent</p>
<p><strong>摘要：</strong>
自动化程序修复领域近期正朝着大语言模型与智能体系统方向发展，但现有系统大多依赖本地快照上下文，忽略了代码仓库的历史信息。已有研究表明，由于最后修改故障代码行的提交往往就是引入缺陷的提交，仓库历史有助于修复单行缺陷。本文系统性地探究仓库历史能否在更大范围内提升智能体式APR系统的修复能力，特别是针对复杂的多区块缺陷。我们提出HAFixAgent——一种具备历史感知的缺陷修复智能体，该智能体将基于代码追溯的仓库启发式信息注入修复循环。通过对Defects4J数据集中854个真实缺陷的初步研究，我们发现与缺陷相关的历史信息不仅广泛存在且高度集中，这为系统设计提供了理论依据。HAFixAgent与两种最先进基准系统的实证对比表明：（1）有效性：相较基于智能体的基准系统提升212.3%，较针对多区块缺陷的基准系统提升29.9%；（2）效率：历史信息未显著增加智能体执行步数，令牌成本保持相当水平，且在复杂多文件-多区块缺陷场景中位数成本显著降低；（3）实用性：融合不同历史启发式策略可修复更多缺陷，形成明确的成本效益权衡。HAFixAgent为构建历史感知的智能体式APR系统提供了可行方案：将智能体锚定于版本控制历史，优先采用基于差异的历史上下文，并在需要时整合互补性启发式策略。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2511.01047">HuggingFace</a> | <a href="https://arxiv.org/abs/2511.01047">arXiv</a></p>
<hr />
<h3>10. CritiCal：批判性反馈能否提升大语言模型的不确定性或置信度校准？</h3>
<p><strong>原文标题：</strong> CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?</p>
<p><strong>摘要：</strong>
大语言模型的精确置信度校准对其在高风险领域的安全应用至关重要，清晰的言语化置信度能有效增强用户信任。传统方法通过模仿参考置信度表达往往难以捕捉准确置信评估所需的推理过程。我们提出采用自然语言批判作为解决方案，该方法特别适用于置信度校准，因为精确的黄金置信标签难以获取且常需多次生成。本文研究自然语言批判如何增强言语化置信度，重点解决：（1）批判对象：应针对不确定性（问题导向）还是置信度（答案特定）？分析表明置信度适用于多项选择题任务，而不确定性在开放式场景中表现更优。（2）批判方式：采用自我批判还是批判校准训练？我们提出自我批判方法使大语言模型能超越准确率指标对自身置信度进行批判优化，同时创新性提出CritiCal——一种基于自然语言批判的校准训练方法，通过批判反馈改进置信度校准，突破直接数值优化的局限。实验表明，CritiCal在复杂推理任务中显著优于自我批判及其他竞争基线，甚至超越其教师模型GPT-4o。在分布外场景下，CritiCal亦展现出强大的泛化能力，有力推动了大语言模型可靠性的发展。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2510.24505">HuggingFace</a> | <a href="https://arxiv.org/abs/2510.24505">arXiv</a></p>
<hr />
<h2>🔍 关键词云图</h2>
<p><img alt="关键词云图" src="../images/keywords_wordcloud.png" /></p>
<h2>📈 近期论文趋势</h2>
<p><img alt="论文趋势" src="../images/daily_papers.png" /></p>
<h2>🎙️ 语音播报</h2>
<ul>
<li><a href="../audio/2025-11-10_daily_papers.mp3">收听今日论文解读</a></li>
</ul>
<h2>📱 订阅渠道</h2>
<ul>
<li>GitHub: <a href="https://github.com/2404589803/hf-daily-paper-newsletter-chinese">hf-daily-paper-newsletter-chinese</a></li>
</ul>
    </div>
</body>
</html>