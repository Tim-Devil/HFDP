
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2025-12-26 论文日报

## 📊 今日论文统计
- 总论文数：7
- 热门领域：综合领域

## 📝 论文详情


### 1. 潜在隐式视觉推理

**原文标题：** Latent Implicit Visual Reasoning

**摘要：**
尽管大型多模态模型已取得显著进展，但其本质上仍以文本为中心，依赖语言作为核心推理模态。这导致其在处理以视觉为主的推理任务时存在明显局限。近期研究尝试通过辅助图像、深度图或图像裁剪来监督中间视觉步骤以解决该问题，但这些策略对“有效”视觉抽象形式施加了限制性先验，增加了大量标注成本，且难以实现跨任务泛化。为突破这一关键局限，本文提出一种任务无关机制，通过无显式监督的方式训练大型多模态模型自主发现并利用视觉推理标记。这些标记通过全局注意力机制以任务自适应方式对图像进行重编码，使模型无需人工标注即可提取相关视觉信息。实验表明，该方法在多种以视觉为中心的任务上——包括难以定义中间抽象层的任务——均优于直接微调方法，取得最先进的性能表现，同时展现出多任务指令调优的泛化能力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.21218) | [arXiv](https://arxiv.org/abs/2512.21218)



---

### 2. 自回归模型中的涌现时间抽象实现分层强化学习

**原文标题：** Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning

**摘要：**
基于下一标记预测进行预训练、并通过强化学习微调的大规模自回归模型已在众多问题领域取得前所未有的成功。在强化学习过程中，这些模型通过逐标记生成新输出来进行探索。然而，这种逐标记采样的行动方式可能导致学习效率低下，尤其在奖励稀疏的场景中。本文研究表明，通过在自回归模型的内部表征空间中进行行动与探索，可以克服这一问题。具体而言，为发现时间抽象动作，我们引入了一个高阶非因果序列模型，其输出可控制基础自回归模型的残差流激活状态。在具有层次结构的网格世界与MuJoCo基准任务中，高阶模型成功将长激活序列块压缩至内部控制器。关键的是，每个控制器能够执行在长时间尺度上展开、具有行为意义的行为序列，并附带学习得到的终止条件，使得多个控制器在时间维度上的组合能够在新任务中实现高效探索。我们证明，通过直接对内部控制器进行强化（这一过程我们称之为“内部强化学习”），能够在标准强化学习微调失效的稀疏奖励场景中实现有效学习。本研究结果揭示了自回归模型中潜在动作生成与强化的优势，表明内部强化学习为实现基础模型中的分层强化学习提供了可行路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.20605) | [arXiv](https://arxiv.org/abs/2512.20605)



---

### 3. Spatia：基于可更新空间记忆的视频生成方法

**原文标题：** Spatia: Video Generation with Updatable Spatial Memory

**摘要：**
现有视频生成模型因视频信号具有密集、高维的特性，难以维持长期的空间与时间一致性。为突破此限制，本文提出Spatia——一种空间记忆感知的视频生成框架，其显式地将三维场景点云作为持久性空间记忆进行维护。Spatia基于该空间记忆迭代生成视频片段，并通过视觉SLAM技术持续更新记忆内容。这种动态-静态解耦的设计增强了生成过程中的空间一致性，同时保持了模型生成逼真动态实体的能力。此外，Spatia支持显式相机控制与三维感知交互编辑等应用，为可扩展、记忆驱动的视频生成提供了几何基础扎实的框架。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.15716) | [arXiv](https://arxiv.org/abs/2512.15716)



---

### 4. 语言模型数学推理的舍恩菲尔德解剖学

**原文标题：** Schoenfeld's Anatomy of Mathematical Reasoning by Language Models

**摘要：**
大型语言模型日益展现出推理轨迹，然而超越表层统计数据，其底层的认知结构与步骤仍难以识别与分析。本研究采用舍恩菲尔德的片段理论作为归纳性、中观尺度的分析视角，并引入ThinkARM（模型推理解剖学）这一可扩展框架，该框架能够将推理轨迹显式抽象为功能性推理步骤，如分析、探索、实施、验证等。当将此框架应用于不同模型的数学问题求解时，这种抽象揭示了可复现的思维动态，以及推理模型与非推理模型之间的结构性差异，这些差异在词元层面的视角下并不明显。我们进一步呈现了两个诊断性案例研究，表明探索功能是影响正确性的关键分支步骤，而面向效率的方法会有选择性地抑制评估反馈步骤，而非均匀地缩短响应长度。综上所述，我们的研究结果表明，片段层面的表征使推理步骤显性化，从而能够系统分析现代语言模型中推理的结构化、稳定化与改变方式。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19995) | [arXiv](https://arxiv.org/abs/2512.19995)



---

### 5. 视频基础模型编码了多少三维信息？

**原文标题：** How Much 3D Do Video Foundation Models Encode?

**摘要：**
视频是三维世界在二维平面上的连续投影。在大规模视频数据上训练后，全局三维理解能力是否会自然涌现？我们通过量化现有视频基础模型在大量视频数据预训练后所获得的三维理解能力来研究这一问题。我们提出了首个模型无关的评估框架，该框架通过浅层读出器从模型特征中估计多种三维属性，从而系统衡量各类视频基础模型的三维感知能力。我们的研究在多个维度上揭示了视频基础模型三维感知能力的重要发现。特别值得注意的是，研究显示当前最先进的视频生成模型虽未经过任何三维数据训练，却展现出对三维物体与场景的深刻理解能力，其表现甚至可能超越专门针对三维任务训练的大型专家模型。本研究所得结论，结合对主流视频基础模型的三维基准测试结果，为构建可扩展的三维模型提供了重要参考。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19949) | [arXiv](https://arxiv.org/abs/2512.19949)



---

### 6. VA-π：面向像素感知自回归生成的可变分策略对齐方法

**原文标题：** VA-π: Variational Policy Alignment for Pixel-Aware Autoregressive Generation

**摘要：**
自回归视觉生成模型依赖于分词器将图像与离散序列进行相互映射。然而，分词器的训练目标是从真实标记重建清晰图像，而自回归生成器仅针对标记似然性进行优化。这种目标错位导致生成的标记序列可能解码为低质量图像，且缺乏来自像素空间的直接监督。本文提出VA-π——一种轻量级的训练后优化框架，通过基于原理的像素空间目标直接优化自回归模型。VA-π将生成器与分词器的对齐问题构建为变分优化，推导出统一像素重建与自回归建模的证据下界。为在离散标记空间中进行优化，VA-π引入基于强化学习的对齐策略：将自回归生成器视为策略网络，以像素空间重建质量作为内在奖励。该奖励通过预测标记序列在教师强制条件下重建原始图像的能力进行度量，使模型获得无需昂贵自由运行采样的像素级直接指导。证据下界中的正则化项作为天然正则器，保持标记的分布一致性。VA-π能够快速适配现有自回归生成器，既无需重新训练分词器，也不依赖外部奖励模型。仅使用1%的ImageNet-1K数据及25分钟微调，即在LlamaGen-XXL模型上将FID从14.36降至7.65，IS从86.55提升至116.70；同时在GenEval文本到图像任务中，视觉生成模型（LlamaGen：从0.306至0.339）与统一多模态模型（Janus-Pro：从0.725至0.744）均取得显著提升。代码发布于https://github.com/Lil-Shake/VA-Pi。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.19680) | [arXiv](https://arxiv.org/abs/2512.19680)



---

### 7. GTR-Turbo：融合检查点在智能视觉语言模型训练中悄然成为免费教师

**原文标题：** GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training

**摘要：**
基于视觉语言模型构建的多模态智能体在进行多轮强化学习时，常受稀疏奖励与长程信用分配问题的制约。近期方法通过引入教师模型提供步骤级反馈以稠密化奖励信号，例如引导思维强化与同策略蒸馏，但这些方法依赖昂贵且通常具有特权访问权限的教师模型，限制了其实用性与可复现性。本文提出GTR-Turbo，作为GTR的高效升级版本，在无需训练或调用昂贵教师模型的情况下实现了同等性能。具体而言，GTR-Turbo将在持续强化学习训练过程中产生的检查点权重进行融合，随后将该融合模型作为“免费”教师，通过监督微调或软对数蒸馏引导后续强化学习。该设计消除了对特权视觉语言模型的依赖，缓解了先前工作中观察到的“熵崩塌”现象，并保持了训练稳定性。在多种视觉智能任务中，相较于GTR方法，GTR-Turbo将基线模型准确率提升10-30%，同时减少50%的实际训练时间与60%的计算成本。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2512.13043) | [arXiv](https://arxiv.org/abs/2512.13043)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2025-12-26_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)