<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hugging Face 论文日报 - 2026-01-12</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
            padding: 20px;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 30px;
            font-size: 28px;
        }
        
        h1 img {
            vertical-align: middle;
            margin-right: 10px;
        }
        
        h2 {
            color: #34495e;
            margin-top: 40px;
            margin-bottom: 20px;
            font-size: 24px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }
        
        h3 {
            color: #2c3e50;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 20px;
        }
        
        p {
            margin-bottom: 15px;
            text-align: justify;
        }
        
        ul {
            margin-left: 20px;
            margin-bottom: 20px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        a {
            color: #3498db;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        strong {
            color: #2c3e50;
            font-weight: 600;
        }
        
        hr {
            border: none;
            border-top: 1px solid #e0e0e0;
            margin: 30px 0;
        }
        
        /* 关键修复:限制图片宽度 */
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        /* 确保图片容器也有宽度限制 */
        p img {
            max-width: 100%;
        }
        
        /* 论文详情区域样式 */
        .paper-section {
            background-color: #f9f9f9;
            padding: 20px;
            border-radius: 6px;
            margin-bottom: 20px;
        }
        
        /* 统计信息样式 */
        .stats {
            background-color: #e8f4f8;
            padding: 15px;
            border-radius: 6px;
            margin-bottom: 20px;
        }
        
        /* 响应式设计 */
        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 24px;
            }
            
            h2 {
                font-size: 20px;
            }
            
            h3 {
                font-size: 18px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1><img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-12 论文日报</h1>
<h2>📊 今日论文统计</h2>
<ul>
<li>总论文数：31</li>
<li>热门领域：GPT, LLM, NLP, RL, Transformer</li>
</ul>
<h2>📝 论文详情</h2>
<h3>1. 思维与地图：用于地理定位的强化并行地图增强智能体</h3>
<p><strong>原文标题：</strong> Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization</p>
<p><strong>摘要：</strong>
图像地理定位任务旨在利用视觉线索预测图像在地球上任意位置的拍摄地点。现有的大型视觉语言模型方法虽能利用世界知识、思维链推理及智能体能力，却忽视了人类常用的策略——使用地图。本研究首先赋予模型“思维与地图”能力，并将其构建为地图内智能体循环框架。我们为此开发了一种两阶段优化方案，包括智能体强化学习阶段及后续的并行测试时扩展阶段。强化学习增强了模型的智能体能力以提高采样效率，而并行测试时扩展使模型能在最终预测前探索多条候选路径，这对地理定位至关重要。为在最新真实场景图像上评估本方法，我们进一步提出了MAPBench——一个完全由真实世界图像构成的综合性地理定位训练与评估基准。实验结果表明，本方法在多数指标上优于现有开源与闭源模型，特别是在与具备谷歌搜索/地图增强模式的Gemini-3-Pro对比时，将Acc@500m指标从8.0%显著提升至22.1%。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05432">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05432">arXiv</a></p>
<hr />
<h3>2. MMFormalizer：开放环境下的多模态自动形式化方法</h3>
<p><strong>原文标题：</strong> MMFormalizer: Multimodal Autoformalization in the Wild</p>
<p><strong>摘要：</strong>
自动形式化旨在将自然语言描述的数学内容转化为形式化语句以支持机器推理，但在开放物理世界中面临根本性挑战——物理问题常需从视觉元素推断隐含约束（如质量或能量）。为此，我们提出MMFormalizer，通过将自适应实体锚定与现实世界的数学及物理领域相结合，将自动形式化扩展至文本之外。该系统通过递归锚定与公理组合，从感知锚定的基本单元递归构建形式化命题，其自适应递归终止机制确保每个抽象概念均获得视觉证据支持，并锚定于维度或公理基础。我们在新基准测试集PhyX-AF上评估MMFormalizer，该数据集包含从MathVerse、PhyX、合成几何与解析几何中精选的115个样本，涵盖多样化的多模态自动形式化任务。实验结果表明，GPT-5与Gemini-3-Pro等前沿模型在编译准确率与语义准确率上表现最佳，其中GPT-5在物理推理方面尤为突出，而几何领域仍是当前最具挑战性的方向。总体而言，MMFormalizer为统一的多模态自动形式化提供了可扩展框架，有效连接了感知与形式化推理。据我们所知，这是首个能够处理经典力学（基于哈密顿量推导）、相对论、量子力学及热力学的多模态自动形式化方法。更多细节详见项目页面：MMFormalizer.github.io</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.03017">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.03017">arXiv</a></p>
<hr />
<h3>3. CaricatureGS：基于高斯曲率的三维高斯泼溅人脸夸张化方法</h3>
<p><strong>原文标题：</strong> CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature</p>
<p><strong>摘要：</strong>
本文提出了一种兼具照片级真实感与可控性的三维人脸夸张化框架。我们首先采用基于本征高斯曲率的表面夸张技术，但该方法与纹理结合时易产生过度平滑的渲染结果。为解决此问题，我们引入近期被证实能生成逼真自由视角虚拟形象的三维高斯泼溅技术。给定多视角序列，我们提取FLAME网格模型，求解曲率加权泊松方程，获得其夸张化形态。然而直接对高斯分布进行变形会导致效果不佳，因此我们通过局部仿射变换将每帧图像扭曲至其对应的二维夸张表征，合成了伪真实夸张图像。随后设计了一种交替使用真实数据与合成数据监督的训练方案，使单一高斯集合能够同时表征自然状态与夸张状态的虚拟形象。该方案提升了保真度，支持局部编辑，并允许对夸张强度进行连续控制。为实现实时变形，我们引入了原始表面与夸张表面的高效插值方法，并通过理论分析证明该方法与闭式解存在有界偏差。在定量与定性评估中，本方法均优于现有工作，能够生成具有照片级真实感且几何可控的夸张虚拟形象。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.03319">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.03319">arXiv</a></p>
<hr />
<h3>4. 思维分子结构：长链推理拓扑映射研究</h3>
<p><strong>原文标题：</strong> The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning</p>
<p><strong>摘要：</strong>
大型语言模型（LLM）常难以通过模仿人类或非长链推理LLM来习得有效的长链推理能力。为探究此问题，我们提出有效且可学习的长链推理轨迹在统一视角下具有稳定的类分子结构，该结构由三种相互作用类型构成：深度推理（类共价键作用）、自我反思（类氢键作用）和自我探索（类范德华作用）。对蒸馏轨迹的分析表明，这些结构产生于长链推理微调过程，而非关键词模仿。我们提出“有效语义异构体”概念，证明仅促进快速熵收敛的键合作用能支撑稳定的长链推理学习，而结构竞争会损害训练效果。基于这些发现，我们开发了Mole-Syn方法——一种基于分布转移图的引导合成技术，可有效构建长链推理结构，在多项基准测试中显著提升模型性能与强化学习稳定性。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.06002">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.06002">arXiv</a></p>
<hr />
<h3>5. 证据链构建：基于引证感知评分奖励的深度搜索智能体鲁棒强化学习</h3>
<p><strong>原文标题：</strong> Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards</p>
<p><strong>摘要：</strong>
强化学习已成为增强基于大语言模型的深度搜索智能体的关键技术。然而，现有方法主要依赖二元结果奖励，无法有效评估智能体推理过程的完整性与事实依据，常导致捷径利用和事实幻觉等不良行为。为应对这些局限，我们提出引证感知评分奖励框架，该细粒度奖励机制强调推理完整性、事实依据与证据连贯性。该框架将复杂问题分解为可验证的单步评分项，要求智能体通过显式识别隐含实体、提供正确引证、构建连接预测答案的完整证据链来满足评分标准。我们进一步提出引证感知分组相对策略优化算法，结合评分奖励与结果奖励以训练鲁棒的深度搜索智能体。实验表明，该算法在多个深度搜索基准测试中持续优于基于结果的强化学习基线方法。分析结果验证了该算法能有效抑制捷径利用行为，促进全面且基于证据的推理过程，并在开放式深度研究任务中展现出强大的泛化能力。相关代码与数据已发布于 https://github.com/THUDM/CaRR。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.06021">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.06021">arXiv</a></p>
<hr />
<h3>6. EnvScaler：基于程序化合成的LLM智能体工具交互环境扩展框架</h3>
<p><strong>原文标题：</strong> EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis</p>
<p><strong>摘要：</strong>
大型语言模型（LLM）需被训练为能在多样现实环境中执行任务的智能体，但这一过程依赖于丰富且多变的工具交互沙箱环境。然而，现实系统的访问往往受限；LLM模拟环境易产生幻觉与不一致问题；而人工构建的沙箱则难以扩展。本文提出EnvScaler，一种通过程序化合成实现可扩展工具交互环境的自动化框架。EnvScaler包含两个核心组件：首先，SkelBuilder通过主题挖掘、逻辑建模与质量评估构建多样化的环境骨架；随后，ScenGenerator为每个环境生成多任务场景及基于规则的轨迹验证函数。基于EnvScaler，我们合成了191个环境与约7000个场景，并将其应用于Qwen3系列模型的监督微调（SFT）与强化学习（RL）训练。在三个基准测试上的实验结果表明，EnvScaler显著提升了LLM在涉及多轮次、多工具交互的复杂环境中解决任务的能力。代码与数据已开源：https://github.com/RUC-NLPIR/EnvScaler。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05808">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05808">arXiv</a></p>
<hr />
<h3>7. Qwen3-VL-Embedding与Qwen3-VL-Reranker：面向先进多模态检索与排序的统一框架</h3>
<p><strong>原文标题：</strong> Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking</p>
<p><strong>摘要：</strong>
本报告介绍了Qwen3-VL-Embedding与Qwen3-VL-Reranker模型系列，它们是基于Qwen3-VL基础模型构建的Qwen家族最新扩展。二者共同构成了一个端到端的高精度多模态搜索流程，能够将文本、图像、文档图像及视频等多种模态映射到统一的表示空间中。Qwen3-VL-Embedding模型采用多阶段训练范式，从大规模对比预训练逐步推进至重排序模型蒸馏，以生成语义丰富的高维向量。该模型支持嵌套表示学习，可实现灵活的嵌入维度，并支持高达32k令牌的输入长度。与之互补，Qwen3-VL-Reranker通过采用具有交叉注意力机制的交叉编码器架构，对查询-文档对进行细粒度相关性估计。两个模型系列均继承了Qwen3-VL的多语言能力，支持超过30种语言，并发布了2B和8B参数规模的版本以适应不同的部署需求。实证评估表明，Qwen3-VL-Embedding系列在多项多模态嵌入评估基准测试中取得了最先进的性能。具体而言，Qwen3-VL-Embedding-8B在MMEB-V2基准上获得77.8的综合得分，在所有模型中位列第一（截至2025年1月8日）。本报告详细阐述了该系列的架构设计、训练方法及实际应用能力，并通过图像-文本检索、视觉问答和视频-文本匹配等多模态检索任务验证了其有效性。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.04720">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.04720">arXiv</a></p>
<hr />
<h3>8. 能否在执行前预测机器学习智能体的行为？</h3>
<p><strong>原文标题：</strong> Can We Predict Before Executing Machine Learning Agents?</p>
<p><strong>摘要：</strong>
自主机器学习智能体虽已推动科学发现领域的革新，但其仍受限于“生成-执行-反馈”的传统范式。现有方法因假设评估完全依赖高成本的物理执行而面临严重的“执行瓶颈”问题。为突破物理约束，本研究受世界模型启发，通过内化执行先验知识，以即时预测推理替代昂贵的运行时验证。我们首先形式化定义了“以数据为中心的解决方案偏好”任务，并构建了包含18,438组配对比较的完整语料库。实验表明，大型语言模型在获得经过验证的数据分析报告提示后，展现出显著的预测能力，达到61.5%的准确率并具备稳健的置信度校准。最终，我们在FOREAGENT智能体中实例化了该框架，采用“预测-验证”循环机制，在收敛速度上实现6倍提升，同时超越基于执行的基线方法6个百分点。相关代码与数据集将于近期在https://github.com/zjunlp/predict-before-execute公开。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05930">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05930">arXiv</a></p>
<hr />
<h3>9. AgentOCR：通过光学自压缩重构智能体历史记录</h3>
<p><strong>原文标题：</strong> AgentOCR: Reimagining Agent History via Optical Self-Compression</p>
<p><strong>摘要：</strong>
大型语言模型（LLM）的最新进展使得基于多轮交互轨迹的强化学习（RL）训练智能体系统成为可能，但实际部署受限于快速增长的文本历史记录，这些记录会扩大令牌预算和内存占用。我们提出AgentOCR框架，该框架通过将累积的观察-行动历史表示为紧凑的渲染图像，利用视觉令牌更高的信息密度。为实现多轮推演的可扩展性，AgentOCR提出了分段光学缓存机制。该机制将历史分解为可哈希的片段并维护视觉缓存，从而消除冗余的重复渲染。除固定渲染外，AgentOCR还引入了智能体自压缩机制，使智能体主动输出压缩率，并通过压缩感知奖励进行训练，以自适应平衡任务成功率和令牌效率。我们在具有挑战性的智能体基准测试（ALFWorld和基于搜索的问答任务）上进行了大量实验。显著的结果表明，AgentOCR在保持基于文本的智能体性能95%以上的同时，大幅降低了令牌消耗（&gt;50%），实现了稳定的令牌和内存效率。进一步分析验证了分段光学缓存带来的20倍渲染加速效果，以及自压缩机制有效的策略平衡能力。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.04786">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.04786">arXiv</a></p>
<hr />
<h3>10. 领域迁移下偏好调优泛化性与多样性的实证研究</h3>
<p><strong>原文标题：</strong> An Empirical Study on Preference Tuning Generalization and Diversity Under Domain Shift</p>
<p><strong>摘要：</strong>
偏好调优通过优化显式偏好信号（而非仅依赖似然性）使预训练语言模型与人类在质量、有用性或安全性方面的判断保持一致。先前研究表明，当在训练领域外进行评估时，偏好调优会降低模型性能并削弱其有用性。然而，适应策略在多大程度上能够缓解这种领域迁移的影响尚未得到充分探索。本研究通过开展领域迁移下对齐泛化能力的全面系统性分析来应对这一挑战。我们在文本摘要和问答有用性任务中，比较了五种主流对齐目标以及从源领域到目标领域的多种适应策略（包括目标领域监督微调和伪标注方法）。研究结果表明，在领域迁移条件下，不同对齐目标的泛化能力存在系统性差异。我们进一步证明，基于伪标注的适应策略能够显著减轻领域迁移导致的性能退化。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05882">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05882">arXiv</a></p>
<hr />
<h3>11. VideoAR：基于下一帧与尺度预测的自回归视频生成</h3>
<p><strong>原文标题：</strong> VideoAR: Autoregressive Video Generation via Next-Frame &amp; Scale Prediction</p>
<p><strong>摘要：</strong>
当前视频生成领域的研究主要由扩散模型和流匹配模型主导，这些模型虽能生成高质量结果，但计算成本高昂且难以扩展。本文提出VideoAR，首个结合多尺度下一帧预测与自回归建模的大规模视觉自回归视频生成框架。VideoAR通过将帧内自回归建模与因果性下一帧预测相结合，并辅以能高效编码时空动态的三维多尺度分词器，实现了空间与时间依赖关系的解耦。为提升长期一致性，我们提出多尺度时序旋转位置编码、跨帧误差校正和随机帧掩码机制，共同抑制误差传播并增强时序连贯性。我们的多阶段预训练流程通过逐步提升分辨率与时长，实现了空间与时间学习的渐进对齐。实验表明，VideoAR在自回归模型中取得了最先进的性能：在UCF-101数据集上将FVD指标从99.5提升至88.6，同时减少超过10倍的推理步数，并在VBench评测中获得81.74分——该成绩可与规模大一个数量级的扩散模型相竞争。这些结果证明VideoAR显著缩小了自回归范式与扩散范式之间的性能差距，为未来视频生成研究提供了可扩展、高效且时序一致的基础框架。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05966">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05966">arXiv</a></p>
<hr />
<h3>12. 自信的幻象？基于邻域一致性的大语言模型真实性诊断</h3>
<p><strong>原文标题：</strong> Illusions of Confidence? Diagnosing LLM Truthfulness via Neighborhood Consistency</p>
<p><strong>摘要：</strong>
随着大语言模型在现实场景中的部署日益广泛，仅关注答案正确性已显不足。可靠部署要求模型在上下文扰动下保持真实信念。现有评估方法主要依赖自洽性等点状置信度指标，这可能掩盖信念的脆弱性。本研究证明，即使在完美自洽性下回答的事实，在轻微上下文干扰下也可能迅速崩溃。为弥补这一缺陷，我们提出邻域一致性信念——一种通过评估概念邻域内响应连贯性来衡量信念鲁棒性的结构化指标。为验证该指标的有效性，我们设计了新的认知压力测试协议，用于探测上下文干扰下的输出稳定性。在多类大语言模型上的实验表明，高邻域一致性信念数据在干扰下表现出更强的抗逆性。最后，我们提出结构感知训练方法，通过优化上下文不变信念结构，将长尾知识的脆弱性降低约30%。代码发布于https://github.com/zjunlp/belief。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05905">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05905">arXiv</a></p>
<hr />
<h3>13. 目标力：教授视频模型实现物理条件化目标</h3>
<p><strong>原文标题：</strong> Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals</p>
<p><strong>摘要：</strong>
视频生成领域的最新进展使得能够开发出可为机器人与规划任务模拟潜在未来的“世界模型”。然而，为这些模型设定精确目标仍具挑战性：文本指令通常过于抽象而难以捕捉物理细节，而目标图像对于动态任务往往难以指定。为此，我们提出“目标力”这一新颖框架，允许用户通过明确的力向量和中间动力学过程来定义目标，这模仿了人类对物理任务的构思方式。我们在精心构建的合成因果基元数据集（如弹性碰撞与多米诺骨牌倾倒）上训练视频生成模型，使其学会在时空维度上传递力的作用。尽管仅基于简单物理数据进行训练，我们的模型在复杂现实场景中展现出卓越的零样本泛化能力，包括工具操纵与多物体因果链任务。实验结果表明，通过将视频生成建立在基础物理交互之上，模型能够演化为隐式神经物理模拟器，从而在不依赖外部引擎的情况下实现精确且具有物理感知的规划。我们已在项目页面公开全部数据集、代码、模型权重及交互式视频演示。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05848">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05848">arXiv</a></p>
<hr />
<h3>14. BizFinBench.v2：面向专家级金融能力对齐的统一双模双语基准</h3>
<p><strong>原文标题：</strong> BizFinBench.v2: A Unified Dual-Mode Bilingual Benchmark for Expert-Level Financial Capability Alignment</p>
<p><strong>摘要：</strong>
大语言模型经历了快速发展，已成为金融运营智能化的关键技术。然而，现有基准常受限于依赖模拟或通用样本、聚焦单一离线静态场景等缺陷，导致其难以契合金融服务对真实性与实时响应性的要求，造成基准表现与实际业务效能之间存在显著差距。为此，我们推出BizFinBench.v2——首个基于中美股市真实业务数据并融合在线评估的大规模评测基准。通过对金融平台真实用户查询进行聚类分析，我们构建了覆盖四大核心业务场景的八项基础任务与两项在线任务，共包含29,578组专家级问答对。实验结果显示：ChatGPT-5在主任务中取得61.5%的突出准确率，但与金融专家仍存明显差距；在线任务中DeepSeek-R1表现优于其他商用大语言模型。错误分析进一步揭示了现有模型在真实金融业务场景中的具体能力短板。BizFinBench.v2突破了现有基准的局限，实现了对大语言模型金融能力的业务级解构，为评估大语言模型在金融领域广泛部署的效能提供了精准依据。数据与代码已公开于https://github.com/HiThink-Research/BizFinBench.v2。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.06401">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.06401">arXiv</a></p>
<hr />
<h3>15. Orient Anything V2：统一朝向与旋转理解</h3>
<p><strong>原文标题：</strong> Orient Anything V2: Unifying Orientation and Rotation Understanding</p>
<p><strong>摘要：</strong>
本研究提出Orient Anything V2，这是一个增强型基础模型，用于从单张或成对图像中统一理解物体的三维朝向与旋转。该模型基于Orient Anything V1（其通过单一独特正面定义朝向）构建，进一步扩展能力以处理具有不同旋转对称性的物体，并直接估计相对旋转。这些改进得益于四项关键创新：1）利用生成模型合成可扩展的三维资产，确保广泛的类别覆盖与均衡的数据分布；2）一种高效的模型在环标注系统，能鲁棒地识别每个物体0到N个有效正面；3）一种感知对称性的周期性分布拟合目标，可捕捉所有合理的正面朝向，有效建模物体的旋转对称性；4）一种直接预测物体相对旋转的多帧架构。大量实验表明，Orient Anything V2在11个广泛使用的基准测试中，于朝向估计、6自由度姿态估计和物体对称性识别任务上均实现了零样本性能的领先水平。该模型展现出强大的泛化能力，显著拓宽了朝向估计在多种下游任务中的适用性。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05573">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05573">arXiv</a></p>
<hr />
<h3>16. 相同主张，不同判断：多语言金融虚假信息检测中情境诱发偏见的基准测试研究</h3>
<p><strong>原文标题：</strong> Same Claim, Different Judgment: Benchmarking Scenario-Induced Bias in Multilingual Financial Misinformation Detection</p>
<p><strong>摘要：</strong>
大语言模型（LLM）已在金融领域的多个方向得到广泛应用。由于其训练数据主要来源于人类撰写的语料库，LLM可能继承一系列人类偏见。行为偏见可能导致决策的不稳定性和不确定性，尤其在处理金融信息时更为突出。然而，现有关于LLM偏见的研究主要集中于直接提问或简化的通用场景，对复杂的现实金融环境以及高风险、情境敏感的多语言金融虚假信息检测任务（MFMD）的考量较为有限。本研究提出MFMDScen——一个用于评估LLM在多样化经济情境下MFMD任务中行为偏见的综合性基准框架。通过与金融专家协作，我们构建了三种复杂金融情境：（i）基于角色与人格特质的场景，（ii）基于角色与地域特征的场景，以及（iii）融合族群与宗教信仰的角色化场景。我们进一步构建了涵盖英语、汉语、希腊语和孟加拉语的多语言金融虚假信息数据集。通过将这些情境与虚假信息主张相结合，MFMDScen实现了对22个主流LLM的系统性评估。研究结果表明，显著的行为偏见在商业模型和开源模型中均持续存在。本项目资源发布于https://github.com/lzw108/FMD。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05403">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05403">arXiv</a></p>
<hr />
<h3>17. AnyDepth：轻松实现深度估计</h3>
<p><strong>原文标题：</strong> AnyDepth: Depth Estimation Made Easy</p>
<p><strong>摘要：</strong>
单目深度估计旨在从二维图像中恢复三维场景的深度信息。近期研究虽取得显著进展，但其对大规模数据集和复杂解码器的依赖限制了模型的效率与泛化能力。本文提出一种轻量级且以数据为中心的零样本单目深度估计框架。我们首先采用DINOv3作为视觉编码器以获取高质量的密集特征；其次，针对DPT结构复杂性的固有缺陷，设计了基于紧凑型Transformer的解码器——简易深度变换器（SDT）。相较于DPT，该解码器采用单路径特征融合与上采样流程，显著降低了跨尺度特征融合的计算开销，在减少约85%-89%参数量的同时实现了更高的精度。此外，我们提出基于质量的过滤策略以筛除有害样本，从而在缩减数据集规模的同时提升整体训练质量。在五个基准数据集上的大量实验表明，本框架在精度上超越DPT。本研究揭示了平衡模型设计与数据质量对于实现高效、可泛化的零样本深度估计的重要性。代码：https://github.com/AIGeeksGroup/AnyDepth。项目网站：https://aigeeksgroup.github.io/AnyDepth。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.02760">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.02760">arXiv</a></p>
<hr />
<h3>18. SmartSearch：面向搜索智能体的过程奖励引导式查询优化框架</h3>
<p><strong>原文标题：</strong> SmartSearch: Process Reward-Guided Query Refinement for Search Agents</p>
<p><strong>摘要：</strong>
基于大语言模型的搜索智能体通过集成信息检索能力，在解决知识密集型问题方面展现出巨大潜力。现有研究主要聚焦于优化搜索智能体的推理范式，然而推理过程中中间搜索查询的质量问题长期被忽视。这导致生成的查询往往不够精确，引发非预期的检索结果，最终制约搜索智能体的整体效能。为缓解这一问题，我们提出SmartSearch框架，其核心机制包括：（1）过程奖励机制：通过双层级信用评估对每个中间搜索查询的质量进行细粒度监督；（2）查询优化机制：通过选择性优化低质量搜索查询，并基于优化结果重新生成后续搜索轮次，从而提升查询生成质量。为使搜索智能体能够在过程奖励引导下逐步内化查询质量改进能力，我们设计了三阶段课程学习框架，引导智能体依次经历模仿、对齐与泛化的渐进式学习过程。实验结果表明，SmartSearch在各项基准测试中均持续超越现有基线方法，定量分析进一步证实其在搜索效率与查询质量方面均取得显著提升。代码已开源：https://github.com/MYVAE/SmartSearch。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.04888">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.04888">arXiv</a></p>
<hr />
<h3>19. 检索增强大语言模型中的过度搜索问题研究</h3>
<p><strong>原文标题：</strong> Over-Searching in Search-Augmented Large Language Models</p>
<p><strong>摘要：</strong>
检索增强大语言模型通过整合外部检索机制，在知识密集型任务中表现出色。然而，这类模型常出现过度搜索现象——即使搜索无助于提升回答质量，仍不必要地调用搜索工具，导致计算效率低下，并可能因引入无关上下文而产生幻觉。本研究从查询类型、模型类别、检索条件及多轮对话等多个维度对过度搜索现象展开系统性评估。研究发现：（1）搜索通常能提升可回答查询的答案准确率，但会削弱模型对不可回答问题的拒答能力；（2）过度搜索现象在复杂推理模型和深度研究系统中更为显著，噪声检索会加剧该现象，且在多轮对话中呈现跨轮次累积效应；（3）检索证据的构成至关重要，负面证据的存在能有效提升模型拒答能力。为量化过度搜索，本文提出"单位正确性所需标记数"评估指标，用以衡量检索增强大语言模型的性能-成本权衡关系。最后，我们从查询层和检索层探索缓解策略，并发布OverSearchQA数据集以推动高效检索增强大语言模型的持续研究。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05503">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05503">arXiv</a></p>
<hr />
<h3>20. DR-LoRA：面向专家混合模型适配的动态秩LoRA方法</h3>
<p><strong>原文标题：</strong> DR-LoRA: Dynamic Rank LoRA for Mixture-of-Experts Adaptation</p>
<p><strong>摘要：</strong>
专家混合模型已成为扩展大语言模型规模的重要范式。参数高效微调技术（如LoRA）被广泛用于将预训练的MoE大语言模型适配至下游任务。然而，现有方法为所有专家分配相同的LoRA秩，忽视了MoE大语言模型内在的功能专化特性。这种均匀分配会导致资源错配：任务相关专家参数配置不足，而相关性较低的专家却获得冗余参数。本文提出一种名为DR-LoRA的动态秩LoRA框架，该框架能够根据任务特定需求在微调过程中动态调整专家LoRA秩。DR-LoRA采用专家显著性评分机制，综合专家路由频率和LoRA秩重要性来量化每个专家对额外容量的需求。具有较高显著性评分的专家将优先进行秩扩展，从而自动形成适应目标任务的异构秩分布。在多个基准测试上的实验表明，在相同参数预算下，DR-LoRA始终优于标准LoRA及静态分配策略，通过更高效的参数利用实现了更优越的任务性能。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.04823">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.04823">arXiv</a></p>
<hr />
<h3>21. 记忆至关重要：以事件为中心的记忆作为智能体搜索与推理的逻辑地图</h3>
<p><strong>原文标题：</strong> Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning</p>
<p><strong>摘要：</strong>
大型语言模型正日益被部署为能够推理、规划并与环境交互的智能体。为有效适应长周期任务场景，此类智能体的关键能力在于具备一种能够保存、组织并检索过往经验以支持下游决策的记忆机制。然而，现有方法大多以扁平化方式组织和存储记忆，并依赖简单的基于相似度的检索技术。即使引入结构化记忆，现有方法仍难以显式捕捉经验或记忆单元间的逻辑关联。此外，记忆访问过程往往与已构建的结构脱节，仍依赖于浅层语义检索，导致智能体无法对长周期依赖关系进行逻辑推理。本研究提出CompassMem——一个受事件分割理论启发的以事件为中心的记忆框架。该框架通过将经验逐步分割为事件并以显式逻辑关系进行连接，将记忆组织为事件图谱。该图谱作为逻辑地图，使智能体能够超越表层检索，在记忆空间中进行结构化、目标导向的导航，逐步积累有价值的记忆以支持长周期推理。在LoCoMo和NarrativeQA数据集上的实验表明，CompassMem在多种骨干模型中均能持续提升检索与推理性能。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.04726">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.04726">arXiv</a></p>
<hr />
<h3>22. GenCtrl——生成模型的形式化可控性工具包</h3>
<p><strong>原文标题：</strong> GenCtrl -- A Formal Controllability Toolkit for Generative Models</p>
<p><strong>摘要：</strong>
随着生成模型的普及，对生成过程进行细粒度控制的需求日益迫切。然而，尽管从提示工程到微调的各种受控生成方法不断涌现，一个根本性问题仍未得到解答：这些模型本身是否真正具备可控性？本研究提出了一个理论框架来形式化地回答这一问题。通过将人机交互建模为控制过程，我们提出了一种新颖算法，用于在对话场景中估计模型的可控集合。值得注意的是，我们基于样本复杂度给出了估计误差的形式化保证：推导出具有概率近似正确性的可控集合估计边界，该边界不依赖于数据分布，除输出有界性外无需任何假设，且适用于任何黑箱非线性控制系统（即任意生成模型）。我们在对话过程控制的不同任务上对理论框架进行了实证验证，涵盖语言模型和文生图生成场景。实验结果表明，模型可控性具有出人意料的脆弱性，且高度依赖实验设置。这凸显了进行严格可控性分析的必要性，应将研究重点从单纯尝试控制转向首先理解其根本性局限。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05637">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05637">arXiv</a></p>
<hr />
<h3>23. TCAndon-Router：面向多智能体协作的自适应推理路由机制</h3>
<p><strong>原文标题：</strong> TCAndon-Router: Adaptive Reasoning Router for Multi-Agent Collaboration</p>
<p><strong>摘要：</strong>
多智能体系统已成为构建高性能智能应用的重要范式。在该类系统中，负责决策特定查询应由哪些专家智能体处理的路由机制对整体性能起着关键作用。现有路由策略主要分为两类：性能路由（通过权衡不同规模模型间的延迟与成本实现负载均衡）和任务路由（将查询分配给领域专家以提升准确性）。在实际企业应用中，任务路由更具适用性；然而，现有方案多依赖静态单标签决策机制，存在两大局限：（1）难以随业务领域扩展而无缝集成新智能体；（2）因智能体能力重叠引发路由冲突，最终导致准确性与鲁棒性下降。为应对这些挑战，我们提出TCAndon-Router（TCAR）：一种面向多智能体协作的自适应推理路由机制。与传统路由器不同，TCAR支持动态智能体接入，并首先生成自然语言推理链，再预测能够处理查询的候选智能体集合。此外，我们设计了协同执行流水线：被选中的智能体独立生成响应，随后由专用优化智能体进行聚合提炼，形成单一高质量响应。在公开数据集和企业实际数据上的实验表明，TCAR显著提升了路由准确性，降低了路由冲突，并在模糊场景中保持鲁棒性。我们已在https://huggingface.co/tencent/TCAndon-Router开源TCAR，以支持可解释协同多智能体路由的未来研究。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.04544">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.04544">arXiv</a></p>
<hr />
<h3>24. 将反馈提炼为记忆即工具</h3>
<p><strong>原文标题：</strong> Distilling Feedback into Memory-as-a-Tool</p>
<p><strong>摘要：</strong>
本研究提出一种框架，通过基于文件的记忆系统与智能体控制的工具调用，将瞬态批评转化为可检索的指导原则，从而分摊推理时思考的计算成本。我们在Rubric Feedback Bench（一种基于量规学习的新型数据集）上对该方法进行评估。实验表明，增强后的大型语言模型能快速达到测试时精炼流程的性能水平，同时显著降低推理成本。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05960">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05960">arXiv</a></p>
<hr />
<h3>25. TowerMind：面向大语言模型智能体的塔防游戏学习环境与基准测试平台</h3>
<p><strong>原文标题：</strong> TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents</p>
<p><strong>摘要：</strong>
大语言模型（LLMs）的最新突破使其成为构建智能体的潜力范式，其中长期规划与决策能力正逐步发展为适应多样化场景与任务的核心通用能力。实时策略（RTS）游戏因其游戏机制天然要求宏观战略规划与微观战术适应及动作执行，成为评估这两类能力的理想测试平台。然而，现有基于RTS游戏的环境普遍存在计算需求较高或缺乏文本观察支持的问题，限制了大语言模型在RTS游戏中的评估应用。为此，我们提出了TowerMind——一个基于RTS游戏子类塔防游戏构建的新型环境。该环境在保留RTS游戏对大语言模型核心评估优势的同时，具备低计算需求与多模态观察空间的特点，支持像素级画面、文本描述及结构化游戏状态表征。此外，TowerMind支持模型幻觉评估，并提供高度可定制性。我们设计了五个基准关卡，在不同多模态输入设置下对多个广泛使用的大语言模型进行评估。实验结果表明，大语言模型在能力维度与幻觉维度均与人类专家存在明显差距。研究进一步揭示了大语言模型行为的关键局限，包括规划验证不足、决策缺乏多终局性以及动作使用效率低下。我们还评估了两种经典强化学习算法：Ape-X DQN与PPO。通过提供轻量化、多模态的设计，TowerMind既补充了现有基于RTS游戏的环境体系，也为人工智能智能体领域引入了新的基准测试标准。项目源代码已在GitHub平台开源（https://github.com/tb6147877/TowerMind）。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05899">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05899">arXiv</a></p>
<hr />
<h3>26. Router-Suggest：视觉对话中多模态自动补全的动态路由方法</h3>
<p><strong>原文标题：</strong> Router-Suggest: Dynamic Routing for Multimodal Auto-Completion in Visually-Grounded Dialogs</p>
<p><strong>摘要：</strong>
实时多模态自动补全对于数字助手、聊天机器人、设计工具及医疗咨询等依赖共享视觉情境的用户输入场景至关重要。本文提出多模态自动补全任务，该任务利用部分已输入文本及视觉线索预测实时对话中的后续字符。与传统纯文本自动补全不同，MAC将预测基于多模态语境，以更精准捕捉用户意图。为支持此任务，我们基于MMDialog与ImageChat构建了基准数据集。通过将前沿视觉语言模型与强文本基线模型进行对比评估，本文揭示了精度与效率间的权衡关系。我们提出Router-Suggest——一种基于对话语境动态选择文本模型或视觉语言模型的路由框架，并设计了适用于资源受限环境的轻量化变体。实验表明，Router-Suggest相较性能最佳的视觉语言模型实现了2.3至10倍的加速。用户研究证实，在多轮对话中视觉语言模型在用户满意度方面显著优于文本模型，特别是在减少用户输入负担与提升补全质量方面表现突出。这些发现凸显了多模态语境在自动补全中的必要性，为构建更智能、更具用户感知能力的辅助系统提供了方向。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05851">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05851">arXiv</a></p>
<hr />
<h3>27. ViTNT-FIQA：基于视觉Transformer的无训练人脸图像质量评估方法</h3>
<p><strong>原文标题：</strong> ViTNT-FIQA: Training-Free Face Image Quality Assessment with Vision Transformers</p>
<p><strong>摘要：</strong>
人脸图像质量评估（FIQA）对于构建可靠的人脸识别系统至关重要。现有方法主要仅利用最终层表征，而无训练方法通常需要多次前向传播或反向传播过程。本文提出ViTNT-FIQA，一种无需训练的方法，通过度量中间视觉Transformer（ViT）模块间图像块嵌入演化的稳定性实现质量评估。我们发现高质量人脸图像在跨模块间呈现稳定的特征优化轨迹，而质量退化图像则表现出不稳定的特征变换。该方法通过计算连续Transformer模块间L2归一化图像块嵌入的欧氏距离，并将其聚合为图像级质量分数。我们在具有可控退化等级的质量标注合成数据集上实证验证了这种相关性。与现有无训练方法不同，ViTNT-FIQA仅需单次前向传播，无需反向传播或模型结构修改。通过在八个基准数据集（LFW、AgeDB-30、CFP-FP、CALFW、Adience、CPLFW、XQLFW、IJB-C）上的广泛实验表明，ViTNT-FIQA在保持计算效率、可直接应用于任何预训练ViT人脸识别模型的同时，达到了与先进方法相竞争的性能水平。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05741">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05741">arXiv</a></p>
<hr />
<h3>28. IIB-LPO：基于迭代信息瓶颈的隐式策略优化</h3>
<p><strong>原文标题：</strong> IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck</p>
<p><strong>摘要：</strong>
近期，针对大语言模型推理的可验证奖励强化学习虽取得进展，却始终受限于探索崩溃这一核心挑战。随机推演的语义同质性常使模型陷入狭窄且过度优化的行为模式。现有方法虽利用策略熵鼓励探索，却存在固有局限：全局熵正则化易受奖励黑客攻击，可能导致无意义的冗长输出；而局部词元选择性更新则受预训练模型强归纳偏置的制约。为此，我们提出基于迭代信息瓶颈的隐式策略优化方法，该方法将探索机制从词元分布的统计扰动转向推理轨迹的拓扑分岔。IIB-LPO 在高熵状态触发隐式分岔以多样化推理路径，并运用信息瓶颈原理同时作为轨迹过滤器与自奖励机制，确保探索过程兼具简洁性与信息量。在四个数学推理基准测试上的实验结果表明，IIB-LPO 实现了最先进的性能，其准确率较现有方法提升最高达5.3%，多样性指标提升最高达7.4%。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05870">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05870">arXiv</a></p>
<hr />
<h3>29. Afri-MCQA：面向非洲语言的多模态文化问答基准</h3>
<p><strong>原文标题：</strong> Afri-MCQA: Multimodal Cultural Question Answering for African Languages</p>
<p><strong>摘要：</strong>
非洲拥有全球超过三分之一的语言，但在人工智能研究中仍代表性不足。我们推出了Afri-MCQA，这是首个覆盖12个国家15种非洲语言、包含7.5万组问答对的多语言文化问答基准。该基准提供跨文本与语音模态的英语-非洲语言平行问答对，且全部由母语者创建。基于Afri-MCQA对大语言模型（LLMs）的评估表明，开源模型在所有测评文化场景中表现欠佳，当以母语或语音形式进行开放式视觉问答时准确率接近零。为评估语言能力，我们设计了控制实验以区分文化知识与语言能力，观察到模型在文本和语音模态上对非洲母语与英语的处理存在显著性能差距。这些发现凸显了发展语音优先方法、文化本位预训练及跨语言文化迁移的必要性。为支持更具包容性的非洲语言多模态人工智能发展，我们已在HuggingFace平台以学术许可协议及CC BY-NC 4.0协议开源Afri-MCQA数据集（https://huggingface.co/datasets/Atnafu/Afri-MCQA）。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05699">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05699">arXiv</a></p>
<hr />
<h3>30. 角色悖论：临床语言模型中的医学角色作为行为先验</h3>
<p><strong>原文标题：</strong> The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models</p>
<p><strong>摘要：</strong>
角色调节可视为大型语言模型（LLM）的一种行为先验，通常被认为能以单调方式赋予专业能力并提升安全性。然而，其对高风险临床决策的影响仍缺乏深入刻画。本研究系统评估了临床LLM中基于角色的控制机制，探究专业角色（如急诊科医师、护士）与交互风格（果敢型vs.谨慎型）如何影响不同模型在医疗任务中的行为表现。通过涵盖任务准确性、校准度和安全相关风险行为的多维度评估体系，我们系统检验了模型在临床分诊与患者安全任务中的表现。研究发现存在系统性、情境依赖性且非单调的影响效应：医学角色能提升急危重症护理任务的表现，使准确性与校准度最高提升约+20%，但在初级诊疗场景中却会导致相当程度的性能下降。交互风格虽能调节风险倾向与敏感度，但其效果高度依赖模型特性。尽管在安全关键案例中，聚合的LLM评估结果倾向于医学角色优于非医学角色，但人类临床医生在安全合规性上仅呈现中等一致性（平均科恩κ系数=0.43），且对其95.9%的推理质量回答表现出较低置信度。本研究表明，角色作为行为先验会引发情境依赖的权衡效应，而非安全性与专业性的绝对保障。代码已发布于https://github.com/rsinghlab/Persona_Paradox。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.05376">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.05376">arXiv</a></p>
<hr />
<h3>31. 面向安全与伦理人工智能的法律对齐</h3>
<p><strong>原文标题：</strong> Legal Alignment for Safe and Ethical AI</p>
<p><strong>摘要：</strong>
人工智能对齐包含规范性问题（即明确人工智能系统应如何行动）与技术性问题（即确保人工智能系统符合这些规范）。迄今为止，人工智能对齐研究普遍忽视了一个应对这些问题的重要知识与实践来源：法律。本文旨在填补这一空白，探讨如何借助法律规则、原则及方法来解决对齐问题，并为设计安全、符合伦理的人工智能系统提供参考。这一新兴领域——法律对齐——聚焦三个研究方向：（1）设计符合通过合法制度与程序制定的法律规则内容的人工智能系统；（2）借鉴法律解释方法以指导人工智能系统的推理与决策过程；（3）运用法律概念作为应对人工智能系统中可靠性、信任与合作挑战的结构性蓝图。这些研究方向提出了新的概念性、实证性与制度性问题，包括探究特定人工智能系统应遵循的具体法律集合、创建评估体系以衡量其在现实场景中的法律合规性，以及构建支持法律对齐实践落地的治理框架。解决这些问题需要融合法学、计算机科学等多学科专业知识，为相关领域研究者提供了协作设计更优人工智能系统的契机。</p>
<p><strong>论文链接：</strong> <a href="https://huggingface.co/papers/2601.04175">HuggingFace</a> | <a href="https://arxiv.org/abs/2601.04175">arXiv</a></p>
<hr />
<h2>🔍 关键词云图</h2>
<p><img alt="关键词云图" src="../images/keywords_wordcloud.png" /></p>
<h2>📈 近期论文趋势</h2>
<p><img alt="论文趋势" src="../images/daily_papers.png" /></p>
<h2>🎙️ 语音播报</h2>
<ul>
<li><a href="../audio/2026-01-12_daily_papers.mp3">收听今日论文解读</a></li>
</ul>
<h2>📱 订阅渠道</h2>
<ul>
<li>GitHub: <a href="https://github.com/2404589803/hf-daily-paper-newsletter-chinese">hf-daily-paper-newsletter-chinese</a></li>
</ul>
    </div>
</body>
</html>