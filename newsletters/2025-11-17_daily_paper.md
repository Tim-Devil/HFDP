
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2025-11-17 论文日报

## 📊 今日论文统计
- 总论文数：23
- 热门领域：LLM, Transformer, GPT, RL

## 📝 论文详情


### 1. DoPE：旋转位置编码去噪方法

**原文标题：** DoPE: Denoising Rotary Position Embedding

**摘要：**
Transformer模型中的旋转位置编码存在固有局限，会削弱长度外推能力。我们将带位置编码的注意力图重新解读为含噪声的特征图，并提出基于截断矩阵熵的去噪位置编码方法——一种无需训练即可检测特征图中异常频带的方案。利用特征图的噪声特性，我们进一步通过无参数高斯分布对其进行重参数化，以实现稳健的外推。本方法从理论上揭示了注意力汇聚现象的根本成因及其与截断矩阵熵的关联。在"大海捞针"测试和多样本上下文学习任务上的实验表明，DoPE能在长上下文场景（最高64K词元）中显著提升检索精度与推理稳定性。研究结果证明，针对位置嵌入的去噪策略可有效缓解注意力汇聚问题，恢复均衡的注意力模式，为改进长度泛化能力提供了简洁而有效的解决方案。项目主页详见：https://The-physical-picture-of-LLMs.github.io

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.09146) | [arXiv](https://arxiv.org/abs/2511.09146)



---

### 2. WEAVE：解锁与评测上下文交织式多模态理解与生成能力

**原文标题：** WEAVE: Unleashing and Benchmarking the In-context Interleaved Comprehension and Generation

**摘要：**
统一多模态模型的最新进展显著推动了视觉理解与生成能力的发展。然而现有数据集和基准主要关注单轮交互，未能体现真实世界图像创作与编辑中多轮次、上下文依赖的特性。为弥补这一空白，我们提出WEAVE——首个面向上下文交织式跨模态理解与生成的综合套件。该套件包含两个互补部分：WEAVE-100k作为大规模数据集包含10万个交织样本，覆盖37万轮对话和50万张图像，涵盖需要历史上下文推理的理解、编辑与生成任务；WEAVEBench是基于480张图像构建的100项人工标注基准，采用融合参考图像及原图与编辑指令的混合式视觉语言模型评判框架，系统评估模型在多轮生成、视觉记忆和跨领域常识推理等方面的能力。实验表明，基于WEAVE-100k的训练能有效提升视觉理解、图像编辑及理解-生成协作能力，同时促进统一多模态模型涌现视觉记忆能力。而WEAVEBench的广泛评测则揭示了现有方法在多轮上下文感知图像生成与编辑方面存在的持续局限与挑战。我们相信WEAVE为多模态社区研究上下文交织式理解与生成提供了新的视角与基础。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.11434) | [arXiv](https://arxiv.org/abs/2511.11434)



---

### 3. GGBench：面向统一多模态模型的几何生成推理基准

**原文标题：** GGBench: A Geometric Generative Reasoning Benchmark for Unified Multimodal Models

**摘要：**
统一多模态模型（UMMs）的出现标志着人工智能领域的范式转变——从被动感知转向跨模态的主动生成。尽管这些模型展现出前所未有的信息融合能力，但其评估体系仍存在关键缺陷：现有基准主要分别考察判别式理解或无约束图像生成能力，未能有效衡量生成推理这一整合性认知过程。为弥补这一空白，我们提出几何构造任务可作为理想测试平台，因其本质要求语言理解与精确视觉生成的深度融合。我们开发的GGBench基准专门用于评估几何生成推理能力，通过系统化诊断模型在理解、推理及主动构建解决方案等方面的综合表现，为新一代智能系统设立了更严谨的评估标准。项目主页：https://opendatalab-raiser.github.io/GGBench/。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.11134) | [arXiv](https://arxiv.org/abs/2511.11134)



---

### 4. UI2Code^N：支持测试时扩展交互的界面到代码生成视觉语言模型

**原文标题：** UI2Code^N: A Visual Language Model for Test-Time Scalable Interactive UI-to-Code Generation

**摘要：**
用户界面编程是现代软件开发中核心且高度复杂的环节。视觉语言模型的最新进展凸显了自动界面编程的潜力，但现有方法存在两个关键局限：多模态编程能力尚未充分发展，单轮交互范式难以有效利用迭代视觉反馈。我们通过交互式界面到代码生成范式应对这些挑战，该范式更贴合实际工作流程并提升了性能上限。在此范式下，我们提出UI2Code^N视觉语言模型，通过分阶段预训练、微调与强化学习实现多模态编程能力的根本性提升。该模型统一了三大核心能力：界面到代码生成、界面编辑与界面优化。我们进一步探索测试时扩展的交互生成机制，实现多轮反馈的系统化利用。在界面到代码生成与界面优化基准测试中，UI2Code^N在开源模型中确立了最新技术标杆，其性能可与Claude-4-Sonnet、GPT-5等领先闭源模型相媲美。代码与模型已发布于https://github.com/zai-org/UI2Code_N。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.08195) | [arXiv](https://arxiv.org/abs/2511.08195)



---

### 5. AIonopedia：基于大语言模型的多模态学习协同框架用于离子液体发现

**原文标题：** AIonopedia: an LLM agent orchestrating multimodal learning for ionic liquid discovery

**摘要：**
新型离子液体的发现面临物性预测领域的多重挑战，包括数据稀缺、模型精度不足及工作流程碎片化等问题。本研究基于大语言模型技术，首次提出名为AIonopedia的离子液体发现智能体。该智能体通过融合大语言模型增强的多模态领域基础模型，实现了精准的物性预测功能，并采用分层搜索架构支撑分子筛选与设计工作。基于新构建的综合性离子液体数据集进行训练与评估，本模型展现出卓越的性能表现。对文献报道体系的验证实验进一步表明，该智能体能够有效执行离子液体结构优化任务。突破离线测试范畴，我们通过真实湿实验验证了系统的实际效能：该智能体在具有挑战性的分布外任务中展现出卓越的泛化能力，充分证明其加速实际离子液体发现进程的潜力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.11257) | [arXiv](https://arxiv.org/abs/2511.11257)



---

### 6. 虚拟宽度网络

**原文标题：** Virtual Width Networks

**摘要：**
本文提出虚拟宽度网络（VWN）框架，该框架能够在保持隐藏层规模二次方成本不变的前提下，实现宽表征网络的性能优势。VWN通过将表征宽度与主干网络宽度解耦，在维持主干计算量基本恒定的同时扩展嵌入空间。我们的大规模实验表明：在8倍扩展配置下，下一词元预测任务的优化速度提升2倍以上，下两词元预测任务加速达3倍。随着训练进程推进，损失差距持续扩大且收敛加速比不断增长，证明VWN不仅具有词元效率优势，更随规模扩大持续增强效能。此外，我们发现虚拟宽度与损失降低之间存在近似对数线性的缩放关系，这为探索虚拟宽度缩放作为大模型效率新维度提供了初步实证依据与研究动机。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.11238) | [arXiv](https://arxiv.org/abs/2511.11238)



---

### 7. LiteAttention：面向扩散变换器的时间稀疏注意力机制

**原文标题：** LiteAttention: A Temporal Sparse Attention for Diffusion Transformers

**摘要：**
扩散变换器在视频生成等领域取得了卓越的生成质量，但其二次方注意力复杂度导致计算延迟居高不下。现有加速方法面临根本性权衡：在去噪过程中动态估计稀疏注意力模式会产生高昂的计算开销与估计误差，而静态稀疏模式则在整个去噪过程中保持固定且往往非最优。我们发现扩散注意力具有关键的结构特性——其稀疏模式在连续去噪步骤间展现出强时间连贯性。在步骤t中被判定为非关键的注意力区块，通常在步骤t+δ中仍保持非关键状态。基于这一发现，我们提出LiteAttention方法，通过利用时间连贯性实现跨去噪序列的演化计算跳跃。该方法通过早期标记非关键区块并向前传播跳跃决策，在避免重复分析开销的同时消除冗余注意力计算，兼具动态方法的自适应性与静态方法的高效性。我们在FlashAttention基础上实现了高度优化的LiteAttention内核，在商用视频扩散模型上实现了显著加速，且未造成质量损失。代码与实现细节将公开发布。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.11062) | [arXiv](https://arxiv.org/abs/2511.11062)



---

### 8. 用人工智能模拟视觉世界：发展路线图

**原文标题：** Simulating the Visual World with Artificial Intelligence: A Roadmap

**摘要：**
视频生成领域正在经历重大转型——从聚焦生成视觉吸引力片段转向构建支持交互且保持物理合理性的虚拟环境。这些进展预示着视频基础模型的崛起，它们不仅是视觉生成器，更是能够模拟物理动力学、智能体-环境交互及任务规划的隐式世界模型，这些模型支撑着真实或虚构世界的运行。本文系统梳理了这一演进历程，将现代视频基础模型概念化为两个核心组件的结合：隐式世界模型与视频渲染器。世界模型编码关于世界的结构化知识，包括物理定律、交互动力学和智能体行为，其作为潜在模拟引擎支持连贯的视觉推理、长期时序一致性与目标驱动规划；视频渲染器则将这种潜在模拟转化为逼真的视觉观测，使生成的视频成为窥视模拟世界的“窗口”。我们通过四代演进追溯视频生成的发展脉络：核心能力逐步提升，最终形成以视频生成模型为基底的世界模型，其具备内在物理合理性、实时多模态交互及跨时空尺度的规划能力。针对每一代技术，我们界定其核心特征，重点介绍代表性工作，并剖析其在机器人、自动驾驶、交互式游戏等领域的应用。最后，我们探讨下一代世界模型面临的开放挑战与设计原则，包括智能体智能在系统构建与评估中的作用。相关文献动态列表请访问此链接。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.08585) | [arXiv](https://arxiv.org/abs/2511.08585)



---

### 9. SpatialThinker：通过空间奖励增强多模态大语言模型的三维推理能力

**原文标题：** SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards

**摘要：**
多模态大语言模型在视觉语言任务中取得了显著进展，但在空间理解方面仍存在明显不足。现有空间多模态大语言模型往往依赖显式三维输入或特定架构修改，且受限于大规模数据集或稀疏监督。为突破这些局限，我们提出SpatialThinker——一种通过强化学习训练的三维感知多模态大语言模型，将结构化空间定位与多步推理相融合。该模型通过构建任务相关对象与空间关系的场景图，并借助密集空间奖励进行推理推演，模拟类人空间认知能力。本研究的核心贡献包括：（1）开发数据合成流程，生成包含7,000个样本的高质量空间视觉问答数据集STVQA-7K；（2）采用多目标密集空间奖励的在线强化学习机制以强化空间定位。实验表明，SpatialThinker-7B在空间理解和真实场景视觉问答基准测试中均优于监督微调与稀疏强化学习基线，其基础模型增益较稀疏强化学习提升近一倍，并超越GPT-4o。这些结果验证了将空间监督与奖励对齐推理相结合的有效性，能够在有限数据条件下实现稳健的三维空间理解，推动多模态大语言模型向人类水平的视觉推理迈进。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07403) | [arXiv](https://arxiv.org/abs/2511.07403)



---

### 10. HI-TransPA：听力障碍翻译个人助手

**原文标题：** HI-TransPA: Hearing Impairments Translation Personal Assistant

**摘要：**
为给听障人士日常交流提供统一灵活的解决方案，我们将全模态范式引入辅助技术领域，提出HI-TransPA——一个指令驱动的视听个人助手。该模型通过融合模糊语音与高帧率唇部动态，在统一多模态框架内实现翻译与对话双重功能。针对原始数据噪声干扰强、异质性显著，以及现有全模态模型对听障语音适应性有限等挑战，我们构建了完整的预处理与数据治理流程：通过面部关键点检测实现唇部区域定位与稳定化处理，并建立多模态样本质量的量化评估体系。基于质量评分实施的课程学习策略，优先训练清洁高置信度样本，逐步引入复杂案例以增强模型鲁棒性。采用SigLIP编码器与统一三维重采样器相结合的方法，实现对高帧率唇部运动的高效编码。在自主研发的HI-Dialogue数据集上的实验表明，HI-TransPA在字面准确度与语义保真度方面均达到最先进水平。本研究为全模态在辅助通信技术中的应用奠定基础，为后续研究提供端到端建模框架及核心处理工具。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.09915) | [arXiv](https://arxiv.org/abs/2511.09915)



---

### 11. MarsRL：基于智能体流水线并行强化学习的多智能体推理系统进阶研究

**原文标题：** MarsRL: Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism

**摘要：**
近期大语言模型的发展主要得益于可验证奖励的强化学习与测试时缩放技术。然而，大语言模型有限的输出长度制约了单次推理过程中的推理深度。多智能体推理系统通过部署求解器、验证器和校正器等多类智能体迭代优化解决方案，为此提供了有前景的替代路径。尽管该体系在Gemini 2.5 Pro等闭源模型中表现优异，但由于开源模型缺乏足够的评判与修正能力，其泛化性能受限。为此，我们提出MarsRL——一种融合智能体流水线并行的新型强化学习框架，旨在实现系统中所有智能体的联合优化。MarsRL通过引入智能体专属奖励机制以降低奖励噪声，并采用流水线式训练策略提升长轨迹处理效率。在Qwen3-30B-A3B-Thinking-2507模型上的实验表明，MarsRL将AIME2025准确率从86.5%提升至93.3%，BeyondAIME准确率从64.9%提升至73.8%，其性能甚至超越Qwen3-235B-A22B-Thinking-2507。这些发现充分证明MarsRL在推动多智能体推理系统发展、拓展其在多样化推理任务中应用潜力的重要价值。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.11373) | [arXiv](https://arxiv.org/abs/2511.11373)



---

### 12. RF-DETR：基于神经架构搜索的实时检测变换器

**原文标题：** RF-DETR: Neural Architecture Search for Real-Time Detection Transformers

**摘要：**
开放词汇检测器在COCO数据集上表现出色，但在面对预训练数据中未包含的分布外类别时，往往难以泛化至真实世界数据集。不同于直接对笨重的视觉语言模型进行新领域微调，我们提出RF-DETR——一种轻量级专业检测变换器，通过权重共享神经架构搜索为任意目标数据集构建精度-延迟帕累托曲线。该方法在目标数据集上微调预训练基础网络，无需重新训练即可评估数千种具有不同精度-延迟权衡的网络配置。此外，我们重新审视神经架构搜索的"可调参数"，以提升DETR模型向多样化目标领域的迁移能力。值得注意的是，RF-DETR在COCO和Roboflow100-VL数据集上显著超越了现有最先进的实时检测方法。RF-DETR（纳米版）在COCO上达到48.0 AP，在相同延迟条件下较D-FINE（纳米版）提升5.3 AP；RF-DETR（2倍大版）在Roboflow100-VL上以20倍运行速度超越GroundingDINO（微型版）1.2 AP。据我们所知，RF-DETR（2倍大版）是首个在COCO上突破60 AP的实时检测器。代码已开源：https://github.com/roboflow/rf-detr

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.09554) | [arXiv](https://arxiv.org/abs/2511.09554)



---

### 13. 经验引导的推理时策略自适应方法

**原文标题：** Experience-Guided Adaptation of Inference-Time Reasoning Strategies

**摘要：**
使智能体AI系统能够基于训练后交互自适应调整问题解决方式仍是一项基础性挑战。现有支持推理时更新维护记忆的系统仅通过修改语言模型或智能体的文本输入进行调控，这意味着无法调整采样参数、移除工具、修改系统提示或在智能体与工作流范式间切换。另一方面，具备更强自适应能力的系统需要离线优化且在部署后保持静态。我们提出经验引导推理器（EGuR），该系统基于累积经验在推理时动态生成定制化策略——包含LLM调用、工具使用、采样参数与控制逻辑的完整计算流程。这一目标通过基于LLM的元策略（即输出策略的策略）实现，支持对所有策略组件（提示词、采样参数、工具配置与控制逻辑）进行自适应调整。EGuR通过双组件运作：引导器基于当前问题与结构化经验记忆生成多个候选策略，整合器则通过执行反馈优化后续策略生成。该系统可生成针对每个问题优化的完整可执行策略，支持缓存、检索与按需执行，避免资源浪费。在五项挑战性基准测试（AIME 2025、3-SAT及三项Big Bench Extra Hard任务）中，EGuR相较最强基线实现最高14%的准确率提升，同时将计算成本降低达111倍，且两项指标均随系统经验积累持续优化。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.11519) | [arXiv](https://arxiv.org/abs/2511.11519)



---

### 14. DiscoX：专业领域篇章级翻译任务的基准测试框架

**原文标题：** DiscoX: Benchmarking Discourse-Level Translation task in Expert Domains

**摘要：**
专业领域的篇章级翻译评估体系仍不完善，尽管其对知识传播与跨语言学术交流至关重要。当前翻译任务既要求篇章层面的连贯性，又需要严格的术语精确度，但现有评估方法主要聚焦于句段层面的准确性与流畅度。为弥补这一缺陷，我们提出DiscoX——一个面向篇章级专业领域汉英翻译的新型基准测试体系。该体系包含7个专业领域的200篇经专家审校文本，平均长度超过1700词符。为评估系统在DiscoX上的表现，我们同步开发了Metric-S无参考评估系统，可从准确性、流畅度及适配性三个维度提供细粒度自动评估。Metric-S与人工评判呈现高度一致性，显著优于现有评估指标。实验数据显示出显著的性能差距：即使最先进的大语言模型在这些任务中仍落后于人类专家。这一发现验证了DiscoX的挑战性，也揭示了实现专业级机器翻译仍面临的困境。本研究提出的基准体系与评估系统为更严格的翻译质量评估提供了可靠框架，将推动基于大语言模型的翻译技术持续发展。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.10984) | [arXiv](https://arxiv.org/abs/2511.10984)



---

### 15. EmoVid：面向情感中心视频理解与生成的多模态情感视频数据集

**原文标题：** EmoVid: A Multimodal Emotion Video Dataset for Emotion-Centric Video Understanding and Generation

**摘要：**
情感在视频表达中具有关键作用，但现有视频生成系统主要关注低层次视觉指标而忽略情感维度。尽管情感分析在视觉领域已取得进展，视频学界仍缺乏专门资源来衔接情感理解与生成任务，特别是在风格化与非现实语境中。为填补这一空白，我们推出EmoVid——首个专为创意媒体设计的多模态情感标注视频数据集，包含卡通动画、电影片段和动态表情包。每个视频均标注有情感标签、视觉属性（亮度、色彩饱和度、色调）及文本描述。通过系统分析，我们揭示了不同视频形式中视觉特征与情感感知关联的时空模式。基于这些发现，我们通过对Wan2.1模型进行微调，开发出情感条件视频生成技术。实验结果表明，在文本到视频和图像到视频任务中，生成视频的量化指标与视觉质量均获得显著提升。EmoVid为情感视频计算设立了新基准。本研究不仅为艺术风格化视频的视觉情感分析提供了重要见解，更为增强视频生成中情感表达提供了实用方法。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.11002) | [arXiv](https://arxiv.org/abs/2511.11002)



---

### 16. 物尽其用：通过多头解码以结构化人类先验引导生成式推荐系统

**原文标题：** Don't Waste It: Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding

**摘要：**
为推荐系统优化除准确性之外的目标（如多样性、新颖性和个性化）对实现长期用户满意度至关重要。为此，工业实践者已积累了海量的结构化领域知识，我们称之为人类先验（如物品分类体系、时序模式）。这类知识通常通过排名阶段或后排名阶段的后期调整方式应用，但该方法仍与核心模型学习相分离——这在行业向端到端生成式推荐基础模型转型的背景下尤显不足。另一方面，针对这些超准确性目标的诸多方法往往需要针对特定架构进行修改，并以完全无监督的方式学习用户意图，从而丢弃了这些宝贵的人类先验。

我们提出了一种与主干模型无关的框架，将积累多年实践的人类先验直接整合到生成式推荐器的端到端训练中，而非将其丢弃。通过受高效大语言模型解码策略启发的轻量级先验条件适配头，我们的方法引导模型沿着人类可理解的维度（如交互类型、长期与短期兴趣）解耦用户意图。同时，我们引入了分层组合策略来建模不同先验类型间的复杂交互关系。在三个大规模数据集上的实验表明，我们的方法能显著提升准确性及超准确性目标。研究还证明，人类先验可使主干模型更有效地利用更长上下文窗口和更大模型规模。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.10492) | [arXiv](https://arxiv.org/abs/2511.10492)



---

### 17. 工作负载调度器——起源、算法与差异

**原文标题：** Workload Schedulers -- Genesis, Algorithms and Differences

**摘要：**
本文提出了一种现代工作负载调度器的新型分类方法。我们详细描述了三类调度器：操作系统进程调度器、集群系统作业调度器与大数据调度器。通过考量算法应用与特性，我们阐述了这些调度器从早期雏形到现代实现的发展历程。总体而言，我们探讨了所有已述调度器类别之间的差异，并分析了其历时性发展脉络。最后我们着重指出，适用于本地与分布式系统的调度策略设计在关注重点上存在共性特征。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.10258) | [arXiv](https://arxiv.org/abs/2511.10258)



---

### 18. 面向科学创意生成的大语言模型：以创造力为核心的综述研究

**原文标题：** Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey

**摘要：**
科学创意生成是科学发现的核心驱动力，无论是通过解决悬而未决的难题还是提出解释未知现象的新颖假说，这一过程始终推动着人类文明进步。与标准科学推理或通用创意生成不同，科学领域的创意生成具有多目标性与开放性的特点，其成果的新颖性与实证严谨性同等重要。大语言模型近期展现出作为科学创意生成工具的潜力，能够输出兼具连贯性、事实准确性、惊人直觉与合格推理能力的成果，但其创造力表现仍存在不稳定且认知不足的问题。本综述对驱动大语言模型科学创意生成的方法进行结构化梳理，重点考察不同方法如何平衡创造力与科学严谨性。我们将现有方法归纳为五大互补体系：外部知识增强、基于提示的分布导向、推理时参数调控、多智能体协作以及参数级自适应。为解析其贡献，我们采用双重理论框架：运用博登提出的组合型、探索型与变革型创造力分类法来界定各方法体系预期产生的创意层级，借助罗兹的4P框架（创作者、创作过程、创作环境、创作成果）来定位不同方法强调的创造力维度。通过将方法论进展与创造力理论框架相融合，本综述明晰了该领域的发展现状，并为实现大语言模型在科学发现中可靠、系统化且具有变革性应用的关键路径指明了方向。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.07448) | [arXiv](https://arxiv.org/abs/2511.07448)



---

### 19. 构建面向智能体的网络：一种声明式的智能体-网络交互框架

**原文标题：** Building the Web for Agents: A Declarative Framework for Agent-Web Interaction

**摘要：**
当前自主AI智能体在网络上的部署受到一个根本性错位问题的阻碍：智能体必须从面向人类的用户界面推断功能可见性，导致交互变得脆弱、低效且不安全。为解决这一问题，我们提出VOIX——一个原生网络框架，通过简单的声明式HTML元素使网站能够为AI智能体提供可靠、可审计且保护隐私的能力。VOIX引入<tool>和<context>标签，允许开发者明确定义可用操作及相关状态，从而为智能体行为建立清晰的机器可读契约。该方法将控制权转移至网站开发者，同时通过将会话交互与网站分离来保护用户隐私。我们通过为期三天的黑客松研究（16名开发者参与）评估了该框架的实用性、易学性和表达力。结果表明，无论参与者先前经验如何，均能快速构建多样化且功能完善的智能体赋能网络应用。最终，这项工作为实现智能体网络提供了基础机制，为未来网络上无缝安全的人机协作奠定了基础。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.11287) | [arXiv](https://arxiv.org/abs/2511.11287)



---

### 20. CATS-V2V：面向复杂恶劣交通场景的真实世界车车协同感知数据集

**原文标题：** CATS-V2V: A Real-World Vehicle-to-Vehicle Cooperative Perception Dataset with Complex Adverse Traffic Scenarios

**摘要：**
车车协同感知技术通过克服复杂恶劣交通场景下的感知局限，在提升自动驾驶性能方面具有巨大潜力。与此同时，数据作为现代自动驾驶人工智能的基础设施至关重要。然而由于严苛的数据采集要求，现有数据集主要聚焦于常规交通场景，限制了协同感知效益的发挥。为应对这一挑战，我们推出CATS-V2V——首个面向复杂恶劣交通场景的真实世界车车协同感知数据集。该数据集通过两辆硬件时间同步的车辆采集完成，覆盖10个不同地理位置的10类天气与光照条件。包含100段数据序列的该数据集提供了6万帧10Hz激光雷达点云与126万张多视角30Hz相机图像，并附带75万条经过匿名化处理的高精度RTK固定GNSS/IMU记录。我们相应提供了时序一致的物体三维边界框标注及静态场景信息，以构建四维鸟瞰图表征。基于此，我们提出基于目标的时序对齐方法，确保所有物体在所有传感器模态间实现精确对齐。我们希望CATS-V2V这一迄今同类数据集中规模最大、支持性最强、质量最高的数据集，能够推动自动驾驶领域相关研究的发展。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.11168) | [arXiv](https://arxiv.org/abs/2511.11168)



---

### 21. 从证明到程序：大语言模型中工具诱发推理幻觉的特征分析

**原文标题：** From Proof to Program: Characterizing Tool-Induced Reasoning Hallucinations in Large Language Models

**摘要：**
工具增强语言模型能够调用外部工具来解决超越其参数能力的问题。然而，这些工具带来的性能提升是否反映可信推理仍不明确。本研究聚焦代码解释器工具，发现即使工具被正确选择和执行，工具增强语言模型仍会将工具输出视为推理的替代品，生成看似正确但缺乏连贯论证的解决方案。我们将这种失效模式定义为工具诱发短视，并基于PYMATH基准（包含1,679个竞赛级数学问题，其中Python代码具有辅助作用但非充分条件）展开研究。我们进一步开发了多维评估体系，量化工具增强语言模型相较于无工具模型的推理能力退化。研究结果表明：虽然工具增强语言模型的最终答案准确率最高提升19.3个百分点，但其推理行为持续恶化（例如在推理过程的两两比较中，无工具大语言模型胜出率最高提升41.5%）。这种退化随工具使用频次增加而加剧：模型调用工具越频繁，其推理连贯性越差。此外，工具使用使错误类型从算术失误转向全局推理失效（逻辑、假设、创造性错误），约55%的高风险案例中存在工具诱发短视现象。最后，我们提出基于偏好优化的对齐框架，引导工具增强语言模型将工具作为辅助证据，在工具使用场景下同步提升最终答案准确率与推理深度。代码与数据详见：https://github.com/megagonlabs/TIM。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.10899) | [arXiv](https://arxiv.org/abs/2511.10899)



---

### 22. 一种面向云计算系统的元启发式负载均衡器

**原文标题：** A Meta-Heuristic Load Balancer for Cloud Computing Systems

**摘要：**
本文提出一种云系统服务分配策略，该策略能够在实现节点免过载与维持系统稳定性的同时保持最低成本。我们构建了云计算资源利用的抽象模型，该模型涵盖多类资源考量并兼顾服务迁移成本因素。研究通过原型系统展示了元启发式负载均衡器的实现，并对实验结果进行了分析与讨论。此外，我们创新性地提出一种遗传算法，该算法通过引入其他元启发式算法的输出结果作为初始种群进行优化。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.11721) | [arXiv](https://arxiv.org/abs/2511.11721)



---

### 23. miniF2F-Lean再审视：局限分析与未来路径规划

**原文标题：** miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward

**摘要：**
本文从参与数学奥林匹克竞赛的AI系统视角，对miniF2F基准测试中的形式化与非形式化命题进行全面分析。在此设定下，模型需要阅读理解自然语言表述的数学问题，将其形式化为Lean语言，继而完成证明过程。当形式化证明与原始非形式化命题相符时，系统方可获得相应积分。评估结果表明：采用文献中现有最优模型，该流程的最高准确率约为36%，显著低于自动形式化与定理证明文献中分别报告的97%与69%的单项最优准确率。通过分析错误模式，我们发现准确率下降的主要原因在于miniF2F中超过半数问题的形式化与非形式化表述存在差异。我们系统修正了形式化与非形式化陈述中的所有错误、差异及简化问题，推出具有完全验证的形式化/非形式化陈述及证明的miniF2F-v2。在新基准上的全流程定理证明测试显示，最佳准确率提升至70%（原miniF2F为40%），但仍反映出自动形式化模型与定理证明器之间存在显著偏差。深度分析表明，更高质量的基准测试将有助于学界更精准评估形式推理领域进展，并更好诊断自动形式化与定理证明模型的成败模式。本数据集详见：https://github.com/roozbeh-yz/miniF2F_v2

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.03108) | [arXiv](https://arxiv.org/abs/2511.03108)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2025-11-17_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)