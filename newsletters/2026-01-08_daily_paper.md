
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-08 论文日报

## 📊 今日论文统计
- 总论文数：20
- 热门领域：LLM, GPT, RL, Transformer

## 📝 论文详情


### 1. 熵自适应微调：解决置信冲突以缓解遗忘

**原文标题：** Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting

**摘要：**
监督微调是领域适应的标准范式，但其常伴随灾难性遗忘的代价。与之形成鲜明对比的是，在线策略强化学习能有效保留模型的通用能力。我们深入探究这一差异，发现其根源在于根本性的分布差异：强化学习与模型内部信念保持一致，而监督微调则强制模型拟合外部监督信号。这种不匹配常表现为“置信冲突”标记——这些标记具有低概率但低熵的特征。在此类情况下，模型对其自身预测高度确信，却被强制学习相悖的真实标注，从而引发破坏性的梯度更新。为解决该问题，我们提出熵自适应微调方法。与仅依赖预测概率的方法不同，该方法利用标记层级的熵作为门控机制，以区分认知不确定性与知识冲突。这使得模型能够从不确定样本中学习，同时抑制冲突数据产生的梯度。我们在数学、医疗和智能体领域对千问及GLM系列模型（参数量覆盖40亿至320亿）开展的广泛实验验证了我们的假设。熵自适应微调在保持与标准监督微调相当的下游性能的同时，显著缓解了通用能力的退化。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.02151) | [arXiv](https://arxiv.org/abs/2601.02151)



---

### 2. 演化式程序化技能网络

**原文标题：** Evolving Programmatic Skill Networks

**摘要：**
本研究探讨在开放式具身环境中智能体的持续技能获取问题，其需构建、优化并复用不断扩展的可执行技能库。我们提出程序化技能网络（PSN）框架，该框架将技能定义为可执行的符号化程序，形成通过经验演化的组合式网络。PSN通过大语言模型实例化三个核心机制：（1）基于结构化故障定位的REFLECT机制，用于技能组合的精准问题定位；（2）采用成熟度感知更新门控的渐进式优化策略，在稳定可靠技能的同时保持对不确定技能的适应性；（3）基于回滚验证的规范化结构重构机制，保障网络结构的紧凑性。研究进一步揭示PSN的学习动态与神经网络训练存在结构相似性。在MineDojo和Crafter环境中的实验表明，该系统在开放式任务分布中展现出鲁棒的技能复用能力、快速适应能力及强大的泛化性能。\footnote{我们计划开源相关代码。}

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03509) | [arXiv](https://arxiv.org/abs/2601.03509)



---

### 3. Atlas：面向多领域复杂推理的异构模型与工具协同编排框架

**原文标题：** Atlas: Orchestrating Heterogeneous Models and Tools for Multi-Domain Complex Reasoning

**摘要：**
大型语言模型（LLM）与外部工具的融合显著扩展了智能代理的能力。然而，随着模型与工具多样性的增加，选择最优的模型-工具组合已成为一个高维优化难题。现有方法通常依赖单一模型或固定的工具调用逻辑，未能充分利用异构模型-工具组合间的性能差异。本文提出ATLAS（自适应工具-模型对齐与协同调用框架），一种面向跨领域复杂推理的动态工具调用双路径框架。ATLAS通过双路径机制运行：（1）基于无训练聚类路由，利用经验先验实现领域自适应对齐；（2）基于强化学习的多步路由，通过自主轨迹探索实现分布外泛化。在15个基准测试上的大量实验表明，本方法在分布内任务（+10.1%）和分布外任务（+13.1%）上均超越GPT-4o等闭源模型，并显著优于现有路由方法。此外，通过协同编排专用多模态工具，本框架在视觉推理任务中展现出显著性能提升。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03872) | [arXiv](https://arxiv.org/abs/2601.03872)



---

### 4. Benchmark^2：大语言模型基准测试的系统性评估

**原文标题：** Benchmark^2: Systematic Evaluation of LLM Benchmarks

**摘要：**
用于评估大语言模型的基准测试数量激增，亟需系统性的方法来评估基准测试本身的质量。我们提出了Benchmark^2，这是一个包含三个互补指标的综合性框架：（1）跨基准排名一致性，用于衡量一个基准测试产生的模型排名是否与其他同类基准测试的结果一致；（2）区分度评分，用于量化基准测试区分不同模型的能力；（3）能力对齐偏差，用于识别同一模型系列中更强模型失败而更弱模型却成功的异常测试实例。我们在涵盖数学、推理和知识领域的15个基准测试上进行了广泛实验，评估了来自四个模型系列的11个大语言模型。我们的分析揭示了现有基准测试之间存在显著的质量差异，并证明基于我们提出的指标进行选择性基准构建，能够在使用大幅缩减的测试集的情况下，获得可比较的评估性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03986) | [arXiv](https://arxiv.org/abs/2601.03986)



---

### 5. ROI推理：基于预计算元认知的推理理性优化

**原文标题：** ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition

**摘要：**
大型语言模型在充足计算资源支持下可实现强大的推理性能，但其本身无法预知任务所需计算量。本研究针对严格全局令牌约束下的多任务推理场景，将其形式化为有序随机多选择背包问题。该视角揭示出元认知需求——需要预判任务难度、评估投资回报率并策略性分配计算资源。我们提出ROI推理框架，通过两阶段训练赋予大型语言模型内在的预算感知理性能力。第一阶段通过元认知微调使模型在生成前预测推理成本与期望效用，实现显式的"求解-跳过"决策机制。第二阶段采用理性感知强化学习，在硬性令牌预算约束下优化序列决策，使模型掌握长时程资源分配策略。在多个预算约束数学推理基准测试中，ROI推理框架在严格计算预算下持续提升总体得分，同时显著降低决策遗憾度。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03822) | [arXiv](https://arxiv.org/abs/2601.03822)



---

### 6. Klear：统一多任务音视频联合生成

**原文标题：** Klear: Unified Multi-Task Audio-Video Joint Generation

**摘要：**
音视频联合生成技术发展迅速，但仍面临重大挑战。非商业化方法仍存在音视频异步、唇语-语音对齐不佳及单模态退化等问题，其根源在于音视频对应关系建模薄弱、泛化能力有限以及高质量密集标注数据稀缺。为解决这些问题，我们提出Klear系统，并从三个维度展开研究——模型架构、训练策略与数据构建。在架构层面，我们采用统一DiT模块的单塔式设计及全向全局注意力机制，实现了紧密的音视频对齐与强大的可扩展性。在训练策略上，我们采用渐进式多任务范式——通过随机模态掩码实现跨任务联合优化，结合多阶段课程学习，从而获得鲁棒的表示、强化音视频对齐的世界知识并防止单模态崩溃。数据方面，我们构建了首个大规模带密集标注的音视频数据集，并提出创新的自动化数据构建流程，可标注并筛选数百万条多样化、高质量、严格对齐的音视频-文本三元组。基于此，Klear能够扩展至大规模数据集，在联合生成与单模态生成场景中均能实现高保真度、语义与时序对齐的指令跟随生成，并对分布外场景展现出强大的泛化能力。在多项任务评估中，本方法显著超越现有技术，达到与Veo 3相当的性能，为下一代音视频合成提供了统一且可扩展的技术路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04151) | [arXiv](https://arxiv.org/abs/2601.04151)



---

### 7. 动态物体世界的编排

**原文标题：** Choreographing a World of Dynamic Objects

**摘要：**
在我们所处的物理四维（三维空间+时间）世界中，动态物体持续演化、形变并与其他物体相互作用，形成了多样化的四维场景动态。本文提出了一种通用生成框架CHORD，用于编排动态物体与场景并合成此类现象。传统基于规则的图形学流程虽能创建此类动态，但依赖于特定类别的启发式方法，不仅耗时费力且难以扩展。近期基于学习的方法通常需要大规模数据集，而这些数据集可能无法覆盖所有目标物体类别。我们的方法通过提出一种基于蒸馏的流程，从二维视频的欧拉表示中提取隐藏的丰富拉格朗日运动信息，从而继承了视频生成模型的普适性。本方法具有通用性、多功能性且不依赖特定类别。我们通过生成多样化多体四维动态的实验验证了其有效性，展示了相较于现有方法的优势，并证明了其在生成机器人操作策略中的适用性。项目页面：https://yanzhelyu.github.io/chord

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04194) | [arXiv](https://arxiv.org/abs/2601.04194)



---

### 8. 作为软件工程智能体情境验证器的能动性评估准则

**原文标题：** Agentic Rubrics as Contextual Verifiers for SWE Agents

**摘要：**
验证对于改进智能体至关重要：它为强化学习提供奖励信号，并通过测试时扩展技术实现推理阶段的性能提升。尽管验证在软件工程智能体场景中具有重要意义，当前方法仍主要依赖代码执行，而环境配置开销使得该方法难以扩展。虽然存在补丁分类器和启发式方法等可扩展替代方案，但这些方法往往缺乏代码库情境支撑且可解释性较弱。为此，我们提出“能动性评估准则”方法：专家智能体通过交互式分析代码仓库，生成基于具体情境的评估清单，随后在不执行测试的情况下依据该清单对候选补丁进行评分。在并行测试时扩展评估框架下的SWE-Bench Verified基准测试中，该方法在Qwen3-Coder-30B-A3B模型上获得54.2%的得分，在Qwen3-32B模型上获得40.6%的得分，较对比组中最强基线模型提升至少3.5个百分点。我们进一步分析评估准则的行为特征，证明其评分结果与真实测试结果具有一致性，同时能识别传统测试未能捕捉的问题。消融实验表明，智能体驱动的情境收集机制对于生成针对特定代码库的明确评估标准具有关键作用。综合而言，这些结果表明能动性评估准则能为软件工程智能体提供高效、可扩展且精细化的验证信号。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04171) | [arXiv](https://arxiv.org/abs/2601.04171)



---

### 9. MDAgent2：面向分子动力学代码生成与知识问答的大语言模型

**原文标题：** MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics

**摘要：**
分子动力学模拟在材料科学的原子尺度行为研究中具有关键作用，但编写LAMMPS脚本仍是高度专业化且耗时的工作。尽管大语言模型在代码生成和领域特定问答任务中展现出潜力，但其在分子动力学场景中的应用仍受限于领域数据稀缺、前沿大语言模型部署成本高昂以及代码可执行率低等问题。基于我们先前开发的MDAgent，本文提出MDAgent2——首个能够在分子动力学领域同时实现知识问答与代码生成的端到端框架。我们构建了领域专用的数据生成流程，产出涵盖分子动力学知识、问答与代码生成的三类高质量数据集。基于这些数据集，我们采用三阶段训练策略（持续预训练、监督微调与强化学习）训练出两个领域适应模型：MD-Instruct与MD-Code。此外，我们提出MD-GRPO强化学习方法，通过模拟结果作为奖励信号，并循环利用低奖励轨迹实现持续优化。我们进一步开发了可部署的多智能体系统MDAgent2-RUNTIME，集成代码生成、执行、评估与自我修正功能。结合本文提出的首个LAMMPS代码生成与问答评估基准MD-EvalBench，我们的模型与系统在多项指标上超越现有基线方法。本工作系统论证了大语言模型在工业仿真任务中的适应性与泛化能力，为“AI for Science”及工业级模拟的自动化代码生成奠定了方法论基础。项目地址：https://github.com/FredericVAN/PKU_MDAgent2

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.02075) | [arXiv](https://arxiv.org/abs/2601.02075)



---

### 10. E-GRPO：高熵步长驱动流模型的有效强化学习

**原文标题：** E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models

**摘要：**
近期强化学习技术提升了流匹配模型在人类偏好对齐任务中的表现。虽然随机采样能够探索去噪方向，但现有在多步去噪过程中进行优化的方法常面临奖励信号稀疏且模糊的问题。我们观察到，高熵步长能够实现更高效、更有效的探索，而低熵步长则会导致生成轨迹缺乏区分度。为此，我们提出E-GRPO，一种基于熵感知的分组相对策略优化方法，旨在提高随机微分方程采样步长的熵值。由于随机微分方程的积分过程会因多步随机性而产生模糊的奖励信号，我们特别将连续的低熵步长合并为一个高熵步长用于随机微分方程采样，而对其他步长采用常微分方程采样。在此基础上，我们引入了多步分组归一化优势函数，该函数在共享同一合并去噪步长的样本组内计算组间相对优势。在不同奖励设置下的实验结果验证了我们方法的有效性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.00423) | [arXiv](https://arxiv.org/abs/2601.00423)



---

### 11. EpiQAL：面向增强对齐与推理能力的流行病学问答大语言模型评测基准

**原文标题：** EpiQAL: Benchmarking Large Language Models in Epidemiological Question Answering for Enhanced Alignment and Reasoning

**摘要：**
可靠的流行病学推理需要综合研究证据，以推断人群层面的疾病负担、传播动态和干预效果。现有的医学问答评测基准主要侧重于临床知识或患者层面的推理，但鲜有系统评估基于证据的流行病学推断能力。本研究提出EpiQAL——首个涵盖多种疾病的流行病学问答诊断性评测基准，该基准包含基于开放获取文献构建的三个子集。这些子集分别评估基于文本的事实召回能力、连接文献证据与流行病学原理的多步推理能力，以及隐藏讨论部分情况下的结论重构能力。基准构建过程融合了专家设计的分类学指导、多模型验证和基于检索的难度控制。对十个开源模型的实验表明，当前大语言模型在流行病学推理任务上表现有限，其中多步推理任务挑战最大。模型在不同子集上的排名存在波动，且仅靠模型规模无法预测其表现。思维链提示策略对多步推理任务有所助益，但在其他任务中效果参差不齐。EpiQAL为证据锚定、推断推理和结论重构能力提供了细粒度的诊断信号。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03471) | [arXiv](https://arxiv.org/abs/2601.03471)



---

### 12. RedBench：面向大型语言模型全面红队测试的通用数据集

**原文标题：** RedBench: A Universal Dataset for Comprehensive Red Teaming of Large Language Models

**摘要：**
随着大型语言模型（LLM）在安全关键型应用中的普及，确保其对抗性提示的鲁棒性至关重要。然而，现有红队测试数据集存在风险分类不一致、领域覆盖有限及评估方法过时等问题，阻碍了系统化的漏洞评估。为应对这些挑战，我们提出了RedBench——一个聚合了来自顶级学术会议与开源仓库的37个基准数据集的通用数据集，共包含29,362个涵盖攻击性提示与拒绝性提示的样本。RedBench采用包含22个风险类别和19个领域的标准化分类体系，能够对LLM漏洞进行一致且全面的评估。我们系统分析了现有数据集，为现代LLM建立了性能基线，并开源了数据集与评估代码。本研究的贡献在于：推动鲁棒性比较研究，促进未来安全评估工作的发展，并为实际场景中安全可靠LLM的部署提供支持。代码地址：https://github.com/knoveleng/redeval

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03699) | [arXiv](https://arxiv.org/abs/2601.03699)



---

### 13. 为何大语言模型尚未成为科学家：从四次自主研究尝试中汲取的教训

**原文标题：** Why LLMs Aren't Scientists Yet: Lessons from Four Autonomous Research Attempts

**摘要：**
本文报告了一项案例研究，通过构建由六个大语言模型智能体组成的流程，对应科学工作流程的不同阶段，进行了四次端到端的自主生成机器学习研究论文的尝试。在这四次尝试中，三次在实施或评估阶段失败。其中一次成功完成了全流程，其成果被要求以人工智能系统为第一作者的实验性首届会议Agents4Science 2025接收，并同时通过了人类评审与多智能体评审。基于这些尝试，我们记录了六种反复出现的失败模式：倾向于训练数据默认设定、执行压力下的实施偏移、长周期任务中的记忆与上下文退化、面对明显失败仍过度兴奋地宣布成功、领域智能不足，以及实验设计中的科学品味薄弱。最后，我们讨论了构建更稳健的AI-科学家系统的四项设计原则，分析了其对自主科学发现的意义，并公开了所有提示词、过程产物及输出结果，详见 https://github.com/Lossfunk/ai-scientist-artefacts-v1。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03315) | [arXiv](https://arxiv.org/abs/2601.03315)



---

### 14. ThinkRL-Edit：基于强化学习思维推理的图像编辑方法

**原文标题：** ThinkRL-Edit: Thinking in Reinforcement Learning for Reasoning-Centric Image Editing

**摘要：**
基于统一多模态生成模型的指令驱动图像编辑技术发展迅速，但其底层的视觉推理能力仍然有限，导致在以推理为核心的编辑任务中表现欠佳。强化学习已被探索用于提升图像编辑质量，但面临三个关键挑战：(1) 受限于去噪随机性的推理探索空间不足，(2) 存在偏置的奖励融合机制，以及(3) 基于视觉语言模型的指令奖励不稳定。本研究提出ThinkRL-Edit——一个以推理为核心的强化学习框架，该框架将视觉推理与图像合成解耦，并将推理探索拓展至去噪过程之外。为此，我们引入基于思维链的推理采样机制，在在线采样的生成阶段前设置规划与反思环节，迫使模型在确定视觉输出前探索多种语义假设并验证其合理性。为避免加权聚合的失效问题，我们提出跨多奖励维度的无偏链式偏好分组策略。此外，我们将基于区间的视觉语言模型评分替换为二元检查表，从而为复杂推理任务提供更精确、低方差且可解释的奖励机制。实验表明，本方法在以推理为核心的图像编辑任务上显著优于现有技术，能够生成符合指令要求、视觉连贯且语义可靠的编辑结果。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03467) | [arXiv](https://arxiv.org/abs/2601.03467)



---

### 15. 通过语言学习任务预训练增强语言模型的语言能力

**原文标题：** Enhancing Linguistic Competence of Language Models through Pre-training with Language Learning Tasks

**摘要：**
语言模型通常在原始文本数据集上进行预训练，以逐词生成文本序列。虽然这种方法有助于学习世界知识和推理能力，但并未明确优化语言能力。为弥补这一差距，我们提出L2T预训练框架，将语言学习任务与标准的下一个词预测相结合。受人类语言习得过程启发，L2T将原始文本转化为结构化输入-输出对，以提供明确的语言刺激。在原始文本与L2T数据的混合数据集上预训练语言模型，不仅能提升语言能力基准测试的整体表现、加速语言能力习得，同时能在通用推理任务中保持竞争优势。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03448) | [arXiv](https://arxiv.org/abs/2601.03448)



---

### 16. Pearmut：轻松实现翻译的人工评估

**原文标题：** Pearmut: Human Evaluation of Translation Made Trivial

**摘要：**
人工评估是多语言自然语言处理领域的黄金标准，但在实践中常因现有工具设置复杂、耗时且需大量工程与运维投入而被自动指标替代。我们推出Pearmut——一个轻量级但功能丰富的平台，使端到端人工评估能像自动评估一样简便运行。该平台消除了常见的入门障碍，支持多语言任务评估，尤其专注于机器翻译领域。Pearmut实现了包括直接评估、错误标注评估、多维质量度量在内的标准评估协议，同时具备可扩展性以支持新协议的原型设计。其核心功能涵盖文档级上下文评估、绝对与对比评估、注意力检查、基于ESAAI的预标注，以及静态与主动学习驱动的任务分配策略。通过Pearmut，可靠的人工评估得以成为模型开发与诊断中实用且常规的组成部分，而非偶然性工作。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.02933) | [arXiv](https://arxiv.org/abs/2601.02933)



---

### 17. Gen3R：三维场景生成与前馈式重建的融合

**原文标题：** Gen3R: 3D Scene Generation Meets Feed-Forward Reconstruction

**摘要：**
本文提出Gen3R方法，该方法通过桥接基础重建模型与视频扩散模型的强先验知识，实现场景级三维生成。我们重新利用VGGT重建模型，通过在其特征标记上训练适配器来生成几何隐变量，并对其进行正则化以与预训练视频扩散模型的外观隐变量对齐。通过联合生成这些解耦但对齐的隐变量，Gen3R能够同时生成RGB视频及对应的三维几何信息（包括相机位姿、深度图和全局点云）。实验表明，我们的方法在单图像与多图像条件化三维场景生成任务中均达到了最先进的性能。此外，本方法能够通过利用生成先验增强重建的鲁棒性，证明了重建模型与生成模型的紧密耦合具有相互促进的效益。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.04090) | [arXiv](https://arxiv.org/abs/2601.04090)



---

### 18. ResTok：面向自回归图像生成的一维视觉分词器层次残差学习

**原文标题：** ResTok: Learning Hierarchical Residuals in 1D Visual Tokenizers for Autoregressive Image Generation

**摘要：**
现有用于自回归生成的一维视觉分词器主要遵循语言建模的设计原则，因其直接基于先验源自语言领域的Transformer构建，仅生成单层次潜在标记并将视觉数据视为扁平化的序列标记流。然而，这种类语言范式忽视了视觉任务的关键特性，尤其是长期以来对视觉模型收敛性与效率至关重要的层次化结构与残差网络设计。为使视觉任务回归其本质，我们提出残差分词器（ResTok），这是一种通过构建图像标记与潜在标记双重层次残差的一维视觉分词器。通过渐进式融合获得的层次化表征可在每一层实现跨层级特征融合，显著提升表征能力。同时，层次间的语义残差可避免信息重叠，形成更集中的潜在分布，从而更易于自回归建模。跨层级绑定关系由此自然涌现而无需显式约束。为加速生成过程，我们进一步提出层次化自回归生成器，通过一次性预测整层潜在标记而非严格逐标记生成，大幅减少采样步骤。大量实验表明，在视觉分词中恢复层次残差先验能显著提升自回归图像生成质量，在ImageNet-256数据集上仅需9步采样即可达到2.34的gFID指标。代码已开源：https://github.com/Kwai-Kolors/ResTok。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03955) | [arXiv](https://arxiv.org/abs/2601.03955)



---

### 19. MAGMA：基于多图架构的智能体记忆系统

**原文标题：** MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents

**摘要：**
记忆增强生成技术通过为大型语言模型引入外部记忆机制来支持长上下文推理，但现有方法主要依赖单一记忆存储的语义相似性检索，导致时间、因果与实体信息相互耦合。这种设计限制了查询意图与检索证据之间的可解释性与对齐度，进而影响推理准确性。本文提出MAGMA——一种基于多图结构的智能体记忆架构，该架构将每个记忆单元映射至正交的语义图、时间图、因果图与实体图中。MAGMA将检索过程定义为基于策略的多图遍历机制，实现查询自适应的记忆选择与结构化上下文构建。通过解耦记忆表征与检索逻辑，MAGMA提供了透明的推理路径与细粒度检索控制。在LoCoMo与LongMemEval基准上的实验表明，MAGMA在长程推理任务中持续优于当前最先进的智能体记忆系统。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.03236) | [arXiv](https://arxiv.org/abs/2601.03236)



---

### 20. RGS-SLAM：基于单次密集初始化的鲁棒高斯溅射SLAM系统

**原文标题：** RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization

**摘要：**
本文提出RGS-SLAM，一种鲁棒的高斯溅射SLAM框架。该框架采用免训练的对应关系-高斯初始化方法，取代了GS-SLAM中依赖残差驱动的致密化阶段。不同于传统方法通过残差揭示缺失几何结构来逐步添加高斯元素，RGS-SLAM通过对经置信感知内点分类器优化的DINOv3描述符所生成的密集多视角对应关系进行单次三角测量，在优化前即可生成分布均匀且具有结构感知能力的高斯种子。这种初始化策略显著提升了早期建图的稳定性，并使收敛速度加快约20%，在纹理丰富和结构复杂的场景中实现了更高的渲染保真度，同时完全兼容现有GS-SLAM流程。在TUM RGB-D和Replica数据集上的评估表明，相较于当前最先进的高斯溅射与点云SLAM系统，RGS-SLAM在定位与重建精度方面达到竞争性乃至更优的性能，同时保持高达925 FPS的实时建图能力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.00705) | [arXiv](https://arxiv.org/abs/2601.00705)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2026-01-08_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)