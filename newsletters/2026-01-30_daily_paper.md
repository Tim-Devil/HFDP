
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-30 论文日报

## 📊 今日论文统计
- 总论文数：45
- 热门领域：LLM, RL, Diffusion, Transformer, GPT

## 📝 论文详情


### 1. Idea2Story：将研究概念转化为完整科学叙事的自动化流程

**原文标题：** Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives

**摘要：**
基于大语言模型（LLM）的智能体在自主科学发现领域近期取得显著进展，展现出自动化端到端研究流程的能力。然而，现有系统主要依赖以运行时为中心的执行范式，需反复在线读取、总结并推理大量科学文献。这种即时计算策略计算成本高昂，受限于上下文窗口长度，且常导致推理过程脆弱并产生幻觉。本文提出Idea2Story——一种以预计算驱动的自主科学发现框架，将文献理解从在线推理转向离线知识构建。Idea2Story持续收集经同行评审的论文及其审稿反馈，提取核心方法单元，组合可复用的研究模式，并将其组织为结构化的方法知识图谱。在运行时，未充分明确的用户研究意图可与既定的研究范式对齐，从而实现高质量研究模式的高效检索与复用，而非依赖开放式生成与试错。通过将研究规划与执行建立在预构建的知识图谱基础上，Idea2Story缓解了LLM的上下文窗口瓶颈，并大幅减少了对文献的重复运行时推理。我们通过定性分析与初步实证研究表明，Idea2Story能够生成连贯、方法可靠且新颖的研究模式，并可在端到端场景中产出多项高质量研究范例。这些结果表明，离线知识构建为可靠的自主科学发现提供了实用且可扩展的基础。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20833) | [arXiv](https://arxiv.org/abs/2601.20833)



---

### 2. 各得其所：文本到图像模型空间智能基准测试

**原文标题：** Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models

**摘要：**
文本到图像（T2I）模型在生成高保真图像方面取得了显著成功，但在处理复杂空间关系（如空间感知、推理或交互）时仍存在明显不足。由于现有基准测试普遍采用简短或信息稀疏的提示设计，这些关键维度长期被忽视。本文提出SpatialGenEval基准测试，旨在系统评估T2I模型的空间智能，涵盖两大核心维度：（1）该基准包含25个真实场景下的1,230条长文本密集提示，每条提示整合10个空间子领域及对应的10组多选题对，涵盖物体位置、布局、遮挡关系与因果推理等维度。通过对21个前沿模型的广泛测试，我们发现高阶空间推理仍是当前模型的主要瓶颈。（2）为证明信息密集设计的价值超越单纯评估，我们同步构建了SpatialT2I数据集。该数据集包含15,400个文本-图像对，通过提示词重写在保持信息密度的同时确保图像一致性。基于当前基础模型（包括Stable Diffusion-XL、Uniworld-V1、OmniGen2）的微调实验显示，模型在空间关系表现上获得稳定性能提升（+4.2%、+5.7%、+4.4%）并生成更符合真实空间逻辑的图像，这为通过数据中心化范式实现T2I模型空间智能提供了新路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20354) | [arXiv](https://arxiv.org/abs/2601.20354)



---

### 3. 语言模型中扩展嵌入优于扩展专家模型

**原文标题：** Scaling Embeddings Outperforms Scaling Experts in Language Models

**摘要：**
尽管专家混合架构已成为大型语言模型稀疏扩展的标准方案，但其边际效益递减与系统级瓶颈问题日益凸显。本研究探索了嵌入扩展作为稀疏化扩展中一个高效且正交的维度。通过系统分析与实验验证，我们发现了嵌入扩展在特定条件下能获得优于专家扩展的帕累托前沿。我们系统性地揭示了影响该方案效能的关键架构因素——涵盖参数分配策略、模型宽度与深度的协同机制等维度。通过整合定制化系统优化与推测解码技术，我们成功将这种稀疏性转化为可观的推理加速。基于这些发现，我们提出了LongCat-Flash-Lite模型：该68.5B参数模型在训练中激活约3B参数，虽分配超过300亿参数至嵌入层，但其性能不仅超越参数规模相当的专家混合基线模型，更在智能体与代码生成领域展现出与同规模现有模型相匹敌的卓越竞争力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21204) | [arXiv](https://arxiv.org/abs/2601.21204)



---

### 4. DynamicVLA：一种用于动态物体操作的视觉-语言-动作模型

**原文标题：** DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation

**摘要：**
对于视觉-语言-动作模型而言，操作动态物体仍是一个开放性的挑战。尽管此类模型在静态操作任务中展现出强大的泛化能力，但在需要快速感知、时序预测与持续控制的动态场景中却表现不佳。本文提出DynamicVLA，一个用于动态物体操作的框架，通过三项关键设计整合了时序推理与闭环适应能力：1）采用卷积视觉编码器构建了一个紧凑的0.4B参数VLA模型，实现了空间高效且结构保真的编码，支持快速多模态推理；2）连续推理机制，允许推理与执行过程重叠，以降低延迟并及时适应物体运动；3）潜在感知的动作流式执行，通过强制时序对齐的动作执行来弥合感知与执行之间的间隙。为填补动态操作数据基础的缺失，我们构建了动态物体操作基准数据集，该数据集通过自动数据采集流程从零创建，高效收集了涵盖2.8K个场景、206个物体的20万条合成交互轨迹，并无需遥操作即可快速采集2K条真实世界交互轨迹。大量实验评估表明，该框架在响应速度、感知能力与泛化性能上均取得显著提升，使DynamicVLA成为一个可跨越不同实体形态的通用动态物体操作统一框架。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22153) | [arXiv](https://arxiv.org/abs/2601.22153)



---

### 5. OCRVerse：面向端到端视觉语言模型的全方位OCR技术

**原文标题：** OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models

**摘要：**
大规模视觉语言模型的发展推动了对海量多模态数据管理及应用的需求，使得从视觉图像中提取信息的OCR技术日益受到关注。然而，现有OCR方法主要集中于从图像或扫描文档中识别文本元素（以文本为中心的OCR），而忽视了从视觉信息密集的图像源（如图表、网页和科学图表）中识别视觉元素（以视觉为中心的OCR）。实际上，这类视觉信息密集的图像在互联网中广泛存在，并具有重要的实际应用价值，例如数据可视化和网页分析。本技术报告提出了OCRVerse，这是首个以端到端方式实现统一文本中心OCR与视觉中心OCR的全方位OCR方法。为此，我们构建了全面的数据工程，涵盖广泛的文本中心文档（如报纸、杂志和书籍）以及视觉中心渲染复合图像（包括图表、网页和科学图表）。此外，我们为OCRVerse提出了一种两阶段的SFT-RL多领域训练方法。SFT直接混合跨领域数据进行训练以建立初始领域知识，而RL则侧重于针对各领域特点设计个性化奖励策略。具体而言，由于不同领域需要多样化的输出格式和预期结果，我们在RL阶段提供了充分的灵活性，为每个领域定制灵活的奖励信号，从而提升跨领域融合能力并避免数据冲突。实验结果表明，OCRVerse在文本中心与视觉中心数据类型上均取得了具有竞争力的效果，甚至可与大规模开源及闭源模型相媲美。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21639) | [arXiv](https://arxiv.org/abs/2601.21639)



---

### 6. MMFineReason：通过开放式数据驱动方法弥合多模态推理鸿沟

**原文标题：** MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods

**摘要：**
视觉语言模型（VLMs）的最新进展显著推动了视觉推理领域的发展。然而，开源视觉语言模型仍落后于专有系统，这主要归因于高质量推理数据的缺乏。现有数据集在STEM图表、视觉谜题等复杂领域的覆盖范围有限，且缺乏能够激发强大推理能力所必需的一致、长形式的思维链标注。为弥合这一鸿沟，我们提出了MMFineReason——一个包含180万样本和51亿解答标记的大规模多模态推理数据集，其高质量推理标注提炼自Qwen3-VL-235B-A22B-Thinking模型。该数据集通过系统化的三阶段流程构建：（1）大规模数据收集与标准化，（2）思维链原理生成，（3）基于推理质量与难度感知的综合筛选。最终数据集涵盖STEM问题、视觉谜题、游戏及复杂图表，每个样本均配有基于视觉的推理轨迹标注。我们在MMFineReason上对Qwen3-VL-Instruct进行微调，开发出MMFineReason-2B/4B/8B系列模型。这些模型在其规模类别中取得了最新的最优性能。值得注意的是，MMFineReason-4B成功超越了Qwen3-VL-8B-Thinking，而MMFineReason-8B甚至优于Qwen3-VL-30B-A3B-Thinking，并接近Qwen3-VL-32B-Thinking的性能，展现出卓越的参数效率。关键的是，我们通过难度感知筛选策略发现了“少即是多”的现象：仅使用7%（12.3万样本）的数据子集即可达到与完整数据集相当的性能。尤为重要的是，我们揭示了以推理为导向的数据组合能同步提升模型通用能力的协同效应。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21821) | [arXiv](https://arxiv.org/abs/2601.21821)



---

### 7. ConceptMoE：面向隐式计算分配的自适应令牌到概念压缩方法

**原文标题：** ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation

**摘要：**
大型语言模型通常对所有令牌分配均匀的计算量，忽略了某些序列易于预测而另一些则需要深度推理的事实。本文提出ConceptMoE模型，该模型能够动态地将语义相似的令牌合并为概念表示，从而实现隐式的令牌级计算分配。通过可学习的分块模块测量令牌间相似度以确定最优边界，在序列进入计算密集型概念模型前按目标压缩比R进行压缩。关键的是，混合专家（MoE）架构支持受控评估：我们将节省的计算量重新分配，以匹配基线激活的浮点运算量（不含注意力图计算）和总参数量，从而分离出纯架构优势。在此条件下，ConceptMoE在语言和视觉-语言任务中持续超越标准MoE模型，在语言预训练中提升0.9个点，在长上下文理解中提升2.3个点，在多模态基准测试中提升0.6个点。当在持续训练中通过层循环转换预训练的MoE模型时，性能增益可达5.5个点，证明了其实用价值。除性能提升外，ConceptMoE可将注意力计算量降低至R^2倍，KV缓存降低至R倍。在R=2时，实际测量显示长序列的预填充速度最高提升175%，解码速度最高提升117%。该架构仅需最小改动即可直接集成到现有MoE模型中，表明自适应概念级处理能够从根本上提升大型语言模型的效能与效率。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21420) | [arXiv](https://arxiv.org/abs/2601.21420)



---

### 8. PLANING：一种面向流式三维重建的松耦合三角-高斯框架

**原文标题：** PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction

**摘要：**
基于单目图像序列的流式三维重建仍面临挑战，现有方法通常难以兼顾高质量渲染与精确几何重建。本文提出PLANING，一种基于混合表征的高效实时重建框架，通过将显式几何基元与神经高斯场进行松耦合，实现了几何与外观建模的解耦。这种解耦机制支持分离几何更新与外观优化的在线初始化与优化策略，能够在显著降低结构冗余度的同时实现稳定的流式重建。实验表明，PLANING在稠密网格Chamfer-L2指标上较PGSR提升18.52%，PSNR指标超越ARTDECO达1.31 dB，重建ScanNetV2场景耗时低于100秒（比二维高斯泼溅提速5倍以上），且重建质量达到离线逐场景优化的水准。除重建质量外，该框架具备清晰的结构层次与高效的计算性能，可广泛适用于大规模场景建模、具身智能仿真环境构建等下游任务。项目页面：https://city-super.github.io/PLANING/。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22046) | [arXiv](https://arxiv.org/abs/2601.22046)



---

### 9. Qwen3-ASR技术报告

**原文标题：** Qwen3-ASR Technical Report

**摘要：**
本报告介绍了Qwen3-ASR系列模型，包括两款强大的一体化语音识别模型和一种新颖的非自回归语音强制对齐模型。Qwen3-ASR-1.7B与Qwen3-ASR-0.6B是支持52种语言与方言的语音识别模型，兼具语言识别功能。两款模型均利用大规模语音训练数据及其基础模型Qwen3-Omni强大的音频理解能力。由于语音识别模型在开源基准测试中可能表现相近，但在实际场景中却存在显著质量差异，我们在开源基准之外进行了全面的内部评估。实验表明，1.7B版本在开源语音识别模型中达到最先进性能，并与最强的商业API模型具有竞争力；而0.6B版本在准确性与效率之间实现了最佳平衡。Qwen3-ASR-0.6B的平均首次响应时间可低至92毫秒，在128并发条件下能以1秒完成2000秒语音的转写。Qwen3-ForcedAligner-0.6B是基于大语言模型的非自回归时间戳预测器，可对11种语言的文本-语音对进行对齐。时间戳准确性实验显示，该模型性能超越当前三种最强的强制对齐模型，并在效率与泛用性方面更具优势。为加速语音识别与音频理解领域的社区研究，我们已将上述模型基于Apache 2.0许可证开源发布。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21337) | [arXiv](https://arxiv.org/abs/2601.21337)



---

### 10. AgentLongBench：一种通过环境推演实现长上下文智能体可控评估的长基准框架

**原文标题：** AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts

**摘要：**
大型语言模型向自主智能体的演进要求其能够处理广泛且动态变化的上下文信息。然而，现有基准测试大多保持静态，依赖于被动检索任务，无法模拟智能体与环境交互中的复杂特性，如非线性推理与迭代反馈。为此，我们提出了AgentLongBench，该框架基于横向思维谜题，通过模拟环境推演来评估智能体性能。该框架能够在知识密集与知识无关的场景中生成严格的交互轨迹。通过对先进模型与记忆系统（32K至4M词元）的实验，我们揭示了一个关键缺陷：尽管智能体擅长静态检索，但在工作流所必需的动态信息整合方面表现欠佳。分析表明，性能下降主要受解决查询所需的最小词元数量驱动。这一因素解释了为何海量工具响应中固有的高信息密度，比长轮对话中典型的内存碎片化问题，构成了更为严峻的挑战。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20730) | [arXiv](https://arxiv.org/abs/2601.20730)



---

### 11. 探索智能体推理奖励模型

**原文标题：** Exploring Reasoning Reward Model for Agents

**摘要：**
智能体强化学习在实现复杂推理与工具使用方面已取得显著成功。然而，现有方法仍主要依赖基于结果的稀疏奖励进行训练。此类反馈无法区分中间推理过程的质量，导致训练效果欠佳。本文提出智能体推理奖励模型，该多维度奖励模型可为智能体行为轨迹提供结构化反馈，包括：（1）显式推理轨迹；（2）聚焦式评析，通过指出推理缺陷提供改进指导；（3）评估过程表现的综合评分。基于这些反馈信号，我们系统研究了三种集成策略：文本增强改进型、奖励增强指导型与统一反馈集成型。在12个多样化基准测试中的广泛评估表明，统一反馈集成型方案实现了性能飞跃，在GAIA和WebWalkerQA基准上分别达到43.7%和46.2%的得分，验证了所提推理奖励模型与训练方案的有效性。代码、模型与数据集均已开源以促进后续研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22154) | [arXiv](https://arxiv.org/abs/2601.22154)



---

### 12. LoL：更长再长，将视频生成扩展至小时级

**原文标题：** LoL: Longer than Longer, Scaling Video Generation to Hour

**摘要：**
近期长视频生成研究已从双向模型转向自回归模型，但这些方法普遍存在误差累积与长期连贯性丧失的问题。尽管注意力汇聚帧被引入以缓解性能衰减，但其常引发我们称为“汇聚塌缩”的关键失效模式：生成内容反复回归至汇聚帧，导致场景突变重置与循环运动模式。我们的分析表明，汇聚塌缩源于旋转位置编码的周期结构与当前生成模型中普遍采用的多头注意力机制之间的内在冲突。为解决该问题，我们提出一种轻量级、无需训练的方法，通过引入打破头间注意力同质化的多头旋转位置编码扰动，有效抑制该行为并缓解长时程塌缩。大量实验表明，我们的方法在保持生成质量的同时成功缓解了汇聚塌缩。据我们所知，本研究首次实现了质量衰减极低的实时、流式、无限长度视频生成。为证明其鲁棒性，我们生成了长达12小时的连续视频，这据我们所知是当前流式视频生成领域公开演示的最长结果之一。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.16914) | [arXiv](https://arxiv.org/abs/2601.16914)



---

### 13. 基于语言的试错法在经验时代已显滞后

**原文标题：** Language-based Trial and Error Falls Behind in the Era of Experience

**摘要：**
尽管大语言模型在基于语言的代理任务中表现出色，但其在未见过的非语言环境（如符号或空间任务）中的适用性仍然有限。先前研究将这种性能差距归因于预训练分布与测试分布之间的不匹配。本文论证其主要瓶颈在于探索成本过高：掌握这些任务需要大量试错，这对于在高维语义空间中运行的重参数大语言模型而言，在计算上是不可持续的。为解决这一问题，我们提出SCOUT（未见任务下的子尺度协作）这一创新框架，将探索与利用过程解耦。我们采用轻量级“侦察器”（如小型多层感知机）以远超大语言模型的速度和规模探测环境动态，收集的轨迹通过监督微调用于引导大语言模型，再经过多轮强化学习激活其潜在的世界知识。实验表明，SCOUT使Qwen2.5-3B-Instruct模型平均得分达到0.86，显著优于包括Gemini-2.5-Pro（0.60）在内的专有模型，同时节省约60%的GPU时耗。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21754) | [arXiv](https://arxiv.org/abs/2601.21754)



---

### 14. 模型仓库中隐藏瑰宝的发现机制研究

**原文标题：** Discovering Hidden Gems in Model Repositories

**摘要：**
公共模型仓库托管了数百万个微调模型，但社区使用量仍过度集中于少数基础检查点。本研究旨在探究这种集中现象究竟反映了有效的市场选择机制，还是存在优质模型被系统性忽视的问题。通过对超过2000个模型进行大规模评估，我们揭示了“隐藏瑰宝”现象的普遍性——这些不受关注的微调模型在性能上显著优于主流模型。以Llama-3.1-8B模型家族为例，我们发现某些极少被下载的检查点能将数学推理性能从83.2%提升至96.0%，且无需增加推理成本。然而，通过对每个上传模型进行穷举评估来发现这些优质模型在计算上是不可行的。为此，我们将模型发现问题建模为多臂老虎机问题，通过采用共享查询集和激进淘汰策略，对序列二分搜索算法进行加速优化。该方法仅需对每个候选模型进行50次查询即可定位最优模型，实现超过50倍的发现效率提升。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22157) | [arXiv](https://arxiv.org/abs/2601.22157)



---

### 15. 基于隐空间对抗正则化的离线偏好优化

**原文标题：** Latent Adversarial Regularization for Offline Preference Optimization

**摘要：**
基于人类反馈的学习通常依赖于偏好优化方法，该方法通过词元级正则化约束策略更新。然而，语言模型的偏好优化面临特殊挑战，因为词元空间的相似性并不等同于语义或行为层面的相似性。为解决这一问题，我们提出在语言模型偏好优化中引入隐空间正则化方法。我们设计了GANPO框架，通过惩罚策略模型与参考模型内部表征之间的差异来实现隐空间正则化。鉴于隐空间表征缺乏显式概率密度定义，我们借鉴生成对抗网络的对抗训练思想来最小化隐空间差异。我们将GANPO作为正则化模块集成到现有离线偏好优化目标函数中。在多模型架构与多任务场景下的实验表明，隐空间正则化能带来持续的性能提升。进一步通过对比GANPO与词元级正则化引发的推理偏差，我们发现GANPO在数据分布偏移和噪声干扰下能提供更稳健的结构化反馈，同时以微小的计算开销保持与基线相当的下游任务性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22083) | [arXiv](https://arxiv.org/abs/2601.22083)



---

### 16. 可扩展的幂采样：通过分布锐化实现大语言模型高效免训练推理

**原文标题：** Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening

**摘要：**
强化学习后训练是提升大语言模型推理性能的主流方法，但越来越多的证据表明其效果提升主要源于分布锐化而非新能力的获得。近期研究表明，通过马尔可夫链蒙特卡洛方法从大语言模型的幂分布中采样，可在不依赖外部奖励的情况下达到与强化学习后训练相当的性能；然而，马尔可夫链蒙特卡洛的高计算成本限制了此类方法的广泛应用。本研究提出一种理论完备的替代方案，无需依赖迭代式马尔可夫链蒙特卡洛过程。我们推导出一种新颖的数学表述，证明全局幂分布可通过词元级别的缩放低温分布来近似，其中缩放因子能够捕捉未来轨迹的质量。基于这一发现，我们提出一种免训练且无需验证器的自回归算法，能够逐级锐化基础模型的生成分布。实验部分，我们在四个大语言模型上对数学、问答及代码生成任务进行评估，结果表明：该方法在不依赖任何外部奖励的情况下，性能达到或超越单次GRPO方法，同时相比基于马尔可夫链蒙特卡洛的采样方法将推理延迟降低了10倍以上。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21590) | [arXiv](https://arxiv.org/abs/2601.21590)



---

### 17. 通过词元级数据过滤塑造模型能力

**原文标题：** Shaping capabilities with token-level data filtering

**摘要：**
当前减少语言模型中不良能力的方法大多属于事后干预，因此容易被对抗性攻击绕过。一种自然的替代方案是在预训练阶段直接塑造模型能力。以消除医学能力为代理任务，我们证明简单的预训练数据过滤干预方法具有高度有效性、鲁棒性且易于大规模实施。受数据归因研究的启发，我们发现词元级过滤比文档级过滤更有效，能在降低对良性能力损害的同时达到同等的不良能力抑制效果。通过训练跨越两个数量级的模型，我们进一步证明过滤效果随模型规模扩大而增强：对于最大规模模型，词元过滤可使目标遗忘领域的计算效率降低7000倍。研究还表明，经过词元过滤训练的模型仍可在遗忘领域进行对齐优化。在此过程中，我们提出了一种基于稀疏自编码器的词元标注方法，并实现了低成本高质量分类器的知识蒸馏。实验同时证明，在充足预训练计算资源支持下，过滤方法对噪声标签具有良好鲁棒性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21571) | [arXiv](https://arxiv.org/abs/2601.21571)



---

### 18. Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B 技术报告

**原文标题：** Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report

**摘要：**
我们推出 Foundation-Sec-8B-Reasoning，这是首个面向网络安全领域的开源原生推理模型。该模型基于我们先前发布的 Foundation-Sec-8B 基础模型（源自 Llama-3.1-8B-Base），通过结合监督微调（SFT）和可验证奖励强化学习（RLVR）的两阶段训练流程构建。我们的训练利用了涵盖网络安全分析、指令遵循和数学推理的专有推理数据。在 10 项网络安全基准测试和 10 项通用基准测试上的评估表明，该模型在网络安全任务中展现出与规模显著更大的模型相竞争的性能，同时保持了强大的通用能力。该模型在多跳推理任务上表现出有效的泛化能力，并在部署适当的系统提示和防护机制时展现出优异的安全性能。本研究表明，领域专用推理模型能够在保持广泛通用能力的同时，在专业任务上实现强劲性能。我们已通过 https://huggingface.co/fdtn-ai/Foundation-Sec-8B-Reasoning 公开释放该模型。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21051) | [arXiv](https://arxiv.org/abs/2601.21051)



---

### 19. 台风-S：主权大语言模型的最小化开放式后训练方法

**原文标题：** Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models

**摘要：**
大语言模型（LLM）发展迅速，然而当前最先进的模型主要基于英语、汉语等高资源语言进行训练与评估，且通常由少数能够获取大规模计算资源与数据的机构开发。这种技术壁垒为主权应用场景带来了实际障碍：在资源有限且透明度要求严格的条件下，区域或国家层面的机构及领域所有者需保持对模型权重、训练数据及部署流程的控制权与可解释性。为此，我们提出两大核心需求：（1）可适配性——将基础模型转化为通用助手的能；（2）主权能力——执行高风险、区域特定任务（如本地语言法律推理与文化知识应用）的能力。本研究探讨能否在不依赖大规模指令数据扩展、复杂偏好调优流程或大规模强化微调的前提下实现这些目标。我们提出台风-S，一种最小化开放式后训练方案，融合监督微调、同策略蒸馏与小规模强化微调。以泰语作为代表性案例，我们证明该方法可将主权适配型与通用型基础模型转化为具备强大通用性能的指令调优模型。进一步研究发现，采用InK-GRPO（通过在GRPO损失函数中融入下一词预测损失进行扩展）的小规模强化微调，能在保持通用能力的同时显著提升泰语法律推理与泰国本土知识处理能力。实验结果表明，精心设计的后训练策略可降低对指令数据规模与计算资源的需求，为在学术级资源条件下构建高质量主权大语言模型提供了可行路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18129) | [arXiv](https://arxiv.org/abs/2601.18129)



---

### 20. VTC-R1：面向高效长上下文推理的视觉-文本压缩方法

**原文标题：** VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning

**摘要：**
长上下文推理显著增强了大语言模型处理复杂任务的能力，但因其计算复杂性也带来了严重的效率瓶颈。现有高效方法通常依赖复杂的额外训练或外部模型进行压缩，这限制了可扩展性并丢弃了关键的细粒度信息。本文提出VTC-R1——一种集成视觉-文本压缩的新型高效推理范式。该方法将冗长的文本推理轨迹转化为紧凑的图像片段，作为“光学记忆”迭代反馈给视觉-语言模型，而非直接处理原始长文本。基于OpenR1-Math-220K构建的训练数据集实现了3.4倍的token压缩率，并以此微调了代表性视觉语言模型Glyph与Qwen3-VL。在MATH500、AIME25、AMC23及GPQA-D等基准测试上的大量实验表明，VTC-R1持续优于标准长上下文推理方法。此外，本方法显著提升了推理效率，端到端延迟降低至原来的2.7倍，凸显了其作为推理密集型应用可扩展解决方案的潜力。代码已开源：https://github.com/w-yibo/VTC-R1。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22069) | [arXiv](https://arxiv.org/abs/2601.22069)



---

### 21. MAD：模态自适应解码——缓解多模态大语言模型中的跨模态幻觉问题

**原文标题：** MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models

**摘要：**
多模态大语言模型（MLLMs）存在跨模态幻觉问题，即某一模态不适当地影响对其他模态内容的生成，导致输出结果失真。这暴露出模型在模态交互控制方面存在更深层的缺陷。为解决这一问题，我们提出模态自适应解码（MAD），一种无需训练的方法，能够根据任务需求自适应地加权特定模态的解码分支。MAD利用模型固有的自评估能力，通过查询每个任务所需的模态来判定模态相关性。提取的模态概率随后用于自适应加权对比解码分支，使模型能够聚焦相关信息并抑制跨模态干扰。在CMM和AVHBench数据集上的大量实验表明，MAD显著降低了多种视听语言模型的跨模态幻觉（VideoLLaMA2-AV模型提升7.8%和2.0%，Qwen2.5-Omni模型提升8.7%和4.7%）。我们的方法证明，通过自评估实现的显式模态感知对鲁棒的多模态推理至关重要，为现有对比解码方法提供了理论扩展。代码已开源：https://github.com/top-yun/MAD

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21181) | [arXiv](https://arxiv.org/abs/2601.21181)



---

### 22. 脑电图基础模型：进展、基准测试与开放性问题

**原文标题：** EEG Foundation Models: Progresses, Benchmarking, and Open Problems

**摘要：**
脑电图基础模型作为脑机接口领域新兴的前沿范式，旨在通过大规模异质性脑电记录学习可迁移的神经表征。尽管该领域发展迅速，但由于预训练目标、预处理流程与下游评估协议缺乏统一标准，现有模型尚未形成公平全面的性能比较。本文系统填补了这一空白：首先回顾了50个代表性模型，将其设计选择归纳为包含数据标准化、模型架构与自监督预训练策略的统一分类框架；进而选取12个开源基础模型与具有竞争力的专业基线模型，在涵盖九类脑机接口范式的13个脑电数据集上进行评估。为贴近实际部署场景，我们同时考察留一被试协议下的跨被试泛化能力与被试内少样本场景下的快速校准性能。通过对比全参数微调与线性探测方法，评估了预训练表征的可迁移性，并探究了模型规模与下游性能的关联规律。实验结果表明：1）线性探测方法常表现不足；2）从头训练的专业模型在多类任务中仍具竞争力；3）在当前数据规模与训练范式下，扩大基础模型规模未必能提升泛化性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17883) | [arXiv](https://arxiv.org/abs/2601.17883)



---

### 23. DeepSearchQA：弥合深度研究智能体综合能力差距的基准框架

**原文标题：** DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents

**摘要：**
本文提出DeepSearchQA，这是一个包含900个提示任务的基准测试集，用于评估智能体在17个不同领域中执行复杂多步骤信息检索任务的能力。与传统聚焦单一答案检索或宽泛事实性验证的基准不同，DeepSearchQA通过精心设计的高难度任务数据集，专门评估智能体执行复杂搜索计划以生成穷尽式答案列表的能力。该设计范式转变明确测试了三个关键但长期未被充分评估的能力：1）从分散来源系统整合碎片化信息；2）通过去重与实体消歧确保结果精确性；3）在开放式搜索空间中合理判断检索终止条件。每个任务均构建为因果链式结构，后续步骤的信息发现依赖于前序步骤的成功完成，从而强调长程规划与上下文保持能力。所有任务均基于开放网络环境构建，并配备可客观验证的答案集。通过对前沿智能体架构的全面评估，我们发现了显著的性能局限：即使最先进的模型也难以平衡高召回率与精确度。我们观察到从过早终止检索（检索不足）到防御性检索行为等多种失效模式——后者表现为智能体通过提交大量低置信度答案人为提高召回率。这些发现揭示了当前智能体设计中的关键提升空间，并使DeepSearchQA成为推动未来研究向更鲁棒的深度研究能力发展的重要诊断工具。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20975) | [arXiv](https://arxiv.org/abs/2601.20975)



---

### 24. 超越模仿：基于强化学习的主动潜在规划

**原文标题：** Beyond Imitation: Reinforcement Learning for Active Latent Planning

**摘要：**
为实现高效且密集的思维链推理，潜在推理方法通过微调大语言模型，将离散的语言标记替换为连续的潜在标记。相较于传统的语言思维链推理，这类方法消耗的标记更少，并具备在密集潜在空间中进行规划的潜力。然而，当前潜在标记的监督通常基于对语言标签的模仿。考虑到同一问题可能存在多个等价但形式各异的思维链标签，被动模仿任意标签可能导致次优的潜在标记表示与推理策略，从而削弱潜在规划能力，并造成训练与测试阶段的明显差距。本研究强调在潜在标记表示空间中进行主动规划对实现最优潜在推理策略的重要性。为此，我们提出主动潜在规划方法，该方法将潜在标记的监督过程建模为条件变分自编码器，以获得更平滑的潜在空间。此外，为构建最合理的潜在推理策略，该方法引入基于一致性的辅助奖励进行强化学习——该奖励通过计算潜在标记经变分自编码器解码内容的一致性获得，从而实现有导向的强化学习过程。在LLaMA-1B模型上的实验表明，相较于先进基线方法，该方法在四个基准测试中实现了准确率提升4.1%、标记消耗降低3.3%的效果。代码已发布于https://github.com/zz1358m/ATP-Latent-master。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21598) | [arXiv](https://arxiv.org/abs/2601.21598)



---

### 25. 基于像素均值流的单步无潜变量图像生成方法

**原文标题：** One-step Latent-free Image Generation with Pixel Mean Flows

**摘要：**
现代基于扩散/流模型的图像生成方法通常具有两个核心特征：(1)采用多步采样策略，(2)在潜空间中进行操作。近期研究已在这两个独立方面取得显著进展，为无需潜空间的单步扩散/流模型开辟了道路。本研究朝着该目标迈出关键一步，提出"像素均值流"方法。我们的核心设计原则是将网络输出空间与损失空间分别进行建模：网络输出目标被设计在预设的低维图像流形上（即x-预测），而损失函数则通过速度空间中的均值流进行定义。我们引入了图像流形与平均速度场之间的简易转换机制。实验结果表明，在256×256分辨率（FID 2.22）和512×512分辨率（FID 2.48）的ImageNet数据集上，像素均值流方法实现了单步无潜变量生成的优异性能，填补了该领域的关键技术空白。本研究有望进一步拓展基于扩散/流模型的生成式人工智能技术边界。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22158) | [arXiv](https://arxiv.org/abs/2601.22158)



---

### 26. 混合线性注意力机制的正确实现：面向超长上下文的高效蒸馏与有效架构

**原文标题：** Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts

**摘要：**
混合Transformer架构通过结合softmax注意力模块与循环神经网络（RNN），已在长上下文建模中展现出理想的性能与计算效率平衡，但其大规模从头预训练所需的巨大成本阻碍了该架构的广泛应用与研究。近期研究表明，预训练的softmax注意力模块可通过参数迁移与知识蒸馏转化为RNN模块。然而，现有迁移方法需要海量训练数据（超过100亿词元），且所得混合模型在长上下文场景中表现欠佳——而这正是混合模型相比传统Transformer模型具有显著推理加速优势的场景。本文提出HALO（基于层优化的混合注意力），一种将Transformer模型蒸馏为RNN-注意力混合模型的流程。进而提出HypeNet混合架构，该架构通过新颖的位置编码方案（命名为HyPE）及多项结构改进，实现了卓越的长度泛化能力。我们使用HALO将Qwen3系列模型转化为HypeNet，在保持与原Transformer模型相当性能的同时，获得了更优异的长上下文处理能力与计算效率。该转化过程仅需23亿词元，不足其预训练数据量的0.01%。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22156) | [arXiv](https://arxiv.org/abs/2601.22156)



---

### 27. FineInstructions：将合成指令扩展至预训练规模

**原文标题：** FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale

**摘要：**
由于监督训练数据有限，大型语言模型通常通过自监督的“预测下一个词”目标在海量非结构化文本数据上进行预训练。为使所得模型对用户有用，还需在规模小得多的“指令调优”数据上进行进一步训练，该数据由指令与响应的监督训练样本构成。为克服监督数据量的限制，我们提出一种方法，能够将互联网规模预训练文档中的知识转化为数十亿条合成指令与答案训练对。所得数据集名为FineInstructions，使用了基于真实用户编写的查询和提示创建的约1800万条指令模板。这些指令模板与非结构化预训练语料库中人工撰写的源文档进行匹配并实例化。借助此规模生成的“监督式”合成训练数据，大型语言模型可完全基于指令调优目标从头开始预训练，该目标与大型语言模型的下游预期用途（响应用户提示）具有更高的分布一致性。我们进行了严格的逐词训练对照实验，发现在衡量自由形式响应质量的标准基准测试中，基于FineInstructions的预训练表现优于标准预训练及其他已提出的合成预训练技术。相关资源可在 https://huggingface.co/fineinstructions 获取。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22146) | [arXiv](https://arxiv.org/abs/2601.22146)



---

### 28. KromHC：基于克罗内克积残差矩阵的流形约束超连接

**原文标题：** KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices

**摘要：**
超连接（HC）在神经网络（NN）中的成功应用，也凸显了其训练不稳定性和可扩展性受限的问题。流形约束超连接（mHC）通过将残差连接空间投影到Birkhoff多胞体上缓解了这些挑战，但仍面临两个问题：1）其迭代Sinkhorn-Knopp（SK）算法并不总能产生精确的双随机残差矩阵；2）mHC的参数复杂度高达O(n^3C)，其中n为残差流的宽度，C为特征维度。近期提出的mHC-lite通过Birkhoff-von-Neumann定理对残差矩阵进行重参数化以保证双随机性，但其参数复杂度也面临阶乘爆炸问题，达到O(nC·n!)。为同时解决这两大挑战，本文提出KromHC方法，该方法利用较小双随机矩阵的克罗内克积来参数化mHC中的残差矩阵。通过对张量化残差流各模态上的因子残差矩阵施加流形约束，KromHC在保证残差矩阵精确双随机性的同时，将参数复杂度降低至O(n^2C)。综合实验表明，KromHC在性能上匹配甚至超越最先进的mHC变体，且所需可训练参数显著减少。代码已发布于https://github.com/wz1119/KromHC。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21579) | [arXiv](https://arxiv.org/abs/2601.21579)



---

### 29. 自改进预训练：利用后训练模型预训练更优模型

**原文标题：** Self-Improving Pretraining: using post-trained models to pretrain better models

**摘要：**
确保大语言模型生成内容的安全性、事实性与整体质量是一项关键挑战，尤其在模型日益广泛应用于现实场景的背景下。当前主流解决方案依赖于收集成本高昂、精心标注的数据集，并进行多阶段的微调与对齐处理。然而，即使采用如此复杂的流程，仍无法完全修正模型在预训练阶段习得的不良模式。因此，在预训练阶段解决这些问题至关重要，因为这一阶段塑造了模型的核心行为模式，能从根本上防止不安全或虚构内容被深度固化。为此，我们提出一种新型预训练方法：该方法通过流式处理文档数据，并运用强化学习技术逐步优化后续K个生成标记。在这一过程中，一个经过充分后训练的强模型将对候选生成内容（包括模型自生成序列、原始后缀文本及重写后缀文本）进行质量、安全性与事实性评估。训练初期，系统主要依赖原始文本与重写后缀；随着模型性能提升，强化学习机制将给予高质量自生成序列正向奖励。该方法能够从底层构建质量更高、更安全且更符合事实的模型。实验结果表明，相较于标准预训练方法，本方案在事实性与安全性指标上分别实现36.2%和18.5%的相对提升，在整体生成质量方面最高可获得86.3%的胜率改进。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21343) | [arXiv](https://arxiv.org/abs/2601.21343)



---

### 30. ECO：无需全精度主权重的量化训练方法

**原文标题：** ECO: Quantized Training without Full-Precision Master Weights

**摘要：**
量化技术已显著提升大语言模型（LLL）训练的计算与内存效率。然而，现有方法仍需依赖高精度累积更新：具体而言，梯度更新必须作用于高精度权重缓冲区（即主权重）。该缓冲区会带来显著的内存开销，尤其对于稀疏专家混合模型（SMoE）而言，模型参数与优化器状态占据了内存使用的主要部分。为解决此问题，我们提出误差补偿优化器（ECO），该方法通过直接将更新应用于量化参数来消除主权重。ECO在每一步训练后对权重进行量化，并将产生的量化误差精准注入优化器动量中，形成一个无需额外内存的误差反馈循环。我们证明，在标准假设与递减学习率条件下，ECO能够收敛至最优解固定半径邻域内，而简单移除主权重可能导致误差与学习率成反比。我们通过预训练小型Transformer模型（30-800M参数）、Gemma-3 1B模型及采用FP8量化的2.1B参数稀疏MoE模型，并在INT4精度下对DeepSeek-MoE-16B进行微调，展示了实证结果。在所有实验中，ECO在保持近乎无损精度的前提下，与使用主权重的基线方法性能相当，显著改善了静态内存与验证损失的帕累托前沿边界。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22101) | [arXiv](https://arxiv.org/abs/2601.22101)



---

### 31. Metric Anything：利用异构噪声源实现度量深度预训练的规模化扩展

**原文标题：** MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources

**摘要：**
规模化推动了视觉基础模型的近期进展，但将这一范式扩展到度量深度估计领域仍面临挑战，原因在于异构传感器噪声、相机相关偏差以及跨来源噪声三维数据中的度量模糊性。我们提出了Metric Anything，一个简单且可扩展的预训练框架，能够从噪声多样化的三维数据源中学习度量深度，无需人工设计提示、相机特定建模或任务专用架构。我们方法的核心是稀疏度量提示——通过随机掩码深度图生成，它作为一种通用接口，将空间推理与传感器及相机偏差解耦。利用涵盖重建、采集和渲染三维数据的大约2000万张图像-深度对（涉及10000种相机型号），我们首次在度量深度研究方向上展示了清晰的规模化扩展趋势。预训练模型在提示驱动任务（如深度补全、超分辨率及雷达-相机融合）中表现优异，而其蒸馏出的无提示学生模型在单目深度估计、相机内参恢复、单/多视角度量三维重建以及视觉语言动作规划任务中达到了最先进水平。我们还证明，使用Metric Anything的预训练视觉变换器作为视觉编码器，能显著提升多模态大语言模型在空间智能方面的能力。这些结果表明，度量深度估计能够受益于驱动现代基础模型的相同扩展定律，为可扩展、高效的真实世界度量感知开辟了新路径。我们在http://metric-anything.github.io/metric-anything-io/开源Metric Anything以支持社区研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22054) | [arXiv](https://arxiv.org/abs/2601.22054)



---

### 32. 机制化数据归因：追溯可解释大语言模型单元的训源

**原文标题：** Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units

**摘要：**
尽管机制可解释性研究已在大语言模型中识别出可解释电路，但其在训练数据中的因果起源仍不明确。本文提出机制化数据归因框架，该可扩展框架运用影响函数将可解释单元溯源至具体训练样本。通过对Pythia模型系列的系列实验，我们因果验证了定向干预——即移除或增强少量高影响力样本——能显著调控可解释注意力头的形成，而随机干预则无此效果。分析表明重复性结构化数据（如LaTeX、XML）发挥着机制催化作用。进一步研究发现，针对归纳头形成的干预会同步改变模型的上下文学习能力，这为归纳头与上下文学习功能关联的长期假设提供了直接因果证据。最后，我们提出一种机制化数据增强流程，该流程能跨模型规模持续加速电路收敛，为引导大语言模型发展轨迹提供了系统化方法论。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21996) | [arXiv](https://arxiv.org/abs/2601.21996)



---

### 33. 多表征生成增强统一多模态模型的理解能力

**原文标题：** Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation

**摘要：**
统一多模态模型（UMMs）将视觉理解与生成功能整合于单一框架中，其最终目标是构建理解与生成相互强化的循环机制。尽管近期后训练方法已成功利用理解能力提升生成质量，但利用生成任务增强理解能力的反向路径仍鲜有探索。本研究提出UniMRG（统一多表征生成）——一种简洁高效且与模型架构无关的后训练方法。该方法通过引入辅助生成任务来增强UMMs的理解能力。具体而言，我们在标准视觉理解任务基础上，训练UMMs同步生成输入图像的多种内在表征：像素级（重建）、深度（几何）与分割（结构）信息。通过合成这些多样化表征，UMMs能够捕捉关于外观特征、空间关系与结构布局的互补信息，从而实现对视觉输入更深入、更全面的理解。跨多种UMM架构的大规模实验表明，本方法显著提升了模型的细粒度感知能力，减少了幻觉现象，增强了空间理解性能，同时同步强化了生成能力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21406) | [arXiv](https://arxiv.org/abs/2601.21406)



---

### 34. BMAM：类脑多智能体记忆框架

**原文标题：** BMAM: Brain-inspired Multi-Agent Memory Framework

**摘要：**
基于语言模型的智能体在长程交互中持续面临两大挑战：难以维持基于时间线的信息保存，以及无法在多次会话间保持行为一致性——我们将这种失效模式称为“灵魂侵蚀”。本文提出BMAM（类脑多智能体记忆框架），这是一种通用记忆架构，其将智能体记忆建模为功能专化的子系统集合，而非单一非结构化存储。受认知记忆系统启发，BMAM将记忆解构为情景记忆、语义记忆、显著性感知记忆与控制导向记忆四个在互补时间尺度上运作的组件。为支持长程推理，BMAM沿显式时间线组织情景记忆，并通过融合多重互补信号进行记忆检索。在LoCoMo基准测试中，BMAM在标准长程评估设定下达到78.45%的准确率，消融实验证实受海马体启发的的情景记忆子系统在时序推理中起着关键作用。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20465) | [arXiv](https://arxiv.org/abs/2601.20465)



---

### 35. JUST-DUB-IT：基于联合视听扩散模型的视频配音方法

**原文标题：** JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion

**摘要：**
视听基础模型通过预训练联合生成声音与视觉内容，近期在多模态生成与编辑任务中展现出前所未有的建模能力，为下游应用开辟了新机遇。视频配音任务尤其能够受益于此先验知识，然而现有解决方案大多依赖复杂且任务特定的流程，在真实场景中常面临挑战。本研究提出一种单模型方法，通过轻量级LoRA适配基础音视频扩散模型，实现视频到视频的配音转换。该LoRA使模型能够以输入音视频为条件，同步生成翻译后的音频与协调的面部动作。为训练此LoRA，我们利用生成模型自身合成同一发言者的多语言配对视频：首先生成包含单片段内语言切换的多语言视频，随后对每半段视频进行面部与音频修复，使其语言特征与另半段匹配。通过充分挖掘视听模型的丰富生成先验，本方法在保持说话者身份特征与唇形同步的同时，对复杂动作和真实场景动态具有强鲁棒性。实验表明，相较于现有配音流程，本方法生成的配音视频在视觉保真度、唇形同步性与鲁棒性方面均表现出更优质量。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22143) | [arXiv](https://arxiv.org/abs/2601.22143)



---

### 36. FROST：基于注意力机制过滤推理异常值的高效推理方法

**原文标题：** FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning

**摘要：**
本文提出FROST——一种基于注意力感知的高效推理方法。与传统方法不同，FROST通过注意力权重剪枝非关键推理路径，从而生成更简短且更可靠的推理轨迹。在方法论层面，我们提出推理异常值的概念，并设计基于注意力的机制予以剔除。理论上，FROST在保持并增强模型推理能力的同时，实现了句子层级的异常值消除。实证研究中，我们使用两个强推理模型（Phi-4-Reasoning与GPT-OSS-20B）在四个基准测试上验证FROST，其性能优于TALE、ThinkLess等前沿方法。值得注意的是，相较于基础模型，FROST平均降低69.68%的令牌使用量，并提升26.70%的准确率。此外，在注意力异常值指标评估中，FROST将最大无穷范数降低15.97%，平均峰度减少91.09%。代码已开源：https://github.com/robinzixuan/FROST

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.19001) | [arXiv](https://arxiv.org/abs/2601.19001)



---

### 37. 基于元评估的强化学习：无需真实标签的语言模型对齐方法

**原文标题：** Reinforcement Learning from Meta-Evaluation: Aligning Language Models Without Ground-Truth Labels

**摘要：**
当前大多数用于训练大语言模型的强化学习方法需要真实标签或特定任务验证器，当正确性难以界定或获取成本高昂时，这种方法会限制模型的可扩展性。本文提出基于元评估的强化学习方法，该方法通过评估者对自然语言元问题的回答生成奖励信号来优化生成模型。元问题包括“该答案是否正确？”或“推理过程是否逻辑一致？”等类型。该方法将评估者给出肯定判断的概率作为奖励信号，并通过组间相对策略优化更新生成器，从而实现无需标签的学习。一系列实验表明：该方法在准确性和样本效率上达到与基于标签训练相当的水平；支持多目标间的可控权衡；能够引导模型形成可靠的推理模式而非事后合理化；在缺乏真实标签的开放域场景中具有良好的泛化能力，从而拓展了强化学习在大语言模型训练中的应用领域。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21268) | [arXiv](https://arxiv.org/abs/2601.21268)



---

### 38. 基于对比分析的代码环境奖励攻击检测基准测试

**原文标题：** Benchmarking Reward Hack Detection in Code Environments via Contrastive Analysis

**摘要：**
代码生成强化学习的最新进展使得鲁棒环境对于防止奖励攻击变得至关重要。随着大语言模型日益成为基于代码的强化学习评估工具，其检测奖励攻击的能力仍未得到充分研究。本文提出了一种涵盖54个类别的奖励攻击新型分类法，并引入了TRACE（代码环境奖励异常测试基准）——一个包含517条测试轨迹的合成构建且经人工验证的基准集。与以往在孤立分类场景中评估奖励攻击检测的研究不同，我们在TRACE基准上采用更贴近实际的对比式异常检测框架进行对比评估。实验表明，模型在对比设置下比孤立分类设置能更有效地识别奖励攻击：在TRACE基准上，GPT-5.2最高推理模式的检测率从孤立设置的45%提升至63%。基于此发现，我们论证了当前最先进模型对语义语境化奖励攻击的检测难度显著高于句法语境化攻击。我们进一步对模型行为进行了定性分析，并通过消融实验证明良性轨迹与攻击轨迹的比例及分析聚类规模会显著影响检测性能。本研究公开了基准数据集与评估框架，以推动学界扩展TRACE基准并评估相关模型。

---

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20103) | [arXiv](https://arxiv.org/abs/2601.20103)



---

### 39. 分段长度的重要性：音频指纹识别性能中分段长度的研究

**原文标题：** Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance

**摘要：**
音频指纹识别为声学信号提供了一种可识别的表征方式，该表征后续可用于识别与检索系统。为获得具有区分性的表征，输入音频通常被分割为较短的时间区间，以便提取和分析局部声学特征。现代神经网络方法通常在固定时长的短音频片段上操作，但片段时长的选择往往基于启发式方法，鲜有深入研究。本文系统研究了分段长度对音频指纹识别性能的影响。我们扩展了一种现有的神经指纹识别架构，使其能够适配不同分段长度，并评估了不同分段长度与查询时长下的检索准确率。实验结果表明，较短的分段长度（0.5秒）通常能获得更优的性能。此外，我们评估了大语言模型在推荐最佳分段长度方面的能力，发现在所研究的三种大语言模型中，GPT-5-mini在五项评估维度上均能给出最佳建议。本研究结果为大规模神经音频检索系统中分段时长的选择提供了实践指导。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17690) | [arXiv](https://arxiv.org/abs/2601.17690)



---

### 40. PRISM：从数据中学习设计知识以提升风格化设计水平

**原文标题：** PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement

**摘要：**
平面设计通常需要探索不同的风格方向，这对非专业人士而言往往耗时费力。本文针对基于自然语言指令进行风格化设计改进的问题展开研究。尽管视觉语言模型在平面设计领域已取得初步成果，但其预训练的风格知识通常过于笼统，且与特定领域数据存在偏差。例如，视觉语言模型可能将极简主义与抽象设计相关联，而设计师更注重形状与色彩的选择。我们的核心思路是借助设计数据——即隐含设计师原则的真实设计案例集合——来学习设计知识并指导风格化改进。我们提出PRISM（先验信息驱动的风格化修改）框架，通过三个阶段构建并应用设计知识库：（1）对高方差设计进行聚类以捕捉风格内部的多样性；（2）将每个聚类总结为可操作的设计知识；（3）在推理过程中检索相关知识以实现风格感知的优化。在Crello数据集上的实验表明，PRISM在风格对齐任务中以1.49的平均排名（越接近1越好）超越基线方法。用户研究进一步验证了该结果，显示设计师持续倾向于选择PRISM生成的设计方案。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11747) | [arXiv](https://arxiv.org/abs/2601.11747)



---

### 41. WebArbiter：一种面向网络智能体的原则引导推理过程奖励模型

**原文标题：** WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents

**摘要：**
网络智能体在自动化复杂计算机任务方面具有巨大潜力，但其交互过程涉及长周期、序列化的决策，且包含不可逆操作。在此类场景中，基于结果的监督信号稀疏且延迟，常常错误奖励无效轨迹，且无法支持推理时的扩展需求。这促使了过程奖励模型在网络导航任务中的应用，但现有方法仍存在局限：标量化WebPRM将进展压缩为粗糙且缺乏依据的信号，而基于清单的WebPRM依赖脆弱的模板匹配机制，在界面布局或语义变化时容易失效，并常将表面正确的动作误判为成功，导致模型可解释性与洞察力不足。为解决这些挑战，我们提出WebArbiter——一种推理优先、原则引导的WebPRM框架，将奖励建模转化为文本生成任务，生成包含偏好判定结论的结构化论证，并识别当前情境下最有利于任务完成的动作。训练采用两阶段流程：推理蒸馏使模型掌握连贯的原则引导推理能力，强化学习则通过直接对齐判定结果与正确性来修正教师模型偏差，从而提升泛化性能。为支持系统化评估，我们发布了WebPRMBench基准测试集，涵盖四个多样化网络环境，包含丰富任务场景与高质量偏好标注。在WebPRMBench上，WebArbiter-7B以9.1分的优势超越最强基线模型GPT-5。在WebArena-Lite的奖励引导轨迹搜索任务中，其表现较现有最优WebPRM提升最高达7.2分，彰显了该模型在现实复杂网络任务中的鲁棒性与实用价值。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21872) | [arXiv](https://arxiv.org/abs/2601.21872)



---

### 42. 聚焦任务相关特征：以物体为中心的表示方法提升机器人操作泛化能力

**原文标题：** Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation

**摘要：**
机器人操作策略的泛化能力在很大程度上受视觉表示选择的影响。现有方法通常依赖于预训练编码器提取的表示，主要采用两种特征类型：全局特征（通过单一池化向量概括整幅图像）和密集特征（保留编码器最后一层的分块嵌入）。尽管广泛应用，这两种特征类型均混合了任务相关与无关信息，导致在光照、纹理变化或存在干扰物等分布偏移情况下泛化性能较差。本研究探索了一种中间结构化替代方案：基于槽位的物体中心表示（SBOCR），该方法将密集特征分组为有限个类物体实体。这种表示能够自然减少提供给机器人操作策略的噪声，同时保留足够信息以高效执行任务。我们在从简单到复杂的一系列仿真与真实世界操作任务中，系统比较了多种全局表示、密集表示与基于槽位的中间表示。通过评估它们在光照、纹理变化及存在干扰物等多种视觉条件下的泛化能力，发现基于SBOCR的策略在泛化场景中优于基于密集表示和全局表示的策略，且无需任务特定预训练。这些结果表明，SBOCR为设计能在动态真实世界机器人环境中有效泛化的视觉系统提供了有前景的研究方向。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21416) | [arXiv](https://arxiv.org/abs/2601.21416)



---

### 43. WorldBench：面向世界模型诊断性评估的物理概念解耦基准

**原文标题：** WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models

**摘要：**
生成式基础模型（常被称为“世界模型”）的最新进展激发了将其应用于机器人规划与自主系统训练等关键任务的兴趣。为确保可靠部署，此类模型必须具备高物理保真度，能够准确模拟真实世界动态。然而，现有基于物理的视频基准普遍存在概念耦合问题——单个测试同时评估多项物理定律与概念，这从根本上限制了其诊断能力。我们提出WorldBench，这是一个专为概念特异性解耦评估设计的新型视频基准，能够严格隔离并逐项评估对单一物理概念或定律的理解。为构建全面评估体系，我们设计了两个层级的基准：1）针对物体恒存性、尺度/透视等概念的直观物理理解评估；2）针对摩擦系数、流体黏度等底层物理常数与材料属性的评估。通过对当前最先进的视频世界模型进行WorldBench测试，我们发现所有被测模型均存在特定物理概念上的系统性缺陷，缺乏生成可靠真实世界交互所需的物理一致性。WorldBench通过其概念特异性评估机制，为视频生成与世界模型的物理推理能力提供了更精细、可扩展的严谨评估框架，为开发更鲁棒、更具泛化能力的世界模型驱动学习开辟了新路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21282) | [arXiv](https://arxiv.org/abs/2601.21282)



---

### 44. STORM：面向机器人操作的基于槽位的任务感知物体中心表征

**原文标题：** STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation

**摘要：**
视觉基础模型为机器人学提供了强大的感知特征，但其稠密表征缺乏显式的物体级结构，限制了操作任务中的鲁棒性与可泛化性。本文提出STORM（面向机器人操作的基于槽位的任务感知物体中心表征），这是一种轻量级的物体中心自适应模块，通过为机器人操作引入少量语义感知槽位来增强冻结的视觉基础模型。STORM采用多阶段训练策略而非重新训练大型骨干网络：首先通过语言嵌入的视觉-语义预训练稳定物体中心槽位，随后与下游操作策略联合自适应。这种分阶段学习避免了槽位退化形成，在保持语义一致性的同时将感知与任务目标对齐。在物体发现基准测试与仿真操作任务上的实验表明，相较于直接使用冻结基础模型特征或端到端训练物体中心表征，STORM能有效提升对视觉干扰的泛化能力与控制性能。我们的研究结果凸显了多阶段自适应作为一种高效机制，可将通用基础模型特征转化为适用于机器人控制的任务感知物体中心表征。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20381) | [arXiv](https://arxiv.org/abs/2601.20381)



---

### 45. 基于流模型的极值数学结构发现

**原文标题：** Flow-based Extremal Mathematical Structure Discovery

**摘要：**
数学中极值结构的发现需要在广阔且非凸的搜索空间中探索，分析方法难以提供有效指导，而暴力搜索又不可行。本文提出FlowBoost，一种闭环生成框架，通过整合三个核心组件学习发现稀有且极值的几何结构：（一）几何感知的条件流匹配模型，学习采样高质量构型；（二）奖励引导的策略优化与动作探索机制，在保持多样性的同时直接优化生成过程以趋近目标；（三）用于训练数据生成与最终优化的随机局部搜索。与以往开环方法（如依赖过滤离散样本重训练的PatternBoost，或依靠冻结大语言模型作为进化变异算子的AlphaEvolve）不同，FlowBoost在采样过程中强制保证几何可行性，并将奖励信号直接反馈至生成模型，从而形成闭环优化。该方法大幅减少所需训练集规模与训练时间，将外层循环迭代次数降低数个数量级，同时消除对大语言模型的依赖。我们在四个几何优化问题上验证了该框架：超立方体中的球体填充、半径和最大化的圆盘填充、Heilbronn三角形问题以及星形差异最小化。在多个案例中，FlowBoost发现的构型达到或超越了已知最佳结果。针对圆盘填充问题，我们提升了已知下界，在显著减少计算资源消耗的同时，超越了基于大语言模型的AlphaEvolve系统。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18005) | [arXiv](https://arxiv.org/abs/2601.18005)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2026-01-30_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)