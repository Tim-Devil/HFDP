
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-30 论文日报

## 📊 今日论文统计
- 总论文数：45
- 热门领域：LLM, RL, Diffusion, Transformer, GPT

## 📝 论文详情


### 1. Idea2Story：将研究概念转化为完整科学叙事的自动化流程

**原文标题：** Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives

**摘要：**
基于大语言模型（LLM）的智能体在自主科学发现领域近期取得显著进展，展现出自动化端到端研究流程的能力。然而，现有系统主要依赖以运行时为中心的执行范式，需反复在线读取、总结并推理大量科学文献。这种即时计算策略不仅计算成本高昂，受限于上下文窗口长度，还常导致推理过程脆弱并产生幻觉。本文提出Idea2Story——一种以预计算驱动的自主科学发现框架，将文献理解从在线推理转向离线知识构建。该框架持续收集经同行评审的论文及其审稿反馈，提取核心方法单元，组合可复用的研究模式，并将其组织为结构化的方法知识图谱。在运行时，用户未充分明确的研究意图可与已确立的研究范式进行匹配，从而实现高质量研究模式的高效检索与复用，而非依赖开放式生成与试错。通过将研究规划与执行建立在预构建的知识图谱基础上，Idea2Story缓解了LLM的上下文窗口瓶颈，大幅减少了对文献的重复运行时推理。我们通过定性分析与初步实证研究表明：Idea2Story能够生成连贯、方法可靠且新颖的研究模式，并可在端到端场景中产出多项高质量研究示例。这些结果表明，离线知识构建为可靠、可扩展的自主科学发现提供了实用基础。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20833) | [arXiv](https://arxiv.org/abs/2601.20833)



---

### 2. 各归其位：文本到图像模型空间智能的基准测试

**原文标题：** Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models

**摘要：**
文本到图像（T2I）模型在生成高保真度图像方面取得了显著成功，但在处理复杂空间关系（如空间感知、推理或交互）时仍常出现失误。由于现有基准测试的提示设计通常简短或信息稀疏，这些关键方面在很大程度上被忽视。本文提出SpatialGenEval，这是一个旨在系统评估T2I模型空间智能的新基准，涵盖两个关键方面：（1）SpatialGenEval包含25个真实场景下的1,230条长文本、信息密集的提示。每条提示整合了10个空间子领域及对应的10组多项选择题-答案对，内容涵盖物体位置、布局到遮挡关系和因果推理等。我们对21个前沿模型进行的广泛评估表明，高阶空间推理仍是主要瓶颈。（2）为证明信息密集设计的实用性不仅限于简单评估，我们还构建了SpatialT2I数据集。该数据集包含15,400个文本-图像对，通过重写提示确保图像一致性同时保持信息密度。在现有基础模型（如Stable Diffusion-XL、Uniworld-V1、OmniGen2）上的微调实验显示，模型在空间关系处理上取得了稳定的性能提升（+4.2%、+5.7%、+4.4%）和更真实的效果，这凸显了以数据为中心实现T2I模型空间智能的新范式。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20354) | [arXiv](https://arxiv.org/abs/2601.20354)



---

### 3. 语言模型中扩展嵌入优于扩展专家模型

**原文标题：** Scaling Embeddings Outperforms Scaling Experts in Language Models

**摘要：**
虽然专家混合架构已成为大语言模型稀疏性扩展的标准方案，但其边际效益递减与系统级瓶颈问题日益凸显。本研究探索将嵌入扩展作为稀疏性扩展中一个高效且正交的维度。通过系统性分析与实验，我们识别出嵌入扩展在特定机制下能够获得优于专家扩展的帕累托前沿。我们系统性地揭示了影响该效能的关键架构因素——涵盖参数预算分配、模型宽度与深度的交互机制等维度。此外，通过整合定制化系统优化与推测解码技术，我们成功将这种稀疏性转化为可观的推理加速。基于这些发现，我们提出了LongCat-Flash-Lite模型：该68.5B参数模型通过从头训练激活约3B参数，虽分配超过300亿参数至嵌入层，但其性能不仅超越参数等效的专家混合基线模型，更在智能体与代码生成领域展现出与同规模现有模型相匹敌的卓越竞争力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21204) | [arXiv](https://arxiv.org/abs/2601.21204)



---

### 4. DynamicVLA：一种用于动态物体操作的视觉-语言-动作模型

**原文标题：** DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation

**摘要：**
动态物体操作仍然是视觉-语言-动作模型面临的一项开放挑战。尽管这类模型在静态操作中展现出强大的泛化能力，但在需要快速感知、时序预测和持续控制的动态场景中仍存在困难。本文提出DynamicVLA，这是一个用于动态物体操作的框架，通过三项关键设计整合了时序推理与闭环适应能力：1）采用卷积视觉编码器构建的紧凑型0.4B参数VLA模型，实现空间高效且结构保真的编码，支持快速多模态推理；2）连续推理机制，通过重叠的推理与执行过程降低延迟，实现对物体运动的及时适应；3）潜在感知动作流，通过强制时序对齐的动作执行弥合感知与执行的间隙。为填补动态操作数据基础的空白，我们构建了动态物体操作基准数据集。该数据集通过自动数据采集流程从零创建，高效收集了涵盖2.8K个场景、206类物体的20万条合成交互序列，并无需遥操作即可快速采集2千条真实世界交互序列。大量实验评估表明，该框架在响应速度、感知能力和泛化性能方面均取得显著提升，使DynamicVLA成为跨具身形态的通用动态物体操作统一框架。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22153) | [arXiv](https://arxiv.org/abs/2601.22153)



---

### 5. OCRVerse：迈向端到端视觉语言模型中的全息OCR技术

**原文标题：** OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models

**摘要：**
大规模视觉语言模型的发展推动了对海量多模态数据管理及应用的需求，使得从视觉图像中提取信息的OCR技术日益受到关注。然而，现有OCR方法主要集中于从图像或扫描文档中识别文本元素（以文本为中心的OCR），而忽视了从视觉信息密集的图像源（如图表、网页和科学图表）中识别视觉元素（以视觉为中心的OCR）。实际上，这类视觉信息密集的图像在互联网中广泛存在，并具有重要的实际应用价值，例如数据可视化和网页分析。在本技术报告中，我们提出了OCRVerse，这是首个以端到端方式实现统一文本中心OCR与视觉中心OCR的全息OCR方法。为此，我们构建了全面的数据工程，覆盖了广泛的文本中心文档（如报纸、杂志和书籍）以及视觉中心渲染合成图像（包括图表、网页和科学图表）。此外，我们为OCRVerse提出了一种两阶段的SFT-RL多领域训练方法：SFT阶段通过直接混合跨领域数据进行训练以建立初步领域知识，而RL阶段则针对各领域特点设计个性化奖励策略。具体而言，由于不同领域需要多样化的输出格式和预期结果，我们在RL阶段提供了充分的灵活性，为每个领域定制灵活的奖励信号，从而提升跨领域融合效果并避免数据冲突。实验结果表明，OCRVerse在文本中心与视觉中心数据类型上均取得了具有竞争力的结果，其性能甚至可与大规模开源及闭源模型相媲美。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21639) | [arXiv](https://arxiv.org/abs/2601.21639)



---

### 6. MMFineReason：通过开放式数据驱动方法弥合多模态推理鸿沟

**原文标题：** MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods

**摘要：**
视觉语言模型（VLMs）的最新进展显著推动了视觉推理领域的发展。然而，开源VLMs仍落后于专有系统，其主要原因在于缺乏高质量推理数据。现有数据集在STEM图表、视觉谜题等挑战性领域的覆盖范围有限，且缺乏能够激发强大推理能力所必需的一致、长链思维过程标注。为弥合这一鸿沟，我们提出了MMFineReason——一个包含180万样本、51亿解答标记的大规模多模态推理数据集，其高质量推理标注源自Qwen3-VL-235B-A22B-Thinking模型的提炼。该数据集通过系统化的三阶段流程构建：（1）大规模数据收集与标准化，（2）思维链原理生成，（3）基于推理质量与难度感知的综合筛选。最终数据集涵盖STEM问题、视觉谜题、游戏及复杂图表，每个样本均配有基于视觉的推理轨迹标注。我们在MMFineReason上对Qwen3-VL-Instruct进行微调，开发出MMFineReason-2B/4B/8B系列模型。这些模型在其规模类别中均取得了最先进的性能。值得注意的是，MMFineReason-4B成功超越Qwen3-VL-8B-Thinking，而MMFineReason-8B甚至优于Qwen3-VL-30B-A3B-Thinking，并接近Qwen3-VL-32B-Thinking水平，展现出卓越的参数效率。关键的是，我们通过难度感知筛选策略发现了“少即是多”现象：仅使用7%（12.3万样本）的数据子集即可达到与完整数据集相当的性能。尤为重要的是，我们揭示了推理导向的数据组合能同步提升模型通用能力的协同效应。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21821) | [arXiv](https://arxiv.org/abs/2601.21821)



---

### 7. ConceptMoE：面向隐式计算分配的自适应令牌到概念压缩方法

**原文标题：** ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation

**摘要：**
大型语言模型通常对所有令牌进行均匀计算分配，忽略了某些序列易于预测而另一些则需要深度推理的特性。本文提出ConceptMoE模型，通过动态将语义相似的令牌合并为概念表示，实现隐式的令牌级计算分配。可学习的分块模块通过测量令牌间相似性确定最优边界，在序列进入计算密集型概念模型前按目标压缩比R进行压缩。关键创新在于混合专家架构实现了可控评估：我们重新分配节省的计算量以匹配基准激活浮点运算量（不含注意力图计算）和总参数量，从而分离出纯架构优势。在此条件下，ConceptMoE在语言与视觉语言任务中持续超越标准混合专家模型，在语言预训练任务上提升0.9个点，长上下文理解任务提升2.3个点，多模态基准任务提升0.6个点。通过层循环技术在持续训练中转换预训练混合专家模型时，性能增益可达5.5个点，证明了其实用价值。除性能提升外，ConceptMoE将注意力计算量最高降低R^2倍，键值缓存降低R倍。当R=2时，实际测量显示长序列的预填充速度最高提升175%，解码速度最高提升117%。该架构仅需最小改动即可无缝集成至现有混合专家系统，证明自适应概念级处理能从根本上提升大型语言模型的效能与效率。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21420) | [arXiv](https://arxiv.org/abs/2601.21420)



---

### 8. PLANING：一种用于流式三维重建的松耦合三角-高斯框架

**原文标题：** PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction

**摘要：**
基于单目图像序列的流式重建仍具挑战性，现有方法通常侧重高质量渲染或精确几何重建，难以兼顾二者。本文提出PLANING，一种高效的实时重建框架，其基于一种混合表示构建，将显式几何基元与神经高斯场进行松耦合，使得几何与外观能够以解耦方式进行建模。这种解耦机制支持一种在线初始化与优化策略，能够分离几何与外观的更新过程，从而实现结构冗余显著降低的稳定流式重建。PLANING在稠密网格Chamfer-L2指标上较PGSR提升18.52%，PSNR指标超越ARTDECO 1.31 dB，并在100秒内完成ScanNetV2场景重建，速度比二维高斯泼溅方法快5倍以上，同时达到与离线逐场景优化相当的质量。除重建质量外，PLANING清晰的结构表达与高效的计算性能使其广泛适用于各类下游应用，例如支持大规模场景建模及为具身智能构建可直接用于仿真的环境。项目页面：https://city-super.github.io/PLANING/。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22046) | [arXiv](https://arxiv.org/abs/2601.22046)



---

### 9. Qwen3-ASR技术报告

**原文标题：** Qwen3-ASR Technical Report

**摘要：**
本报告介绍了Qwen3-ASR系列模型，包括两款强大的一体化语音识别模型和一种新颖的非自回归语音强制对齐模型。Qwen3-ASR-1.7B与Qwen3-ASR-0.6B是支持52种语言及方言的语音识别与语种识别模型。两款模型均基于大规模语音训练数据及其基础模型Qwen3-Omni强大的音频理解能力构建。鉴于语音识别模型在开源基准测试中性能差异有限而在实际场景中可能表现出显著质量差距，我们在开源基准之外进行了全面的内部评估。实验表明：1.7B版本在开源语音识别模型中达到最优性能，并与最强的商业API表现相当；而0.6B版本实现了最佳的精度-效率平衡，其平均首字延迟可低至92毫秒，在128并发条件下能以1秒完成2000秒语音的转写。Qwen3-ForcedAligner-0.6B是基于大语言模型的非自回归时间戳预测器，可对11种语言的文本-语音对进行对齐。时间戳精度实验显示，该模型性能超越当前三种最强的强制对齐模型，并在效率与泛化能力方面更具优势。为加速语音识别与音频理解领域的社区研究，我们已将上述模型基于Apache 2.0协议开源发布。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21337) | [arXiv](https://arxiv.org/abs/2601.21337)



---

### 10. AgentLongBench：基于环境推演的受控长上下文智能体基准测试框架

**原文标题：** AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts

**摘要：**
大型语言模型向自主智能体的演进需要处理大规模动态上下文的能力。然而现有基准测试大多保持静态特性，依赖被动检索任务，无法模拟智能体与环境交互中的非线性推理与迭代反馈等复杂场景。为此，我们提出AgentLongBench基准框架，通过基于横向思维谜题的环境推演模拟来评估智能体性能。该框架能在知识密集型与知识无关场景中生成严格的交互轨迹。通过对先进模型与记忆系统（32K至400万词元规模）的实验，我们揭示出关键缺陷：智能体虽擅长静态检索，却难以完成工作流所必需的动态信息整合。分析表明，性能衰减主要受解析查询所需的最小词元数量驱动。这一发现解释了为何海量工具响应固有的高信息密度，比长轮对话中典型的内存碎片化问题带来更为严峻的挑战。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20730) | [arXiv](https://arxiv.org/abs/2601.20730)



---

### 11. 探索智能体推理奖励模型

**原文标题：** Exploring Reasoning Reward Model for Agents

**摘要：**
智能体强化学习在实现复杂推理与工具使用方面已取得显著成功。然而，现有方法仍主要依赖基于结果的稀疏奖励进行训练。此类反馈无法区分中间推理过程的质量，导致训练效果欠佳。本文提出智能体推理奖励模型，该多维度奖励模型可为智能体行为轨迹提供结构化反馈，包括：（1）显式推理轨迹；（2）聚焦式评析，通过指出推理缺陷提供改进指导；（3）评估过程性能的综合评分。基于这些反馈信号，我们系统研究了三种集成策略：文本增强改进型、奖励增强引导型与统一反馈集成型。在12个多样化基准测试中的广泛实验表明，统一反馈集成策略实现了性能跨越式提升——在GAIA基准上达到43.7%，在WebWalkerQA基准上达到46.2%，有效验证了推理奖励模型与训练方案的有效性。我们已公开代码、模型与数据集以促进后续研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22154) | [arXiv](https://arxiv.org/abs/2601.22154)



---

### 12. LoL：更长胜于长，将视频生成扩展至小时级别

**原文标题：** LoL: Longer than Longer, Scaling Video Generation to Hour

**摘要：**
近期长视频生成研究已从双向模型转向自回归模型，但这些方法普遍存在误差累积与长期连贯性丧失的问题。尽管注意力汇聚帧的引入缓解了性能衰减，却常引发一种我们称为“汇聚坍缩”的关键失效模式：生成内容反复回归至汇聚帧，导致场景突变重置与循环运动模式。通过分析发现，汇聚坍缩源于旋转位置编码的周期结构与当前生成模型中普遍采用的多头注意力机制之间的内在冲突。为解决此问题，我们提出一种轻量级、免训练的方法，通过引入多头旋转位置编码扰动来打破头间注意力同质化，从而有效抑制该现象并缓解长程坍缩。大量实验表明，该方法在保持生成质量的同时成功缓解了汇聚坍缩问题。据我们所知，本研究首次实现了质量几乎无衰减的实时、流式、无限长度视频生成。为验证其鲁棒性，我们生成了长达12小时的连续视频，这据我们所知是当前流式视频生成领域公开演示中最长的成果之一。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.16914) | [arXiv](https://arxiv.org/abs/2601.16914)



---

### 13. 经验时代下基于语言的试错法已显滞后

**原文标题：** Language-based Trial and Error Falls Behind in the Era of Experience

**摘要：**
尽管大语言模型在基于语言的代理任务中表现出色，但其在未见过的非语言环境（如符号或空间任务）中的适用性仍然有限。先前研究将这种性能差距归因于预训练分布与测试分布之间的不匹配。本研究指出，其主要瓶颈在于探索成本过高：掌握这些任务需要大量试错，这对于在高维语义空间中运行、参数量庞大的大语言模型而言，在计算上是不可持续的。为此，我们提出SCOUT（未见任务的子尺度协作框架），这是一种将探索与利用解耦的创新框架。我们采用轻量级“侦察模块”（如小型多层感知机）以远超大语言模型的速度和规模探测环境动态。收集到的轨迹数据通过监督微调引导大语言模型，再经过多轮强化学习激活其潜在的世界知识。实验表明，SCOUT使Qwen2.5-3B-Instruct模型平均得分达到0.86，显著优于包括Gemini-2.5-Pro（0.60）在内的专有模型，同时节省约60%的GPU时耗。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21754) | [arXiv](https://arxiv.org/abs/2601.21754)



---

### 14. 模型仓库中隐藏精品的发现研究

**原文标题：** Discovering Hidden Gems in Model Repositories

**摘要：**
公共模型仓库托管着数百万个微调模型，然而社区使用量仍不成比例地集中在少数基础检查点上。我们研究这种集中现象究竟反映了高效的市场选择机制，还是存在系统性忽略优质模型的问题。通过对2000多个模型进行大规模评估，我们揭示了"隐藏精品"现象的普遍性——这些不受欢迎的微调模型在性能上显著优于热门模型。值得注意的是，在Llama-3.1-8B模型系列中，我们发现某些极少被下载的检查点能够将数学推理性能从83.2%提升至96.0%，且不增加推理成本。然而，通过对每个上传模型进行穷举评估来发现优质模型在计算上是不可行的。为此，我们将模型发现问题建模为多臂赌博机问题，通过采用共享查询集和激进淘汰机制，对序列二分搜索算法进行加速优化。我们的方法仅需对每个候选模型进行50次查询即可检索出最优模型，将发现效率提升超过50倍。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22157) | [arXiv](https://arxiv.org/abs/2601.22157)



---

### 15. 面向离线偏好优化的隐式对抗正则化方法

**原文标题：** Latent Adversarial Regularization for Offline Preference Optimization

**摘要：**
基于人类反馈的学习通常依赖于偏好优化方法，该方法通过词元级正则化约束策略更新。然而，语言模型的偏好优化面临特殊挑战，因为词元空间的相似性并不等同于语义或行为层面的相似性。为解决这一问题，我们提出在语言模型偏好优化中引入隐空间正则化方法。我们设计了GANPO框架，通过惩罚策略模型与参考模型内部表征之间的差异来实现隐空间正则化。鉴于隐空间表征缺乏显式概率密度定义，我们采用受生成对抗网络启发的对抗训练方法以最小化隐空间差异。我们将GANPO作为正则化模块集成到现有离线偏好优化目标函数中。在多模型架构与多任务场景下的实验表明，隐空间正则化能带来持续的性能提升。进一步通过对比GANPO与词元级正则化引发的推理偏差，我们发现GANPO在分布偏移和噪声条件下能提供更稳健的结构化反馈，同时以微小的计算开销保持相当的下游任务性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22083) | [arXiv](https://arxiv.org/abs/2601.22083)



---

### 16. 可扩展的幂采样：通过分布锐化实现大语言模型高效免训练推理

**原文标题：** Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening

**摘要：**
强化学习后训练是提升大语言模型推理性能的主流方法，但越来越多的证据表明其效果提升主要源于分布锐化而非新能力的习得。近期研究表明，通过马尔可夫链蒙特卡洛方法从大语言模型的幂分布中采样，可在不依赖外部奖励的情况下达到与强化学习后训练相当的性能；然而，马尔可夫链蒙特卡洛的高计算成本限制了此类方法的广泛应用。本研究提出一种基于理论构建的替代方案，无需依赖迭代式马尔可夫链蒙特卡洛过程。我们推导出一种新颖的数学表述，证明全局幂分布可通过词元级缩放低温分布来近似，其中缩放因子能够捕捉未来轨迹的质量。基于这一发现，我们提出一种免训练且无需验证器的自回归算法，可逐级锐化基础模型的生成分布。我们在数学、问答和代码生成任务上对四种大语言模型进行实证评估，结果表明：该方法在不依赖任何外部奖励的情况下，性能达到或超越单次GRPO方法，同时相较于基于马尔可夫链蒙特卡洛的采样方法，推理延迟降低超过10倍。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21590) | [arXiv](https://arxiv.org/abs/2601.21590)



---

### 17. 基于词元级数据过滤的能力塑造

**原文标题：** Shaping capabilities with token-level data filtering

**摘要：**
当前减少语言模型中不良能力的方法大多属于事后干预，容易被对抗性手段规避。一种自然的替代方案是在预训练阶段直接塑造模型能力。以消除医疗能力为代理任务，本研究表明：简单的预训练数据过滤干预方法在大规模应用中具有高效性、鲁棒性和低成本优势。受数据归因研究的启发，我们证明词元级过滤比文档级过滤更有效，能够在降低对良性能力影响的同时达到同等的不良能力抑制效果。通过训练跨越两个数量级的模型，我们进一步证明过滤效果随模型规模扩大而增强：在最大规模模型中，词元过滤使目标遗忘领域的计算效率降低7000倍。研究还表明，经过词元过滤训练的模型仍可在遗忘领域进行对齐优化。本研究同步提出了一种基于稀疏自编码器的词元标注方法，并实现了低成本高质量分类器的知识蒸馏。实验同时证明，在充足预训练计算资源支持下，过滤方法对噪声标签具有良好鲁棒性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21571) | [arXiv](https://arxiv.org/abs/2601.21571)



---

### 18. Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B 技术报告

**原文标题：** Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report

**摘要：**
我们推出 Foundation-Sec-8B-Reasoning，这是首个面向网络安全领域的开源原生推理模型。该模型基于我们先前发布的 Foundation-Sec-8B 基础模型（源自 Llama-3.1-8B-Base），通过结合监督微调（SFT）和基于可验证奖励的强化学习（RLVR）的两阶段训练流程构建而成。我们的训练利用了涵盖网络安全分析、指令遵循和数学推理的专有推理数据。在 10 个网络安全基准测试和 10 个通用基准测试上的评估表明，该模型在网络安全任务上展现出与规模显著更大的模型相竞争的性能，同时保持了强大的通用能力。该模型在多跳推理任务上表现出有效的泛化能力，并在部署适当的系统提示和防护机制时展现出强大的安全性能。这项工作表明，领域专用的推理模型能够在保持广泛通用能力的同时，在专业任务上实现卓越性能。我们已在 https://huggingface.co/fdtn-ai/Foundation-Sec-8B-Reasoning 公开释放该模型。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21051) | [arXiv](https://arxiv.org/abs/2601.21051)



---

### 19. 台风-S：主权大语言模型的最小化开放式后训练方法

**原文标题：** Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models

**摘要：**
大语言模型（LLM）发展迅速，然而当前最先进的模型主要基于英语和汉语等高资源语言进行训练与评估，且往往由少数拥有大规模计算资源和数据的机构开发。这种技术壁垒为主权应用场景带来了实际障碍——在资源有限且透明度要求严格的条件下，区域或国家层面的机构或领域所有者需要对模型权重、训练数据和部署保持控制与理解。为此，我们提出两个核心要求：（1）可适配性：将基础模型转化为通用助手的能力；（2）主权能力：执行高风险、区域特定任务的能力（例如使用本地语言进行法律推理与文化知识应用）。本研究探讨是否能在不依赖海量指令数据、复杂偏好调优流程或大规模强化微调（RFT）的情况下实现这些目标。我们提出台风-S，一种最小化开放式后训练方案，融合监督微调、同策略蒸馏与小规模RFT。以泰语作为代表性案例，我们证明该方法可将主权适配型与通用型基础模型转化为具有强大通用性能的指令调优模型。进一步研究表明，采用InK-GRPO（通过在GRPO损失函数中增加下一词预测损失进行扩展）的小规模RFT能显著提升泰语法律推理与本土知识处理能力，同时保持通用性能。实验结果表明，精心设计的后训练策略可降低对指令数据规模和计算资源的需求，为在学术级资源条件下构建高质量主权大语言模型提供了可行路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18129) | [arXiv](https://arxiv.org/abs/2601.18129)



---

### 20. VTC-R1：面向高效长上下文推理的视觉-文本压缩方法

**原文标题：** VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning

**摘要：**
长上下文推理显著增强了大语言模型处理复杂任务的能力，但也因计算复杂度引入了严重的效率瓶颈。现有高效方法通常依赖复杂的额外训练或外部模型进行压缩，这限制了可扩展性并丢失了关键的细粒度信息。本文提出VTC-R1——一种集成视觉-文本压缩的新型高效推理范式。该方法将冗长的文本推理轨迹转化为紧凑的图像片段，作为"光学记忆"迭代输入视觉-语言模型，而非直接处理原始长文本。基于OpenR1-Math-220K构建的训练数据集实现了3.4倍的令牌压缩率，并对代表性视觉语言模型Glyph和Qwen3-VL进行微调。在MATH500、AIME25、AMC23和GPQA-D等基准测试上的大量实验表明，VTC-R1持续优于标准长上下文推理方法。此外，本方法显著提升了推理效率，端到端延迟加速比达2.7倍，凸显其作为推理密集型应用可扩展解决方案的潜力。代码已开源：https://github.com/w-yibo/VTC-R1。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22069) | [arXiv](https://arxiv.org/abs/2601.22069)



---

### 21. MAD：模态自适应解码——缓解多模态大语言模型中的跨模态幻觉问题

**原文标题：** MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models

**摘要：**
多模态大语言模型（MLLMs）普遍存在跨模态幻觉问题，即某一模态不适当地影响对其他模态内容的生成，导致输出结果失真。这暴露出当前模型在模态交互控制方面存在根本性缺陷。为解决这一问题，我们提出模态自适应解码方法（MAD），这是一种无需训练的技术，能够根据任务需求自适应地加权特定模态的解码分支。MAD通过查询每个任务所需模态，利用模型固有的模态相关性自评估能力。提取的模态概率随后用于自适应加权对比解码分支，使模型能够聚焦相关信息并抑制跨模态干扰。在CMM和AVHBench基准上的大量实验表明，MAD显著降低了多种视听语言模型的跨模态幻觉（VideoLLaMA2-AV模型提升7.8%和2.0%，Qwen2.5-Omni模型提升8.7%和4.7%）。我们的研究证明，通过自评估实现的显式模态感知对鲁棒的多模态推理至关重要，为现有对比解码方法提供了理论拓展。代码已开源：https://github.com/top-yun/MAD

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21181) | [arXiv](https://arxiv.org/abs/2601.21181)



---

### 22. 脑电图基础模型：进展、基准测试与开放性问题

**原文标题：** EEG Foundation Models: Progresses, Benchmarking, and Open Problems

**摘要：**
脑电图基础模型作为脑机接口领域一种新兴的范式，旨在从大规模异构脑电记录中学习可迁移的神经表征。尽管发展迅速，但由于预训练目标、预处理流程与下游评估方案缺乏统一标准，现有脑电图基础模型尚缺乏公平全面的性能比较。本文致力于填补这一空白。我们首先系统回顾了50个代表性模型，并将其设计要素归纳为包含数据标准化、模型架构与自监督预训练策略的统一分类框架。随后，我们在涵盖九类脑机接口范式的13个脑电数据集上，对12个开源基础模型及具有竞争力的专业基线模型进行了全面评估。为贴近实际应用场景，我们同时考察了留一被试协议下的跨被试泛化能力，以及被试内少样本场景下的快速校准性能。通过对比全参数微调与线性探测方法，我们进一步评估了预训练表征的可迁移性，并探究了模型规模与下游性能的关联。实验结果表明：1）线性探测方法往往性能不足；2）从头训练的专业模型在多类任务中仍具竞争力；3）在当前数据规模与训练范式下，扩大基础模型规模未必能提升泛化性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17883) | [arXiv](https://arxiv.org/abs/2601.17883)



---

### 23. DeepSearchQA：弥合深度研究智能体全面性差距的基准框架

**原文标题：** DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents

**摘要：**
本文提出DeepSearchQA，这是一个包含900个提示任务的基准测试集，用于评估智能体在17个不同领域中执行复杂多步骤信息检索任务的能力。与传统专注于单一答案检索或宽泛事实性验证的基准不同，DeepSearchQA通过精心设计的高难度任务数据集，重点评估智能体执行复杂搜索计划以生成穷尽式答案列表的能力。该设计范式转变旨在系统检验三项关键但未被充分评估的能力：1）从分散来源系统整合碎片化信息；2）通过去重与实体消歧确保答案精确性；3）在开放式搜索空间中合理设定终止条件。每个任务均构建为因果链式结构，后续步骤的信息发现依赖于前序步骤的成功完成，从而强调长程规划与上下文保持能力。所有任务均基于开放网络环境，并配备可客观验证的答案集。通过对前沿智能体架构的全面评估，我们揭示了显著的性能局限：即使最先进的模型也难以在高召回率与精确度之间取得平衡。我们观察到从过早终止（检索不足）到防御性检索行为等多种失效模式——后者表现为智能体通过过度扩展低置信度答案范围来人为提升召回率。这些发现凸显了当前智能体设计中的关键提升空间，并使DeepSearchQA成为推动未来研究向更稳健、更深层次研究能力发展的重要诊断工具。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20975) | [arXiv](https://arxiv.org/abs/2601.20975)



---

### 24. 超越模仿：基于强化学习的主动潜在规划

**原文标题：** Beyond Imitation: Reinforcement Learning for Active Latent Planning

**摘要：**
为实现高效且密集的思维链推理，潜在推理方法通过微调大语言模型，将离散的语言标记替换为连续的潜在标记。相较于传统的语言思维链推理，这类方法消耗的标记更少，并具备在密集潜在空间中进行规划的潜力。然而，现有潜在标记的监督通常基于对语言标签的模仿。考虑到同一问题可能存在多个等价但形式各异的思维链标签，被动模仿任意标签可能导致次优的潜在标记表示与推理策略，从而削弱模型的潜在规划能力，并造成训练与测试阶段的明显差距。本研究强调在潜在标记表示空间中进行主动规划对实现最优潜在推理策略的重要性。为此，我们提出主动潜在规划方法，该方法将潜在标记的监督过程建模为条件变分自编码器，以获得更平滑的潜在空间。此外，为构建最合理的潜在推理策略，该方法引入基于一致性的辅助奖励机制进行强化学习——该奖励通过计算潜在标记经变分自编码器解码内容的一致性生成，从而实现有导向的强化学习过程。在LLaMA-1B模型上的实验表明，相较于先进基线方法，本方法在四个基准测试中实现了准确率提升4.1%、标记消耗降低3.3%的效果。代码已开源：https://github.com/zz1358m/ATP-Latent-master。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21598) | [arXiv](https://arxiv.org/abs/2601.21598)



---

### 25. 基于像素均值流的单步无隐变量图像生成方法

**原文标题：** One-step Latent-free Image Generation with Pixel Mean Flows

**摘要：**
当前基于扩散/流模型的图像生成方法通常具有两个核心特征：(1)采用多步采样策略，(2)在隐空间中进行操作。近期研究已在这两个独立方面取得显著进展，为无需隐空间的单步扩散/流模型奠定了基础。本研究朝着该目标迈出关键一步，提出"像素均值流"方法。我们的核心设计原则是将网络输出空间与损失空间进行分离：网络输出目标被设计在预设的低维图像流形上（即x预测），而损失函数则通过速度空间中的均值流进行定义。我们引入了一种图像流形与平均速度场之间的简洁转换机制。实验表明，在ImageNet数据集256×256分辨率（FID 2.22）和512×512分辨率（FID 2.48）的单步无隐变量生成任务中，像素均值流方法取得了优异性能，填补了该领域的关键技术空白。本研究有望进一步拓展基于扩散/流模型的生成方法边界。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22158) | [arXiv](https://arxiv.org/abs/2601.22158)



---

### 26. 混合线性注意力机制的正确实现：面向超长上下文的高效蒸馏与有效架构

**原文标题：** Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts

**摘要：**
混合Transformer架构通过结合Softmax注意力模块与循环神经网络（RNN），在长上下文建模中展现出理想的性能与计算效率平衡，但其大规模从头预训练的巨大成本阻碍了该架构的广泛应用与研究。近期研究表明，通过参数迁移与知识蒸馏可将预训练的Softmax注意力模块转化为RNN模块。然而，现有迁移方法需要海量训练数据（超过100亿词元），且所得混合模型在长上下文场景中表现欠佳——而这正是混合模型相比传统Transformer模型具备显著推理加速优势的场景。本文提出HALO（基于层优化的混合注意力）流程，用于将Transformer模型蒸馏为RNN-注意力混合模型。进而提出HypeNet混合架构，该架构通过新型位置编码方案（命名为HyPE）及多项结构改进，实现了卓越的长度泛化能力。我们运用HALO将Qwen3系列模型转化为HypeNet，在保持与原Transformer模型相当性能的同时，获得了更优的长上下文处理性能与效率。该转化过程仅需23亿词元，不足其预训练数据量的0.01%。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22156) | [arXiv](https://arxiv.org/abs/2601.22156)



---

### 27. FineInstructions：将合成指令扩展至预训练规模

**原文标题：** FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale

**摘要：**
由于监督训练数据有限，大型语言模型通常通过自监督的“预测下一个词”目标在海量非结构化文本数据上进行预训练。为使模型能有效服务于用户，还需使用规模小得多的“指令调优”数据进行进一步训练，该数据由指令与响应的监督训练样本构成。为突破监督数据量的限制，本研究提出一种方法，可将互联网规模预训练文档中的知识转化为数十亿条合成指令与答案训练对。由此构建的数据集名为FineInstructions，其利用约1800万个基于真实用户查询与提示构建的指令模板。这些指令模板通过与来自非结构化预训练语料库的人工撰写源文档进行匹配与实例化，生成大规模“监督式”合成训练数据。基于此规模的数据，大型语言模型可完全通过指令调优目标从头开始预训练，该目标与模型下游应用场景（响应用户提示）的分布特性高度契合。通过开展严格的逐词元训练对比实验，我们发现基于FineInstructions的预训练在衡量自由形式响应质量的基准测试中，表现优于标准预训练及其他已提出的合成预训练技术。相关资源详见 https://huggingface.co/fineinstructions。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22146) | [arXiv](https://arxiv.org/abs/2601.22146)



---

### 28. KromHC：基于克罗内克积残差矩阵的流形约束超连接

**原文标题：** KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices

**摘要：**
超连接在神经网络中的成功应用也凸显了其训练不稳定性和可扩展性受限的问题。流形约束超连接通过将残差连接空间投影到Birkhoff多胞体来缓解这些挑战，但仍面临两个问题：1）其迭代Sinkhorn-Knopp算法并不总能生成精确的双随机残差矩阵；2）当残差流宽度为n、特征维度为C时，mHC会产生高达O(n^3C)的参数复杂度。最近提出的mHC-lite通过Birkhoff-von-Neumann定理对残差矩阵进行重参数化以保证双随机性，但其参数复杂度也面临阶乘爆炸问题，达到O(nC·n!)。为同时解决这两个挑战，我们提出KromHC方法，该方法使用较小双随机矩阵的克罗内克积来参数化mHC中的残差矩阵。通过对张量化残差流各模态上的因子残差矩阵施加流形约束，KromHC在保证残差矩阵精确双随机性的同时，将参数复杂度降低至O(n^2C)。综合实验表明，KromHC在性能上达到甚至超越了最先进的mHC变体，且所需可训练参数显著减少。代码已发布于https://github.com/wz1119/KromHC。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21579) | [arXiv](https://arxiv.org/abs/2601.21579)



---

### 29. 自我改进的预训练方法：利用后训练模型预训练更优模型

**原文标题：** Self-Improving Pretraining: using post-trained models to pretrain better models

**摘要：**
确保大语言模型生成内容的安全性、事实性与整体质量是一项关键挑战，尤其在模型日益广泛应用于现实场景的背景下。当前主流解决方案依赖于收集成本高昂、精心标注的数据集，并实施多阶段的微调与对齐流程。然而，即使采用如此复杂的处理流程，仍无法完全修正模型在预训练阶段习得的不良模式。因此，在预训练阶段解决这些问题至关重要，因为该阶段塑造了模型的核心行为模式，能从根本上避免不安全或虚构内容被深度固化。为应对这一挑战，我们提出一种新型预训练方法：该方法通过流式文档处理，运用强化学习技术逐步优化后续K个生成标记。在这一过程中，一个经过充分后训练的强模型将对候选生成内容（包括模型自生成序列、原始文本后缀及重写后缀）进行质量、安全性与事实性评估。训练初期，系统主要依赖原始文本与重写后缀；随着模型性能提升，强化学习机制将对高质量自生成序列给予奖励。该方法实现了从底层构建更优质、更安全、更符合事实的模型。实验结果表明，相较于标准预训练方法，本方案在事实性指标上取得36.2%的相对提升，安全性指标提升18.5%，在整体生成质量评估中最高可获得86.3%的胜率提升。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21343) | [arXiv](https://arxiv.org/abs/2601.21343)



---

### 30. ECO：无需全精度主权重的量化训练方法

**原文标题：** ECO: Quantized Training without Full-Precision Master Weights

**摘要：**
量化技术已显著提升大语言模型（LLM）训练的计算与内存效率。然而，现有方法仍需依赖高精度累积更新：具体而言，梯度更新必须作用于高精度权重缓冲区（即主权重）。该缓冲区会带来显著的内存开销，尤其在稀疏专家混合模型中，模型参数与优化器状态占据了内存使用的主要部分。为解决这一问题，我们提出误差补偿优化器，该方法通过直接将更新应用于量化参数，从而消除了主权重。ECO在每一步训练后量化权重，并将产生的量化误差精确注入优化器动量中，形成一个无需额外内存的误差反馈循环。我们证明，在标准假设与递减学习率的条件下，ECO能够收敛至最优解的常数半径邻域内，而简单移除主权重的方法可能产生与学习率成反比的误差。我们展示了在FP8量化下预训练小型Transformer模型（参数量3千万至8亿）、Gemma-3 1B模型及21亿参数稀疏专家混合模型的实证结果，以及在INT4精度下微调DeepSeek-MoE-16B模型的结果。实验表明，ECO在保持近乎无损精度的前提下，与使用主权重的基线方法性能相当，显著改善了静态内存与验证损失之间的帕累托前沿边界。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22101) | [arXiv](https://arxiv.org/abs/2601.22101)



---

### 31. Metric Anything：利用异构噪声源扩展度量深度预训练

**原文标题：** MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources

**摘要：**
规模化推动了视觉基础模型的近期进展，但将这一范式扩展到度量深度估计仍面临挑战，主要源于异构传感器噪声、相机相关偏差以及跨源噪声三维数据中的度量模糊性。本文提出Metric Anything，一个简单且可扩展的预训练框架，能够直接从噪声多样化的三维数据中学习度量深度，无需人工设计提示、相机特定建模或任务专用架构。方法的核心是稀疏度量提示——通过随机掩码深度图生成，其作为通用接口将空间推理与传感器及相机偏差解耦。利用涵盖重建、采集和渲染三维数据约2000万张图像-深度对（涉及10000种相机模型），我们首次在度量深度领域证明了清晰的规模化趋势。预训练模型在提示驱动任务（如深度补全、超分辨率及雷达-相机融合）中表现优异，其蒸馏出的无提示学生模型在单目深度估计、相机内参恢复、单/多视角度量三维重建及视觉语言动作规划任务中达到最先进水平。我们还证明，将Metric Anything的预训练ViT作为视觉编码器可显著提升多模态大语言模型的空间推理能力。这些结果表明，度量深度估计能够受益于驱动现代基础模型的相同规模化定律，为可扩展、高效的真实世界度量感知开辟了新路径。我们在http://metric-anything.github.io/metric-anything-io/开源Metric Anything以支持社区研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22054) | [arXiv](https://arxiv.org/abs/2601.22054)



---

### 32. 机制化数据归因：追溯可解释大语言模型单元的训源

**原文标题：** Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units

**摘要：**
尽管机制可解释性研究已在大语言模型中发现可解释电路，但其在训练数据中的因果起源仍不明确。本文提出机制化数据归因框架——一种基于影响函数的可扩展方法，能够将可解释单元溯源至具体训练样本。通过对Pythia模型系列的系列实验，我们通过因果验证发现：针对性地干预（移除或增强少量高影响力样本）能显著调节可解释注意力头的形成，而随机干预则无此效果。分析表明，重复性结构化数据（如LaTeX、XML）发挥着机制催化作用。进一步研究发现，针对归纳头形成的干预会同步改变模型的上下文学习能力，这为"归纳头与上下文学习存在功能关联"的长期假设提供了直接因果证据。最后，我们提出一种机制化数据增强流程，该流程能在不同模型规模下持续加速电路收敛，为引导大语言模型发展轨迹提供了理论化方法。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21996) | [arXiv](https://arxiv.org/abs/2601.21996)



---

### 33. 通过多表征生成增强统一多模态模型的理解能力

**原文标题：** Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation

**摘要：**
统一多模态模型（UMMs）在单一框架内整合了视觉理解与生成能力，其最终目标是构建理解与生成相互促进的循环机制。尽管近期的后训练方法已成功利用理解能力提升生成质量，但如何通过生成任务增强理解能力的研究仍较为缺乏。本研究提出UniMRG（统一多表征生成），一种简洁且与模型架构无关的后训练方法。该方法通过引入辅助生成任务增强UMMs的理解能力：在标准视觉理解任务基础上，训练模型同步生成输入图像的多种内在表征——包括像素（重建）、深度（几何）与分割（结构）信息。通过合成这些多样化表征，UMMs能够捕捉关于外观特征、空间关系与结构布局的互补信息，从而形成对视觉输入更深入、更全面的理解。跨多种UMM架构的大量实验表明，本方法显著提升了模型的细粒度感知能力，减少了幻觉现象，改善了空间理解性能，同时进一步强化了其生成能力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21406) | [arXiv](https://arxiv.org/abs/2601.21406)



---

### 34. BMAM：类脑多智能体记忆框架

**原文标题：** BMAM: Brain-inspired Multi-Agent Memory Framework

**摘要：**
基于语言模型的智能体在长程交互中持续面临两大挑战：难以保持基于时间线的信息连贯性，以及无法维持跨会话的行为一致性——我们将这种失效模式称为“灵魂侵蚀”。本文提出BMAM（类脑多智能体记忆框架），该通用型记忆架构将智能体记忆建模为功能专化的子系统集合，而非单一非结构化存储。受认知记忆系统启发，BMAM将记忆解构为情景记忆、语义记忆、显著性感知记忆与调控导向记忆四个在互补时间尺度运作的组件。为支持长程推理，BMAM沿显式时间轴组织情景记忆，并通过融合多重互补信号实现证据检索。在LoCoMo基准测试中，BMAM在标准长程评估设定下达到78.45%的准确率，消融实验证实受海马体启发的的情景记忆子系统在时序推理中具有关键作用。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20465) | [arXiv](https://arxiv.org/abs/2601.20465)



---

### 35. JUST-DUB-IT：基于联合视听扩散模型的视频配音方法

**原文标题：** JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion

**摘要：**
视听基础模型通过预训练联合生成声音与视觉内容，近期在多模态生成与编辑任务中展现出前所未有的建模能力，为下游应用开辟了新机遇。视频配音任务尤其能受益于此，但现有方案大多依赖复杂且任务特定的流程，难以应对真实场景的挑战。本研究提出一种单模型解决方案，通过轻量化的LoRA模块适配基础视听扩散模型，实现视频到视频的配音转换。该LoRA模块使模型能够以输入音视频为条件，同步生成翻译后的音频与协调的面部动作。为训练此模块，我们利用生成模型自身合成同一发言者的多语言配对视频：首先生成包含单片段内语言切换的多语言视频，随后对每半段视频的面部与音频进行修复，使其与另一半的语言特征相匹配。通过充分挖掘视听模型丰富的生成先验，本方法在保持说话者身份特征与唇形同步的同时，对复杂动作和真实场景动态具有强鲁棒性。实验表明，相较于现有配音流程，本方法生成的配音视频在视觉保真度、唇形同步性与鲁棒性方面均表现出更优品质。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.22143) | [arXiv](https://arxiv.org/abs/2601.22143)



---

### 36. FROST：基于注意力机制过滤推理异常值的高效推理方法

**原文标题：** FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning

**摘要：**
本文提出FROST，一种基于注意力感知的高效推理方法。与传统方法不同，FROST通过利用注意力权重剪枝非关键推理路径，从而生成更简短且更可靠的推理轨迹。在方法论上，我们引入推理异常值的概念，并设计了一种基于注意力的机制来消除这些异常值。从理论层面看，FROST在保持并增强模型推理能力的同时，实现了句子级别的异常值剔除。通过实证研究，我们在四个基准测试中使用两种强推理模型（Phi-4-Reasoning和GPT-OSS-20B）验证了FROST的有效性，其性能优于TALE和ThinkLess等前沿方法。值得注意的是，与基础模型相比，FROST平均降低了69.68%的令牌使用量，并将准确率提升了26.70%。此外，在注意力异常值指标评估中，FROST相较于基础模型将最大无穷范数降低了15.97%，平均峰度减少了91.09%。代码已开源：https://github.com/robinzixuan/FROST

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.19001) | [arXiv](https://arxiv.org/abs/2601.19001)



---

### 37. 基于元评估的强化学习：无需真实标签的语言模型对齐方法

**原文标题：** Reinforcement Learning from Meta-Evaluation: Aligning Language Models Without Ground-Truth Labels

**摘要：**
当前大多数用于训练大语言模型的强化学习方法依赖于真实标签或特定任务验证器，当答案正确性难以界定或标注成本高昂时，该方法可扩展性受限。本文提出基于元评估的强化学习方法，通过自然语言元问题（如“该答案正确吗？”或“推理过程是否逻辑一致？”）的评估结果生成奖励信号，以此优化生成模型。该方法将评估者对正向判断的概率作为奖励函数，采用组相对策略优化算法更新生成器，实现无需人工标注的学习机制。实验表明：该方法在准确率和样本效率上达到与基于标签训练相当的水平；支持多目标间的可控权衡；能够引导模型形成可靠推理模式而非事后合理化；在缺乏真实标签的开放域场景中展现出良好泛化能力，从而拓展了强化学习在大语言模型训练中的应用边界。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21268) | [arXiv](https://arxiv.org/abs/2601.21268)



---

### 38. 基于对比分析的代码环境奖励攻击检测基准研究

**原文标题：** Benchmarking Reward Hack Detection in Code Environments via Contrastive Analysis

**摘要：**
代码生成强化学习的最新进展使得构建鲁棒环境以防止奖励攻击变得至关重要。随着大语言模型日益成为基于代码的强化学习评估器，其检测奖励攻击的能力仍未得到充分研究。本文提出了一种涵盖54个类别的新型奖励利用分类法，并引入了TRACE（代码环境中的奖励异常测试基准）——一个包含517条测试轨迹的合成策划且经过人工验证的基准数据集。与以往在孤立分类场景中评估奖励攻击检测的研究不同，我们在TRACE基准上采用更具现实性的对比异常检测框架进行对比评估。实验表明，模型在对比设置中比在孤立分类设置中能更有效地识别奖励攻击：在TRACE基准上，最高推理模式的GPT-5.2检测率从孤立设置的45%提升至63%。基于这一发现，我们证明当前最先进的模型对语义上下文化奖励攻击的处理能力明显弱于对句法上下文化攻击的处理。我们进一步对模型行为进行了定性分析，并通过消融实验表明：良性轨迹与攻击轨迹的比例以及分析聚类规模会显著影响检测性能。我们公开了基准数据集与评估工具，以支持学术界扩展TRACE基准并评估其模型性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20103) | [arXiv](https://arxiv.org/abs/2601.20103)



---

### 39. 分段长度的重要性：分段长度对音频指纹识别性能的影响研究

**原文标题：** Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance

**摘要：**
音频指纹识别技术能够为声学信号生成可识别的表征，该表征可后续应用于身份识别与检索系统。为获得具有区分度的表征，输入音频通常被分割为较短的时间片段，以便提取和分析局部声学特征。现代神经网络方法通常基于短时、固定时长的音频片段进行处理，然而片段时长的选择往往依赖经验性判断，鲜有深入研究。本文系统研究了分段长度对音频指纹识别性能的影响。我们扩展了现有神经指纹识别架构以适配不同分段长度，并评估了不同分段长度与查询时长条件下的检索准确率。实验结果表明，较短的分段长度（0.5秒）通常能获得更优性能。此外，我们评估了大语言模型在推荐最佳分段长度方面的能力，研究发现：在三种测试的大语言模型中，GPT-5-mini在五项评估维度上均能持续提供最佳建议。本研究为大规模神经音频检索系统中分段时长的选择提供了实践指导。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17690) | [arXiv](https://arxiv.org/abs/2601.17690)



---

### 40. PRISM：从数据中学习设计知识以实现风格化设计改进

**原文标题：** PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement

**摘要：**
平面设计通常涉及探索不同的风格方向，这对非专业人士而言可能耗时费力。本文研究如何基于自然语言指令实现设计的风格化改进。尽管视觉语言模型在平面设计领域已取得初步成功，但其预训练的风格知识往往过于笼统，且与特定领域数据存在偏差。例如，视觉语言模型可能将极简主义与抽象设计相关联，而设计师更注重形状与色彩的选择。我们的核心思路是利用设计数据——即隐含设计师原则的真实设计案例集合——来学习设计知识并指导风格化改进。我们提出PRISM（先验信息驱动的风格化修改）方法，通过三个阶段构建并应用设计知识库：（1）对高方差设计进行聚类以捕捉风格内部的多样性；（2）将每个聚类总结为可操作的设计知识；（3）在推理过程中检索相关知识以实现风格感知的改进。在Crello数据集上的实验表明，PRISM在风格对齐任务中以1.49的平均排名（越接近1越好）优于基线方法。用户研究进一步验证了这些结果，显示设计师对PRISM方案具有持续偏好。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11747) | [arXiv](https://arxiv.org/abs/2601.11747)



---

### 41. WebArbiter：一种面向网络智能体的原则引导推理过程奖励模型

**原文标题：** WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents

**摘要：**
网络智能体在自动化复杂计算机任务方面具有巨大潜力，但其交互过程涉及长周期、序列化的决策，且包含不可逆操作。在此类场景中，基于结果的监督信号稀疏且延迟，往往会对错误轨迹给予奖励，且无法支持推理时的扩展需求。这促使了过程奖励模型在网络导航任务中的应用，但现有方法仍存在局限：标量型网络过程奖励模型将进展压缩为粗糙且缺乏依据的信号，而基于清单的网络过程奖励模型依赖脆弱的模板匹配机制，在界面布局或语义发生变化时容易失效，并常将表面正确的动作误判为成功，导致模型可解释性与洞察力不足。为解决这些挑战，我们提出WebArbiter——一种推理优先、原则引导的网络过程奖励模型。该模型将奖励建模构建为文本生成任务，生成结构化的推理依据，最终输出偏好判定并识别当前情境下最有利于任务完成的动作。训练采用两阶段流程：推理蒸馏阶段使模型掌握连贯的原则引导推理能力，强化学习阶段则通过直接对齐判定结果与正确性来修正教师模型偏差，从而提升泛化性能。为支持系统化评估，我们发布了WebPRMBench基准测试集，涵盖四个多样化网络环境，包含丰富任务场景与高质量偏好标注。在WebPRMBench上，WebArbiter-7B以9.1分的优势超越最强基线模型GPT-5。在WebArena-Lite的奖励引导轨迹搜索任务中，其表现较现有最优网络过程奖励模型提升最高达7.2分，彰显了其在现实复杂网络任务中的鲁棒性与实用价值。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21872) | [arXiv](https://arxiv.org/abs/2601.21872)



---

### 42. 聚焦任务相关特征：以物体为中心的表示方法提升机器人操作泛化能力

**原文标题：** Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation

**摘要：**
机器人操作策略的泛化能力在很大程度上受视觉表示选择的影响。现有方法通常依赖于预训练编码器提取的表示，主要采用两种特征类型：全局特征（通过单一池化向量概括整幅图像）和密集特征（保留编码器最终层的分块嵌入）。尽管广泛应用，这两种特征类型均混合了任务相关与无关信息，导致在光照、纹理变化或存在干扰物等分布偏移情况下泛化性能较差。本研究探索了一种中间结构化替代方案：基于槽位的物体中心表示（SBOCR），该方法将密集特征分组为有限个类物体实体。这种表示能够自然减少提供给机器人操作策略的噪声，同时保留足够信息以高效执行任务。我们在从简单到复杂的模拟及现实世界操作任务套件中，系统比较了多种全局特征、密集特征与基于槽位的中间表示方法，并评估了它们在光照、纹理变化及存在干扰物等不同视觉条件下的泛化性能。实验结果表明，即使无需任务特定预训练，基于SBOCR的策略在泛化场景中仍优于基于密集特征和全局特征的策略。这些发现表明，SBOCR为设计能在动态现实机器人环境中有效泛化的视觉系统提供了有前景的研究方向。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21416) | [arXiv](https://arxiv.org/abs/2601.21416)



---

### 43. WorldBench：面向世界模型诊断性评估的物理概念解耦基准

**原文标题：** WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models

**摘要：**
生成式基础模型（常被称为“世界模型”）的最新进展，推动了其在机器人规划与自主系统训练等关键任务中的应用兴趣。为确保可靠部署，此类模型必须具备高物理保真度，能够准确模拟真实世界动态。然而，现有基于物理的视频基准普遍存在概念耦合问题——单个测试同时评估多项物理定律与概念，这从根本上限制了其诊断能力。本文提出WorldBench，一个专门设计用于概念特异性解耦评估的新型视频基准，支持对单一物理概念或定律的理解进行严格隔离与评估。为构建全面评估体系，我们设计了两个层次的基准：1）针对物体恒存性、尺度/透视等概念的直观物理理解评估；2）针对摩擦系数、流体黏度等底层物理常数与材料属性的评估。通过对当前最先进的视频世界模型在WorldBench上进行测试，我们发现所有受测模型均存在特定物理概念上的系统性缺陷，且缺乏生成可靠真实世界交互所需的物理一致性。WorldBench通过其概念特异性评估机制，为视频生成与世界模型的物理推理能力提供了更精细、可扩展的严谨评估框架，为构建更鲁棒、更具泛化能力的世界模型驱动学习开辟了新路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.21282) | [arXiv](https://arxiv.org/abs/2601.21282)



---

### 44. STORM：面向机器人操作的基于槽位的任务感知物体中心表征

**原文标题：** STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation

**摘要：**
视觉基础模型为机器人学提供了强大的感知特征，但其稠密表征缺乏显式的物体级结构，限制了操作任务中的鲁棒性与可操作性。我们提出STORM（面向机器人操作的基于槽位的任务感知物体中心表征），这是一种轻量级的物体中心适配模块，通过为机器人操作引入少量语义感知槽位来增强冻结的视觉基础模型。STORM采用多阶段训练策略而非重新训练大型骨干网络：首先通过语言嵌入的视觉-语义预训练稳定物体中心槽位，随后与下游操作策略联合适配。这种分阶段学习避免了槽位退化形成，在保持语义一致性的同时使感知与任务目标对齐。在物体发现基准测试与仿真操作任务上的实验表明，相较于直接使用冻结基础模型特征或端到端训练物体中心表征，STORM能提升对视觉干扰物的泛化能力与控制性能。我们的研究结果凸显了多阶段适配作为一种高效机制，能够将通用基础模型特征转化为面向机器人控制的任务感知物体中心表征。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.20381) | [arXiv](https://arxiv.org/abs/2601.20381)



---

### 45. 基于流模型的极值数学结构发现

**原文标题：** Flow-based Extremal Mathematical Structure Discovery

**摘要：**
数学中极值结构的发现需要在广阔且非凸的搜索空间中探索，分析方法难以提供有效指导，而暴力搜索又不可行。本文提出FlowBoost——一种闭环生成框架，通过整合三个核心组件学习发现稀有且极值的几何结构：（一）几何感知的条件流匹配模型，学习采样高质量构型；（二）奖励引导的策略优化与动作探索机制，在保持多样性的同时直接优化生成过程以趋近目标；（三）用于训练数据生成与最终优化的随机局部搜索。与以往的开环方法（如基于过滤离散样本重新训练的PatternBoost，或依赖冻结大语言模型作为进化变异算子的AlphaEvolve）不同，FlowBoost在采样过程中强制保证几何可行性，并将奖励信号直接反馈至生成模型，从而形成闭环优化。该方法大幅减少了对训练数据量和训练时长的需求，将外层循环迭代次数降低数个数量级，同时消除了对大语言模型的依赖。我们在四个几何优化问题上验证了该框架：超立方体中的球体填充、半径和最大化的圆盘填充、Heilbronn三角形问题以及星形差异最小化。在多个案例中，FlowBoost发现的构型达到或超越了已知最优结果。对于圆盘填充问题，我们提升了已知下界，在显著减少计算资源消耗的同时超越了基于大语言模型的AlphaEvolve系统。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18005) | [arXiv](https://arxiv.org/abs/2601.18005)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2026-01-30_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)