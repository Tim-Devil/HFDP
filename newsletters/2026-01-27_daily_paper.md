
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-27 论文日报

## 📊 今日论文统计
- 总论文数：40
- 热门领域：LLM, Transformer, GPT, RL

## 📝 论文详情


### 1. 大语言模型能否清理数据乱局？基于LLM的应用就绪型数据准备技术综述

**原文标题：** Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs

**摘要：**
数据准备旨在对原始数据集进行去噪处理、揭示跨数据集关联并从中提取有价值的洞见，这对各类以数据为中心的应用至关重要。在三大驱动力推动下——（一）对应用就绪型数据（如用于分析、可视化、决策支持）的需求日益增长，（二）大语言模型技术能力持续增强，（三）支持灵活智能体构建的基础设施兴起（例如基于Databricks Unity Catalog的架构）——基于大语言模型增强的数据准备方法正迅速成为该领域的变革性范式，并可能占据主导地位。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17058) | [arXiv](https://arxiv.org/abs/2601.17058)



---

### 2. daVinci-Dev：面向软件工程的智能体原生中期训练

**原文标题：** daVinci-Dev: Agent-native Mid-training for Software Engineering

**摘要：**
近年来，大型语言模型（LLM）能力的前沿已从单轮代码生成转向智能体化软件工程——即模型能够自主导航、编辑和测试复杂代码仓库的范式。尽管后训练方法已成为代码智能体的事实标准，但**智能体中期训练**——在模拟真实智能体工作流程的大规模数据上进行中期训练（MT）——虽比单纯依赖昂贵的强化学习提供了更具扩展性的基础智能体行为培养路径，却因资源需求巨大而仍未得到充分探索。实现有效智能体中期训练的核心挑战在于静态训练数据与真实开发中动态、富含反馈的环境之间的分布不匹配。为解决这一问题，我们对智能体中期训练进行了系统性研究，建立了大规模有效智能体开发的数据合成原则与训练方法。我们方法的核心是**智能体原生数据**——包含两种互补类型轨迹的监督数据：**上下文原生轨迹**，完整保留智能体所经历的信息流，提供广泛的覆盖范围和多样性；以及**环境原生轨迹**，从可执行代码仓库中收集，其观测结果源自实际工具调用和测试执行，提供深度和交互真实性。我们在`SWE-Bench Verified`上验证了模型的智能体能力。在采用对齐基础模型和智能体框架的两种后训练设置下，我们证明了本方法优于先前开放的软件工程中期训练方案`Kimi-Dev`，同时使用了不到一半的中期训练词元（730亿）。除相对优势外，我们表现最佳的320亿和720亿参数模型分别实现了**56.1%**和**58.5%**的问题解决率，这些结果……

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18418) | [arXiv](https://arxiv.org/abs/2601.18418)



---

### 3. 剧本即一切：面向长时程对话-电影视频生成的智能体框架

**原文标题：** The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation

**摘要：**
近期视频生成技术的进展已能根据简单文本提示合成令人惊叹的视觉内容。然而，现有模型难以从对话等高层次概念中生成长篇幅、连贯的叙事内容，这揭示了创意构想与其影像化呈现之间存在“语义鸿沟”。为弥合这一鸿沟，我们提出了一种新颖的端到端智能体框架，用于实现从对话到电影视频的生成。该框架的核心是剧本生成智能体，该模型经训练可将粗粒度对话转化为细粒度、可执行的电影剧本。为此，我们构建了ScriptBench——一个通过专家指导流程标注、包含丰富多模态上下文的大规模新基准数据集。生成的剧本随后指导导演智能体，该智能体采用跨场景连续生成策略协调多个前沿视频模型，以确保长时程叙事连贯性。我们通过AI驱动的评论智能体及新提出的视觉-剧本对齐指标展开综合评估，结果表明本框架在所有测试视频模型上均显著提升了剧本忠实度与时序保真度。进一步分析揭示了当前先进模型在视觉表现力与严格剧本遵循性之间存在关键权衡，这为自动化电影制作的未来发展提供了重要启示。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17737) | [arXiv](https://arxiv.org/abs/2601.17737)



---

### 4. 科学图像合成：基准测试、方法论与下游应用价值

**原文标题：** Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility

**摘要：**
尽管合成数据在提升文本领域科学推理能力方面已被证明有效，但多模态推理仍受限于生成科学严谨图像的困难。现有文本到图像（T2I）模型常生成视觉合理但科学错误的输出，导致持续的视觉-逻辑偏差，限制了下游推理的应用价值。基于新一代T2I模型的最新进展，本研究对科学图像合成的生成范式、评估方法及下游应用进行了系统性探讨。我们分析了基于像素的直接生成与程序化合成两种路径，并提出ImgCoder——一种遵循显式“理解-规划-编码”工作流程的逻辑驱动框架，以提升结构精确性。为严格评估科学正确性，我们构建了SciGenBench基准，从信息效用与逻辑有效性两个维度评估生成图像。实验揭示了基于像素模型的系统性缺陷，并指出表达力与精确度之间存在根本性权衡。最后，我们证明基于严格验证的科学合成图像对大型多模态模型（LMMs）进行微调，能持续提升其推理能力，其扩展潜力与文本域具有相似规律，这验证了高保真科学图像合成可作为释放海量多模态推理能力的可行路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17027) | [arXiv](https://arxiv.org/abs/2601.17027)



---

### 5. 弹性注意力：面向高效Transformer的测试时自适应稀疏比率

**原文标题：** Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers

**摘要：**
标准注意力机制的二次复杂度在长上下文场景下对大型语言模型（LLM）的可扩展性构成了显著瓶颈。尽管在单一模型中结合稀疏注意力与全注意力的混合注意力策略提供了可行解决方案，但这些策略通常采用静态计算比率（即稀疏注意力与全注意力的固定比例），无法在推理过程中适应下游任务对稀疏性的动态敏感度差异。为解决此问题，我们提出弹性注意力机制，使模型能够根据输入动态调整整体稀疏度。该方法通过在现有预训练模型中集成轻量级注意力路由器实现，该路由器能够动态为每个注意力头分配不同的计算模式。仅需在8张A800 GPU上进行12小时训练，我们的方法即可使模型同时实现强劲性能与高效推理。在多个广泛使用的LLM上进行的三个长上下文基准测试实验证明了本方法的优越性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17367) | [arXiv](https://arxiv.org/abs/2601.17367)



---

### 6. iFSQ：一行代码改进FSQ以提升图像生成性能

**原文标题：** iFSQ: Improving FSQ for Image Generation with 1 Line of Code

**摘要：**
当前图像生成领域主要分为基于离散令牌的自回归模型和利用连续隐变量的扩散模型。这一分野根植于VQ-VAE与VAE的差异，阻碍了统一建模与公平基准评估。有限标量量化（FSQ）提供了理论桥梁，但原始FSQ存在关键缺陷：其等间隔量化机制可能导致激活崩溃。这种不匹配迫使模型在重建保真度与信息效率之间进行权衡。本研究通过将原始FSQ中的激活函数替换为分布匹配映射以强制均匀先验，从而解决了这一困境。该方法被命名为iFSQ，仅需一行代码即可在数学上同时保证最优的量化箱利用率和重建精度。借助iFSQ作为受控基准，我们揭示了两个关键发现：（1）离散与连续表示之间的最优平衡点约为每维度4比特；（2）在相同重建约束下，自回归模型表现出快速的初始收敛性，而扩散模型能达到更优的性能上限，这表明严格的序列排序可能限制生成质量的上界。最后，我们通过将表示对齐方法（REPA）适配至自回归模型扩展了分析，由此构建了LlamaGen-REPA。代码已开源：https://github.com/Tencent-Hunyuan/iFSQ

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17124) | [arXiv](https://arxiv.org/abs/2601.17124)



---

### 7. 模型自教：可学习性边缘的推理研究

**原文标题：** Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability

**摘要：**
模型能否学会突破自身的学习瓶颈？针对大型推理模型的强化学习微调方法在初始成功率较低的数据集上容易陷入停滞，从而缺乏有效的训练信号。我们探究一个根本性问题：预训练大语言模型能否利用潜在知识为自身无法解决的问题生成自动化课程？为此，我们设计了SOAR框架：一种通过元强化学习挖掘教学信号的自改进框架。该框架通过模型教师副本为学生副本生成合成问题，并根据其在困难问题子集上的进步获得奖励。SOAR的关键创新在于将课程设计锚定于可量化的学生进步，而非依赖内在代理奖励。我们在数学基准测试中最困难子集（初始成功率0/128）上的研究揭示了三个核心发现：首先，通过激发预训练模型生成有效阶梯问题的潜在能力，可以实现基于稀疏二元奖励的双层元强化学习；其次，基于实际进步的奖励机制优于现有大语言模型自博弈中的内在奖励方案，能有效避免其常见的不稳定性和多样性崩溃问题；最后，对生成问题的分析表明，问题的结构质量与明确性比答案正确性对学习进程更具决定性。这些发现表明，生成有效阶梯问题的能力并不以预先解决难题的能力为前提，这为无需额外标注数据即可突破推理瓶颈提供了理论路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18778) | [arXiv](https://arxiv.org/abs/2601.18778)



---

### 8. 自优化视频采样方法

**原文标题：** Self-Refining Video Sampling

**摘要：**
现代视频生成模型在处理复杂物理动态时仍面临挑战，往往难以实现真实的物理效果。现有方法通常依赖外部验证器或对增强数据进行额外训练来解决这一问题，但这些方法计算成本高昂，且在捕捉细粒度运动方面仍存在局限。本研究提出自优化视频采样方法，该简单方法利用在大规模数据集上预训练的视频生成器作为自身的优化器。通过将生成器解释为去噪自编码器，我们能够在推理阶段实现无需外部验证器或额外训练的迭代式内循环优化。我们进一步提出基于不确定性的优化策略，该策略根据自一致性选择性地优化特定区域，从而避免因过度优化而产生的伪影。在先进视频生成模型上的实验表明，该方法在运动连贯性与物理对齐方面取得显著改进，相较于默认采样器与基于引导的采样器，获得了超过70%的人类偏好度。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18577) | [arXiv](https://arxiv.org/abs/2601.18577)



---

### 9. VIBEVOICE-ASR技术报告

**原文标题：** VIBEVOICE-ASR Technical Report

**摘要：**
本报告介绍了VibeVoice-ASR，这是一个基于VibeVoice构建的通用语音理解框架，旨在解决长音频（如会议、播客）中尽管近期短语音识别技术有所进步，但仍持续存在的上下文碎片化和多说话人复杂性等挑战。与依赖音频分块的传统流水线方法不同，VibeVoice-ASR支持对长达60分钟的音频进行单次处理。它将自动语音识别、说话人日志和时间戳标注统一为单一的端到端生成任务。此外，VibeVoice-ASR支持超过50种语言，无需显式语言设置，并能原生处理话语内及跨话语的语码转换。我们还引入了一种基于提示的上下文注入机制，允许用户提供定制化上下文，从而显著提升领域特定术语和多音字消歧的准确性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18184) | [arXiv](https://arxiv.org/abs/2601.18184)



---

### 10. DeepPlanning：基于可验证约束的长周期智能体规划基准测试

**原文标题：** DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints

**摘要：**
尽管智能体评估已转向长周期任务，但现有基准测试仍侧重于局部、步骤层面的推理，而非需要真正规划能力的全局约束优化（如时间和财务预算）。同时，现有的LLM规划基准未能充分体现现实场景中典型的信息主动获取与细粒度局部约束特性。为此，我们提出DeepPlanning——一个面向实际长周期智能体规划的挑战性基准测试。该基准包含多日旅行规划与多商品购物任务，要求智能体具备主动信息获取、局部约束推理和全局约束优化能力。在DeepPlanning上的评估表明，即使是前沿的智能体LLM也难以有效处理此类问题，这凸显了可靠的显式推理模式与并行工具调用对于实现更优效果-效率权衡的重要性。错误分析进一步指出了改进长周期规划场景下智能体LLM的潜在研究方向。我们将开源代码与数据以支持未来研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18137) | [arXiv](https://arxiv.org/abs/2601.18137)



---

### 11. CGPT：基于聚类引导的部分表格与LLM生成监督的表格检索方法

**原文标题：** CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval

**摘要：**
通用嵌入模型在文本检索中表现出色，但在表格检索中仍存在不足，高度结构化的内容导致语义压缩和查询-表格匹配偏差。近期基于大语言模型的检索增强方法通过生成合成查询缓解了这一问题，但这些方法通常依赖启发式的部分表格选择策略，且很少利用合成查询作为监督信号来优化嵌入模型。本文提出CGPT训练框架，通过大语言模型生成的监督信号提升表格检索性能。CGPT采用K-means对表格实例进行聚类，并通过跨聚类采样构建语义多样化的部分表格集合以扩展语义覆盖范围。随后利用大语言模型为这些部分表格生成合成查询，通过困难负样本对比微调策略优化嵌入模型。在四个公开基准数据集（MimoTable、OTTQA、FetaQA和E2E-WTQ）上的实验表明，CGPT在检索性能上持续优于包括QGpT在内的基线方法，平均R@1指标提升16.54%。在统一多领域语料场景中，CGPT展现出强大的跨领域泛化能力，即使使用较小规模的大语言模型生成合成查询仍保持有效性。这些结果表明：语义引导的部分表格构建策略，结合大语言模型生成监督的对比训练，为大规模表格检索提供了高效可扩展的解决方案。代码已开源：https://github.com/yumeow0122/CGPT。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.15849) | [arXiv](https://arxiv.org/abs/2601.15849)



---

### 12. STAR：基于表头感知聚类与自适应加权融合的语义表格表示方法

**原文标题：** STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion

**摘要：**
表格检索任务旨在根据自然语言查询从大规模语料库中检索最相关的表格。然而，非结构化文本与结构化表格之间的结构和语义差异使得嵌入对齐尤为困难。现有方法（如QGpT）尝试通过生成合成查询来丰富表格语义，但仍依赖于粗糙的部分表格采样和简单的融合策略，这限制了语义多样性并阻碍了有效的查询-表格对齐。本文提出STAR（语义表格表示）这一轻量级框架，通过语义聚类与加权融合提升表格语义表示能力。STAR首先采用表头感知的K均值聚类对语义相似的行进行分组，并选取代表性中心实例构建多样化的部分表格；随后生成针对特定聚类的合成查询，以全面覆盖表格的语义空间；最后通过加权融合策略整合表格与查询嵌入，实现细粒度的语义对齐。该设计使STAR能够从结构化与文本化数据源中捕获互补信息，从而提升表格表示的表达能力。在五个基准数据集上的实验表明，STAR在所有数据集上的召回率均持续优于QGpT，验证了语义聚类与自适应加权融合对构建鲁棒表格表示的有效性。代码已开源：https://github.com/adsl135789/STAR。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.15860) | [arXiv](https://arxiv.org/abs/2601.15860)



---

### 13. 降低泛化代价：大语言模型智能体强化学习训练的跨领域泛化研究

**原文标题：** Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents

**摘要：**
通用型大语言模型智能体通常在有限环境集合中进行后训练，却需部署至更广泛、未经见的领域中。本研究探讨了当最终测试领域未知时，智能体后训练所面临的挑战。具体而言，我们分析了强化学习环境特性与建模选择中哪些因素对领域外性能影响最为显著。首先，我们识别出与跨领域泛化强相关的两个环境维度：（一）状态信息丰富度，即智能体从状态中需处理的信息量；（二）规划复杂度，通过基础策略下的目标可达性与轨迹长度进行估算。值得注意的是，领域真实性与文本层面相似性并非主要因素；例如，简单的网格世界领域“推箱子”在SciWorld中产生的泛化能力甚至优于更贴近现实的ALFWorld领域。基于这些发现，我们进一步证明仅提升状态信息丰富度即可有效增强跨领域鲁棒性。我们提出一种低开销且广泛适用的随机化技术：在状态中添加少量与目标无关的干扰特征，在不改变任务本质的前提下增加状态丰富度。除环境侧特性外，我们还检验了多项建模选择：（a）监督微调预热或训练中插入虽能防止强化学习期间的灾难性遗忘，但会削弱对未包含在训练数据混合领域中的泛化能力；（b）在强化学习中启用逐步推理机制，虽不总能提升领域内性能，但对保持泛化能力具有关键作用。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18217) | [arXiv](https://arxiv.org/abs/2601.18217)



---

### 14. AR-Omni：一种适用于任意模态间生成的统一自回归模型

**原文标题：** AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation

**摘要：**
现实世界的感知与交互本质上是多模态的，不仅涉及语言，还包括视觉与语音，这推动了支持多模态输入与多模态输出的“全能”多模态大语言模型的发展。尽管一系列全能多模态大语言模型已相继出现，但现有系统大多仍依赖额外的专家组件来实现多模态生成，限制了统一训练与推理的简洁性。自回归建模以其单一令牌流、单一下一令牌目标及单一解码器的特点，在文本领域是一种优雅且可扩展的基础框架。受此启发，我们提出了AR-Omni——一种在自回归范式下无需任何专家解码器的统一任意模态间生成模型。AR-Omni支持自回归文本与图像生成，以及流式语音生成，所有功能均通过单一Transformer解码器实现。我们进一步解决了统一自回归建模中的三个实际问题：通过任务感知的损失重加权应对模态不平衡问题，通过针对图像令牌的轻量级令牌级感知对齐损失提升视觉保真度，以及通过有限状态解码机制平衡稳定性与创造性。实验表明，AR-Omni在三种模态上均实现了高质量生成，同时保持实时性，其语音生成的实时因子达到0.88。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17761) | [arXiv](https://arxiv.org/abs/2601.17761)



---

### 15. TSRBench：面向通用模型的多任务多模态时间序列推理综合基准

**原文标题：** TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models

**摘要：**
时间序列数据在现实场景中无处不在，对从能源管理到交通控制等关键应用至关重要。因此，对时间序列进行推理的能力是通用模型解决实际问题的核心技能。然而，现有通用模型基准显著缺乏对这一维度的评估。为填补这一空白，我们提出了TSRBench——一个全面的多模态基准，旨在系统测试时间序列推理的全方位能力。TSRBench具备以下特点：i) 涵盖14个领域的4125个多样化问题，并划分为感知、推理、预测与决策四大核心维度；ii) 通过四大维度下的15项任务评估关键推理能力（如数值推理）。我们通过大量实验，在TSRBench上评估了30余个领先的专有及开源大语言模型、视觉语言模型与时间序列大语言模型。研究发现：i) 缩放定律在感知与推理任务中成立，但在预测任务中失效；ii) 强大的推理能力不能保证准确的上下文感知预测，表明语义理解与数值预测之间存在解耦现象；iii) 尽管文本与视觉两种时间序列表征形式具有输入互补性，当前多模态模型仍未能有效融合二者以实现性能协同提升。TSRBench提供了一个标准化评估平台，不仅揭示了现有挑战，更为推进通用模型发展提供了重要参考。代码与数据集已发布于 https://tsrbench.github.io/。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18744) | [arXiv](https://arxiv.org/abs/2601.18744)



---

### 16. SAGE：基于执行反馈的可控智能体数据生成方法在深度搜索中的应用

**原文标题：** SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback

**摘要：**
深度搜索智能体旨在回答需要跨多文档推理的复杂问题，能够显著加速信息检索过程。由于探索路径长且复杂，为此类应用收集人工标注的成本极高。本文提出一种智能体流程，能够针对给定语料库和目标难度级别自动生成高质量、难度可控的深度搜索问答对。我们的SAGE流程包含两个核心组件：数据生成器负责提出问答对，搜索智能体则尝试解答生成的问题并向数据生成器提供执行反馈。两个组件通过多轮交互迭代优化问答对，直至其满足目标难度要求。内在评估表明，SAGE生成的问题需要多样化的推理策略，同时显著提升了生成数据的准确性与难度。外在评估显示，使用我们合成的数据训练深度搜索智能体，在主流深度搜索基准测试中可获得最高23%的相对性能提升。补充实验进一步证明，基于我们数据训练的智能体能够在推理时从固定语料检索无缝适配至谷歌搜索，且无需额外训练。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18202) | [arXiv](https://arxiv.org/abs/2601.18202)



---

### 17. 具身化超长视频理解

**原文标题：** Agentic Very Long Video Understanding

**摘要：**
随着智能眼镜等全天候可穿戴设备的普及，始终在线的个人人工智能助手对情境理解提出了更高要求——需要超越短暂、孤立的事件，涵盖连续、纵向的第一人称视频流。实现这一愿景需要长时域视频理解技术的突破，系统必须能够解读并回溯跨越数天甚至数周的视觉与听觉信息。现有方法（包括大语言模型和检索增强生成技术）受限于有限的上下文窗口，且缺乏对超长视频流进行组合式多跳推理的能力。本研究通过EGAgent框架应对这些挑战：该增强型具身化框架以实体场景图为核心，动态表征人物、地点、物体及其随时间演化的关系。我们的系统为规划智能体配备了结构化图搜索推理工具，以及混合视觉-听觉检索能力，从而实现精细化、跨模态且时序连贯的推理。在EgoLifeQA和Video-MME（长时域）数据集上的实验表明，本方法在复杂纵向视频理解任务中取得了EgoLifeQA（57.5%）的最优性能，并在Video-MME（长时域）（74.1%）上达到领先水平。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18157) | [arXiv](https://arxiv.org/abs/2601.18157)



---

### 18. DRPG（分解、检索、规划、生成）：一种用于学术反驳的智能体框架

**原文标题：** DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal

**摘要：**
尽管大语言模型在科学研究工作流程中的应用日益广泛，但针对学术交流与同行评审中关键环节——学术反驳的自动化支持仍鲜有深入探索。现有方法通常依赖于现成的大语言模型或简单流水线，这些方法在长上下文理解方面存在不足，且往往难以生成具有针对性、说服力的回应。本文提出DRPG框架，该框架通过四个步骤实现自动化学术反驳生成：将评审意见分解为原子化问题、从论文中检索相关证据、规划反驳策略，并据此生成回应。值得注意的是，DRPG中的规划器在识别最可行反驳方向的任务中准确率超过98%。在顶级会议数据上的实验表明，DRPG显著优于现有反驳生成流程，且仅使用80亿参数模型即可达到超越人类平均水平的性能。我们的分析进一步验证了规划器设计的有效性及其在提供多视角、可解释建议方面的价值。实验还证明DRPG在更复杂的多轮交互场景中表现良好。这些结果凸显了DRPG框架的有效性，及其在生成高质量反驳内容、支持学术讨论规模化拓展方面的潜力。本项目代码已开源：https://github.com/ulab-uiuc/DRPG-RebuttalAgent。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18081) | [arXiv](https://arxiv.org/abs/2601.18081)



---

### 19. IVRA：基于无训练提示引导的视觉-标记关系优化以提升机器人动作策略

**原文标题：** IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance

**摘要：**
当前多数视觉-语言-动作模型将图像块展平为一维标记序列，削弱了精确操作所需的二维空间线索。本文提出IVRA，一种轻量级、无需训练的方法，通过利用模型内置视觉编码器中已有的关联提示来增强空间理解能力，无需任何外部编码器或重新训练。IVRA选择性地将这些关联信号注入到包含实例级特征的语言模型层中。这种推理时干预机制在保持所有模型参数固定的同时，重新校准视觉-标记的交互关系，更好地保留几何结构。我们在涵盖二维与三维操作的仿真基准（VIMA和LIBERO）及多种真实机器人任务中，将IVRA应用于不同视觉-语言-动作架构（LLaRA、OpenVLA和FLOWER），验证了其普适性。在二维VIMA任务中，IVRA在低数据场景下较基线LLaRA平均成功率提升4.2%；在三维LIBERO任务中，对OpenVLA和FLOWER基线模型均带来稳定增益，即使在基线准确率接近饱和时仍实现提升（从96.3%至97.1%）。所有代码与模型将公开发布，可视化结果请访问：jongwoopark7978.github.io/IVRA

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.16207) | [arXiv](https://arxiv.org/abs/2601.16207)



---

### 20. 儿童-成人互动场景下的端到端联合语音识别与说话人角色分类

**原文标题：** End-to-End Joint ASR and Speaker Role Diarization with Child-Adult Interactions

**摘要：**
儿童与成人言语互动的准确转写和说话人分类对发展心理学与临床研究至关重要。然而人工标注耗时费力且难以规模化。现有自动化系统通常采用级联式的说话人分类与语音识别流程，易导致误差传播。本文提出一种统一的端到端框架，通过扩展Whisper编码器-解码器架构，实现语音识别与儿童-成人说话人角色分类的联合建模。该方案整合了四大核心模块：（一）采用序列化输出训练机制，同步生成说话人标签及起止时间戳；（二）设计轻量级帧级分类头，增强编码器表征的说话人区分能力；（三）引入基于分类的静音抑制机制以提升时间边界精度；（四）构建基于状态机的强制解码流程，确保输出结构合法性。在两个数据集上的综合实验表明，相比两种级联基线方法，本框架在Whisper-small与Whisper-large模型上均取得稳定且显著的性能提升：不仅降低了多说话人词错误率，同时保持了具有竞争力的说话人分类准确率。这些发现验证了所提联合建模框架在规模化生成儿童-成人互动场景下说话人归属转录文本方面的有效性与实用价值。相关代码与模型权重已开源发布。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17640) | [arXiv](https://arxiv.org/abs/2601.17640)



---

### 21. SkyReels-V3 技术报告

**原文标题：** SkyReels-V3 Technique Report

**摘要：**
视频生成是构建世界模型的关键基础，而多模态上下文推理能力是衡量其性能的核心标准。为此，我们提出了SkyReels-V3——一个基于扩散Transformer统一多模态上下文学习框架的条件视频生成模型。该模型在单一架构中支持三种核心生成范式：参考图像到视频合成、视频到视频扩展以及音频引导的视频生成。（一）参考图像到视频模型旨在生成具有高度主体身份保持性、时间连贯性和叙事一致性的高保真视频。为增强对参考内容的遵循能力与构图稳定性，我们设计了一套综合数据处理流程，通过跨帧配对、图像编辑和语义重写等技术，有效减少了复制粘贴带来的伪影。训练过程中采用图像-视频混合策略并结合多分辨率联合优化，以提升模型在不同场景下的泛化能力与鲁棒性。（二）视频扩展模型将时空一致性建模与大规模视频理解相结合，既能实现无缝的单镜头延续，也能依据专业影视范式进行智能的多镜头切换。（三）数字人模型通过训练首尾帧插入模式并重构关键帧推理范式，支持分钟级音频条件视频生成，在保障视觉质量的同时优化了音视频同步效果。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17323) | [arXiv](https://arxiv.org/abs/2601.17323)



---

### 22. 最小负载专家并行：一种面向不平衡专家混合模型的负载均衡方法

**原文标题：** Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts

**摘要：**
专家混合模型通常在预训练阶段采用显式负载均衡约束以确保专家路由的统计平衡。然而，我们发现即使经过充分训练的专家混合模型仍会表现出显著的路由不平衡现象。这种行为具有内在合理性——甚至可视为有益特性——因为不平衡路由能使模型将领域特定知识集中于部分专家内部。专家并行技术旨在通过将专家分布到多个设备上来扩展专家混合模型，但其设计隐含了路由平衡的前提假设。在极端不平衡场景下，专家并行可能将过量令牌集中路由至少数专家，导致训练后阶段或推理过程中过载设备出现计算与内存边界故障，而此时显式负载均衡往往难以实施。本文提出最小负载专家并行算法，该新型专家并行算法能动态将过载设备的超额令牌及相关专家参数重路由至低负载设备，在满足内存约束的前提下确保所有设备在最小集体延迟内完成计算任务。在不同规模模型实验中，该算法相比标准专家并行实现最高5倍加速比和4倍峰值内存使用降低，其中gpt-oss-120b模型推理速度提升约1.9倍。我们通过理论分析与综合实验评估（包括消融研究）验证该方法，揭示了关键性能权衡关系，并建立了面向特定硬件的超参数调优原则框架以实现最优性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17111) | [arXiv](https://arxiv.org/abs/2601.17111)



---

### 23. 以一适万：面向个性化大语言模型对齐的元奖励建模

**原文标题：** One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment

**摘要：**
大语言模型的对齐旨在使其输出符合人类偏好，而个性化对齐则进一步使模型适配于个体用户。这依赖于能够捕捉用户特定偏好并自动提供个性化反馈的奖励模型。然而，开发此类模型面临两大关键挑战：个体用户反馈数据的稀缺性，以及对未见用户进行高效适配的需求。我们认为，解决这些限制需要将范式从拟合数据以学习用户偏好，转变为学习偏好适应的过程。为此，我们提出元奖励建模方法，将个性化奖励建模重新定义为元学习问题。具体而言，我们将每个用户的奖励模型表示为若干基础奖励函数的加权组合，并采用模型无关元学习框架优化这些权重的初始化，以支持在有限反馈下的快速适配。为确保鲁棒性，我们引入了鲁棒个性化目标，该目标在元优化过程中更加强调难以学习的用户。在个性化偏好数据集上进行的大量实验验证了所提方法能够增强少样本个性化性能、提升用户鲁棒性，并持续优于基线模型。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18731) | [arXiv](https://arxiv.org/abs/2601.18731)



---

### 24. 云珏智能体技术报告：面向开放式任务的全可复现、零启动原位自进化智能体系统

**原文标题：** Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks

**摘要：**
传统智能体系统在任务分布持续漂移且外部监督稀缺的开放式环境中往往表现不佳。其对静态工具集或离线训练的依赖难以适应动态变化，导致系统能力边界僵化且不可知。为解决这一问题，我们提出原位自进化范式。该方法将序列化任务交互视为持续的经验流，使系统能够在缺乏真实标签的情况下，将短期执行反馈提炼为长期可重用的能力。在此框架中，我们识别出工具进化作为能力扩展的关键路径，其可提供可验证的二元反馈信号。基于此框架，我们开发了云珏智能体系统，通过迭代合成、优化和重用工具以应对新兴挑战。为提升进化效率，我们进一步提出并行批量进化策略。在零启动设置下对五个多样化基准的实证评估表明，该系统相较于专有基线模型取得显著性能提升。补充性热启动实验进一步证实，系统积累的通用知识可无缝迁移至新领域。最后，我们提出一种监测进化收敛的新颖指标，其功能类似于传统优化中的训练损失函数。我们已开源代码库、系统轨迹及进化工具，以促进韧性自进化智能领域的后续研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18226) | [arXiv](https://arxiv.org/abs/2601.18226)



---

### 25. 面向空间感知的掩蔽深度建模

**原文标题：** Masked Depth Modeling for Spatial Perception

**摘要：**
在与三维环境交互的需求驱动下，空间视觉感知已成为自动驾驶、机器人操控等物理世界应用的基础能力。使用RGB-D相机获取像素对齐的度量深度本是最可行的方案，但该方法常受硬件限制与复杂成像条件（特别是镜面或弱纹理表面）的制约。本研究提出：深度传感器的测量误差可被视为反映底层几何模糊性的“掩蔽”信号。基于此观点，我们提出LingBot-Depth深度补全模型，该模型通过掩蔽深度建模机制利用视觉上下文优化深度图，并集成自动化数据筛选流程以实现可扩展训练。实验表明，该模型在深度精度与像素覆盖率方面均优于顶级RGB-D相机。在多项下游任务中的实验结果进一步证明，LingBot-Depth能够为RGB与深度模态提供对齐的潜在表征。我们已向空间感知研究社区开源代码、模型检查点及300万组RGB-深度配对数据（含200万真实数据与100万仿真数据）。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17895) | [arXiv](https://arxiv.org/abs/2601.17895)



---

### 26. 视频生成作为世界模型的机制视角：状态与动态

**原文标题：** A Mechanistic View on Video Generation as World Models: State and Dynamics

**摘要：**
大规模视频生成模型已展现出涌现的物理一致性，使其具备成为潜在世界模型的可能。然而，当前“无状态”的视频架构与经典以状态为中心的世界模型理论之间仍存在差距。本研究通过提出一个以两大支柱为核心的新分类体系来弥合这一差距：状态构建与动态建模。我们将状态构建分为隐式范式（上下文管理）与显式范式（潜在压缩），同时通过知识整合与架构重构来分析动态建模。此外，我们主张评估标准应从视觉保真度转向功能基准测试，以检验物理持久性与因果推理能力。最后，我们指出两个关键前沿方向：通过数据驱动的记忆与压缩保真度提升持久性，以及通过潜在因子解耦与推理先验整合推进因果建模。通过应对这些挑战，该领域有望从生成视觉合理的视频，演进为构建鲁棒、通用的世界模拟器。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17067) | [arXiv](https://arxiv.org/abs/2601.17067)



---

### 27. 扩散中的扩散：在半自回归扩散模型中重获全局连贯性

**原文标题：** Diffusion In Diffusion: Reclaiming Global Coherence in Semi-Autoregressive Diffusion

**摘要：**
全局离散扩散语言模型最引人注目的特征之一是其全局双向上下文建模能力。然而，现有的基于分块的扩散研究往往引入自回归先验，这虽然带来一定优势，却可能导致模型在宏观层面丧失全局连贯性。为了在保留半自回归范式优点的同时恢复全局上下文理解能力，我们提出“扩散中的扩散”——一种“先草拟后精修”的框架，旨在克服分块扩散模型固有的不可逆性与短视性问题。该方法首先通过小分块扩散快速生成文本草稿，随后利用具有更大双向感受野的全局双向扩散对这些草稿进行精细化重构。我们采用置信度快照重掩码技术识别需要修改的关键词元，并运用混合尺度训练拓展分块扩散模型的全局建模能力。实验结果表明，我们的方法在OpenWebText数据集上为离散扩散模型设立了新的性能基准：仅使用基线模型26%的微调计算量，便将生成困惑度从25.7降至21.9，显著缩小了与自回归模型的性能差距。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.13599) | [arXiv](https://arxiv.org/abs/2601.13599)



---

### 28. UI Remix：通过交互式案例检索与重组支持用户界面设计

**原文标题：** UI Remix: Supporting UI Design Through Interactive Example Retrieval and Remixing

**摘要：**
用户界面（UI）设计是发布产品、构建作品集或个性化项目中的关键步骤，然而不具备设计专业知识的终端用户往往难以清晰表达其设计意图，并对自身的设计选择缺乏信心。现有的基于案例的设计工具要么鼓励广泛探索（可能导致信息过载与设计方向偏离），要么要求用户仅基于单一案例进行修改（存在设计固化的风险）。本文提出UI Remix，一个通过案例驱动的工作流程来支持移动端UI设计的交互式系统。该系统基于多模态检索增强生成（MMRAG）模型，支持用户在整体界面（全局）和界面组件（局部）两个层面上进行迭代式的案例搜索、选择与适配。为增强用户信任，系统提供了来源透明度提示，如评分、下载量和开发者信息等。一项针对24名终端用户的实证研究表明，UI Remix显著提升了参与者实现其设计目标的能力，促进了有效的设计迭代，并鼓励了对替代设计的探索。参与者还反馈，来源透明度提示增强了他们在适配案例时的信心。我们的研究结果为人工智能辅助的案例驱动系统指明了新的方向，这类系统能够赋能终端用户，使其在设计过程中拥有更强的控制力、更高的信任度以及更开放的探索心态。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18759) | [arXiv](https://arxiv.org/abs/2601.18759)



---

### 29. PingPong：多轮语码转换对话的自然基准测试集

**原文标题：** PingPong: A Natural Benchmark for Multi-Turn Code-Switching Dialogues

**摘要：**
语码转换是全球多语使用者的普遍现象，但现有基准测试集鲜能准确反映其在日常交流中的复杂性。本文提出PingPong——一个涵盖五种语言组合变体（部分为三语混合）的自然多方言码转换对话基准测试集。该数据集由2至4名参与者进行人工撰写的对话构成，呈现真实的多线程对话结构，其中应答内容常指向对话中较早的节点。我们证明该数据在信息长度、说话者主导性和应答距离等方面，比机器生成数据具有更强的自然性与结构多样性，且对话线索更复杂。基于这些对话，我们定义了三个下游任务：问答系统、对话摘要和主题分类。通过在PingPong上对多种前沿语言模型进行评估，我们发现现有模型对语码转换输入的处理能力仍显不足，这凸显了亟需开发能够应对现实世界多语交流复杂性的更强健自然语言处理系统。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17277) | [arXiv](https://arxiv.org/abs/2601.17277)



---

### 30. 强化学习算法在大规模流动控制中的即插即用基准测试框架

**原文标题：** Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control

**摘要：**
强化学习在主动流动控制领域已展现出良好前景，但该领域进展仍难以评估，因为现有研究依赖于异构的观测与执行方案、数值设置及评估协议。当前AFC基准测试虽试图解决这些问题，但严重依赖外部计算流体动力学求解器，不具备完全可微性，且对三维与多智能体场景支持有限。为突破这些限制，我们提出首个独立、完全可微的AFC强化学习基准测试套件FluidGym。该框架完全基于PyTorch构建于GPU加速的PICT求解器之上，在单一Python环境中运行，无需外部CFD软件，并提供标准化评估协议。我们展示了PPO与SAC算法的基线测试结果，并将所有仿真环境、数据集及训练模型作为公共资源发布。FluidGym实现了控制方法的系统性比较，为基于学习的流动控制研究建立了可扩展的基础平台，项目地址：https://github.com/safe-autonomous-systems/fluidgym。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.15015) | [arXiv](https://arxiv.org/abs/2601.15015)



---

### 31. 智能的副作用：多模态大语言模型在多图像推理中的安全风险

**原文标题：** The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning

**摘要：**
随着多模态大语言模型（MLLMs）在处理复杂多图像指令方面获得更强的推理能力，这一进步可能带来新的安全风险。我们通过引入首个专注于多图像推理安全的基准测试MIR-SafetyBench来研究此问题，该基准包含涵盖9种多图像关系分类的2,676个实例。我们对19个MLLMs进行的广泛评估揭示了一个令人担忧的趋势：具有更先进多图像推理能力的模型在MIR-SafetyBench上可能更加脆弱。除了攻击成功率之外，我们发现许多被标记为安全的回应是表面化的，通常源于误解或回避性的、不置可否的答复。我们进一步观察到，不安全的生成结果平均表现出比安全结果更低的注意力熵。这一内部特征表明，模型可能过度专注于任务解决而忽视安全约束，存在潜在风险。我们的代码和数据可在https://github.com/thu-coai/MIR-SafetyBench获取。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14127) | [arXiv](https://arxiv.org/abs/2601.14127)



---

### 32. 少即是多——直至崩溃：大视觉语言模型中视觉令牌压缩的安全隐患

**原文标题：** Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models

**摘要：**
视觉令牌压缩技术被广泛采用以提升大视觉语言模型（LVLMs）的推理效率，使其能够部署在延迟敏感和资源受限的场景中。然而，现有研究主要关注效率与性能，而视觉令牌压缩的安全影响在很大程度上尚未得到探索。本研究首次揭示，视觉令牌压缩会显著降低LVLMs的鲁棒性：在未压缩推理下表现稳健的模型，一旦启用压缩便会变得高度脆弱。这些漏洞具有状态特异性：故障模式仅在压缩设置下出现，并在禁用压缩时完全消失，这使得它们尤为隐蔽且难以诊断。通过分析压缩过程的关键阶段，我们发现令牌重要性排序的不稳定性是导致鲁棒性下降的主要原因。微小且难以察觉的扰动即可显著改变令牌排序，导致压缩机制错误地丢弃任务关键信息，最终引发模型故障。基于这一观察，我们提出了一种压缩感知攻击（CAA）来系统性地研究和利用此漏洞。CAA直接针对令牌选择机制，并仅在压缩推理下诱发故障。我们进一步将此方法扩展到更现实的“黑盒”场景，提出了迁移CAA，其中既无法访问目标模型，也无法获知其压缩配置。我们还评估了潜在的防御措施，发现其提供的保护作用有限。跨模型、数据集和压缩方法的广泛实验表明，视觉令牌压缩显著削弱了模型的鲁棒性，揭示了一个先前被忽视的效率与安全之间的权衡关系。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.12042) | [arXiv](https://arxiv.org/abs/2601.12042)



---

### 33. MortalMATH：评估推理目标与紧急情境之间的冲突

**原文标题：** MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts

**摘要：**
大型语言模型正日益针对深度推理进行优化，其优先考虑复杂任务的正确执行，而非一般性对话。本研究探讨这种对计算能力的侧重是否会造成一种“隧道视野”，即在危急情况下忽视安全性。我们提出了MortalMATH基准测试，包含150个场景，其中用户在描述日益危及生命的紧急情况（例如中风症状、自由落体）的同时请求代数帮助。我们发现模型行为存在显著分化：通用模型（如Llama-3.1）能够成功拒绝数学请求以应对危险。相比之下，专用推理模型（如Qwen-3-32b和GPT-5-nano）常常完全忽略紧急情况，在用户描述濒死状态时仍保持超过95%的任务完成率。此外，推理所需的计算时间会引入危险的延迟：在提供任何潜在帮助前可能长达15秒。这些结果表明，训练模型不懈追求正确答案可能会无意中使其丧失安全部署所需的生存本能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18790) | [arXiv](https://arxiv.org/abs/2601.18790)



---

### 34. HalluGuard：解析大语言模型中数据驱动与推理驱动幻觉的生成机制

**原文标题：** HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs

**摘要：**
大语言模型在医疗、法律与科学发现等高风险领域中的可靠性常因幻觉问题而受到损害。此类错误通常源于两类成因：数据驱动幻觉与推理驱动幻觉。然而，现有检测方法往往仅针对单一成因，且依赖特定任务的启发式规则，难以推广至复杂场景。为突破这些局限，我们提出“幻觉风险边界”理论框架，将幻觉风险形式化分解为数据驱动与推理驱动两个组成部分，分别对应训练阶段的数据失配与推理阶段的不稳定性，从而为系统分析幻觉的生成与演化机制奠定理论基础。基于此框架，我们进一步提出HalluGuard检测方法，通过构建基于神经正切核的量化指标，利用其诱导的几何结构与表征信息，实现对数据驱动与推理驱动幻觉的联合识别。我们在10个多样化基准测试集、11个竞争性基线方法与9个主流大语言模型架构上对HalluGuard进行评估，结果表明该方法在检测多种形式的大语言模型幻觉任务中均能取得最先进的性能表现。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18753) | [arXiv](https://arxiv.org/abs/2601.18753)



---

### 35. RouteMoA：无需预推理的动态路由机制提升高效智能体混合架构性能

**原文标题：** RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents

**摘要：**
智能体混合架构通过分层协作提升大语言模型性能，但其密集拓扑结构会增加计算成本与延迟。现有方法采用大语言模型作为评判器对响应进行筛选，但仍需所有模型在评判前完成推理，未能有效降低成本。这些方法缺乏模型选择标准，且难以应对大规模模型池场景——完整推理成本高昂并可能超出上下文长度限制。为此，我们提出RouteMoA，一种融合动态路由机制的高效智能体混合框架。该框架采用轻量化评分器，通过查询语句预测粗粒度性能指标进行初始筛选，在无需推理的情况下将候选模型缩减为高潜力子集。随后通过混合评判器基于现有模型输出进行轻量级自评估与交叉评估，实现无需额外推理的后验校正。最终通过平衡性能、成本与延迟的模型排序机制完成模型选择。实验表明，RouteMoA在不同任务与模型池规模下均优于传统智能体混合架构，在大规模模型池中可降低89.8%的成本并减少63.6%的延迟。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.18130) | [arXiv](https://arxiv.org/abs/2601.18130)



---

### 36. TensorLens：基于高阶注意力张量的端到端Transformer分析

**原文标题：** TensorLens: End-to-End Transformer Analysis via High-Order Attention Tensors

**摘要：**
注意力矩阵是Transformer研究的核心基础，支撑着包括可解释性、可视化、操控与蒸馏在内的广泛应用。然而，现有分析大多聚焦于单个注意力头或单层结构，未能充分考虑模型的全局行为。尽管先前研究已通过平均化、矩阵乘法等方式扩展了跨多头注意力的计算形式，或引入了归一化与前馈网络等组件，但仍缺乏一个能够完整封装所有Transformer模块的统一表征框架。为此，我们提出TensorLens这一创新性方法，通过构建高阶注意力交互张量，将整个Transformer模型表达为单一且依赖于输入的线性算子。该张量联合编码了注意力机制、前馈网络、激活函数、归一化操作与残差连接，从理论上提供了连贯且富有表现力的模型计算线性表征。TensorLens具有坚实的理论基础，实证研究表明其能生成比以往注意力聚合方法更丰富的表征。实验进一步证明，注意力张量可作为开发可解释性与模型理解工具的强大基础。相关代码已作为补充材料附上。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17958) | [arXiv](https://arxiv.org/abs/2601.17958)



---

### 37. Fast KVzip：基于门控KV淘汰的高效准确大语言模型推理

**原文标题：** Fast KVzip: Efficient and Accurate LLM Inference with Gated KV Eviction

**摘要：**
高效的键值（KV）缓存管理对于大语言模型的实际部署至关重要，然而现有的压缩技术往往需要在性能损失与计算开销之间进行权衡。本文针对权重冻结的大语言模型，提出一种新颖的基于门控机制的KV缓存淘汰方法，该方法能以可忽略的计算成本实现高压缩率。我们的方法引入了轻量级的汇聚注意力门控模块，用于识别并保留关键的KV对，并可无缝集成到预填充和解码两个阶段。所提出的门控训练算法仅依赖大语言模型的前向传播，避免了昂贵的反向传播过程，同时通过任务无关的重建目标实现了强大的任务泛化能力。在Qwen2.5-1M、Qwen3和Gemma3系列模型上的大量实验表明，本方法在淘汰高达70% KV缓存的同时，仍能保持近乎无损的性能。该结果在长文本理解、代码解析和数学推理等多种任务中均表现一致，充分证明了本方法的普适性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17668) | [arXiv](https://arxiv.org/abs/2601.17668)



---

### 38. 自主搜索在真实场景中的表现：基于1400万+真实搜索请求的意图与轨迹动态分析

**原文标题：** Agentic Search in the Wild: Intents and Trajectory Dynamics from 14M+ Real Search Requests

**摘要：**
基于大语言模型的搜索智能体正日益广泛地应用于多步骤信息检索任务，然而信息检索领域对于自主搜索会话的实际展开方式及检索证据的运用机制仍缺乏实证理解。本文通过对DeepResearchGym（一个供外部自主客户端访问的开源搜索API）收集的1444万次搜索请求（397万个会话）进行大规模日志分析，系统探究了自主搜索行为。我们通过会话划分、基于大语言模型的会话级意图标注与分步查询重构标签分类，并提出上下文驱动术语采纳率指标，用以量化新引入查询术语是否可追溯至先前检索证据。分析揭示了以下显著行为模式：首先，超过90%的多轮会话包含不超过十个步骤，89%的步骤间间隔在一分钟以内；其次，不同意图会话呈现差异化特征——事实查询会话表现出随时间增强的高重复性，而需要推理的会话则持续保持更广泛的探索行为；第三，智能体在跨步骤间复用检索证据，平均54%的新引入查询术语出现在累积证据上下文中，且早期步骤的贡献超越最近一次检索结果。这些发现表明，自主搜索系统可能受益于重复感知的早停机制、意图自适应的检索资源分配以及显式的跨步骤上下文追踪。我们计划公开匿名化日志数据以支持后续研究。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17617) | [arXiv](https://arxiv.org/abs/2601.17617)



---

### 39. C-RADIOv4（技术报告）

**原文标题：** C-RADIOv4 (Tech Report)

**摘要：**
通过利用多教师蒸馏技术，聚合视觉骨干网络提供了一个统一的学生模型，该模型保留并提升了多位教师网络的独特能力。在本技术报告中，我们介绍了C-RADIO模型系列的最新版本C-RADIOv4。该版本基于AM-RADIO/RADIOv2.5的设计框架，在保持相同计算复杂度的前提下，显著提升了关键下游任务的性能。我们发布了-SO400M（参数4.12亿）和-H（参数6.31亿）两种模型变体，二者均采用更新的教师模型集合（SigLIP2、DINOv3和SAM3）进行训练。除了在核心指标上的提升以及通过模仿SAM3获得的新能力外，C-RADIOv4模型系列进一步增强了任意分辨率支持能力，重新引入了ViTDet选项以大幅提升高分辨率下的处理效率，并采用了宽松的开源许可协议。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.17237) | [arXiv](https://arxiv.org/abs/2601.17237)



---

### 40. Interp3D：基于对应关系的生成式纹理三维变形插值方法

**原文标题：** Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing

**摘要：**
纹理三维变形旨在生成两个三维资产之间平滑且合理的过渡，同时保持结构连贯性与细粒度外观。该能力不仅对推动三维生成研究至关重要，也在动画制作、模型编辑及数字内容创作等实际应用中具有关键价值。现有方法或仅直接在几何结构上操作，局限于仅形状变形而忽略纹理；或将二维插值策略简单扩展至三维，常导致语义模糊、结构错位及纹理模糊等问题。这些挑战凸显了在过渡过程中同时保持几何一致性、纹理对齐与鲁棒性的必要性。为此，我们提出Interp3D——一种无需训练的新型纹理三维变形框架。该方法利用生成先验，并采用渐进对齐原则，以确保几何保真度与纹理连贯性。Interp3D从条件空间的语义对齐插值出发，通过结构化潜在表示引导的结构插值强化结构一致性，最终借助细粒度纹理融合实现外观细节迁移。为进行全面评估，我们构建了专用数据集Interp3DData，其包含多级难度样本，并从保真度、过渡平滑性与合理性三个维度对生成结果进行评估。定量指标与人工评估均表明，所提方法较现有技术具有显著优势。源代码公开于：https://github.com/xiaolul2/Interp3D。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14103) | [arXiv](https://arxiv.org/abs/2601.14103)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2026-01-27_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)