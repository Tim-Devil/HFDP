
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2025-11-27 论文日报

## 📊 今日论文统计
- 总论文数：20
- 热门领域：LLM, RL, GPT

## 📝 论文详情


### 1. 俄语架构的多模态评估框架

**原文标题：** Multimodal Evaluation of Russian-language Architectures

**摘要：**
多模态大语言模型目前已成为研究焦点，其在规模与能力层面呈现快速发展，但其智能水平、局限性及潜在风险仍未被充分认知。针对这一现状，特别是在俄语语境下尚无多模态基准测试的背景下，我们推出Mera Multi——一个面向俄语架构的开放式多模态评估框架。该基准采用指令驱动模式，涵盖默认的文本、图像、音频和视频模态，包含为通用模型及特定模态架构（图像到文本、视频到文本、音频到文本）全新构建的18项评估任务。我们的贡献包括：（i）建立多模态能力的统一分类体系；（ii）充分考虑俄罗斯文化与语言特性，从头构建18个数据集，并统一提示词与评估指标；（iii）提供闭源与开源模型的基线结果；（iv）制定防止基准泄露的方法论，包括水印技术与私有数据集许可机制。虽然当前研究聚焦俄语，但本基准提出的方法论可为类型学特征丰富的语言（特别是斯拉夫语系）构建多模态基准提供可复现的范式。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.15552) | [arXiv](https://arxiv.org/abs/2511.15552)



---

### 2. 多智能体系统中的潜在协作

**原文标题：** Latent Collaboration in Multi-Agent Systems

**摘要：**
多智能体系统（MAS）将大语言模型（LLMs）从独立的单模型推理扩展至协同的系统级智能。现有LLM智能体主要依赖基于文本的中介进行推理与通信，本研究通过实现模型在连续潜在空间中的直接协作推进了这一范式。我们提出LatentMAS——一种支持LLM智能体间纯潜在协作的端到端免训练框架。在该框架中，智能体首先通过末层隐藏嵌入进行自回归潜在思维生成，随后通过共享潜在工作记忆保存并传递各智能体的内部表征，确保无损信息交换。理论分析表明，相较于传统基于文本的MAS，LatentMAS能以显著更低的复杂度实现更强的表达能力与无损信息保持。在涵盖数学科学推理、常识理解和代码生成的9个综合基准测试中，实证评估表明LatentMAS持续优于强单模型与文本MAS基线：准确率最高提升14.6%，输出令牌使用量减少70.8%-83.7%，端到端推理速度提升4-4.3倍。这些结果证明，我们的潜在协作框架在提升系统级推理质量的同时，无需额外训练即可实现显著效能增益。代码与数据已开源：https://github.com/Gen-Verse/LatentMAS。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.20639) | [arXiv](https://arxiv.org/abs/2511.20639)



---

### 3. Inferix：基于块扩散的新一代世界模拟推理引擎

**原文标题：** Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation

**摘要：**
世界模型作为智能体AI、具身AI和游戏等领域的核心模拟器，能够生成长时序、物理真实且交互式的高质量视频。此外，扩展这些模型有望释放视觉感知、理解与推理的涌现能力，为超越当前以LLM为中心的视觉基础模型开辟新范式。实现这一突破的关键在于半自回归（块扩散）解码范式，该范式融合了扩散方法与自回归方法的优势，通过分块生成视频令牌——在块内应用扩散过程的同时以前序块为条件，从而产生更连贯稳定的视频序列。该方法通过重新引入LLM风格的KV缓存管理机制，突破了标准视频扩散模型的局限，实现了高效、可变长度的高质量生成。

因此，Inferix被专门设计为新一代推理引擎，通过优化的半自回归解码过程实现沉浸式世界合成。这种对世界模拟的专注定位使其区别于面向高并发场景的系统（如vLLM或SGLang）和经典视频扩散模型（如xDiTs）。Inferix进一步通过交互式视频流传输与性能分析功能增强系统能力，支持实时交互与逼真模拟以精确建模世界动态。此外，系统通过无缝集成LV-Bench（专为分钟级视频生成场景设计的新型细粒度评估基准）实现高效性能评估。我们期待学界携手推进Inferix发展，共同推动世界模型研究的深入探索。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.20714) | [arXiv](https://arxiv.org/abs/2511.20714)



---

### 4. Harmony：通过跨任务协同实现音视频生成的和谐统一

**原文标题：** Harmony: Harmonizing Audio and Video Generation through Cross-Task Synergy

**摘要：**
同步音视频内容的合成是生成式人工智能面临的关键挑战，开源模型在实现鲁棒的音视频对齐方面存在诸多难题。我们的分析表明，这一问题根源于联合扩散过程的三个基本挑战：(1) 对应漂移现象——并发演化的噪声潜在表示阻碍了对齐关系的稳定学习；(2) 低效的全局注意力机制难以捕捉细粒度时序特征；(3) 传统无分类器引导机制存在的模态内偏差，虽能增强条件可控性却无益于跨模态同步。为解决这些挑战，我们提出Harmony这一创新框架，通过机制化设计强化音视频同步。首先提出跨任务协同训练范式，利用音频驱动视频生成与视频驱动音频生成任务中的强监督信号来抑制漂移现象；继而设计全局-局部解耦交互模块，实现高效精准的时序风格对齐；最后提出同步增强型无分类器引导机制，在推理阶段显式分离并增强对齐信号。大量实验表明，Harmony创造了新的技术标杆，在生成保真度及关键的细粒度音视频同步效果上均显著超越现有方法。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.21579) | [arXiv](https://arxiv.org/abs/2511.21579)



---

### 5. 重新审视跨难度水平的泛化能力：并非易事

**原文标题：** Revisiting Generalization Across Difficulty Levels: It's Not So Easy

**摘要：**
本文系统研究大型语言模型在不同任务难度间的泛化能力，这是影响数据筛选与评估效果的核心问题。现有研究对"使用简易数据还是困难数据进行训练效果更佳"以及"性能提升体现在简易测试集还是困难测试集"等问题尚未达成共识。我们通过构建跨模型、跨数据集及跨细粒度难度分组的系统评估框架，采用数千种大型语言模型输出结果与教育测试领域成熟难度指标——项目反应理论(IRT)相结合的方法，对六个数据集中的实例进行难度分级。与既往研究不同，本研究的难度评级完全基于多样化大型语言模型的自身能力，排除了人类主观难度判断。通过更客观、大规模、细粒度的分析，我们发现跨难度泛化能力存在普遍局限性：无论使用简易数据还是困难数据进行训练，均无法在全难度范围内实现持续性能提升。这些结果表明在大型语言模型的训练与评估数据中保持难度多样性的重要性，同时也警示在难度处理上采取捷径存在风险。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.21692) | [arXiv](https://arxiv.org/abs/2511.21692)



---

### 6. 英伟达Nemotron Parse 1.1模型

**原文标题：** NVIDIA Nemotron Parse 1.1

**摘要：**
本文介绍Nemotron-Parse-1.1——一个轻量级文档解析与OCR模型，该模型在其前身Nemoretriever-Parse-1.0的基础上实现了全面功能升级。该模型在通用OCR识别、Markdown格式解析、结构化表格分析以及图片/图表/示意图文本提取等任务中均表现出显著提升，同时支持对视觉密集文档进行更长序列的输出处理。与前一版本相同，该模型能够提取文本段的边界框及对应语义类别。Nemotron-Parse-1.1采用编码器-解码器架构，参数量达8.85亿（其中语言解码器为紧凑型2.56亿参数），在公开基准测试中达到具有竞争力的准确率，成为强有力的轻量级OCR解决方案。我们已在Huggingface平台公开发布模型权重，同步提供优化版NIM容器及部分训练数据（作为Nemotron-VLM-v2数据集组成部分）。此外还推出了Nemotron-Parse-1.1-TC版本，该版本通过缩减视觉标记长度实现处理速度提升20%，且质量损失控制在最小范围。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.20478) | [arXiv](https://arxiv.org/abs/2511.20478)



---

### 7. Monet：超越图像与语言的潜在视觉空间推理

**原文标题：** Monet: Reasoning in Latent Visual Space Beyond Images and Language

**摘要：**
"图像思维"已成为推进视觉推理的有效范式，通过将视觉证据注入中间推理步骤，超越了纯文本的思维链模式。然而，现有方法因受限于外部工具，其灵活性远未达到类人的抽象视觉思维水平。本研究提出Monet训练框架，使多模态大语言模型能够通过生成作为中间视觉思维的连续嵌入表示，直接在潜在视觉空间中进行推理。我们识别出训练潜在视觉推理MLLMs的两个核心挑战：潜在视觉对齐的高计算成本与对潜在嵌入监督不足，并通过三阶段基于蒸馏的监督微调流程予以解决。进一步发现GRPO在潜在推理中的应用局限：它主要增强文本推理而非潜在推理。为此，我们提出VLPO（视觉潜在策略优化），这种强化学习方法将潜在嵌入显式纳入策略梯度更新。为支持监督微调，我们构建了包含12.5万条真实世界图表、OCR和几何思维链的高质量图文交错数据集Monet-SFT-125K。我们的Monet-7B模型在真实世界感知与推理基准测试中表现持续提升，并在具有挑战性的抽象视觉推理任务上展现出强大的分布外泛化能力。我们通过实证分析各训练组件的作用，并讨论早期失败尝试，为视觉潜在推理的未来发展提供见解。模型、数据及代码已发布于https://github.com/NOVAglow646/Monet。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.21395) | [arXiv](https://arxiv.org/abs/2511.21395)



---

### 8. 终端速度匹配

**原文标题：** Terminal Velocity Matching

**摘要：**
本文提出终端速度匹配（TVM）方法，作为流匹配的泛化形式，能够实现高保真度的单步及少步生成建模。TVM模拟任意两个扩散时间步之间的转移过程，并在终端时刻而非初始时刻对其行为进行正则化处理。我们证明当模型满足Lipschitz连续性时，TVM能为数据分布与模型分布之间的2-Wasserstein距离提供上界。然而由于扩散变换器不具备该性质，我们引入了最小化架构调整以实现稳定的单阶段训练。为提升TVM的实际效率，我们开发了融合注意力核函数，该函数支持雅可比-向量乘积的反向传播，并能与变换器架构良好适配。在ImageNet-256x256数据集上，TVM以单次函数评估（NFE）取得3.29 FID，4次NFE取得1.99 FID；在ImageNet-512x512数据集上分别实现4.32（1-NFE）和2.94（4-NFE）的FID，这代表了从零开始训练的单步/少步模型的最先进性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.19797) | [arXiv](https://arxiv.org/abs/2511.19797)



---

### 9. UniGame：将统一多模态模型转化为自身对抗者

**原文标题：** UniGame: Turning a Unified Multimodal Model Into Its Own Adversary

**摘要：**
统一多模态模型（UMMs）通过单一架构在理解与生成任务中均展现出卓越性能。然而这类模型仍存在根本性不一致问题：理解任务偏好紧凑嵌入表示，而生成任务需要重构丰富的表征。这种结构性权衡导致决策边界失准、跨模态连贯性下降，以及在分布偏移和对抗攻击下的脆弱性加剧。本文提出UniGame——一种针对上述不一致性设计的自对抗后训练框架。通过在共享令牌接口施加轻量化扰动器，该框架使生成分支能够主动探寻并挑战脆弱理解环节，将模型自身转化为其对抗者。实验表明，UniGame显著提升模型一致性（+4.6%），同时在理解任务（+3.6%）、生成质量（+0.02）、分布外泛化与对抗鲁棒性（在NaturalBench和AdVQA数据集上分别提升+4.8%和+6.2%）方面取得实质性进步。该框架具备架构无关性，仅引入不足1%的额外参数，且可与现有后训练方法形成互补。这些成果确立了对抗自博弈作为增强未来多模态基础模型的连贯性、稳定性与统一能力的普适性原则。项目代码已开源：https://github.com/AIFrontierLab/UniGame

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.19413) | [arXiv](https://arxiv.org/abs/2511.19413)



---

### 10. G^2VLM：基于几何基础的视觉语言模型——统一三维重建与空间推理的新范式

**原文标题：** G^2VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning

**摘要：**
当前视觉语言模型在空间智能方面仍存在明显不足，在空间理解与推理任务中表现欠佳。我们认为这一缺陷源于缺乏能够从二维图像重建三维空间的视觉几何学习过程。本文提出G^2VLM模型，该几何基础视觉语言模型融合了空间智能的两个核心维度：三维空间重建与空间理解。G^2VLM原生利用学习得到的三维视觉几何特征，通过上下文学习和交错推理机制，直接预测三维属性并增强空间推理任务。我们的统一架构在空间理解方面具有高度扩展性：既能利用海量多视角图像与视频数据进行训练，又可获得通常仅通过难以采集的标注数据才能构建的三维视觉先验优势。实验结果表明，G^2VLM在双重任务中均表现优异，其三维重建效果与前沿前馈模型相当，在空间理解与推理任务中取得领先或具有竞争力的成绩。通过将语义强大的视觉语言模型与底层三维视觉任务相融合，我们期待G^2VLM能成为该领域的强基准，并为三维场景编辑等未来应用开启新的可能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.21688) | [arXiv](https://arxiv.org/abs/2511.21688)



---

### 11. 块级联：无需训练的块因果视频模型加速方法

**原文标题：** Block Cascading: Training Free Acceleration of Block-Causal Video Models

**摘要：**
块因果视频生成面临显著的速度-质量权衡：13亿参数的小型模型仅能达到16 FPS，而140亿参数的大型模型更是低至4.5 FPS，迫使用户在响应速度与生成质量之间做出取舍。块级联方法通过无需训练的并行化技术显著缓解了这一矛盾。我们的核心发现是：后续视频块的生成无需等待当前块完全去噪完成。通过基于前驱块部分去噪的上下文启动新块生成，我们将串行处理流程转换为多块同时去噪的并行级联系统。借助5张GPU实现时序并行计算，我们在所有模型规模上均实现约2倍加速：13亿模型从16 FPS提升至30 FPS，140亿模型从4.5 FPS提升至12.5 FPS。除推理速度提升外，块级联还消除了交互式生成中上下文切换时KV重缓存带来的约200毫秒开销。通过对多种块因果流程的广泛评估验证表明，从块因果推理切换至块级联推理不会导致生成质量显著下降。项目页面：https://hmrishavbandy.github.io/block_cascading_page/

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.20426) | [arXiv](https://arxiv.org/abs/2511.20426)



---

### 12. MobileVLA-R1：面向移动机器人的视觉-语言-动作强化框架

**原文标题：** MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots

**摘要：**
将自然语言指令映射为四足机器人的连续控制仍是视觉-语言-动作领域的核心挑战。现有方法难以实现高层语义推理与底层执行控制的衔接，导致现实场景中的指令落地不稳定且泛化能力薄弱。为此，我们提出MobileVLA-R1——一个支持四足机器人显式推理与连续控制的统一视觉-语言-动作框架。我们构建了MobileVLA-CoT大规模具身轨迹多粒度思维链数据集，为语义对齐提供结构化推理监督。基于此，我们引入结合监督式思维链对齐与GRPO强化学习的双阶段训练范式，显著提升推理一致性、控制稳定性和长周期任务执行能力。在VLN和VLA任务上的大量实验表明，本方法较现有基线模型性能提升约5%。在四足机器人实体上的部署验证了其在复杂环境中的鲁棒性。代码：https://github.com/AIGeeksGroup/MobileVLA-R1 项目网站：https://aigeeksgroup.github.io/MobileVLA-R1

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.17889) | [arXiv](https://arxiv.org/abs/2511.17889)



---

### 13. 通过预知强化动作策略

**原文标题：** Reinforcing Action Policies by Prophesying

**摘要：**
视觉-语言-动作策略在语言、感知与机器人控制的协同方面表现卓越。然而多数视觉-语言-动作模型仅通过模仿学习进行训练，这会导致对演示数据的过拟合，且在分布偏移时表现脆弱。强化学习通过直接优化任务奖励来解决此类错位问题，但真实机器人交互成本高昂，传统模拟器又难以构建和迁移。我们通过构建学习型世界模型与适配流式动作头的强化学习流程，同步解决视觉-语言-动作模型后训练阶段的数据效率与优化稳定性问题。具体而言，我们提出Prophet——一个基于大规模异构机器人数据预训练的统一动作-视频机器人执行框架，可学习可重用的动作-结果动态关系。该框架能够通过少量样本适配新机器人、物体及环境，形成可直接部署的模拟系统。基于Prophet框架，我们通过适配视觉-语言-动作操作的流式动作GRPO算法，以及通过FlowScale步进重加权技术调整流式头中逐步梯度，共同强化动作策略。Prophet、流式动作GRPO与FlowScale三者构成ProphRL系统，为视觉-语言-动作模型后训练提供了实用且节省数据计算资源的解决方案。实验表明，在不同视觉-语言-动作模型变体上，公开基准测试成功率提升5-17%，真实机器人实验提升24-30%。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.20633) | [arXiv](https://arxiv.org/abs/2511.20633)



---

### 14. 基于轨迹采样对连续时间一致性的免图像时间步蒸馏方法

**原文标题：** Image-Free Timestep Distillation via Continuous-Time Consistency with Trajectory-Sampled Pairs

**摘要：**
时间步蒸馏是提升扩散模型生成效率的有效方法。一致性模型作为基于轨迹的框架，凭借其坚实的理论基础和高质量少步生成能力展现出巨大潜力。然而，当前连续时间一致性蒸馏方法仍严重依赖训练数据和计算资源，这阻碍了其在资源受限场景中的部署，并限制了跨领域扩展能力。针对此问题，我们提出轨迹反向一致性模型，通过直接从教师模型的生成轨迹中提取潜在表征，消除对外部训练数据的依赖。与需要VAE编码和大规模数据集的传统方法不同，我们的自包含蒸馏范式显著提升了效率与简洁性。此外，轨迹提取样本天然弥合了训练与推理间的分布差异，从而实现更有效的知识迁移。实验表明，在单步生成条件下，TBCM在MJHQ-30k数据集上取得了6.52的FID分数和28.08的CLIP分数，同时相较Sana-Sprint减少约40%训练时间并节省大量GPU内存，在保证质量的前提下展现出卓越效率。我们进一步揭示了连续时间一致性蒸馏中的扩散-生成空间差异，并分析采样策略如何影响蒸馏性能，为未来蒸馏研究提供重要参考。GitHub链接：https://github.com/hustvl/TBCM。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.20410) | [arXiv](https://arxiv.org/abs/2511.20410)



---

### 15. SPHINX：面向视觉感知与推理的合成环境

**原文标题：** SPHINX: A Synthetic Environment for Visual Perception and Reasoning

**摘要：**
本文提出Sphinx——一个针对核心认知基元的视觉感知与推理合成环境。该系统通过程序化生成包含纹样、图块、图表、图标及几何基元的谜题，每个谜题均配有可验证的基准解，既能实现精准评估又可支持大规模数据集构建。该基准测试涵盖对称检测、几何变换、空间推理、图表解读和序列预测等25类任务。对近期大规视觉语言模型的评估表明，即便是最先进的GPT-5模型准确率也仅为51.1%，远低于人类表现。最后我们验证了基于可验证奖励的强化学习能显著提升模型在这些任务上的准确率，并在外部视觉推理基准测试中产生增益，凸显了该方法对推进多模态推理发展的潜力。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.20814) | [arXiv](https://arxiv.org/abs/2511.20814)



---

### 16. 立场声明：完美AI对齐的复杂性——形式化强化学习人类反馈三难困境

**原文标题：** Position: The Complexity of Perfect AI Alignment -- Formalizing the RLHF Trilemma

**摘要：**
基于人类反馈的强化学习（RLHF）被广泛用于对齐大型语言模型，但实践者始终面临一个难题：提升安全性往往损害公平性，扩展到多样化群体时计算复杂度难以处理，增强系统鲁棒性又会放大主流偏见。我们将这种张力形式化为"对齐三难困境"：任何RLHF系统都无法同时实现（i）跨多元人类价值观的ε-代表性，（ii）样本与计算复杂度的多项式可处理性，以及（iii）对抗性扰动与分布偏移的δ-鲁棒性。通过融合统计学习理论与鲁棒优化的计算复杂性分析，我们证明要实现全球规模群体的代表性（ε≤0.01）与鲁棒性（δ≤0.001）需要Ω(2^{d_context})量级运算，这在上下文维度上呈超多项式增长。研究表明当前RLHF实施方案通过牺牲代表性来解决该困境：仅从同质标注群体收集10^3--10^4个样本，而真实全球代表性需要10^7--10^8个样本。我们的框架为已记录的RLHF缺陷（包括偏好坍缩、谄媚效应和系统性偏见放大）提供了统一解释。最后我们提出通过策略性放宽对齐要求来应对这些根本性权衡的具体方向。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.19504) | [arXiv](https://arxiv.org/abs/2511.19504)



---

### 17. NAF：基于邻域注意力滤波的零样本特征上采样方法

**原文标题：** NAF: Zero-Shot Feature Upsampling via Neighborhood Attention Filtering

**摘要：**
视觉基础模型提取的空间下采样表征为像素级任务带来挑战。现有上采样方法面临根本性权衡：经典滤波器虽快速通用但依赖固定形式，而现代上采样器通过可学习的VFM专用形式实现更高精度，却需为每个VFM重新训练。本文提出邻域注意力滤波方法，通过跨尺度邻域注意力与旋转位置编码学习自适应空间-内容权重，仅以高分辨率输入图像作为指导，成功弥合这一差距。NAF具备零样本特性：无需重新训练即可对任意VFM的特征进行上采样，成为首个在多个下游任务中超越VFM专用上采样器并达到最优性能的VFM无关架构。该方法保持高效性，可扩展至2K特征图并以18FPS重建中间分辨率图谱。除特征上采样外，NAF在图像复原任务中也展现出卓越性能，体现了其多功能的特性。代码与检查点已发布于https://github.com/valeoai/NAF。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.18452) | [arXiv](https://arxiv.org/abs/2511.18452)



---

### 18. RAISECity：面向城市级现实对齐三维世界生成的多模态智能体框架

**原文标题：** RAISECity: A Multimodal Agent Framework for Reality-Aligned 3D World Generation at City-Scale

**摘要：**
城市级三维生成对于具身智能与世界模型的发展具有重要意义。然而现有方法在三维世界生成的质量、真实性与可扩展性方面面临重大挑战。为此，我们提出RAISECity——一个能够创建精细化城市级三维世界的现实对齐智能合成引擎。我们引入了一种智能体框架，通过利用多样化的多模态基础工具获取现实世界知识，保持鲁棒的中间表征，并构建复杂的三维场景。该智能体设计具有动态数据处理、迭代式自反思优化以及调用先进多模态工具等特点，能有效减少累积误差并提升整体性能。大量定量实验与定性分析验证了RAISECity在现实对齐度、几何精度、纹理保真度与美学水平上的卓越表现，在整体感知质量评估中以超过90%的胜率显著优于现有基线方法。这种兼具三维质量、现实对齐性、可扩展性以及与计算机图形管线无缝兼容的特性，使RAISECity成为沉浸式媒体、具身智能和世界模型等领域极具前景的基础平台。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.18005) | [arXiv](https://arxiv.org/abs/2511.18005)



---

### 19. I-GLIDE：退化估计中潜在健康指标的输入分组方法

**原文标题：** I-GLIDE: Input Groups for Latent Health Indicators in Degradation Estimation

**摘要：**
准确的剩余使用寿命预测依赖于健康指标的质量，然而现有方法往往难以解耦多传感器系统中的复杂退化机制或量化健康指标可靠性的不确定性。本文提出了一种创新的健康指标构建框架，具有三个关键贡献：首先，我们首次将投影路径重建方法改造为适用于剩余使用寿命预测的健康指标，证明其性能优于传统重构误差指标；其次，通过蒙特卡洛丢弃法和概率潜空间实现偶然性与认知性不确定度量化，显著增强了基于投影路径重建的健康指标在剩余使用寿命预测中的鲁棒性；第三也是最重要的，我们提出指标分组范式，通过隔离传感器子集来建模系统特定退化机制，由此形成名为I-GLIDE的创新方法，可实现可解释的机制特异性诊断。在航空航天与制造系统数据上的评估表明，相较于最先进的健康指标方法，本方案在预测精度与泛化能力方面取得显著提升，同时为系统失效路径提供了可操作的洞见。该研究填补了异常检测与预测性维护之间的空白，为复杂系统中不确定性感知的退化建模提供了理论框架。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.21208) | [arXiv](https://arxiv.org/abs/2511.21208)



---

### 20. 提升三维高斯溅射泛化能力的频率自适应锐度正则化方法

**原文标题：** Frequency-Adaptive Sharpness Regularization for Improving 3D Gaussian Splatting Generalization

**摘要：**
尽管三维高斯溅射（3DGS）在多数场景中表现卓越，但在稀疏观测数据下的少样本场景中，由于对观测数据的过拟合，其在新视角下的泛化能力存在不足。本文从机器学习视角重新审视3DGS优化过程，将新视角合成问题定义为对未观测视角的泛化问题——这一方向尚未被充分探索。我们提出频率自适应锐度正则化方法（FASR），通过重构3DGS训练目标函数，引导3DGS收敛至更具泛化能力的解。虽然锐度感知最小化（SAM）方法同样通过降低损失景观的锐度来提升分类模型的泛化能力，但由于任务差异，直接将其应用于3DGS存在局限。具体而言，过度正则化会阻碍高频细节重建，而降低正则化强度又会导致锐度惩罚不足。为解决该问题，我们通过反映图像的局部频率特性来设定正则化权重及局部锐度估计时的邻域半径。该方法既能有效抑制新视角下的浮游伪影，又能重建SAM方法容易过度平滑的精细细节。在多种配置的数据集测试中，本方法持续提升了各类基线的性能。代码将在https://bbangsik13.github.io/FASR 发布。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2511.17918) | [arXiv](https://arxiv.org/abs/2511.17918)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2025-11-27_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)