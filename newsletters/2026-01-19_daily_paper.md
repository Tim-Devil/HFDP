
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-19 论文日报

## 📊 今日论文统计
- 总论文数：22
- 热门领域：RL, LLM, GPT, Transformer, NLP

## 📝 论文详情


### 1. 群体相对优势估计存在偏差

**原文标题：** Your Group-Relative Advantage Is Biased

**摘要：**
基于验证器奖励的强化学习已成为推理任务中大规模语言模型后训练的主流方法，其中以GRPO及其变体为代表的群体化方法得到广泛应用。该方法依赖群体相对优势估计以避免学习判别器，但其理论性质尚未得到充分理解。本文揭示了群体化强化学习的一个根本问题：群体相对优势估计量相对于真实（期望）优势存在固有偏差。我们首次通过理论分析证明，该方法会系统性低估困难提示的优势值，同时高估简单提示的优势值，导致探索与利用的失衡。为解决此问题，我们提出历史感知自适应难度加权方法——一种基于动态难度锚点与训练过程的自适应重加权方案，可调整优势估计值。在五个数学推理基准测试中，理论分析与实验结果表明，将HA-DW集成至GRPO及其变体后能持续提升模型性能。本研究证明，修正有偏差的优势估计对于实现稳健高效的RLVR训练至关重要。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.08521) | [arXiv](https://arxiv.org/abs/2601.08521)



---

### 2. 毒苹果效应：通过AI智能体技术扩张对中介市场进行策略性操纵

**原文标题：** The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents

**摘要：**
AI智能体融入经济市场从根本上改变了策略互动的格局。本文通过三个经典博弈论场景——议价（资源分配）、谈判（非对称信息交易）与劝说（策略性信息传递），系统研究了可用技术集合扩张的经济影响。研究发现，单纯增加AI代理人的选择范围即可能剧烈改变均衡收益与监管结果，这常常激励监管机构主动开发并发布新技术。相反地，我们揭示了一种被称为“毒苹果”效应的策略现象：行为主体可能发布一项新技术（其自身与对手最终皆不采用），其唯一目的是操纵监管机构选择对己方有利的市场设计方案。这种策略性技术发布以牺牲对手利益和监管公平目标为代价，提升了发布者的福利水平。本研究证明，静态监管框架易受技术扩张的操纵，因此需要构建能够适应AI能力动态演进的市场设计机制。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11496) | [arXiv](https://arxiv.org/abs/2601.11496)



---

### 3. 解锁隐含经验：基于文本的工具使用轨迹合成

**原文标题：** Unlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text

**摘要：**
使大型语言模型（LLM）在多轮交互中有效利用工具，对于构建具备能力的自主智能体至关重要。然而，获取多样化且真实的多轮工具使用数据仍是一项重大挑战。本研究提出一种新颖的基于文本的范式。我们发现文本语料库天然包含丰富的多步骤问题解决经验，可作为多轮工具使用任务中尚未开发、可扩展且真实的数据源。基于这一洞察，我们提出了GEM——一种数据合成流程，通过四阶段处理（相关性筛选、工作流与工具提取、轨迹锚定、复杂度优化）从文本语料中生成并提取多轮工具使用轨迹。为降低计算成本，我们进一步通过监督微调训练了专用的轨迹合成器。该模型将复杂的生成流程提炼为高效的端到端轨迹生成器。实验表明，我们的GEM-32B模型在BFCL V3多轮基准测试中实现了16.5%的性能提升。我们的模型在部分领域（航空与零售）数据上超越了基于τ-bench领域内数据训练的模型性能，凸显了基于文本合成范式带来的卓越泛化能力。值得注意的是，我们的轨迹合成器在保持全流程生成质量的同时，显著降低了推理延迟与计算成本。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.10355) | [arXiv](https://arxiv.org/abs/2601.10355)



---

### 4. RubricHub：基于自动化由粗到细生成框架构建的全面且高区分度的评分标准数据集

**原文标题：** RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation

**摘要：**
基于可验证奖励的强化学习（RLVR）在数学等推理密集型领域已取得显著进展。然而，由于缺乏真实基准，优化开放式生成任务仍面临挑战。基于评分标准的评估虽能为验证提供结构化代理，但现有方法受限于可扩展性瓶颈与粗糙的评价标准，导致监督效果存在天花板效应。为此，我们提出一种自动化“由粗到细”的评分标准生成框架。该方法融合原则引导合成、多模型聚合与难度演化机制，能够生成全面且具有高区分度的评价标准，从而捕捉生成内容中的细微差异。基于此框架，我们构建了RubricHub——一个大规模（约11万条）跨领域数据集。我们通过包含基于评分标准的拒绝采样微调（RuFT）和强化学习（RuRL）的两阶段后训练流程验证其实用性。实验结果表明，RubricHub能显著提升模型性能：经后训练的Qwen3-14B模型在HealthBench基准上达到69.3分的最先进水平，超越了GPT-5等前沿专有模型。代码与数据即将开源发布。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.08430) | [arXiv](https://arxiv.org/abs/2601.08430)



---

### 5. 当个性化误导：理解并缓解个性化大语言模型中的幻觉现象

**原文标题：** When Personalization Misleads: Understanding and Mitigating Hallucinations in Personalized LLMs

**摘要：**
个性化大语言模型通过适应用户个体特征以提升用户满意度，但个性化过程可能无意中扭曲事实推理。我们发现，当个性化大语言模型面对事实性查询时，存在一种现象：模型倾向于生成符合用户历史偏好的答案而非客观事实，从而导致个性化诱导的幻觉。这种幻觉会降低事实可靠性，并可能传播错误信念，其根源在于个性化表征与事实表征之间的表示纠缠。为解决此问题，我们提出事实保持个性化导向方法，这是一种轻量级的推理时干预方法，能够在保持个性化行为的同时缓解个性化导致的事实扭曲。我们进一步提出PFQABench，这是首个专门用于在个性化设置下联合评估事实性与个性化问答能力的基准测试。在多种大语言模型架构与个性化方法上的实验表明，事实保持个性化导向方法能显著提升事实准确性，同时保持个性化性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11000) | [arXiv](https://arxiv.org/abs/2601.11000)



---

### 6. ACoT-VLA：面向视觉-语言-动作模型的动作思维链

**原文标题：** ACoT-VLA: Action Chain-of-Thought for Vision-Language-Action Models

**摘要：**
视觉-语言-动作（VLA）模型已成为处理多样化操作任务的关键通用机器人策略，传统方法依赖通过视觉-语言模型（VLM）嵌入将多模态输入直接转换为动作。近期研究引入了显式中间推理机制（如子任务预测的语言推理或目标图像合成的视觉推理）以指导动作生成。然而，这些中间推理往往具有间接性，且本质上难以传递精确动作执行所需的完整细粒度信息。为此，我们提出最有效的推理形式应直接在动作空间中进行推演。本文引入动作思维链（ACoT）范式，将推理过程构建为结构化粗粒度动作意图序列以指导最终策略。我们提出ACoT-VLA这一实现ACoT范式的新型架构，具体包含两个互补组件：显式动作推理器（EAR）与隐式动作推理器（IAR）。前者通过提出粗粒度参考轨迹作为显式动作级推理步骤，后者从多模态输入的内部表征中提取潜在动作先验，共同构成ACoT以约束下游动作头模块，实现具身化的策略学习。在真实环境与仿真环境中的大量实验表明，所提方法在LIBERO、LIBERO-Plus和VLABench基准上分别达到98.5%、84.1%和47.4%的性能表现，验证了其优越性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11404) | [arXiv](https://arxiv.org/abs/2601.11404)



---

### 7. BAPO：面向可靠智能体搜索的边界感知策略优化

**原文标题：** BAPO: Boundary-Aware Policy Optimization for Reliable Agentic Search

**摘要：**
基于强化学习的智能体搜索使大语言模型能够通过动态规划和外部搜索解决复杂问题。尽管该方法通过大规模强化学习优化的智能体策略显著提升了准确性，但我们发现其可靠性存在关键缺陷：这些智能体无法识别其推理边界，即使在证据不足或推理达到极限时也极少承认“我不知道”（IDK）。可靠性的缺失往往导致看似合理但不可靠的答案，这在许多现实场景中会带来重大风险。为此，我们提出边界感知策略优化（BAPO），这是一种新颖的强化学习框架，旨在培养可靠的边界感知能力，同时不牺牲准确性。BAPO引入两个关键组件：（i）基于群体的边界感知奖励机制，仅在推理达到极限时鼓励模型给出IDK响应；（ii）自适应奖励调节器，在早期探索阶段策略性地暂停该奖励，防止模型将IDK作为捷径进行利用。在四个基准测试上的大量实验表明，BAPO显著提升了智能体搜索的整体可靠性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11037) | [arXiv](https://arxiv.org/abs/2601.11037)



---

### 8. FrankenMotion：部件级人体运动生成与组合

**原文标题：** FrankenMotion: Part-level Human Motion Generation and Composition

**摘要：**
近年来，基于文本提示的人体运动生成取得了显著进展。然而，由于缺乏细粒度的部件级运动标注，现有方法主要依赖于序列级或动作级描述，这限制了对个体身体部位的可控性。在本研究中，我们利用大语言模型（LLMs）的推理能力，构建了一个具有原子化、时序感知的部件级文本标注的高质量运动数据集。与以往仅提供固定时间段同步部件描述或仅依赖全局序列标签的数据集不同，我们的数据集以精细的时间分辨率捕捉了异步且语义独立的部件运动。基于此数据集，我们提出了一种基于扩散的部件感知运动生成框架，即FrankenMotion，其中每个身体部位由其自身的时间结构化文本提示引导。据我们所知，这是首个提供原子化、时序感知的部件级运动标注，并实现同时具备空间（身体部位）与时间（原子动作）控制的运动生成模型的研究。实验表明，FrankenMotion在适应并重训练于本设定下的所有基线模型中表现最优，且我们的模型能够组合训练中未见的运动。代码与数据集将在论文发表后公开提供。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.10909) | [arXiv](https://arxiv.org/abs/2601.10909)



---

### 9. 熵哨兵：基于解码熵迹的STEM领域大语言模型准确性持续监测

**原文标题：** Entropy Sentinel: Continuous LLM Accuracy Monitoring from Decoding Entropy Traces in STEM

**摘要：**
部署大语言模型面临两个相互关联的挑战：(1) 监测——在流量和领域发生漂移时评估模型在哪些方面表现不佳；(2) 改进——通过优先获取数据来弥补最大的性能差距。本研究验证了推理阶段的信号能否在领域偏移下估计分片级准确性。针对每个模型响应，我们基于最终层下一个词元的概率（来自top-k对数概率）计算输出熵分布曲线，并用十一个统计量进行概括。通过轻量级分类器预测单个实例的正确性，并对预测概率进行平均以获得领域级准确性估计。我们在十个STEM推理基准测试上进行了评估，涵盖详尽的训练/测试组合（k取值为{1,2,3,4}；所有“10选k”组合），并测试了来自六个系列的九个大语言模型（参数量3B-20B）。实验表明，估计值往往能有效跟踪保留基准测试的准确性，多个模型在不同领域间呈现出近乎单调的排序关系。因此，输出熵分布曲线为可扩展的模型监测和数据采集目标定位提供了易于获取的有效信号。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.09001) | [arXiv](https://arxiv.org/abs/2601.09001)



---

### 10. 未来光流预测提升机器人控制与视频生成能力

**原文标题：** Future Optical Flow Prediction Improves Robot Control & Video Generation

**摘要：**
未来运动表征（如光流）对控制与生成任务具有重要价值。然而，如何预测具有泛化能力的空间稠密运动表征仍是核心挑战，且从含噪声的真实世界数据中学习此类预测的研究尚不充分。本文提出FOFPred模型——一种基于语言条件的光流预测框架，其创新性地融合了视觉语言模型与扩散模型架构。该组合通过多模态推理能力与像素级生成保真度，实现了对未来运动的高质量预测。模型基于网络规模的人类活动数据进行训练（该数据源可扩展性强但结构松散），为从含噪声的视频-文本数据中提取有效信号，我们采用了关键的数据预处理技术，并依托强图像预训练的融合架构提升模型性能。训练完成的模型可进一步拓展至控制与生成两大下游任务。在语言驱动场景下的机器人操作与视频生成实验表明，FOFPred具备跨领域泛化能力，验证了统一视觉语言-扩散架构的优越性，并证明了基于多样化网络数据进行可扩展学习对未来光流预测的重要价值。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.10781) | [arXiv](https://arxiv.org/abs/2601.10781)



---

### 11. ProFit：通过概率引导的令牌选择在监督微调中利用高价值信号

**原文标题：** ProFit: Leveraging High-Value Signals in SFT via Probability-Guided Token Selection

**摘要：**
监督微调（SFT）是将大型语言模型（LLM）与人类意图对齐的关键后训练策略。然而，传统SFT通常强制模型与单一参考答案对齐，忽视了语言的一对多本质，导致模型过度拟合非核心表达。尽管实证分析表明引入多个参考答案可以缓解此问题，但高昂的数据与计算成本要求策略转向：优先缓解单参考答案导致的过拟合，而非追求代价高昂的答案多样性。为实现这一目标，我们揭示了令牌概率与语义重要性之间的内在关联：高概率令牌承载核心逻辑框架，而低概率令牌多为可替换表达。基于此发现，我们提出ProFit方法，通过选择性掩码低概率令牌来防止表面层级的过拟合。大量实验证实，ProFit在通用推理与数学基准测试中均稳定优于传统SFT基线方法。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.09195) | [arXiv](https://arxiv.org/abs/2601.09195)



---

### 12. ShapeR：基于随意采集数据的鲁棒性条件三维形状生成

**原文标题：** ShapeR: Robust Conditional 3D Shape Generation from Casual Captures

**摘要：**
三维形状生成技术近期取得了显著进展，但现有方法大多依赖于干净、无遮挡且分割良好的输入数据，这些条件在实际场景中往往难以满足。本文提出ShapeR，一种从随意采集序列中生成条件化三维物体形状的新方法。给定图像序列，我们利用现成的视觉-惯性SLAM系统、三维检测算法与视觉-语言模型，为每个物体提取稀疏SLAM点集、多视角位姿图像及机器生成描述文本。通过训练整流流变换器有效融合这些模态信息，最终生成高保真度的度量三维形状。为应对随意采集数据带来的挑战，我们采用多项技术增强鲁棒性，包括动态组合增强、涵盖物体与场景层级数据集的课程训练方案，以及处理背景干扰的策略。此外，我们构建了包含7个真实场景中178个带几何标注的野外物体的新评估基准。实验表明，在该挑战性设定下，ShapeR显著优于现有方法，其倒角距离指标较当前最优方法提升2.7倍。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11514) | [arXiv](https://arxiv.org/abs/2601.11514)



---

### 13. PhysRVG：面向视频生成模型的物理感知统一强化学习框架

**原文标题：** PhysRVG: Physics-Aware Unified Reinforcement Learning for Video Generative Models

**摘要：**
物理原理是实现逼真视觉模拟的基础，但在基于Transformer的视频生成方法中却长期被忽视。这一缺陷尤其体现在刚体运动渲染这一经典力学核心原理的建模上。尽管计算机图形学与基于物理的模拟器能够轻松运用牛顿公式模拟此类碰撞，现代预训练-微调范式却在像素级全局去噪过程中丢弃了物体刚性的概念。即使在训练后的模型优化阶段，完全正确的数学约束也仅被视为次优解（即条件），这从根本上限制了生成视频的物理真实感。基于上述考量，我们首次提出一种面向视频生成模型的物理感知强化学习范式，该范式能够直接在高层特征空间中强制执行物理碰撞规则，确保物理知识被严格应用而非仅作为约束条件。进一步地，我们将此范式扩展为统一框架——模仿-发现循环（MDcycle），该框架在充分保持模型利用物理反馈能力的同时，支持大规模的模型微调。为验证方法的有效性，我们构建了新的基准测试集PhysRVGBench，并通过系统的定性与定量实验全面评估了其性能。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11087) | [arXiv](https://arxiv.org/abs/2601.11087)



---

### 14. 推理模型生成思维社会

**原文标题：** Reasoning Models Generate Societies of Thought

**摘要：**
大语言模型已在多个领域展现出卓越能力，但其复杂推理的内在机制仍不明确。近期研究表明，推理模型在复杂认知任务上表现优于同等规模的指令微调模型，这通常归因于通过更长思维链实现的扩展计算。本文发现，增强的推理能力不仅源于扩展计算，更源于模拟多智能体式交互——即“思维社会”——该机制通过具有不同性格特征和领域专长的内部认知视角之间的多样化与辩论来实现。通过对推理轨迹的定量分析和机制可解释性方法，我们发现DeepSeek-R1和QwQ-32B等推理模型比指令微调模型展现出更显著的视角多样性，在推理过程中激活了更广泛的异质性性格特征与专业知识特征之间的冲突。这种多智能体结构体现于对话行为（包括问答、视角转换和矛盾观点调和）以及表征激烈交锋对话的社会情感角色中，共同构成了推理任务中的准确性优势。受控强化学习实验表明，当仅以推理准确性作为奖励时，基础模型会增强对话行为；而通过对话支架对模型进行微调，能比基础模型更快提升推理能力。这些发现表明，思维的社会化组织能够有效促进解空间的探索。我们认为推理模型建立了与人类群体集体智能的计算平行机制：当多样性被系统化组织时，能够实现更优越的问题解决能力。这为通过智能体组织利用群体智慧开辟了新的研究路径。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.10825) | [arXiv](https://arxiv.org/abs/2601.10825)



---

### 15. PersonalAlign：基于长期用户中心化记录的个性化图形用户界面代理的层次化隐式意图对齐

**原文标题：** PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records

**摘要：**
尽管图形用户界面（GUI）代理在显式完整指令下已展现出强大性能，但其实际部署需与用户更复杂的隐式意图保持对齐。本研究提出面向个性化GUI代理的层次化隐式意图对齐（PersonalAlign），该新型代理任务要求代理利用长期用户记录作为持久化上下文，以解析模糊指令中被省略的用户偏好，并基于用户状态预判潜在操作习惯以实现主动辅助。为推进该研究，我们构建了AndroidIntent基准测试集，用于评估代理通过长期用户记录推理来解析模糊指令及提供主动建议的能力。我们从不同用户的2万条长期记录中标注了775项用户特定偏好与215项操作习惯用于评估。进一步，我们提出层次化意图记忆代理（HIM-Agent），该代理通过持续更新的个人记忆库分层组织用户偏好与操作习惯以实现个性化服务。最后，我们在AndroidIntent上评估了包括GPT-5、Qwen3-VL和UI-TARS在内的多种GUI代理，实验结果表明HIM-Agent将任务执行准确率与主动建议性能分别显著提升15.7%与7.3%。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.09636) | [arXiv](https://arxiv.org/abs/2601.09636)



---

### 16. 构建适用于Gemini的生产就绪型探针

**原文标题：** Building Production-Ready Probes For Gemini

**摘要：**
前沿语言模型的能力正在迅速提升，因此我们需要更强大的缓解措施来防止恶意行为者滥用日益强大的系统。先前研究表明，激活探针可能是一种有前景的滥用缓解技术，但我们发现一个关键挑战：探针在重要的生产环境分布变化下泛化能力不足。特别地，我们发现从短上下文输入转向长上下文输入对现有探针架构构成显著挑战。为此，我们提出了几种能够应对长上下文分布变化的新型探针架构。

我们在网络攻击领域对这些探针进行评估，测试其在多种生产相关场景下的鲁棒性，包括多轮对话、静态越狱攻击和自适应红队测试。结果表明，虽然多最大值方法能够处理上下文长度问题，但要实现广泛泛化仍需结合架构选择与多样化分布训练。此外，我们发现将探针与提示分类器结合使用时，由于探针的计算效率优势，能够以较低成本实现最优准确率。

这些研究成果已成功应用于谷歌前沿语言模型Gemini的用户端实例中，实现了滥用缓解探针的部署。最后，我们通过AlphaEvolve在探针架构搜索和自适应红队测试自动化改进方面取得了初步积极成果，表明部分人工智能安全研究已具备自动化实现的可行性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11516) | [arXiv](https://arxiv.org/abs/2601.11516)



---

### 17. AgencyBench：在百万令牌现实场景中评估自主智能体的前沿能力

**原文标题：** AgencyBench: Benchmarking the Frontiers of Autonomous Agents in 1M-Token Real-World Contexts

**摘要：**
基于大语言模型（LLM）的自主智能体展现出多方面的能力，能够为经济生产作出重要贡献。然而，现有基准测试仍聚焦于单一智能体能力，未能捕捉长周期、现实世界的复杂场景。此外，现实任务对人工反馈的依赖造成了可扩展性瓶颈，阻碍了自动化流程收集与评估。为弥补这一差距，我们提出了AgencyBench——一个源于日常人工智能使用场景的综合基准，在32个现实场景中评估6项核心智能体能力，涵盖138项具有具体查询、交付标准和评估量规的任务。这些场景平均需要90次工具调用、100万令牌以及数小时的执行时间才能完成。为实现自动化评估，我们采用用户模拟智能体提供迭代反馈，并利用Docker沙箱进行基于视觉与功能量规的评估。实验表明，闭源模型显著优于开源模型（48.4% vs 32.1%）。进一步分析揭示了不同模型在资源效率、反馈驱动的自我修正以及特定工具使用偏好方面存在显著差异。最后，我们研究了智能体架构的影响，发现专有模型在其原生生态系统中表现更优（例如通过Claude-Agent-SDK运行的Claude-4.5-Opus），而开源模型则在特定执行框架中呈现独特的性能峰值，表明其存在针对特定框架优化的潜力。AgencyBench为下一代智能体提供了关键测试平台，凸显了模型架构与智能体框架协同优化的必要性。我们相信这项工作为自主智能体的未来发展指明了方向，完整基准与评估工具包已发布于https://github.com/GAIR-NLP/AgencyBench。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11044) | [arXiv](https://arxiv.org/abs/2601.11044)



---

### 18. 更多图像，更多问题？视觉语言模型失效模式的受控分析

**原文标题：** More Images, More Problems? A Controlled Analysis of VLM Failure Modes

**摘要：**
大规模视觉语言模型（LVLMs）已展现出卓越的能力，但其在多图像理解与推理方面的表现仍鲜有研究。尽管现有基准测试已开始评估多图像模型，但对其核心缺陷及其成因的系统分析仍然缺乏。本研究提出MIMIC（多图像模型洞察与挑战）基准，旨在严格评估LVLMs的多图像处理能力。基于MIMIC，我们开展了一系列诊断实验，揭示了普遍存在的问题：LVLMs常难以跨图像整合信息，且在同时追踪或关注多个概念时存在困难。针对这些缺陷，我们提出两种新颖的互补改进方案。在数据层面，我们设计了一种程序化数据生成策略，将单图像标注合成为具有针对性、信息丰富的多图像训练样本。在优化层面，我们通过分析层级注意力模式，推导出适用于多图像输入的注意力掩码方案。实验结果表明，该方法显著提升了跨图像信息聚合能力，同时在现有多图像基准测试中取得性能提升，在多项任务上超越了先前最优方法。数据与代码将在https://github.com/anurag-198/MIMIC公开。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07812) | [arXiv](https://arxiv.org/abs/2601.07812)



---

### 19. AstroReason-Bench：面向异构空间规划问题的统一智能体规划评估基准

**原文标题：** AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems

**摘要：**
智能体大语言模型（LLMs）的最新进展使其成为能够在多样化任务中进行推理与执行的通用规划器。然而，现有智能体基准测试主要集中于符号化或弱实体化环境，对其在物理约束现实领域中的性能评估尚不充分。本研究提出AstroReason-Bench——一个用于评估空间规划问题（SPP）中智能体规划能力的综合性基准。该基准涵盖具有异构目标、严格物理约束和长周期决策特性的高风险问题族，整合了包括地面站通信和敏捷对地观测在内的多种调度机制，并提供统一的面向智能体的交互协议。通过对一系列先进的开源与闭源智能体LLM系统进行评估，我们发现当前智能体在专业求解器面前表现显著不足，这凸显出现实约束下通用规划器的关键局限性。AstroReason-Bench为未来智能体研究提供了一个兼具挑战性与诊断性的测试平台。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11354) | [arXiv](https://arxiv.org/abs/2601.11354)



---

### 20. 思维语言塑造大型语言模型的输出多样性

**原文标题：** Language of Thought Shapes Output Diversity in Large Language Models

**摘要：**
输出多样性对大型语言模型至关重要，它是多元性与创造力的基础。本研究揭示，通过控制模型思考过程中使用的语言——即思维语言——能够为输出多样性提供一种新颖且结构化的来源。初步研究表明，不同思维语言在模型的思维空间中占据着不同区域。基于这一发现，我们研究了多语言思维下的两种重复采样策略——单语言采样与混合语言采样，并对所有输出（无论使用何种思维语言）统一控制为英语进行多样性评估。大量实验表明，将思维语言从英语切换至非英语语言能持续提升输出多样性，且存在明确稳定的正相关关系：思维空间中距离英语越远的语言带来的增益越大。我们进一步证明，通过组合效应聚合多种思维语言的样本可产生额外提升，而基于语言异质性的规模化采样能够拓展模型的多样性上限。最后，我们验证了这些发现在多元对齐场景中的实际价值，能够使大语言模型输出覆盖更广泛的文化知识与价值取向。代码已公开于：https://github.com/iNLP-Lab/Multilingual-LoT-Diversity。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11227) | [arXiv](https://arxiv.org/abs/2601.11227)



---

### 21. 多模态推理数据策展的关键要素？来自DCVLR挑战赛的启示

**原文标题：** What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge

**摘要：**
我们通过NeurIPS 2025视觉语言推理数据策展（DCVLR）挑战赛研究多模态推理的数据策展问题。该挑战赛通过固定模型与训练协议，聚焦于数据集选择机制的独立评估。我们使用主要源自Walton多模态冷启动数据集的精简策展数据集参赛，最终获得冠军。赛后通过消融实验发现：在已对齐的基础数据集上实施基于难度的样本选择是性能提升的核心驱动力。在固定训练方案下，扩大数据集规模并不能稳定提升平均准确率，其主要作用是降低实验随机波动；而常用的多样性筛选与合成数据增强启发式方法不仅未带来额外收益，反而常导致性能下降。这些结果表明DCVLR属于饱和态评估范式，同时凸显了数据对齐与难度控制在高效多模态推理中的核心作用。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.10922) | [arXiv](https://arxiv.org/abs/2601.10922)



---

### 22. PhyRPR：无需训练的物理约束视频生成方法

**原文标题：** PhyRPR: Training-Free Physics-Constrained Video Generation

**摘要：**
当前基于扩散模型的视频生成方法虽能合成视觉上合理的视频，但往往难以满足物理约束。关键原因在于现有方法多为单阶段框架：它们将高层物理理解与低层视觉合成相耦合，导致难以生成需要显式物理推理的内容。为解决这一局限，本文提出一种无需训练的三阶段流程PhyRPR：物理推理（PhyReason）—物理规划（PhyPlan）—物理优化（PhyRefine），该框架将物理理解与视觉合成进行解耦。具体而言，PhyReason阶段采用大型多模态模型进行物理状态推理，并借助图像生成器合成关键帧；PhyPlan阶段通过确定性方法生成可控的粗粒度运动框架；PhyRefine阶段通过潜在融合策略将该框架注入扩散采样过程，在保持规划动态特性的同时优化视觉外观。这种分阶段设计实现了生成过程中对物理属性的显式控制。在物理约束条件下的广泛实验表明，本方法能持续提升生成内容的物理合理性与运动可控性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.09255) | [arXiv](https://arxiv.org/abs/2601.09255)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2026-01-19_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)