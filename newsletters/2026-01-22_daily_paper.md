
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2026-01-22 论文日报

## 📊 今日论文统计
- 总论文数：26
- 热门领域：RL, LLM, GPT

## 📝 论文详情


### 1. 大语言模型的自主推理能力研究

**原文标题：** Agentic Reasoning for Large Language Models

**摘要：**
推理是支撑推断、问题解决与决策制定的基础认知过程。尽管大语言模型在封闭环境中展现出强大的推理能力，但在开放动态环境中仍面临挑战。自主推理通过将大语言模型重构为能够通过持续交互进行规划、行动与学习的自主智能体，标志着研究范式的转变。本综述从三个互补维度系统梳理自主推理体系：首先，通过三层结构刻画环境动态性——基础自主推理层建立核心单智能体能力（包括稳定环境中的规划、工具使用与搜索）；自我进化自主推理层研究智能体如何通过反馈、记忆与适应机制优化能力；集体多智能体推理层将智能拓展至涉及协同、知识共享与共同目标的协作场景。贯穿这三个层面，我们区分了上下文推理（通过结构化编排扩展测试时交互）与训练后推理（通过强化学习与监督微调优化行为）。进一步地，我们综述了现实应用与基准测试中的代表性自主推理框架，涵盖科学、机器人、医疗健康、自主研究与数学等领域。本综述将自主推理方法整合为连接思维与行动的统一路线图，并指出未来面临的开放挑战与发展方向，包括个性化适配、长周期交互、世界模型构建、可扩展多智能体训练以及实际部署的治理机制。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.12538) | [arXiv](https://arxiv.org/abs/2601.12538)



---

### 2. MMDeepResearch-Bench：面向多模态深度研究智能体的基准测试框架

**原文标题：** MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents

**摘要：**
深度研究智能体通过多步骤检索与综合生成引证翔实的报告，然而现有基准主要针对纯文本场景或短形式多模态问答，缺乏对端到端多模态证据利用能力的评估。本文提出MMDeepResearch-Bench（MMDR-Bench），该基准涵盖21个领域的140项专家构建任务，每个任务提供图文组合数据以评估多模态理解能力与基于引证的报告生成质量。相较于现有评估体系，MMDR-Bench强调显式证据利用的报告式综合生成，要求模型必须建立视觉内容与溯源主张的关联，并保持叙述、引证和视觉参照的一致性。我们进一步提出统一且可解释的三维评估流程：采用公式化大语言模型自适应评估（FLAE）衡量报告质量，可信检索对齐引证评估（TRACE）检验基于引证的证据对齐度，多模态支持对齐完整性验证（MOSAIC）检测文本-视觉完整性。每个维度均产生细粒度评估信号，支持超越单一总分的错误诊断。对25个前沿模型的实验表明，生成质量、引证规范性与多模态基础之间存在系统性权衡，凸显了仅凭流畅文本生成无法保证证据使用的忠实性，且多模态完整性仍是深度研究智能体发展的关键瓶颈。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.12346) | [arXiv](https://arxiv.org/abs/2601.12346)



---

### 3. 面向具身世界的视频生成模型再思考

**原文标题：** Rethinking Video Generation Model for the Embodied World

**摘要：**
视频生成模型显著推动了具身智能的发展，为生成能够捕捉物理世界中感知、推理与行动的多样化机器人数据开辟了新可能。然而，合成能够准确反映真实世界机器人交互的高质量视频仍具挑战性，且缺乏标准化基准限制了公平比较与领域进展。为弥补这一空白，我们提出了一个综合性机器人基准RBench，旨在通过五个任务领域和四种不同具身形态评估面向机器人的视频生成性能。该基准通过可复现的子指标（包括结构一致性、物理合理性与动作完整性）同时评估任务层面的正确性与视觉保真度。对25个代表性模型的评估揭示了当前模型在生成物理真实的机器人行为方面存在显著不足。此外，该基准与人类评估的斯皮尔曼相关系数达到0.96，验证了其有效性。尽管RBench为识别这些不足提供了必要的观察视角，但实现物理真实性需要超越评估层面，以解决高质量训练数据严重短缺的核心问题。基于此洞见，我们提出了一套精炼的四阶段数据流程，由此构建了RoVid-X——目前最大的开源机器人视频生成数据集，包含400万个标注视频片段，涵盖数千种任务，并附有全面的物理属性标注。总体而言，这种评估与数据协同的生态系统为视频模型的严谨评估与规模化训练奠定了坚实基础，将加速具身人工智能向通用智能的演进。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.15282) | [arXiv](https://arxiv.org/abs/2601.15282)



---

### 4. Paper2Rebuttal：一个用于透明化作者回复辅助的多智能体框架

**原文标题：** Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance

**摘要：**
撰写有效的反驳意见是一项高风险任务，其要求不仅限于语言流畅性，更需要精准把握审稿人意图与稿件细节之间的对应关系。现有解决方案通常将其视为直接文本生成问题，存在幻觉生成、批评要点遗漏以及缺乏可验证依据等缺陷。为突破这些限制，我们提出了RebuttalAgent——首个将反驳生成重构为以证据为中心的规划任务的多智能体框架。该系统将复杂审稿意见分解为原子化问题点，通过融合压缩摘要与高保真文本动态构建混合上下文，同时集成自主按需的外部检索模块以解决需要外部文献支撑的问题。通过在起草前生成可审查的回复计划，RebuttalAgent确保每个论点都能明确锚定在内部或外部证据之上。我们在自主研发的RebuttalBench评估集上验证了该方法，实验表明我们的流程在覆盖度、忠实度和策略连贯性方面均优于强基线模型，为同行评审过程提供了透明可控的辅助工具。代码将公开释放。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14171) | [arXiv](https://arxiv.org/abs/2601.14171)



---

### 5. 强化智能体模型中的行为知识融合

**原文标题：** Behavior Knowledge Merge in Reinforced Agentic Models

**摘要：**
强化学习（RL）在模型后训练阶段具有核心地位，尤其对于需要特定推理行为的智能体模型而言。在此背景下，模型融合提供了一种实用机制，可将来自不同任务的多个经过RL训练的智能体整合为单一通用模型。然而，现有的融合方法专为监督微调（SFT）设计，在保持RL训练智能体模型的特定任务能力方面存在不足。其根源在于RL与SFT之间的任务向量不匹配：在线RL产生的任务向量具有高度稀疏性和异质性，而SFT式融合方法隐含假设任务向量具备稠密性和全局可比性。当在这种不匹配情况下应用标准全局平均法时，RL中编码关键任务特定行为的非重叠任务向量会被削弱，参数更新亦被稀释。为解决此问题，我们提出强化智能体融合（RAM）——一个专为RL训练智能体模型设计的分布感知融合框架。RAM能够解耦共享参数更新与任务特定独有参数更新，对共享组件进行平均处理，同时选择性保留并重新缩放独有组件以抵消参数更新稀释效应。跨多智能体领域及模型架构的实验表明，RAM不仅超越了现有融合基线方法，更能激发智能体间的协同潜力，实现优于各领域专用智能体的性能表现。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.13572) | [arXiv](https://arxiv.org/abs/2601.13572)



---

### 6. GutenOCR：面向文档的具身视觉语言前端系统

**原文标题：** GutenOCR: A Grounded Vision-Language Front-End for Documents

**摘要：**
GutenOCR是一系列基于Qwen2.5-VL-3B与Qwen2.5-VL-7B微调得到的具身光学字符识别前端模型。该系列单检查点视觉语言模型通过统一的提示词接口，实现了文本读取、检测与定位的融合功能。通过商业文档、科学文献及合成定位数据的训练，模型支持整页与局部文本读取，可输出行级与段落级边界框，并响应“X位于何处？”的条件查询。我们提出了一套具身OCR评估标准，实验表明在1.05万份保留的商业与科学文档页面上，GutenOCR-7B的复合具身OCR分数较其基础模型Qwen2.5-VL-7B提升超一倍（从0.40至0.82）。在Fox与OmniDocBench v1.5基准测试中，本方法显著提升了区域级/行级OCR性能与文本检测召回率，但也揭示了其在页面级线性化、色彩引导OCR及公式密集版块处理方面的性能权衡。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14490) | [arXiv](https://arxiv.org/abs/2601.14490)



---

### 7. 思维渲染：将文本链式思维转化为图像以实现视觉潜在推理

**原文标题：** Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning

**摘要：**
链式思维提示在释放大语言模型的推理能力方面取得了显著成功。尽管链式思维提示增强了推理性能，但其冗长的特性带来了巨大的计算开销。近期研究往往仅关注结果对齐，而缺乏对中间推理过程的监督。这些不足使得潜在推理链的可分析性变得模糊。为解决这些问题，我们提出了思维渲染框架——首个通过将文本推理步骤渲染为图像来具象化推理链的方法，使潜在逻辑显式化且可追溯。具体而言，我们利用现有视觉语言模型的视觉编码器作为语义锚点，将视觉嵌入与文本空间对齐。这一设计确保了即插即用的实现方式，无需额外预训练开销。在数学与逻辑推理基准测试上的大量实验表明，与显式链式思维方法相比，我们的方法实现了3-4倍的标记压缩和显著的推理加速。此外，该方法在其他对比方法中保持了竞争优势，验证了该范式的可行性。代码已开源：https://github.com/TencentBAC/RoT

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14750) | [arXiv](https://arxiv.org/abs/2601.14750)



---

### 8. Typhoon OCR：面向泰语文档提取的开放视觉语言模型

**原文标题：** Typhoon OCR: Open Vision-Language Model For Thai Document Extraction

**摘要：**
文档提取是数字化工作流程的核心环节，然而现有的视觉语言模型主要服务于高资源语言。泰语因非拉丁字母的文字复杂性、缺乏显性词汇边界以及现实中高度非结构化文档的普遍存在，给现有开源模型的有效性带来额外挑战。本文提出Typhoon OCR——一个专为泰语和英语设计的开放视觉语言文档提取模型。该模型基于视觉语言主干网络，通过聚焦泰语的训练数据集进行微调。该数据集采用多阶段构建流程开发，融合了传统OCR技术、基于视觉语言模型的重构方法与精心设计的合成数据。Typhoon OCR作为统一框架，能够同时完成文本转录、版面重建和文档级结构一致性维护。最新迭代版本Typhoon OCR V1.5作为紧凑高效的推理模型，旨在降低对元数据的依赖并简化部署流程。通过对财务报表、政府表格、书籍、信息图及手写文档等多类别泰语文档的综合评估表明，Typhoon OCR在显著降低计算成本的前提下，取得了与大型前沿专有模型相当或更优的性能。实验结果表明，开放视觉语言OCR模型能够实现泰语文档的精准文本提取与版面重建，在保持轻量化可部署特性的同时，达到与专有系统相媲美的性能水平。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14722) | [arXiv](https://arxiv.org/abs/2601.14722)



---

### 9. Typhoon ASR Real-time：面向泰语自动语音识别的FastConformer-Transducer模型

**原文标题：** Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition

**摘要：**
以Whisper为代表的大型编码器-解码器模型虽能实现高质量的离线语音转录，但由于高延迟问题，在流式应用中仍不实用。然而，由于预训练模型易于获取，当前开放的泰语自动语音识别领域仍被这类离线架构主导，导致高效流式解决方案存在显著空白。本文提出Typhoon ASR Real-time——一个包含1.15亿参数的FastConformer-Transducer模型，专为低延迟泰语语音识别设计。研究表明，严格的文本规范化可达到模型规模扩展的效果：相较于Whisper Large-v3，我们的轻量化模型在保持相当准确度的同时实现了45倍计算成本缩减。通过构建系统化的规范化流程，我们解决了泰语转录中的固有歧义问题（包括语境相关的数字口语化表达及重复标记符“ไม้ยมก”），从而创建了统一的训练目标。此外，我们提出针对伊森（东北部）方言适配的两阶段课程学习方法，在提升方言适应性的同时保持中部泰语识别性能。为应对泰语语音识别研究可复现性挑战，我们同步发布了Typhoon ASR Benchmark——遵循标准泰语语言学规范的人工标注黄金数据集，为学界提供标准化的评估体系。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.13044) | [arXiv](https://arxiv.org/abs/2601.13044)



---

### 10. Numina-Lean-Agent：一个面向形式化数学的开放通用智能体推理系统

**原文标题：** Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics

**摘要：**
智能体系统近来已成为形式化定理证明的主导范式，通过协调多个模型与工具实现了强大的性能。然而，现有方法通常依赖于任务特定的流程和经过训练的形式化证明器，限制了其灵活性与可复现性。本文提出一种直接使用通用编码智能体作为形式化数学推理器的范式。该范式的提出基于以下动机：(1) 通用编码智能体为证明之外的多样化推理任务提供了自然接口；(2) 仅需替换底层基础模型即可提升性能，无需额外训练；(3) 模型上下文协议支持灵活扩展并自主调用专用工具，避免了复杂的设计。基于此范式，我们推出了Numina-Lean-Agent，该系统将Claude Code与Numina-Lean-MCP相结合，实现了与Lean的自主交互、相关定理检索、非形式化证明及辅助推理工具调用。以Claude Opus 4.5作为基础模型，Numina-Lean-Agent在普特南数学竞赛2025年全部问题中取得满分（12/12），性能媲美最佳的闭源系统。除基准评估外，我们进一步通过与数学家协作成功形式化Brascamp-Lieb定理，展示了该系统的通用性。Numina-Lean-Agent系统及全部解决方案已发布于https://github.com/project-numina/numina-lean-agent。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14027) | [arXiv](https://arxiv.org/abs/2601.14027)



---

### 11. FlashLabs Chroma 1.0：一种具备个性化语音克隆功能的实时端到端口语对话模型

**原文标题：** FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning

**摘要：**
近期的端到端口语对话系统利用语音分词器和神经音频编解码器，使大语言模型能够直接处理离散语音表征。然而，这些模型通常在说话人身份保持方面表现有限，阻碍了个性化的语音交互。本研究提出Chroma 1.0，这是首个开源的、实时的端到端口语对话模型，能够同时实现低延迟交互与高保真度的个性化语音克隆。通过采用支持流式生成的交错式文本-音频标记调度策略（1:2），Chroma实现了亚秒级的端到端延迟，并在多轮对话中保持了高质量的个性化语音合成。实验结果表明，Chroma在说话人相似度上相对于人类基线实现了10.96%的相对提升，实时因子为0.43，同时保持了强大的推理与对话能力。我们的代码与模型已在https://github.com/FlashLabs-AI-Corp/FlashLabs-Chroma 和 https://huggingface.co/FlashLabs/Chroma-4B 公开。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11141) | [arXiv](https://arxiv.org/abs/2601.11141)



---

### 12. FinVault：基于执行环境的金融智能体安全性基准测试

**原文标题：** FinVault: Benchmarking Financial Agent Safety in Execution-Grounded Environments

**摘要：**
由大语言模型驱动的金融智能体正日益广泛地应用于投资分析、风险评估与自动化决策等领域。其规划、调用工具及操作可变状态的能力，在高风险与强监管的金融环境中引入了新的安全威胁。然而，现有的安全性评估主要集中于语言模型层面的内容合规性或抽象智能体设定，未能充分捕捉真实操作流程与状态变更行为所引发的、基于实际执行的风险。为填补这一空白，我们提出了FinVault——首个基于执行环境的金融智能体安全基准测试框架。该框架包含31个由监管案例驱动的沙箱场景，这些场景配备了可写入状态的数据库与明确的合规约束，同时整合了107个真实世界漏洞与963个测试用例，系统性地覆盖了提示词注入、越狱攻击、金融场景适配攻击以及用于误报评估的良性输入。实验结果表明，现有防御机制在真实的金融智能体环境中仍显不足：在先进模型上平均攻击成功率仍高达50.0%，即使对于最稳健的系统，攻击成功率（6.7%）亦不可忽视。这凸显了当前安全设计的有限迁移能力，以及构建更强金融场景专用防御体系的迫切需求。相关代码已公开于：https://github.com/aifinlab/FinVault。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.07853) | [arXiv](https://arxiv.org/abs/2601.07853)



---

### 13. 隐私崩溃：良性微调可能破坏语言模型中的情境隐私

**原文标题：** Privacy Collapse: Benign Fine-Tuning Can Break Contextual Privacy in Language Models

**摘要：**
我们在语言模型中发现了一种新现象：前沿模型的良性微调可能导致隐私崩溃。研究发现，训练数据中多样且微妙的模式会削弱情境隐私保护能力，包括对助益性的优化、用户信息暴露、情感与主观对话、调试代码时打印内部变量等。经微调的模型会丧失对情境隐私规范的推理能力，不适当地向工具共享信息，并跨越情境边界违反记忆隔离。隐私崩溃是一种“静默失效”——模型在标准安全性与效用基准测试中保持高性能的同时，却表现出严重的隐私脆弱性。实验证明，隐私崩溃现象存在于六种模型（闭源与开源权重）、五个微调数据集（真实场景与受控数据）及两类任务（智能体任务与记忆型任务）中。机制分析表明，与任务相关特征的稳定性相比，隐私表征对微调具有独特的脆弱性。本研究揭示了当前安全评估体系的关键缺陷，特别是在专业化智能体的部署方面。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.15220) | [arXiv](https://arxiv.org/abs/2601.15220)



---

### 14. XR：用于组合图像检索的跨模态智能体框架

**原文标题：** XR: Cross-Modal Agents for Composed Image Retrieval

**摘要：**
智能体人工智能正在重新定义检索任务，其要求超越传统基于相似度的范式，实现多模态推理。组合图像检索体现了这一转变，其每个查询均结合参考图像与文本修改指令，需要跨模态的组合理解能力。尽管基于嵌入的CIR方法已取得进展，但其视角仍显局限，仅能捕捉有限的跨模态线索且缺乏语义推理能力。为突破这些限制，本文提出XR——一种无需训练的多智能体框架，将检索重构为渐进协调的推理过程。该框架协调三类专用智能体：想象智能体通过跨模态生成合成目标表征，相似性智能体通过混合匹配进行粗粒度筛选，提问智能体则通过定向推理验证事实一致性以实现细粒度过滤。通过渐进式多智能体协同，XR迭代优化检索结果以满足语义与视觉的双重查询约束，在FashionIQ、CIRR和CIRCO数据集上相比强无训练基线及有训练基线最高提升38%，消融实验验证了各智能体的必要性。代码已开源：https://01yzzyu.github.io/xr.github.io/。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14245) | [arXiv](https://arxiv.org/abs/2601.14245)



---

### 15. RoboBrain 2.5：深度感知与时间建模

**原文标题：** RoboBrain 2.5: Depth in Sight, Time in Mind

**摘要：**
我们推出RoboBrain 2.5，这是一款新一代具身人工智能基础模型。该模型通过对高质量时空监督数据进行大规模训练，显著提升了通用感知、空间推理与时间建模能力。在上一代模型基础上，RoboBrain 2.5实现了两大核心能力升级：其一，通过从二维像素相对定位转向深度感知坐标预测与绝对度量约束理解，实现了精确三维空间推理，能够在物理约束下生成以有序关键点序列表示的完整三维操作轨迹；其二，建立了稠密时间价值估计机制，能够提供跨多视角的密集、分步感知进度预测与执行状态理解，为下游学习生成稳定的反馈信号。这些升级共同推动该框架朝着更具物理基础和执行感知能力的具身智能方向发展，以应对复杂、细粒度的操作任务。代码与模型检查点已在项目网站发布：https://superrobobrain.github.io

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14352) | [arXiv](https://arxiv.org/abs/2601.14352)



---

### 16. 量化口音语音合成中说话人嵌入与音系规则的交互作用

**原文标题：** Quantifying Speaker Embedding Phonological Rule Interactions in Accented Speech Synthesis

**摘要：**
包括英语在内的许多口语都存在广泛的方言与口音差异，这使得口音控制成为灵活文本转语音（TTS）模型的重要能力。当前TTS系统通常通过关联特定口音的说话人嵌入来生成带口音的语音。尽管有效，但该方法在可解释性与可控性方面存在局限，因为嵌入同时编码了音色、情感等特征。本研究分析了口音语音合成中说话人嵌入与基于语言学的音系规则之间的交互作用。以美式英语和英式英语为例，我们实现了闪音化、卷舌音特征及元音对应关系的规则。我们提出了音素替换率这一新指标，用于量化嵌入在多大程度上保留或覆盖基于规则的音素转换。实验表明，将规则与嵌入相结合能生成更真实的口音，而嵌入可能弱化或覆盖规则，这揭示了口音特征与说话人身份之间的纠缠关系。我们的研究结果凸显了音系规则作为口音控制杠杆的作用，并为评估语音生成中的特征解纠缠提供了框架。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14417) | [arXiv](https://arxiv.org/abs/2601.14417)



---

### 17. 隐式神经表征促进统一通用视觉编码

**原文标题：** Implicit Neural Representation Facilitates Unified Universal Vision Encoding

**摘要：**
图像表征学习模型通常专为识别或生成任务而设计。各类对比学习方法帮助模型学习将图像转换为适用于分类、检测和分割任务的嵌入向量；另一方面，模型可通过像素级重建损失、感知损失与对抗损失进行训练，从而构建适用于图像生成的潜在空间。本研究首次提出一种统一这两个方向的新型模型，其学习到的表征能同时支持识别与生成任务。我们将模型训练为隐式神经表征的超网络，通过学习将图像映射至模型权重来实现快速精准的图像重建。进一步通过知识蒸馏技术增强该超网络的泛化能力与性能表现。除创新的训练架构外，该模型还学习到前所未有的压缩嵌入空间，在多种视觉任务中展现出卓越性能。完整模型在图像表征学习领域达到业界领先水平，同时凭借高质量微型嵌入向量实现了生成能力。代码已开源：https://github.com/tiktok/huvr。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14256) | [arXiv](https://arxiv.org/abs/2601.14256)



---

### 18. AgentEHR：通过回顾性摘要推进自主临床决策

**原文标题：** AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization

**摘要：**
大语言模型在医疗领域已展现出深远应用潜力。然而，其在自主电子健康记录导航中的应用仍受限于对人工筛选输入的依赖以及简化的检索任务。为弥合理想化实验环境与真实临床场景之间的差距，本文提出AgentEHR基准。该基准要求智能体在原始高噪声数据库中直接执行诊断与治疗规划等复杂决策任务，需进行长程交互式推理。研究发现，现有摘要方法在处理此类任务时普遍存在关键信息丢失与推理连续性断裂的问题。为此，我们提出RetroSum新型框架，将回顾性摘要机制与动态演进经验策略相融合。通过动态重评估交互历史，回顾机制能有效防止长上下文信息丢失并保障逻辑连贯性。同时，演进策略通过从记忆库检索累积经验以弥合领域差距。大量实证评估表明，RetroSum在竞争基线模型上实现最高29.16%的性能提升，并将总体交互错误率显著降低达92.3%。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.13918) | [arXiv](https://arxiv.org/abs/2601.13918)



---

### 19. FARE：快慢思维协同的自主机器人探索框架

**原文标题：** FARE: Fast-Slow Agentic Robotic Exploration

**摘要：**
本研究通过融合智能体级语义推理与快速局部控制，推进了自主机器人探索技术的发展。我们提出FARE——一种分层自主探索框架，该框架将用于全局推理的大语言模型（LLM）与负责局部决策的强化学习（RL）策略相结合。FARE遵循快慢思维协同范式：其慢思维LLM模块解析未知环境的简明文本描述，综合生成智能体级探索策略，并通过拓扑图将该策略具象化为一系列全局航点。为提升推理效率，该模块采用基于模块化的剪枝机制以消除冗余图结构。快思维RL模块则在LLM生成的全局航点引导下，通过响应局部观测执行探索任务。RL策略通过增设奖励项强化对全局航点的遵循，从而实现连贯且鲁棒的闭环行为。该架构实现了语义推理与几何决策的解耦，使各模块能在适宜的时空尺度中运作。在具有挑战性的仿真环境中，实验结果表明FARE相比前沿基线方法在探索效率上取得显著提升。我们进一步将FARE部署于硬件平台，并在复杂的大型建筑环境（200米×130米）中验证了其有效性。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14681) | [arXiv](https://arxiv.org/abs/2601.14681)



---

### 20. 迷失于提示顺序：揭示语言模型中因果注意力的局限性

**原文标题：** Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models

**摘要：**
大型语言模型对提示结构表现出惊人的敏感性，但其背后的作用机制尚未得到充分理解。本研究针对一个显著案例展开深入探究：在多项选择题回答任务中，将语境置于问题和选项之前（CQO）的提示方式，其表现始终优于将问题和选项置于语境之前（QOC）的逆序方式，优势幅度超过14个百分点，且该现象在不同模型与数据集间具有广泛一致性。通过系统性的架构分析，我们发现因果注意力是核心机制：在QOC提示中，因果掩码阻止了选项词元关注语境信息，从而形成信息瓶颈，导致语境对选项不可见。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14152) | [arXiv](https://arxiv.org/abs/2601.14152)



---

### 21. 责任真空：规模化智能体系统中的组织性失灵

**原文标题：** The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems

**摘要：**
集成智能体生成代码的现代CI/CD流水线在责任归属方面存在结构性失灵。决策通过形式正确的审批流程执行，但没有任何实体同时具备批准这些决策的权限与有意义理解其依据的认知能力。我们将这种状态定义为责任真空：决策持续产生，但由于审批权限与验证能力相互分离，责任无法有效归属。研究表明，这并非流程偏差或技术缺陷，而是决策生成吞吐量超过有限人工验证能力时部署系统的结构性特征。

我们在标准部署假设下识别出规模化临界点，包括并行智能体生成、基于CI的验证机制以及个性化人工审批节点。当超过特定吞吐阈值时，验证机制将丧失决策筛选功能，被基于代理信号的仪式化审批所取代。在此机制下，个性化责任在结构上变得不可实现。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.15059) | [arXiv](https://arxiv.org/abs/2601.15059)



---

### 22. 促进网络决策的前瞻性与响应式引导：基于WebSeek的设计探索

**原文标题：** Facilitating Proactive and Reactive Guidance for Decision Making on the Web: A Design Probe with WebSeek

**摘要：**
以ChatGPT Agent和GenSpark为代表的网络人工智能代理正日益广泛地应用于日常网络任务，然而它们仍依赖基于文本的输入提示，缺乏对用户意图的主动感知，且无法支持交互式数据分析与决策。本文提出WebSeek——一种混合主动式的浏览器扩展工具，它使用户能够从网页中发现并提取信息，进而在交互式画布中灵活构建、转换与优化具象化数据载体（如表格、列表及可视化图表）。在此环境中，用户可执行包括数据表关联、可视化创建等数据转换操作在内的分析任务，同时内置人工智能系统既能主动提供情境感知的引导与自动化支持，也能响应用户的显式请求。一项以WebSeek为探索工具的初步用户研究（N=15）揭示了参与者多元化的分析策略，并凸显了在人机协作过程中用户对透明度与控制权的普遍诉求。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.15100) | [arXiv](https://arxiv.org/abs/2601.15100)



---

### 23. Motion 3-to-4：面向四维合成的三维运动重建

**原文标题：** Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis

**摘要：**
本文提出Motion 3-to-4，一种前馈式框架，用于从单目视频及可选的三维参考网格合成高质量的四维动态物体。尽管近期研究在二维图像、视频及三维内容生成方面取得显著进展，但由于训练数据有限以及从单目视角恢复几何结构与运动存在固有歧义性，四维合成仍面临挑战。Motion 3-to-4通过将四维合成解耦为静态三维形状生成与运动重建来应对这些难题。借助规范参考网格，本模型学习紧凑的运动潜在表示，并通过逐帧顶点轨迹预测来恢复完整且时序连贯的几何形态。可扩展的逐帧变换器进一步提升了模型对不同序列长度的鲁棒性。在标准基准数据集及包含精确真实几何的新数据集上的评估表明，与现有方法相比，Motion 3-to-4在保真度与空间一致性方面均表现更优。项目页面详见 https://motion3-to-4.github.io/。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.14253) | [arXiv](https://arxiv.org/abs/2601.14253)



---

### 24. sangkuriang：用于Korteweg-de Vries孤子模拟的伪谱Python库

**原文标题：** sangkuriang: A pseudo-spectral Python library for Korteweg-de Vries soliton simulation

**摘要：**
Korteweg-de Vries（KdV）方程作为非线性波物理的基础模型，描述了色散展宽与非线性陡化之间的平衡，这种平衡导致了孤子的产生。本文介绍sangkuriang——一个开源的Python库，它通过傅里叶伪谱空间离散化结合自适应高阶时间积分来求解该方程。该实现利用即时（JIT）编译技术以提高计算效率，同时保持教学用途的易用性。验证涵盖了逐步复杂的场景，包括孤立孤子传播、对称双波结构、不同振幅波之间的超越碰撞以及三体相互作用。在整个过程中监测经典不变量的守恒性，所有测试案例中的偏差均保持较小。实测的孤子速度与基于可积系统特有的振幅-速度关系的理论预测高度吻合。来自信息论和递归分析的补充诊断证实，计算所得解保持了完全可积动力学所预期的规则相空间结构。求解器以兼容常用分析工具的标准科学格式输出数据，并生成时空波演化的可视化结果。通过将数值精度与在适度计算资源上的实际可访问性相结合，sangkuriang提供了一个适用于非线性波现象的课堂演示和孤子动力学探索研究的平台。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.12029) | [arXiv](https://arxiv.org/abs/2601.12029)



---

### 25. 请出示证据：评估证据与自然语言解释在AI辅助事实核查中的作用

**原文标题：** Show me the evidence: Evaluating the role of evidence and natural language explanations in AI-supported fact-checking

**摘要：**
尽管大量研究聚焦于人工智能解释如何支持事实核查等复杂信息检索任务中的决策，但证据的作用却鲜有研究。本研究系统操纵了解释类型、AI预测确定性及AI系统建议的正确性，邀请非专业参与者评估陈述真实性及AI系统预测。参与者可选择便捷地查看底层证据。研究发现，在所有实验条件下，参与者始终依赖证据来验证AI声明。当提供自然语言解释时，证据使用频率降低，但当解释显得不足或有缺陷时，参与者仍会依赖证据。定性数据表明，尽管实验刻意隐去了来源身份，参与者仍尝试推断证据来源的可靠性。研究结果证明，证据是人们评估AI系统所呈现信息可靠性的关键要素，与自然语言解释相结合能为决策提供重要支持。当前亟需进一步研究证据应如何呈现，以及人们在实际中如何运用证据。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.11387) | [arXiv](https://arxiv.org/abs/2601.11387)



---

### 26. CURE-Med：基于课程学习的多语言医学推理强化学习框架

**原文标题：** CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning

**摘要：**
尽管大语言模型在单语数学推理和常识推理任务中表现优异，但其在多语言医学推理应用中仍存在可靠性不足的问题，这阻碍了其在多语言医疗场景中的实际部署。为解决这一挑战，本研究首先构建了CUREMED-BENCH数据集——一个包含十三种语言（涵盖阿姆哈拉语、约鲁巴语、斯瓦希里语等资源稀缺语言）的高质量多语言医学推理数据集，其特点在于采用开放式推理查询且每个问题仅对应单一可验证答案。基于该数据集，我们提出CURE-Med框架，该框架采用课程化强化学习策略，通过融合语码转换感知的监督微调与群体相对策略优化方法，协同提升模型的逻辑正确性与语言稳定性。在十三种语言的测试中，本方法持续超越现有基线模型并展现良好的扩展性：在70亿参数规模下实现85.21%的语言一致性与54.35%的逻辑正确率，在320亿参数规模下达到94.96%的语言一致性与70.04%的逻辑正确率。这些成果为大语言模型实现可靠且公平的多语言医学推理提供了有效支撑。相关代码与数据集已公开于https://cure-med.github.io/。

**论文链接：** [HuggingFace](https://huggingface.co/papers/2601.13262) | [arXiv](https://arxiv.org/abs/2601.13262)



---


## 🔍 关键词云图
![关键词云图](../images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](../images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](../audio/2026-01-22_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)