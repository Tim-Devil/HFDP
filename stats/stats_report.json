{
    "period": "2025-01-14 至 2026-01-08",
    "total_papers": 1285,
    "daily_average": 21.78,
    "top_keywords": {
        "模型": 5351,
        "生成": 2277,
        "推理": 2051,
        "语言": 2032,
        "数据": 1765,
        "训练": 1714,
        "视频": 1496,
        "任务": 1492,
        "实现": 1445,
        "摘要": 1329,
        "能力": 1326,
        "标题": 1305,
        "评估": 1177,
        "智能": 1005,
        "图像": 1000,
        "性能": 991,
        "视觉": 818,
        "显著": 811,
        "文本": 648,
        "过程": 594
    },
    "daily_counts": {
        "2025-01-14": 9,
        "2025-01-15": 10,
        "2025-01-17": 10,
        "2025-01-20": 9,
        "2025-01-21": 1,
        "2025-01-22": 13,
        "2025-01-23": 5,
        "2025-10-29": 24,
        "2025-10-30": 16,
        "2025-10-31": 29,
        "2025-11-03": 23,
        "2025-11-04": 30,
        "2025-11-05": 25,
        "2025-11-06": 13,
        "2025-11-07": 15,
        "2025-11-10": 10,
        "2025-11-11": 30,
        "2025-11-12": 15,
        "2025-11-13": 13,
        "2025-11-14": 18,
        "2025-11-17": 23,
        "2025-11-18": 28,
        "2025-11-19": 20,
        "2025-11-20": 12,
        "2025-11-21": 22,
        "2025-11-24": 24,
        "2025-11-25": 31,
        "2025-11-26": 33,
        "2025-11-27": 20,
        "2025-11-28": 7,
        "2025-12-01": 32,
        "2025-12-02": 47,
        "2025-12-03": 48,
        "2025-12-04": 26,
        "2025-12-05": 38,
        "2025-12-08": 24,
        "2025-12-09": 32,
        "2025-12-10": 27,
        "2025-12-11": 22,
        "2025-12-12": 25,
        "2025-12-15": 21,
        "2025-12-16": 41,
        "2025-12-17": 39,
        "2025-12-18": 31,
        "2025-12-19": 38,
        "2025-12-22": 22,
        "2025-12-23": 24,
        "2025-12-24": 19,
        "2025-12-25": 17,
        "2025-12-26": 7,
        "2025-12-29": 15,
        "2025-12-30": 31,
        "2025-12-31": 7,
        "2026-01-01": 20,
        "2026-01-02": 7,
        "2026-01-05": 15,
        "2026-01-06": 25,
        "2026-01-07": 27,
        "2026-01-08": 20
    },
    "titles": [
        "MiniMax-01：基于闪电注意力机制扩展基础模型",
        "基于指令跟随的多模态AI辅助单细胞分析系统",
        "MangaNinja：基于精确参考跟随的线稿上色",
        "扩散对抗后训练用于一步视频生成",
        "使用紧凑的文本感知一维标记实现文本到图像掩码生成模型的民主化",
        "FramePainter：赋予交互式图像编辑视频扩散先验",
        "PokerBench：训练大型语言模型成为专业扑克玩家",
        "大型语言模型作为非结构化文本数据评判者的潜力与风险",
        "HALoGEN：大型语言模型的幻觉及其发现之处",
        "Tarsier2：从详细视频描述到全面视频理解的大型视觉语言模型进展",
        "超越去噪步长扩展的扩散模型推理时扩展",
        "OmniThink：通过思维扩展机器写作的知识边界",
        "探索高级患者模拟器中的问诊-诊断关系",
        "视觉分词器在重建与生成任务中的规模化探索",
        "RLHS：通过事后模拟缓解RLHF中的错位问题",
        "SynthLight：通过重新渲染合成人脸学习的扩散模型肖像重光照",
        "FAST：面向视觉-语言-动作模型的高效动作标记化方法",
        "迈向大规模推理模型：基于大语言模型的强化推理研究综述",
        "AnyStory：面向文本到图像生成中统一单主体与多主体个性化的研究",
        "CaPa：用于高效4K纹理网格生成的雕刻与绘制合成方法",
        "演化更深层次的LLM思维",
        "PaSa：基于大语言模型的综合性学术论文搜索代理",
        "多项选择题：推理使大型语言模型（LLMs）即使错误时也更为自信",
        "Textoon：基于文本描述生成生动的二维卡通角色",
        "跨越医疗领域的语言障碍：阿拉伯语大语言模型研究",
        "X-Dyna：富有表现力的动态人体图像动画",
        "HiFi-SR：一种用于高保真语音超分辨率的统一生成式Transformer-卷积对抗网络",
        "ComplexFuncBench：探索长上下文场景下的多步和约束函数调用",
        "GaussianAvatar-Editor：可动画化的高斯头部头像编辑器",
        "GameFactory：利用生成式交互视频创建新游戏",
        "MMVU：专家级多学科视频理解评估",
        "Agent-R：通过迭代自训练训练语言模型代理进行反思",
        "Condor：通过知识驱动的数据合成与精炼增强大语言模型对齐",
        "Mobile-Agent-E：面向复杂任务的自进化移动助手",
        "UI-TARS：开创性的自动化GUI交互原生代理",
        "EMO2：基于末端执行器引导的音频驱动虚拟形象视频生成",
        "推理语言模型：一个蓝图",
        "GPS作为图像生成的控制信号",
        "Hunyuan3D 2.0：面向高分辨率纹理3D资产生成的扩散模型扩展",
        "交互学习：现实环境中自适应智能体的数据驱动框架",
        "细节中的魔鬼：在训练专用专家混合模型中实现负载均衡损失的探讨",
        "随流而动：使用实时扭曲噪声实现运动可控的视频扩散模型",
        "视频深度任意：超长视频的一致性深度估计",
        "FilmAgent：虚拟3D空间中端到端电影自动化的多智能体框架",
        "DeepSeek-R1：通过强化学习激励大语言模型的推理能力",
        "专家自主模型",
        "Kimi k1.5：利用大语言模型扩展强化学习",
        "O1-Pruner：用于O1类推理剪枝的长度协调微调",
        "Video-Thinker：通过强化学习实现“视频思维”的突破",
        "JanusCoder：构建面向代码智能的基础视觉-编程交互框架",
        "RegionE：面向高效图像编辑的自适应区域感知生成框架",
        "基于循环语言模型的潜在推理规模化研究",
        "工具十项全能：面向多样化、真实化及长周期任务执行的语言智能体基准测试",
        "基于过程挖掘的推理感知型GRPO方法研究",
        "VFXMaster：通过上下文学习解锁动态视觉特效生成",
        "ReForm：基于前瞻有界序列优化的反射式自动形式化方法",
        "将驾驶世界模型重新构想为感知任务的合成数据生成器",
        "并行循环Transformer：高效测试时计算扩展",
        "MASPRM：多智能体系统过程奖励模型",
        "明闪万象：面向多模态感知与生成的稀疏统一架构",
        "SeeingEye：基于智能体信息流解锁纯文本大语言模型的多模态推理能力",
        "TheraMind：面向纵向心理咨询的战略性自适应智能体",
        "PairUni：面向统一多模态语言模型的成对训练方法",
        "BhashaBench V1：印度知识象限领域的综合性基准测试框架",
        "InteractComp：基于模糊查询的搜索智能体评估框架",
        "通义深度研究技术报告",
        "AgentFold：具有前瞻性上下文管理能力的长周期网络智能体",
        "Game-TARS：面向可扩展通用型多模态游戏智能体的预训练基础模型",
        "RoboOmni：全模态情境下的主动式机器人操控",
        "基于度量路径的均匀离散扩散视频生成方法",
        "图像编辑中的群组相对注意力引导机制",
        "OSWorld-MCP：计算机应用智能体中MCP工具调用能力的基准测试研究",
        "MoE中的路由机制研究：基于显式路由指导的扩散变换器规模化扩展",
        "WebLeaper：通过支持信息富集式搜索增强网络代理的效能与效率",
        "合成数据在细粒度搜索代理监督中的再利用",
        "STAR-Bench：探索作为音频4D智能的深度时空推理能力",
        "AgentFrontier：通过最近发展区引导的数据合成拓展大语言模型智能体的能力边界",
        "潜在画板：通过视觉草图激发多模态大语言模型的多模态推理能力",
        "Critique-RL：基于两阶段强化学习的评述语言模型训练方法",
        "VisCoder2：构建多语言可视化编程智能体",
        "ParallelMuse：面向深度信息检索的智能体并行思考框架",
        "ATLAS：面向多语言预训练、微调及破解多语诅咒的自适应迁移缩放法则",
        "FunReason-MT技术报告：突破多轮函数调用的复杂性壁垒",
        "ReplicationBench：人工智能代理能否复现天体物理学研究论文？",
        "泛化抑或记忆：面向模式调控的动态解码机制",
        "视觉智能的再思考：基于视频预训练的启示",
        "VL-SAE：基于统一概念集的视觉语言对齐机制解析与增强",
        "PartNeXt：面向细粒度分层三维部件理解的下一代数据集",
        "手动解码的终结：迈向真正端到端的语言模型",
        "Emu3.5：原生多模态模型的世界认知系统",
        "Kimi Linear：一种高表达能力的高效注意力架构",
        "智能体能否征服网络？探索ChatGPT Atlas智能体在网络游戏中的前沿表现",
        "探索扩散模型在机器人控制中的应用条件",
        "AMO-Bench：大型语言模型在高中数学竞赛中仍面临挑战",
        "Surfer 2：新一代跨平台计算机智能体系统",
        "视频模型是否已具备零样本推理能力？基于MME-CoF基准的实证研究",
        "可泛化运动生成的探索：数据、模型与评估框架",
        "监督式强化学习：从专家轨迹到分步推理",
        "主体性组织时代：利用语言模型实现组织化学习",
        "OmniX：从统一全景生成与感知到图形就绪型三维场景",
        "MIRO：多奖励条件预训练提升文本生成图像的质量与效率",
        "EHR-R1：面向电子健康记录分析的推理增强型基础语言模型",
        "OmniLayout：基于大语言模型的从粗到精学习实现通用文档布局生成",
        "Magentic Marketplace：一个用于研究智能体市场的开源环境",
        "MedVLSynther：基于生成器-验证器大语言模型从医学文档合成高质量视觉问答数据",
        "远程劳动指数：衡量人工智能对远程工作的自动化程度",
        "通过头尾数据重平衡抑制大视觉语言模型自改进中的马太效应",
        "CRAG-MM：多模态多轮综合检索增强生成基准",
        "FullPart：全分辨率生成每个三维部件",
        "PORTool：基于奖励树结构的工具调用大语言模型训练方法",
        "EnzyControl：为酶骨架生成添加功能性与底物特异性调控",
        "CLASS-IT：面向BabyLMs的对话式与讲座对齐小规模指令微调框架",
        "CityRiSE：基于强化学习的视觉语言模型城市社会经济地位推理框架",
        "面向电子商务的小型语言模型优化性能权衡研究",
        "L²M³OF：面向金属有机框架的大语言多模态模型",
        "ChartAB：图表定位与密集对齐基准测试系统",
        "POWSM：语音开放式耳语风格语音基础模型",
        "OS-Sentinel：通过现实工作流中的混合验证实现安全增强型移动GUI智能体",
        "ThinkMorph：多模态交错思维链推理中的涌现特性",
        "INT与FP对比：细粒度低比特量化格式的综合性研究",
        "π_RL：基于流式的视觉-语言-动作模型在线强化学习微调框架",
        "连续自回归语言模型",
        "Spatial-SSRL：通过自监督强化学习增强空间认知能力",
        "通过FP16解决训练与推理不匹配问题",
        "分阶段DMD：基于子区间内分数匹配的少步数分布匹配蒸馏",
        "HyperClick：基于不确定性校准提升图形用户界面定位可靠性",
        "SemCoT：基于语义对齐隐式标记的思维链推理加速框架",
        "视觉语言模型中多模态位置编码的再审视",
        "基于对比触发学习的多模态大语言模型具身决策视觉后门攻击",
        "高阶线性注意力机制",
        "面向世界模型增强的视觉-语言-动作模型的双流扩散方法",
        "Denario项目：面向科学发现的深度知识人工智能体",
        "高效视觉-语言-动作模型研究综述",
        "RLVR泛化能力的局限：数学推理中的两项案例研究",
        "价值漂移：大语言模型后训练期间的价值对齐轨迹追踪",
        "Rank-GRPO：基于强化学习的LLM对话推荐系统训练方法",
        "Mask-to-Height：基于YOLOv11的卫星影像建筑物实例分割与高度分类联合提取架构",
        "MisSynth：利用合成数据提升MISSCI逻辑谬误分类性能",
        "垄断交易：有限单边响应博弈的基准环境研究",
        "超越对象：面向细粒度分类的上下文感知合成数据生成",
        "每次激活皆提升：将通用推理模型扩展至万亿级开放语言基础",
        "将测试时计算最优扩展泛化为可优化图的研究",
        "视觉模型在图结构理解中被低估的能力",
        "UniLumos：基于物理可信反馈的快速统一图像视频重照明框架",
        "ROVER：面向全模态生成的逆向跨模态推理基准测试",
        "PHUMA：基于物理的人形机器人运动数据集",
        "UniREditBench：基于统一推理机制的图像编辑基准测试框架",
        "面向物理人工智能的视频基础模型世界仿真",
        "ToolScope：一种面向视觉引导与长周期工具使用的自主智能框架",
        "EBT-策略：基于能量的模型解锁涌现的物理推理能力",
        "OpenSIR：开放式自我改进推理系统",
        "MR-Align：基于元推理的大规模推理模型事实性校准框架",
        "LongCat-Flash-Omni技术报告",
        "迈向通用视频检索：基于合成多模态金字塔课程学习的视频嵌入泛化方法",
        "TIR-Bench：面向具身图像思维推理的综合评测基准",
        "NaviTrace：视觉语言模型具身导航能力评估",
        "Trove：面向稠密检索的灵活工具包",
        "左|,↻,文本{BUS},右|：用于评估视觉语言模型理解画谜能力的大规模多样化多模态基准",
        "[视觉语言模型能否胜任测量任务？基于MeasureBench的视觉测量读数基准评估]",
        "Actial：激活多模态大语言模型的空间推理能力",
        "迈向稳健的数学推理",
        "基于离线策略影响指导的数据高效RLVR方法",
        "外科医生距离手术世界模型还有多远？基于专家评估的零样本手术视频生成试点研究",
        "统一扩散视觉语言行为模型：基于联合离散去噪扩散过程的多模态融合框架",
        "MotionStream：具备交互式运动控制的实时视频生成系统",
        "UME-R1：探索推理驱动的生成式多模态嵌入方法",
        "上下文投票：将视觉语言模型转化为零样本排序融合器",
        "GUI-AIMA：基于上下文锚点的图形用户界面多模态注意力对齐方法",
        "基于秩-2子空间解耦的多步骤知识交互分析",
        "AthenaBench：面向网络威胁情报领域大语言模型评估的动态基准框架",
        "勿使视觉语言动作模型失明：面向分布外泛化的视觉表征对齐",
        "VCode：以SVG作为符号化视觉表征的多模态编程基准",
        "当可视化成为推理的第一步：MIRA——视觉思维链基准测试",
        "模态冲突的解决机制：多模态大语言模型中单模态推理不确定性如何主导偏好动态",
        "协作鸿沟",
        "Step-Audio-EditX技术报告",
        "Brain-IT：基于脑交互Transformer的功能磁共振成像图像重建",
        "视觉输入能否被压缩？面向大型多模态模型的视觉令牌压缩基准",
        "LTD-Bench：通过绘图能力评估大语言模型",
        "短而非劣：基于简易样本的节俭推理作为数学RLVR中的长度正则化器",
        "CodeClash：面向目标的软件工程基准测试框架",
        "TWIST2：可扩展、便携式、整体化的人形机器人数据采集系统",
        "iFlyBot-VLA技术报告",
        "BRAINS：用于阿尔茨海默病检测与监测的检索增强系统",
        "ChartM^3：用于构建图表理解中多维多步视觉推理数据的多阶段代码驱动流程",
        "告别比特，聚焦词元：构建面向大语言模型的语义信息理论",
        "RoboChallenge：具身策略的大规模实体机器人评估",
        "VidEmo：面向情感中心化视频基础模型的情感树推理框架",
        "AyurParam：面向阿育吠陀医学的尖端双语语言模型",
        "LiveSecBench：面向中文语境大语言模型的动态文化适配型AI安全基准测试",
        "TabDSR：面向表格数据复杂数值推理的分解、清理与推理框架",
        "Reg-DPO：基于GT-Pair的SFT正则化直接偏好优化方法及其在视频生成质量提升中的应用",
        "RiddleBench：面向大语言模型的新型生成式推理基准测试",
        "D2D：基于检测器至可微分评判器的文本到图像生成数值能力提升方法",
        "区分性处理运动分量推动深度与自运动联合学习演进",
        "扩散语言模型：卓越的数据学习器",
        "UniAVGen：基于非对称跨模态交互的音频视频联合生成框架",
        "LEGO-Eval：基于工具增强的精细化三维具身环境合成评估框架",
        "Orion-MSP：面向表格上下文学习的多尺度稀疏注意力机制",
        "TabTune：面向表格基础模型推理与微调的统一算法库",
        "Kinematify：高自由度铰接物体的开放词汇合成",
        "MME-CC：面向认知能力的挑战性多模态评估基准",
        "LiveTradeBench：基于大语言模型的现实市场阿尔法策略探索",
        "CostBench：评估动态环境中LLM工具使用代理的多轮成本最优规划与适应能力",
        "序列优势：在匹配计算量下逆熵投票机制优于并行自一致性方法",
        "Jr. AI科学家及其风险报告：基于基准论文的自主科学探索",
        "非对称对话中的具身误解：MapTask的视角主义标注框架",
        "通过自适应查询增强让多模态嵌入器学习何时增强查询",
        "以视频思考：视频生成作为一种前景广阔的多模态推理范式",
        "V-Thinker：基于图像交互的思维框架",
        "基于经验合成的智能体规模化学习",
        "寒武纪-S：迈向视频空间超感知之路",
        "GUI-360：面向计算机使用智能体的综合数据集与基准测试框架",
        "英伟达Nemotron Nano V2 VL模型",
        "基于多模态语义扰动的视觉语言模型污染检测",
        "多头注意力机制的强彩票假设",
        "基准设计者应“在测试集上训练”以揭示可被利用的非视觉捷径",
        "面向仿人机器人的视觉驱动反应式足球技能学习",
        "如何利用源语言感知神经机器翻译指标评估语音翻译系统",
        "SIMS-V：面向空间视频理解的模拟指令调优框架",
        "面向大语言模型系统的RDMA点对点通信技术",
        "SAIL-RL：基于双奖励强化学习的多模态大语言模型思考时机与方式引导框架",
        "EVTAR：基于额外非配对视觉参考的端到端虚拟试衣系统",
        "过于良善难以为恶：大型语言模型在反派角色扮演中的失效研究",
        "DeepEyesV2：迈向具身化多模态模型",
        "视觉空间调优",
        "VeriCoT：基于逻辑一致性检验的神经符号思维链验证方法",
        "稠密运动描述生成",
        "通过优化文本嵌入缓解大型视觉语言模型中的幻觉现象",
        "动态环境中的实时推理智能体",
        "大海捞针式越狱攻击",
        "HAFixAgent：具备历史感知能力的自动化程序修复智能体",
        "CritiCal：批判性反馈能否提升大语言模型的不确定性或置信度校准？",
        "HaluMem：智能体记忆系统中的幻觉效应评估",
        "IterResearch：基于马尔可夫状态重构的长视野智能体范式再思考",
        "DRIVE：面向竞技性代码生成中可验证奖励强化学习的数据策管最佳实践",
        "《站台：面向人工智能驱动发现的开放世界环境》",
        "MVU-Eval：面向多模态大语言模型的多视频理解评估体系",
        "路由流形对齐提升混合专家大语言模型的泛化能力",
        "RedOne 2.0：社交网络服务中领域专用大语言模型后训练机制的重构",
        "SofT-GRPO：基于Gumbel重参数化软思考策略优化突破离散令牌大语言模型强化学习",
        "基于置信度的推理：通过不确定性头部实现大语言模型推理步骤的高效验证",
        "基于物理世界模型的机器人学习",
        "基于改进型循环结构的预训练语言模型深度思维教学方法",
        "NURBGen：基于大语言模型驱动的NURBS建模实现高保真文本到CAD生成",
        "长链接地思维：规模化提炼组合式视觉推理链条",
        "RLoop：基于迭代策略初始化的强化学习自改进框架",
        "DigiData：通用移动控制智能体的训练与评估框架",
        "MPJudge：音乐诱发绘画的感知评估研究",
        "Llama-Embed-Nemotron-8B：面向多语言与跨语言任务的通用文本嵌入模型",
        "FLEX：基于经验前向学习的智能体持续进化框架",
        "引领视觉-语言-动作模型未来发展的十大开放挑战",
        "Ariadne：一个用于探索与拓展视觉语言模型推理边界的可控框架",
        "DIMO：面向任意物体的多样化三维运动生成方法",
        "RLVE：基于可验证自适应环境扩展语言模型强化学习规模的方法",
        "大语言模型具有情感感知能力吗？基于提示工程、检索机制与课程学习的情感识别方法研究",
        "SWE-fficiency：语言模型能否在真实工作负载下优化现实代码库？",
        "Diffusion-SDPO：扩散模型的安全直接偏好优化方法",
        "千词成图：基于结构化描述的文本到图像生成增强方法",
        "VADER：基于关系感知大语言模型的因果视频异常理解框架",
        "Omni-AVSR：基于大语言模型的统一多模态语音识别研究",
        "LUT-LLM：基于FPGA内存计算的高效大语言模型推理框架",
        "强化学习提升大语言模型对层次化知识的遍历能力",
        "基于人类示范的计算机使用代理系统基础构建",
        "小模型，大逻辑：多样性驱动优化激发VibeThinker-1.5B的大模型推理能力",
        "对话系统中自适应多智能体响应优化机制研究",
        "Wasm：构建结构化阿拉伯语交错多模态语料库的流程体系",
        "KLASS：基于KL散度的掩码扩散模型快速推理方法",
        "VideoSSR：视频自监督强化学习框架",
        "超越英语：基于大语言模型构建包容可扩展的多语言机器翻译系统",
        "未择之路：RLVR可证明性偏离主成分学习机制研究",
        "超越事实检索：基于生成式语义工作区的RAG情景记忆框架",
        "DynaAct：动态动作空间下的大语言模型推理研究",
        "瓦特智能：衡量本地人工智能的智能效率",
        "BiCA：基于引文感知困难负样本的生物医学稠密检索有效方法",
        "软件开发中大型语言模型的平衡之道：从业者视角",
        "基于对齐模型协作的多样性与质量优化方法",
        "TimeSearch-R：基于自验证强化学习的自适应时序搜索实现长视频理解",
        "Lumine：构建3D开放世界通用智能体的开放方案",
        "MADD：多智能体药物发现协同系统",
        "时序运动：基于双时钟去噪的无训练运动控制视频生成方法",
        "TiDAR：扩散式思考，自回归式表达",
        "LoopTool：构建数据-训练闭环以实现鲁棒的大语言模型工具调用",
        "WMPO：基于世界模型的视觉-语言-动作策略优化方法",
        "MathSE：通过自演进迭代反思与奖励导向微调提升多模态数学推理能力",
        "WebVIA：基于Web的视觉语言智能体框架——面向交互式可验证的UI到代码生成",
        "迈向可靠扩散采样的前沿：基于对抗性Sinkhorn注意力引导的方法",
        "基于合成监督的网页智能体自适应方法",
        "智能体重构实践：AI编程智能体的实证研究",
        "Motif-2-12.7B技术报告",
        "基于授权验证机制抑制语言模型幻觉现象的研究",
        "潜在空间一小步，像素生成大飞跃：面向扩散模型的快速潜在上采样适配器",
        "PAN：一种通用、可交互且长时域的世界仿真世界模型",
        "UniVA：面向开源的新一代视频通用智能体的通用视频智能体框架",
        "大语言模型的黑盒同策略蒸馏",
        "致敬窃贼：探索去中心化GRPO中的攻击与防御策略",
        "Depth Anything 3：从任意视角重建视觉空间",
        "叠加梯度下降法：运用量子原理优化模型训练",
        "零误差完成百万步大语言模型任务的实现方案",
        "AlphaResearch：利用语言模型加速新算法发现的探索",
        "Music Flamingo：音频语言模型中音乐理解能力的规模化拓展",
        "基于量规的基准测试与强化学习在提升大语言模型指令遵循能力中的应用",
        "基于属性条件人工评估的图像生成多样性基准测试",
        "ResearchRubrics：深度研究智能体评估的提示与评分标准基准",
        "MuSc-V2：基于无标签样本互评的零样本多模态工业异常分类与分割方法",
        "AffordBot：基于多模态大语言模型的3D细粒度具身推理",
        "SliderEdit：基于细粒度指令控制的连续图像编辑",
        "MM-CRITIC：大型多模态模型多维度批判能力的系统性评估",
        "CC30k：面向可复现性情感分析的引文上下文数据集",
        "DoPE：旋转位置编码去噪方法",
        "WEAVE：解锁与评测上下文交织式多模态理解与生成能力",
        "GGBench：面向统一多模态模型的几何生成推理基准",
        "UI2Code^N：支持测试时扩展交互的界面到代码生成视觉语言模型",
        "AIonopedia：基于大语言模型的多模态学习协同框架用于离子液体发现",
        "虚拟宽度网络",
        "LiteAttention：面向扩散变换器的时间稀疏注意力机制",
        "用人工智能模拟视觉世界：发展路线图",
        "SpatialThinker：通过空间奖励增强多模态大语言模型的三维推理能力",
        "HI-TransPA：听力障碍翻译个人助手",
        "MarsRL：基于智能体流水线并行强化学习的多智能体推理系统进阶研究",
        "RF-DETR：基于神经架构搜索的实时检测Transformer",
        "经验引导的推理时策略自适应方法",
        "DiscoX：专业领域篇章级翻译任务的基准评测体系",
        "EmoVid：面向情感中心视频理解与生成的多模态情感视频数据集",
        "物尽其用：通过多头解码以结构化人类先验引导生成式推荐系统",
        "工作负载调度器——起源、算法与差异",
        "面向科学创意生成的大语言模型：以创造力为核心的综述研究",
        "构建面向智能体的网络：一种声明式的智能体-网络交互框架",
        "CATS-V2V：面向复杂恶劣交通场景的真实世界车车协同感知数据集",
        "从证明到程序：大语言模型中工具诱发推理幻觉的特征分析",
        "一种面向云计算系统的元启发式负载均衡器",
        "miniF2F-Lean再审视：局限分析与未来路径规划",
        "P1：基于强化学习的物理奥林匹克竞赛解题系统",
        "MiroThinker：通过模型、上下文与交互式扩展突破开源研究智能体的性能边界",
        "Uni-MoE-2.0-Omni：基于先进混合专家架构、训练策略与数据技术的语言核心型全模态大模型扩展",
        "Souper-Model：简单算术如何实现最先进大语言模型性能",
        "Part-X-MLLM：面向部件感知的三维多模态大语言模型",
        "MMaDA-并行：面向思维感知编辑与生成的多模态扩散大语言模型",
        "GroupRank：一种强化学习驱动的分组重排序范式",
        "TiViBench：面向视频生成模型的视觉思维推理基准测试框架",
        "PhysX-Anything：基于单张图像生成仿真就绪的物理三维资产",
        "UFO^3：编织智能体数字星系",
        "进化方法而非提示：大语言模型越狱攻击的演化合成",
        "回归本质：让去噪生成模型真正实现去噪",
        "OlmoEarth：面向多模态地球观测的稳定潜在图像建模",
        "Live-SWE-agent：软件工程智能体能否实现实时自主演进？",
        "基因组下一标记预测器具备上下文学习能力",
        "WebCoach：具备跨会话记忆引导的自演进网络智能体",
        "评估大语言模型在知识图谱中的偶然性发现能力：以药物重定位为例",
        "测试时频谱感知潜空间导向在视觉语言模型零样本泛化中的应用",
        "UnSAMv2：自监督学习实现任意粒度图像分割",
        "MicroVQA++：面向多模态大语言模型的高质量显微图像推理数据集与弱监督图结构",
        "动态反思：通过文本对齐探究视频表征能力",
        "LoCoBench-Agent：长上下文软件工程中LLM智能体的交互式基准测试框架",
        "SafeGRPO：基于规则约束策略优化的自奖励多模态安全对齐方法",
        "AI-Salesman：构建可信赖大语言模型驱动的电话营销系统",
        "Instella：具备卓越性能的完全开放语言模型",
        "一种基于区块链保障来源可靠性的去中心化检索增强生成系统",
        "NORA-1.5：基于世界模型与动作偏好奖励训练的视觉-语言-动作模型",
        "OpenUS：基于自适应掩码对比学习的全开源超声图像分析基础模型",
        "VIDEOP2R：从感知到推理的视频理解框架",
        "Think-at-Hard：通过选择性潜在迭代提升推理语言模型性能",
        "AraLingBench：用于评估大语言模型阿拉伯语语言学能力的人工标注基准",
        "一码定风格：基于离散风格空间的代码驱动图像生成",
        "世界模拟器能否推理？Gen-ViRe：生成式视觉推理基准框架",
        "MVI-Bench：评估LVLM抗误导性视觉输入鲁棒性的综合基准",
        "REVISOR：超越文本反思——面向长视频理解的多模态内省推理框架",
        "OmniZip：面向快速全模态大语言模型的音频引导动态令牌压缩方法",
        "ATLAS：面向前沿科学推理的高难度跨学科基准测试",
        "Agent-R1：基于端到端强化学习的大语言模型智能体训练框架",
        "大语言模型与极端多标签分类的融合：扩展框架与多模态方法",
        "Orion：支持多模态感知、高级视觉推理与执行的一体化视觉智能体",
        "Φeat：基于物理基础的特征表示方法",
        "缓解大语言模型中的标签长度偏差",
        "智能体自述文件：关于自主编程中上下文文件的实证研究",
        "主动式听觉助手：自我中心对话的隔离技术",
        "一脑波编码千标记：基于皮层间神经交互建模的高效脑电情绪识别",
        "面向大语言模型三维定位的误差驱动场景编辑方法",
        "基于大语言模型的全自动混沌工程：助力低成本构建高韧性软件系统",
        "TopoPerception：大视觉语言模型中全局视觉感知的无捷径评估",
        "Kandinsky 5.0：面向图像与视频生成的基座模型系列",
        "视频推理：通过迷宫求解任务首次评估视频模型的推理能力",
        "优秀AI研究智能体需具备何种特质？探讨构思多样性的作用",
        "VisPlay：基于图像自演进的视觉语言模型",
        "基于自动生成大规模数据集的指令引导胸部X光病灶分割",
        "ARC-Chapter：将小时级视频结构化构建为可导航章节与层级化摘要",
        "MHR：动量人体骨骼系统",
        "FreeAskWorld：一种以人为中心的具身AI交互式闭环仿真平台",
        "RoMa v2：更强大、更精准、更快速、更密集的特征匹配",
        "生成式音乐人工智能与人类偏好的对齐：方法与挑战",
        "状态混合：面向多模态生成的路由令牌级动态机制",
        "Medal S：面向医学分割的空间-文本提示模型",
        "首帧：视频内容定制化的关键所在",
        "V-ReasonBench：面向视频生成模型的统一推理基准测试套件",
        "Step-Audio-R1技术报告",
        "基于多模态基础模型的空间智能规模化研究",
        "SAM 3D：图像三维化通用框架",
        "视频即答案：基于联合GRPO的下一事件预测与生成方法",
        "MiMo-Embodied：跨具身基础模型技术报告",
        "Agent0：通过工具集成推理实现零数据自演进智能体",
        "Nemotron Elastic：迈向高效多合一推理大语言模型",
        "通用基础模型在医院运营场景中的临床适用性不足",
        "边生成边思考：视觉生成过程中的文本推理交错机制",
        "TurkColBERT：土耳其语信息检索的稠密与延迟交互模型基准测试",
        "SRPO：视觉-语言-动作模型的自参照策略优化方法",
        "SAM2S：通过语义长期追踪实现手术视频中的任意目标分割",
        "NaTex：作为潜在颜色扩散的无缝纹理生成方法",
        "PartUV：基于部件划分的三维网格UV展开方法",
        "TimeViper：面向高效长视频理解的混合Mamba-Transformer视觉语言模型",
        "EntroPIC：基于比例-积分控制的熵稳定方法实现大语言模型的长期稳定训练",
        "FinTRec：基于Transformer的金融应用统一上下文广告定向与个性化框架",
        "BioBench：超越ImageNet的科学机器学习基准测试蓝图",
        "基于多粒度语言学习的医学视觉理解增强方法",
        "基于视觉专家的草拟与优化框架",
        "OpenMMReasoner：以开放通用方案推进多模态推理前沿研究",
        "揭示文本本征维度：从学术摘要到创意故事",
        "GeoVista：面向地理定位的网络增强型智能视觉推理系统",
        "SAM 3：基于概念的可提示通用分割模型",
        "O-Mem：面向个性化长周期自演进智能体的全域记忆系统",
        "RynnVLA-002：统一视觉-语言-行为与世界模型",
        "PARROT：输出真实性说服力与一致性鲁棒性评级——面向大语言模型的谄媚鲁棒性基准",
        "Loomis Painter：绘画过程重建技术研究",
        "WorldGen：从文本到可遍历交互式三维世界的生成系统",
        "Mantis：具备解耦视觉预见能力的多模态视觉-语言-动作模型",
        "VisMem：潜在视觉记忆解锁视觉语言模型的潜力",
        "InstructMix2Mix：通过多视角模型个性化实现一致性的稀疏视角编辑",
        "MergeDNA：基于动态分词与令牌合并的情境感知基因组建模方法",
        "全知科学家：构建人类与AI科学家协同进化的科研生态系统",
        "缩小智能规模：探索小型多模态模型中的感知与推理瓶颈",
        "视觉自回归模型中的多样性本真溯源",
        "Video-R4：通过视觉反刍增强文本富集视频推理能力",
        "ICLR同行评审与反驳流程的启示",
        "基于草图引导验证的物理感知视频生成规划方法",
        "VLA-4D：将四维感知嵌入视觉-语言-动作模型以实现时空连贯的机器人操控",
        "多维度攻击：揭示配备防御机制的视觉语言模型中的跨模型安全漏洞",
        "基于生成式合成数据的X射线违禁品检测方法优化",
        "重新审视显著性图谱：一种认知对齐的解释方法分类与评估框架",
        "基于全栈AMD平台的基础模型训练：计算、网络与系统设计",
        "基于深度研究的通用代理记忆框架",
        "AutoEnv：面向跨环境智能体学习的自动化环境测评框架",
        "计算机使用代理作为生成式用户界面的评估者",
        "DeCo：面向端到端图像生成的频域解耦像素扩散方法",
        "DR Tulu：基于演化评价标准的深度研究强化学习",
        "UltraFlux：面向多比例原生4K文本到图像生成的数据-模型协同设计方法",
        "视频内指令：作为生成控制信号的视觉标识",
        "预算感知的工具使用实现高效智能体扩展",
        "视觉思维链：通过连续视觉标记提升视觉语言模型的感知与推理能力",
        "混元视频1.5技术报告",
        "Pillar-0：放射学基础模型的新前沿",
        "Plan-X：基于语义规划的教学视频生成框架",
        "M3-Bench：面向多模态、多跳、多线程工具使用型MLLM智能体的基准测试框架",
        "多智能体深度研究：基于M-GRPO的多智能体系统训练方法",
        "超越选择题：面向鲁棒视觉语言强化微调的可验证开放式问答",
        "MIST：基于监督训练的互信息估计方法",
        "图像即自身奖赏：基于对抗性奖励的图像生成强化学习",
        "可控图层分解在可逆多层图像生成中的应用",
        "MASS：面向视觉语言模型物理推理与理解的运动感知时空定位方法",
        "上采样任意内容：一种简单且难以超越的特征上采样基线方法",
        "PRInTS：面向长视野信息搜索的奖励建模方法",
        "AICC：更精细解析HTML，打造更优模型——基于模型的HTML解析器构建的7.3T AI就绪语料库",
        "EvoVLA：自演进视觉-语言-动作模型",
        "无需数据的流映射蒸馏方法",
        "One4D：基于解耦LoRA控制的统一四维生成与重建框架",
        "Target-Bench：世界模型能否实现基于语义目标的无地图路径规划？",
        "大语言模型中真值表征的稳定性研究",
        "SyncMV4D：面向手物交互合成的外观与运动同步多视角联合扩散模型",
        "基于随机路径积分的保真推荐解释方法",
        "推荐系统中交互感知的单语义概念提取方法研究",
        "MSRNet：用于伪装目标检测的多尺度递归网络",
        "GigaEvo：基于大语言模型与进化算法的开源优化框架",
        "MedSAM3：基于医学概念的可分割万物模型探究",
        "Agent0-VL：面向工具集成视觉语言推理的自演进智能体探索",
        "SteadyDancer：基于首帧保持的协调连贯人体图像动画生成框架",
        "iMontage：统一、通用、高动态性的多对多图像生成框架",
        "理解能力是否促进统一多模态模型的生成能力？从分析到发展路径",
        "GigaWorld-0：将世界模型作为数据引擎赋能具身智能体",
        "柔性自适应策略优化",
        "SSA：通过特征空间中对齐全注意力和稀疏注意力输出的稀疏稀疏注意力机制",
        "UltraViCo：突破视频扩散变换器的外推极限",
        "ROOT：面向神经网络训练的鲁棒正交化优化器",
        "MagicWorld：基于几何驱动的交互式视频世界探索系统",
        "STARFlow-V：基于标准化流的端到端视频生成建模",
        "OmniAlpha：面向统一多任务RGBA生成的序列到序列框架",
        "ReDirector：利用旋转相机编码生成任意长度的视频重拍",
        "混元OCR技术报告",
        "VQ-VA世界：迈向高质量视觉问答-视觉应答新境界",
        "Fara-7B：一种高效的计算机操作智能体模型",
        "MajutsuCity：基于语言驱动与美学自适应、具备可控三维资产与布局的城市生成方法",
        "面向视觉语言模型工具集成推理的可扩展智能体强化学习",
        "协同烹饪与清洁：面向并行任务执行的具身智能体教学研究",
        "PhysChoreo：基于部件感知语义关联的物理可控视频生成",
        "视觉思维与文本推理：ARC中的视觉-语言协同机制",
        "DiffSeg30k：面向局部AIGC检测的多轮扩散编辑基准数据集",
        "Yo'City：基于自批判扩展的个性化无边界3D真实城市场景生成",
        "推理的认知基础及其在大语言模型中的体现",
        "基于行列式点过程引导策略优化的多样化视频生成",
        "基于神经场的统一全原子分子生成方法",
        "概念感知批量采样提升语言-图像预训练效果",
        "提升乒乓球技术：一种鲁棒的三维轨迹与旋转估计现实应用方案",
        "CLaRa：通过连续潜在推理桥接检索与生成任务",
        "未来并非均匀分布：大语言模型的预测能力取决于提问内容",
        "SciEducator：基于戴明环多智能体系统的科学视频理解与教育框架",
        "俄语架构的多模态评估框架",
        "多智能体系统中的潜在协作",
        "Inferix：基于块扩散的新一代世界模拟推理引擎",
        "Harmony：通过跨任务协同实现音视频生成的和谐统一",
        "重新审视跨难度水平的泛化能力：并非易事",
        "NVIDIA Nemotron解析模型1.1版",
        "Monet：超越图像与语言的潜在视觉空间推理",
        "终端速度匹配",
        "UniGame：将统一多模态模型转化为自身对抗者",
        "G^2VLM：基于几何基础的视觉语言模型——统一三维重建与空间推理的新范式",
        "块级联：无需训练的块因果视频模型加速方法",
        "MobileVLA-R1：强化移动机器人的视觉-语言-动作协同框架",
        "通过预测强化动作策略",
        "基于轨迹采样对连续时间一致性的免图像时间步蒸馏方法",
        "SPHINX：面向视觉感知与推理的合成环境",
        "立场声明：完美AI对齐的复杂性——形式化RLHF三难困境",
        "NAF：基于邻域注意力滤波的零样本特征上采样方法",
        "RAISECity：面向城市级现实对齐三维世界生成的多模态智能体框架",
        "I-GLIDE：退化估计中潜在健康指标的输入分组方法",
        "基于频率自适应锐度正则化的三维高斯溅射泛化能力提升方法",
        "视频生成模型具备优异的潜在奖励建模能力",
        "画布到图像：基于多模态控制的组合式图像生成",
        "MIRA：面向图像编辑的多模态迭代推理智能体",
        "ENACT：基于自我中心交互世界建模的具身认知评估框架",
        "Multi-Crit：基于多元化标准遵循的多模态评估基准测试",
        "理解语言意味着什么？",
        "具身化学习者：基于生长-精炼机制的多模态语义记忆系统",
        "Z-Image：一种基于单流扩散Transformer的高效图像生成基础模型",
        "REASONEDIT：迈向推理增强型图像编辑模型",
        "AnyTalker：通过交互性优化实现多人对话视频生成的可扩展化",
        "大规模视觉桥接变换器",
        "DeepSeekMath-V2：迈向可自我验证的数学推理",
        "架构解耦并非统一多模态模型的全部所需",
        "CaptionQA：图像描述能否与图像本身同等有效？",
        "DualVLA：通过部分解耦推理与行动构建可泛化的具身智能体",
        "DiP：像素空间扩散模型的高效调控框架",
        "每个标记都重要：大语言模型中1600万超长上下文的泛化能力研究",
        "对抗流模型",
        "解耦DMD：以CFG增强为矛，以分布匹配为盾",
        "RefineBench：基于检查表的语言模型精炼能力评估框架",
        "Nemotron-Flash：面向延迟最优的混合型小语言模型",
        "Captain Safari：一种世界引擎系统",
        "框架中的世界：理解文化混合作为视觉语言模型的新挑战",
        "图像块坍缩现象研究",
        "OralGPT-Omni：一种多功能口腔医学多模态大语言模型",
        "基于流映射的扩散模型测试时缩放",
        "几何约束智能体在空间推理中的应用",
        "聚焦思维链：通过结构化输入信息实现高效大语言模型推理",
        "SO-Bench：多模态大语言模型的结构化输出评估基准",
        "从像素到情感：对齐多模态大语言模型与人类图像认知感知",
        "基于分割-合并的层感知视频合成方法",
        "OmniRefiner：基于强化学习的局部扩散细化模型",
        "YOLO与专家混合模型：面向鲁棒目标检测的自适应专家路由机制",
        "Fast3Dcache：免训练的3D几何合成加速方法",
        "FedRE：一种面向模型异构联邦学习的表示纠缠框架",
        "Xmodel-2.5：13亿参数的数据高效推理小型语言模型",
        "基于深度学习的磁共振成像超分辨率技术综述",
        "查找泄漏，修复分割：基于聚类的视频衍生数据集防泄漏方法",
        "基于弱监督双编码器模型的监控视频异常事件识别",
        "从代码基础模型到智能体与应用：代码智能实践指南",
        "LongVT：通过原生工具调用激励“长视频思考”",
        "Envision：面向因果世界过程洞察的统一理解与生成基准测试",
        "基于大语言模型的强化学习稳定性研究：理论框架与实践方法",
        "我们距离真正有用的深度研究智能体还有多远？",
        "视频生成中的重力问题如何解决？基于可验证奖励的后训练牛顿定律应用",
        "Infinity-RoPE：自回归自展开中涌现的动作可控无限视频生成",
        "一致性评判器：通过参考引导的注意力对齐修正生成图像中的不一致性",
        "TUNA：面向原生统一多模态模型的统一视觉表征驯化",
        "LFM2技术报告",
        "Wikontic：基于大语言模型构建与Wikidata对齐且具备本体感知的知识图谱",
        "基于优化视角的大语言模型思维校正研究",
        "Flash-DMD：通过高效蒸馏与联合强化学习实现高保真少步图像生成",
        "VLASH：基于未来状态感知异步推理的实时视觉-语言-动作模型",
        "GR-RL：面向长时序灵巧操作的高精度机器人强化学习框架",
        "InternVideo-Next：迈向无需视频-文本监督的通用视频基础模型",
        "SpeContext：基于推测性上下文稀疏性实现大语言模型的高效长上下文推理",
        "整流轨迹上的均值流：通过高效一步生成建模实现更直更快的流",
        "基于分层令牌压缩的流式视频大语言模型加速方法",
        "文化褪色之处：揭示文本到图像生成中的文化鸿沟",
        "PromptBridge：面向大语言模型的跨模型提示迁移方法",
        "SCALE：面向数学推理测试时扩展性能瓶颈的选择性资源分配方法",
        "MultiBanana：一个面向多参考文本到图像生成任务的挑战性基准",
        "Script：面向多模态大语言模型的图结构及查询条件化语义令牌剪枝方法",
        "Lotus-2：利用强大图像生成模型推进几何密集预测",
        "StreamGaze：流式视频中的视线引导时序推理与主动理解",
        "POLARIS：基于投影正交最小二乘的扩散模型鲁棒自适应反演方法",
        "ORION：在思维语言中高效训练语言模型推理能力",
        "如苏格拉底般提问：苏格拉底助力视觉语言模型理解遥感图像",
        "基于指令-策略协同进化的智能体策略优化",
        "HiconAgent：面向图形界面智能体的历史上下文感知策略优化",
        "非结构化数据流形特征结构学习",
        "大型语言模型测试时计算扩展的艺术",
        "OpenREAD：基于LLM批判器的端到端自动驾驶开放式推理强化框架",
        "ChronosObserver：基于超空间扩散采样的四维世界构建方法",
        "通用大语言模型在医学基准测试中表现优于临床专用工具",
        "从落叶中看见风：基于视频的力场推断",
        "WiseEdit：面向认知与创意驱动的图像编辑的基准测试框架",
        "CauSight：面向视觉因果发现的学习式超感知",
        "DreamingComics：基于视频模型的主体与布局定制化生成的故事可视化流程",
        "IndicParam：面向低资源印度语言的大语言模型评估基准",
        "一种用于具超限肢体人形机器人运动的分层控制框架",
        "基于三维点轨迹的生成式视频运动编辑",
        "MEGConformer：基于Conformer的MEG解码器用于鲁棒的语音与音素分类",
        "多普勒增强深度学习：基于YOLOv5实例分割的甲状腺结节分割性能提升研究",
        "OmniFusion：基于模块化融合的多语言多模态同步翻译模型",
        "基于视觉语言模型的业务流程图表结构化信息提取",
        "DeepSeek-V3.2：开拓开源大语言模型新前沿",
        "ToolOrchestra：通过高效模型与工具编排提升智能水平",
        "MultiShotMaster：一种可控的多镜头视频生成框架",
        "MG-Nav：基于稀疏空间记忆的双尺度视觉导航框架",
        "Skywork-R1V4：通过图像与深度研究的交错思考迈向具身多模态智能",
        "DualCamCtrl：用于几何感知相机控制视频生成的双分支扩散模型",
        "基于最小化人工监督的引导式自演化大语言模型",
        "SimScale：基于大规模真实世界模拟的驾驶学习",
        "InnoGym：人工智能代理创新潜能的基准测试框架",
        "ViSAudio：端到端视频驱动的双耳空间音频生成",
        "Glance：单样本加速扩散模型",
        "WorldMM：面向长视频推理的动态多模态记忆智能体",
        "深度研究：一项系统性综述",
        "PixelDiT：用于图像生成的像素扩散变换器",
        "动作分块中的混合视界策略",
        "WUSH：面向大语言模型量化的近最优自适应变换方法",
        "GoRL：一种与算法无关的生成策略在线强化学习框架",
        "CUDA-L2：通过强化学习超越cuBLAS性能的矩阵乘法优化系统",
        "听觉是否有助于视觉？视频生成中音视频联合去噪机制研究",
        "类比推理的奇特案例：探究大语言模型中的类比推理机制",
        "DiG-Flow：基于差异引导流匹配的鲁棒视觉-语言-动作模型",
        "RULER-Bench：面向视觉基础智能的下一代视频生成模型规则推理能力评测基准",
        "TRivia：基于自监督微调的视觉语言模型表格识别方法",
        "MagicQuillV2：基于分层视觉线索的精确交互式图像编辑",
        "重新审视视觉中心推理泛化中长链思维的必要性",
        "PAI-Bench：面向物理人工智能的综合基准测试",
        "Video4Spatial：基于上下文引导视频生成的视觉空间智能探索",
        "YingVideo-MV：音乐驱动的多阶段视频生成",
        "SimWorld：面向物理与社会世界中自主智能体的开放式真实模拟器",
        "SwiftVLA：以最小开销解锁轻量级视觉-语言-动作模型的时空动态理解",
        "Ovis-Image技术报告",
        "GUI探索实验室：通过多轮强化学习增强智能体界面导航能力",
        "FlashVGGT：基于压缩描述符注意力机制的高效可扩展视觉几何变换器",
        "BlockVid：基于块扩散的高质量一致性分钟级视频生成方法",
        "C^2DLM：因果概念引导的扩散大语言模型",
        "超越描述：具身智能体细粒度动作的认知基准测试",
        "面向人像视频编辑的上下文同步LoRA方法",
        "基于VideoScience-Bench的视频生成科学理解与推理能力评估",
        "理解与利用统一多模态模型中的稀疏性",
        "视觉同步：基于跨视角物体运动的多相机同步方法",
        "Artemis：面向感知策略学习的结构化视觉推理框架",
        "UnicEdit-10M：通过统一验证打破规模-质量壁垒的推理增强编辑数据集与基准",
        "鞋型不变与地面感知的密集足部接触估计学习",
        "基于高效启发式辅助构造的奥林匹克几何金牌级解题方法",
        "掩码可能造成干扰：论扩散语言模型中的上下文理解能力",
        "CodeV：基于工具感知策略优化的图像代码化可信视觉推理",
        "BOOM：超越单一模态——KIT的多模态多语言讲座伴侣",
        "Click2Graph：基于单次点击的交互式全景视频场景图生成",
        "Qwen3-VL技术报告",
        "引导视觉-语言-动作模型作为反探索：一种测试时缩放方法",
        "PretrainZero：强化主动预训练",
        "ViDiC：视频差异描述",
        "SpaceTools：基于双重交互式强化学习的工具增强空间推理",
        "OneThinker：面向图像与视频的一体化推理模型",
        "重新思考文本到视觉生成中推理时扩展的提示设计",
        "RELIC：具备长时记忆的交互式视频世界模型",
        "以编程视角思考：迈向基于图像思维的统一框架",
        "逆向流动：通过反向表示对齐改进标准化流",
        "Jina-VLM：小型多语言视觉语言模型",
        "CookAnything：一种灵活且一致的多步骤食谱图像生成框架",
        "AutoNeural：面向NPU推理的视觉-语言模型协同设计",
        "SR-GRPO：以稳定秩作为大语言模型对齐的固有几何奖励",
        "开放智能的经济学：模型生态系统中的权力与参与轨迹",
        "上下文表征劫持攻击",
        "UniQL：面向自适应边缘大语言模型的统一量化与低秩压缩框架",
        "AlignBench：基于合成图像-描述对评估细粒度图文对齐的基准",
        "SkillFactory：用于学习认知行为的自蒸馏方法",
        "BlurDM：一种用于图像去模糊的模糊扩散模型",
        "AdaptVision：通过自适应视觉获取实现高效视觉语言模型",
        "PosterCopilot：面向专业平面设计的布局推理与可控编辑",
        "PSA：金字塔稀疏注意力机制用于高效视频理解与生成",
        "分而治之，按需选帧：针对查询类型的长视频理解帧选择适配方法",
        "Light-X：支持相机与光照控制的生成式4D视频渲染",
        "对抗性混淆攻击：对多模态大语言模型的系统性干扰",
        "DAComp：面向全数据智能生命周期的数据智能体基准测试",
        "Live Avatar：基于实时音频驱动的无限长度虚拟形象流式生成系统",
        "Nex-N1：通过统一生态系统训练的大规模环境构建智能体模型",
        "ARM-Thinker：通过智能工具调用与视觉推理增强多模态生成式奖励模型",
        "奖励强制：基于奖励分布匹配蒸馏的高效流式视频生成",
        "语义先行：通过异步潜在扩散协调语义与纹理建模",
        "PaperDebugger：一种基于插件的多智能体系统，用于编辑器内的学术写作、审阅与编辑",
        "4DLangVGGT：基于Transformer的四维语言-视觉几何关联模型",
        "DynamicVerse：一种面向物理感知的多模态四维世界建模框架",
        "UltraImage：重新思考图像扩散变换器中的分辨率外推方法",
        "Splannequin：基于双重检测高斯泼溅的单目人体模型挑战视频冻结渲染",
        "基于模型与样本高效的AI辅助球体堆积数学发现",
        "SIMA 2：面向虚拟世界的通用具身智能体",
        "DraCo：以草稿作为思维链的文本到图像预览与稀有概念生成方法",
        "TV2TV：一种用于交错语言与视频生成的统一框架",
        "SignRoundV2：弥合大语言模型极低位宽训练后量化中的性能差距",
        "论Search-R1中的GRPO崩溃：惰性似然位移死亡螺旋",
        "对齐却刻板？系统提示对基于LVLM的文生图模型社会偏见的隐性影响",
        "SeeNav-Agent：基于视觉提示与步级策略优化的视觉语言导航增强方法",
        "基于视频扩散先验的生成式神经视频压缩",
        "通过自增强对比对齐缓解多模态大语言模型中的物体与动作幻觉",
        "NeuralRemaster：面向结构对齐生成的相位保持扩散方法",
        "基于扩散变换器高效自适应的反射消除方法",
        "FMA-Net++：融合运动与曝光感知的真实世界联合视频超分辨率与去模糊方法",
        "模态并非生而平等：解码与构建多模态大语言模型中的跨模态整合机制",
        "BulletTime：面向视频生成的时空解耦控制框架",
        "LATTICE：规模化实现高保真三维生成的民主化",
        "深度强制：基于深度汇聚与参与式压缩的无训练长视频生成方法",
        "基于源知识屏蔽更新的目标语言适配中缓解大语言模型灾难性遗忘的方法",
        "EgoLCD：基于长上下文扩散模型的第一人称视角视频生成",
        "ShadowDraw：从任意物体到光影绘画的组合艺术",
        "QKAN-LSTM：量子启发的柯尔莫哥洛夫-阿诺德长短期记忆网络",
        "GaussianBlender：基于解耦隐空间的三维高斯模型即时风格化方法",
        "缓解统一多模态模型持续学习中的模态内与模态间遗忘",
        "当AI坐上诊疗椅：心理测量越狱揭示前沿模型的内在冲突",
        "生成式动作叙事：合成视频中人体运动的评估",
        "REFLEX：通过将真相解构为风格与实质实现自优化的可解释事实核查",
        "大规模AI模型中稀疏专家混合的无辅助损失负载均衡理论框架",
        "TwinFlow：基于自对抗流实现大模型单步生成",
        "EditThinker：为任意图像编辑器解锁迭代推理能力",
        "从模仿到判别：一种增强跨域推理任务的广义课程优势机制",
        "EMMA：一种高效多模态理解、生成与编辑的统一架构",
        "PaCo-RL：通过成对奖励建模推进强化学习在一致性图像生成中的应用",
        "SCAIL：通过三维一致性姿态表征的上下文学习实现影视级角色动画",
        "熵比裁剪作为一种软性全局约束用于稳定强化学习",
        "基于单张图像的4D合成：联合三维几何重建与运动生成",
        "COOPER：空间智能中协同感知与推理的统一模型",
        "RealGen：基于检测器引导奖励的逼真文本到图像生成",
        "无需人工标注的自改进视觉语言模型评判器",
        "自知其不知的世界模型：基于校准不确定性的可控视频生成",
        "SpaceControl：在三维生成建模中引入测试时空间控制",
        "ReVSeg：基于强化学习的推理链激励视频分割方法",
        "人工智能与人类协同进化以实现更安全的共同超级智能",
        "M3DR：迈向通用多语言多模态文档检索",
        "主动视频感知：面向智能体长视频理解的迭代式证据搜寻",
        "从片段到场景：基于视觉语言模型的自动驾驶时序理解研究",
        "ProPhy：面向动态世界模拟的渐进式物理对齐框架",
        "SQ-format：一种面向大语言模型的统一稀疏量化硬件友好数据格式",
        "TimesNet-Gen：基于深度学习的场地特定强震动生成方法",
        "Colon-X：从多模态理解到临床推理的智能结肠镜技术演进",
        "从浮点运算到资源足迹：人工智能的资源成本",
        "具有鲁棒护栏的适应性分类大语言模型内容审核系统",
        "原生并行推理器：基于自蒸馏强化学习的并行推理框架",
        "超越实数：长上下文大语言模型中旋转位置编码的虚数扩展",
        "基于时序推理器的统一视频编辑方法",
        "Voxify3D：像素艺术与体素渲染的融合",
        "规模化零样本参考图像到视频生成",
        "DoVer：面向大语言模型多智能体系统的干预驱动自动调试方法",
        "EgoEdit：面向第一人称视频编辑的数据集、实时流式处理模型与基准测试框架",
        "分布匹配变分自编码器",
        "关系视觉相似性",
        "多视角金字塔变换器：见宏窥微，视野更广",
        "论预训练、中期训练与强化学习在推理语言模型中的相互作用",
        "LongCat-Image 技术报告",
        "UnityVideo：面向增强世界感知视频生成的统一多模态多任务学习框架",
        "视觉生成调优",
        "SPARK：面向无参考强化学习的逐步过程感知奖励机制",
        "VG-Refiner：基于智能体强化学习的工具精化指称式接地推理研究",
        "ReCamDriving：一种无需激光雷达的相机控制新型轨迹视频生成方法",
        "OmniSafeBench-MM：多模态越狱攻击-防御评估的统一基准与工具箱",
        "超越词元级监督：通过强化学习释放基于解码的回归潜力",
        "OpenSubject：利用视频衍生的身份与多样性先验知识实现主体驱动的图像生成与编辑",
        "一层足矣：面向图像生成任务的自适应预训练视觉编码器",
        "群表示位置编码",
        "解耦以泛化：面向数据稀缺视觉语言推理的上下文优先自演化学习",
        "VideoVLA：视频生成器可作为通用机器人操作器",
        "尺度自回归生成中的训练动态机制再思考",
        "小增益纳什：可微博弈中经认证的纳什均衡收缩方法",
        "基于高斯变分自编码器的向量量化方法",
        "人机交互中的具身指代表达理解",
        "基于格式强化学习的结构化文档翻译",
        "DZ-TDPO：面向长上下文对话中可变状态追踪的非破坏性时序对齐方法",
        "JEPA作为神经分词器：基于密度自适应注意力的鲁棒语音表征学习",
        "SAM系列模型中SAM2到SAM3的断层：基于提示的专长为何在概念驱动的图像分割中失效",
        "Wan-Move：基于潜在轨迹引导的运动可控视频生成",
        "Visionary：基于WebGPU高斯溅射平台的世界模型载体",
        "保持源视频真实感：面向影视级画质的高保真人脸替换",
        "OneStory：基于自适应记忆的连贯多镜头视频生成",
        "ThreadWeaver：面向语言模型高效并行推理的自适应线程技术",
        "基于自动质量引导自训练的无监督视频实例分割性能提升",
        "套利推理：基于优势感知推测的高效推理方法",
        "MIND-V：基于强化学习物理对齐的长时序机器人操作分层视频生成框架",
        "DeepCode：开放式智能体编码",
        "从下一词元到下一区块：扩散大语言模型的原理性适配路径",
        "视听与理解：多模态大语言模型中人类语音理解的基准测试",
        "COREA：基于双向3D到3D监督的可重光照三维高斯与SDF之间的由粗到细三维表示对齐方法",
        "TreeGRPO：基于树优势的GRPO用于扩散模型在线强化学习后训练",
        "高效动态场景重建：一次一个D4RT",
        "模块化神经图像信号处理",
        "慢思快行：一种面向泛化视觉语言导航的双系统基础模型",
        "SUCCESS-GS：面向高效静态与动态高斯泼溅的紧凑性与压缩技术综述",
        "EcomBench：面向电商领域基础智能体的综合性评估基准",
        "TrackingWorld：以世界坐标系为中心的几乎全像素单目三维跟踪",
        "基于新型深度学习架构的脑部MRI图像肿瘤分类与分割方法研究",
        "LYNX：基于置信度控制推理的动态出口学习机制",
        "MemLoRA：面向设备端内存系统的专家适配器蒸馏方法",
        "SegEarth-OV3：探索SAM 3在遥感图像开放词汇语义分割中的应用",
        "SAM-Body4D：无需训练的从视频中恢复四维人体网格",
        "地形扩散：基于扩散模型的无限实时地形生成技术——柏林噪声的继任者",
        "基于算子网络预测复杂几何结构上的时变流动",
        "相同内容，不同答案：多模态大语言模型中的跨模态不一致性研究",
        "StereoWorld：几何感知的单目到立体视频生成框架",
        "BrainExplore：人脑中可解释视觉表征的大规模发现",
        "OmniPSD：基于扩散变换器的分层PSD生成方法",
        "基于概念提示绑定的图像与视频概念合成",
        "InfiniteVL：融合线性与稀疏注意力机制的高效、无限输入视觉语言模型",
        "重新思考视频思维链推理方法",
        "HiF-VLA：基于运动表征实现视觉-语言-动作模型的后见、洞见与前瞻",
        "基于进度感知置信度调度的扩散语言模型快速解码方法",
        "UniUGP：面向端到端自动驾驶的统一理解、生成与规划框架",
        "WonderZoom：多尺度三维世界生成",
        "EtCon：先编辑后巩固——实现可靠知识编辑的新范式",
        "扩散语言模型中的去掩码策略学习",
        "迈向智能体系统规模化科学",
        "IF-Bench：基于生成式视觉提示的红外图像多模态大语言模型基准测试与性能增强",
        "TED-4DGS：面向4DGS压缩的时序激活与基于嵌入的形变方法",
        "MotionEdit：以运动为中心的图像编辑基准测试与学习方法",
        "超越统一模型：面向服务的实时TTS低延迟上下文感知音素化方法",
        "VideoSSM：基于混合状态空间记忆的自回归长视频生成",
        "GimbalDiffusion：面向视频生成的重力感知相机控制框架",
        "减少对功能词的关注以提升视觉-语言模型的鲁棒性",
        "智能挖矿时机选择：基于深度学习的比特币硬件投资回报率预测框架",
        "重塑临床对话：基于大语言模型的医疗沟通代理范式",
        "T-pro 2.0：一种高效的俄语混合推理模型与实验平台",
        "面向奥赛级数学解题的长程推理智能体",
        "文本到三维生成是否已为强化学习做好准备？一项渐进式探究",
        "OPV：基于结果的过程验证器——面向高效长链思维验证的新方法",
        "通过复杂度提升强化学习实现奥林匹克级别的几何大语言模型智能体",
        "MoCapAnything：基于单目视频的任意骨架统一三维运动捕捉",
        "BEAVER：一种高效的大语言模型确定性验证器",
        "从宏观到微观：基于视觉语言模型的分子微观空间智能基准测试",
        "VQRAE：面向多模态理解、生成与重建的表征量化自编码器",
        "在Veo世界模拟器中评估Gemini机器人策略",
        "基于自调用智能体的图像思维推理",
        "StereoSpace：基于规范空间端到端扩散的无深度立体几何合成方法",
        "更强无需归一化的Transformer模型",
        "FACTS排行榜：大型语言模型事实性综合评估基准",
        "工具增强的时空推理：简化视频问答任务的框架",
        "H2R-Grounder：一种无需配对数据的范式，用于将人类交互视频转化为物理接地的机器人视频",
        "MoRel：基于锚点中继双向混合与分层致密化的长时程无闪烁四维运动建模",
        "Omni-Attribute：面向视觉概念个性化的开放词汇属性编码器",
        "孔子代码智能体：工业级开源人工智能软件工程师",
        "ReViSE：基于自反思学习的统一模型推理感知视频编辑研究",
        "Fed-SE：面向隐私受限多环境大语言模型智能体的联邦自进化框架",
        "MOA：面向角色扮演智能体的多目标对齐框架",
        "X-Humanoid：规模化机器人化人类视频以生成仿人机器人视频",
        "DuetSVG：基于内部视觉引导的统一多模态SVG生成方法",
        "DragMesh：简易交互式三维生成",
        "EgoX：基于单视角第三人称视频的第一人称视频生成",
        "DentalGPT：激励牙科多模态复杂推理能力的发展",
        "SVG-T2I：无需变分自编码器即可扩展文本到图像的潜在扩散模型",
        "V-RGBX：基于本征属性精确控制的视频编辑",
        "滑动窗口注意力自适应方法",
        "PersonaLive! 面向直播的富有表现力肖像图像动画生成",
        "基于MetaCanvas探索多模态大语言模型与扩散模型的信息传递",
        "MeshSplatting：基于不透明网格的可微分渲染",
        "基于跟踪的结构生成：为视频生成提炼结构保持运动",
        "LEO-RobotAgent：面向语言驱动具身操作器的通用机器人智能体",
        "因果评判评估：面向大语言模型系统的校准替代指标",
        "Fairy2i：在参数取值{±1, ±i}条件下从实数大语言模型训练复数大语言模型",
        "CLINIC：面向医疗健康领域的语言模型多语言可信度评估框架",
        "离散扩散语言模型的缩放行为研究",
        "视觉-语言-动作模型的任务适应性：2025年BEHAVIOR挑战赛冠军解决方案",
        "Fast-FoundationStereo：实时零样本立体匹配",
        "CheXmask-U：X光影像中基于解剖标志点分割的不确定性量化",
        "N体问题：基于单人第一人称视频的并行执行",
        "一秒内实现锐利的单目视图合成",
        "基于稀疏自编码器的可解释嵌入：一种数据分析工具包",
        "Particulate：一种用于三维物体关节结构的前馈推断方法",
        "ReFusion：一种具备并行自回归解码能力的扩散大语言模型",
        "面向生成任务的可扩展视觉分词器预训练研究",
        "人工智能代理时代的记忆系统",
        "QwenLong-L1.5：面向长上下文推理与记忆管理的后训练方案",
        "LongVie 2：多模态可控超长视频世界模型",
        "Finch：以电子表格为核心的企业工作流财务与会计基准测试",
        "NL2Repo-Bench：面向代码智能体长周期仓库生成能力的评估基准",
        "无误差线性注意力是免费午餐：基于连续时间动力学的精确解",
        "KlingAvatar 2.0技术报告",
        "MentraSuite：面向心理健康推理与评估的大语言模型后训练框架",
        "Openpi Comet：2025年BEHAVIOR挑战赛竞赛方案",
        "基于人类视频视觉-物理空间对齐的空间感知视觉-语言-动作预训练",
        "WebOperator：面向网页环境中自主智能体的动作感知树搜索方法",
        "DrivePI：面向统一自动驾驶理解、感知、预测与规划的空间感知四维多模态大语言模型",
        "V-REX：基于问题链的探索性视觉推理基准测试",
        "迈向动态视觉：学习基于视觉的主动视角选择",
        "基于一致性求解器的图像扩散预览方法",
        "VLSA：具备即插即用安全约束层的视觉-语言-动作模型",
        "美学对齐风险同化：图像生成与奖励模型如何强化审美偏见与意识形态“审查”",
        "迈向数字人的交互式智能",
        "GenieDrive：基于四维占据栅格引导视频生成的物理感知驾驶世界模型",
        "表征对齐的关键：全局信息还是空间结构？",
        "RecTok：沿修正流的重建蒸馏",
        "文本到图像生成的少步蒸馏：实用指南",
        "AutoMV：一种用于音乐视频生成的自动多智能体系统",
        "Flowception：面向视频生成的时序扩展流匹配方法",
        "CAPTAIN：面向文本到图像扩散模型记忆缓解的语义特征注入方法",
        "DiffusionBrowser：基于多分支解码器的交互式扩散预览框架",
        "LitePT：更轻量且更强大的点云Transformer",
        "I-Scene：三维实例模型作为隐式可泛化空间学习器",
        "面向个性化文本到图像生成的方向性文本反演",
        "FoundationMotion：视频空间运动的自动标注与推理",
        "START：面向图表理解的空间与文本学习",
        "无需观测即可推断组合式四维场景",
        "FIN-bench-v2：用于评估芬兰语大语言模型的统一鲁棒基准套件",
        "状态于词元之上：推理词元角色特性分析",
        "CoRe3D：作为三维智能基础的协同推理框架",
        "重新思考专家轨迹在大语言模型后训练中的利用方式",
        "基于音频世界模型的机器人操作学习",
        "基于细粒度分类的渔业电子监控鱼类视觉重识别研究",
        "KD-OCT：面向临床级视网膜OCT分类的高效知识蒸馏方法",
        "MMGR：多模态生成式推理评估框架",
        "视频真实性测试：AI生成的ASMR视频能否欺骗视觉语言模型与人类？",
        "WorldPlay：面向实时交互式世界建模的长期几何一致性研究",
        "Scone：通过统一的理解-生成建模在主体驱动图像生成中融合构图与区分能力",
        "RoboTracer：面向机器人学的视觉语言模型空间轨迹推理技术",
        "OpenDataArena：一个用于基准测试后训练数据集价值的公平开放平台",
        "矢量棱镜：通过分层语义结构实现矢量图形动画化",
        "从任务中心视角揭示向量相似性搜索的潜在缺陷并引领下一代发展方向",
        "MemFlow：用于一致高效长视频叙事的自适应流动记忆",
        "RecGPT-V2技术报告",
        "ShowTable：通过协作反思与精炼解锁创意表格可视化",
        "基于文本可导向图像到三维的前馈式编辑方法",
        "Nemotron-Cascade：面向通用推理模型的级联强化学习规模化方法",
        "Olmo 3",
        "可微分进化强化学习",
        "VersatileFFN：通过自适应宽深复用实现大语言模型的参数高效性",
        "A4-Agent：一种用于零样本可供性推理的智能体框架",
        "SS4D：基于结构化时空隐变量的原生4D生成模型",
        "Sparse-LaViDa：稀疏多模态离散扩散语言模型",
        "用于视觉标记化与生成的球面Leech量化",
        "CRISP：基于平面场景基元的单目视频接触引导式实景转仿真方法",
        "TimeLens：基于多模态大语言模型重新思考视频时序定位",
        "EVOLVE-VLA：基于环境反馈的视觉-语言-动作模型测试时训练框架",
        "TAT：面向一体化医学图像复原的任务自适应Transformer",
        "Zoom-Zero：通过时序局部放大实现从粗到细的强化视频理解",
        "Efficient-DLM：从自回归到扩散语言模型，以及更快的速度",
        "Janus：面向可扩展MoE推理的注意力与专家模块解耦系统",
        "RePo：基于上下文重定位的语言模型",
        "JMMMU-Pro：基于图像的日本多学科多模态理解基准及其Vibe基准构建方法",
        "MobileWorldBench：面向移动智能体的语义世界建模",
        "大语言模型能力消除方法比较分析：跨架构评估",
        "TraPO：一种提升大语言模型推理能力的半监督强化学习框架",
        "UAGLNet：基于CNN-Transformer协同机制与不确定性聚合的全局-局部融合网络建筑物提取方法",
        "S2D：基于稀疏到稠密关键掩码蒸馏的无监督视频实例分割方法",
        "生成式AI时代用户感知的揭示：基于情感分析的AI教育应用在数字教学转型中的作用评估",
        "面向高质量数据共享的层次化数据集选择方法",
        "MeViS：面向指代运动表达视频分割的多模态数据集",
        "CoSPlan：基于场景图增量更新的纠错式序列规划",
        "ContextAnyone：面向角色一致性的文本到视频生成中的上下文感知扩散方法",
        "Step-GUI技术报告",
        "DEER：基于扩散模型的草稿生成与自回归模型的验证",
        "基于雅可比强迫的快速准确因果并行解码方法",
        "HyperVL：面向边缘设备的高效动态多模态大语言模型",
        "面向视觉中心推理的谜题课程GRPO方法",
        "通用推理模型",
        "Qwen-Image-Layered：基于图层分解实现内在可编辑性",
        "IC-Effect：基于上下文学习的精准高效视频特效编辑方法",
        "Skyra：基于具象化伪影推理的人工智能生成视频检测",
        "鲁棒且可校准的真实多媒体内容检测",
        "SAGE：基于强化学习的智能任意时长代理训练及其在长视频推理中的应用",
        "MMSI-Video-Bench：面向视频空间智能的综合性基准测试",
        "大语言模型能否引导自身探索？面向大语言模型推理的梯度引导强化学习",
        "FiNERweb：面向可扩展多语言命名实体识别的数据集与工具集",
        "DiffusionVL：将任意自回归模型转化为扩散式视觉语言模型",
        "VOYAGER：一种基于大语言模型的无训练多样化数据集生成方法",
        "基于自重采样的自回归视频扩散模型端到端训练方法",
        "VABench：面向音视频生成的综合基准测试框架",
        "追求像素级监督的视觉预训练",
        "自动驾驶中的视觉-语言-动作模型：过去、现在与未来",
        "FrontierCS：演化智能面临的前沿挑战",
        "VTCBench：视觉语言模型能否通过视觉文本压缩理解长上下文？",
        "SCOPE：通过提示演化提升智能体效能",
        "Nano Banana Pro是低层视觉全能选手吗？基于14项任务与40个数据集的全方位评估",
        "WAY：基于全球AIS轨迹的船舶目的地估计方法",
        "理解与改进双曲深度强化学习",
        "用于可解释与鲁棒模型训练的混合归因先验",
        "SonicMoE：通过IO感知与分块感知优化加速混合专家模型",
        "LikeBench：面向个性化的大语言模型主观喜好度评估",
        "面向多模态机器人操作学习的触觉-视觉同步感知",
        "迈向无缝交互：交互式三维会话头部动态的因果轮次建模",
        "Kling-Omni 技术报告",
        "智能体人工智能的适应性研究",
        "LLaDA2.0：将扩散语言模型扩展至千亿参数规模",
        "下一嵌入预测构建强视觉学习器",
        "StereoPilot：基于生成先验学习统一高效立体转换方法",
        "Seedance 1.5 pro：一种原生音视频联合生成基础模型",
        "深度任意全景：全景深度估计的基础模型",
        "生成式重聚焦：基于单张图像的灵活散焦控制",
        "DeContext 防御法：扩散变换器中的安全图像编辑",
        "REGLUE：融合全局与局部语义的隐变量纠缠扩散方法",
        "Alchemist：基于元梯度的数据选择提升文本到图像模型训练效率",
        "世界即画布：基于参考图像、轨迹与文本的可提示事件绘制",
        "N3D-VLM：原生三维定位赋能视觉语言模型实现精准空间推理",
        "JustRL：采用简易强化学习方案扩展15亿参数大语言模型",
        "AdaTooler-V：面向图像与视频的自适应工具调用",
        "探索与利用之辨：基于裁剪、熵与伪奖励的RLVR机制重思",
        "多模态奖励基准2：评估交错文本与图像的全能奖励模型",
        "EasyV2V：一种基于指令的高质量视频编辑框架",
        "FlashPortrait：基于自适应潜在预测的6倍速无限肖像动画生成",
        "RePlan：面向复杂指令图像编辑的推理引导区域规划方法",
        "VenusBench-GD：面向多样化定位任务的多平台综合图形用户界面基准",
        "ModelTables：关于模型的表格语料库",
        "听觉翻译：语音模态集成于大语言模型的有效性研究",
        "差异之重：基于能力差距发现与修正的模型审计方法",
        "Insight Miner：面向跨领域自然语言对齐的时间序列分析数据集",
        "Make-It-Poseable：面向三维人形角色动画的前馈式潜在姿态生成模型",
        "FrameDiffuser：基于G-Buffer条件扩散的神经前向帧渲染",
        "可训练的对数线性稀疏注意力机制用于高效扩散变换器",
        "面向语言模型通用推理的耦合变分强化学习方法",
        "MomaGraph：基于视觉语言模型的状态感知统一场景图用于具身任务规划",
        "TabReX：基于无参考表格的可解释性评估框架",
        "用于创造性连接与表达视觉概念的“氛围空间”",
        "心智内推理：潜在空间中的动态多模态交错",
        "双向归一化流：从数据到噪声及其逆过程",
        "EmoCaliber：通过置信度言语化与校准提升视觉情感理解的可靠性",
        "Nemotron-Math：基于多模态监督的高效长上下文数学推理蒸馏",
        "提示与程序间的状态共享",
        "通过混合LoRA提升递归Transformer的性能",
        "基于科学家对齐工作流程的大语言模型科学通用智能测评",
        "PhysBrain：以人类第一人称数据为桥梁，从视觉语言模型迈向物理智能",
        "当推理遇见其定律",
        "Seed-Prover 1.5：通过经验学习掌握本科水平定理证明",
        "4D-RGPT：基于感知蒸馏的区域级四维理解方法",
        "语义与重建并重：为文本到图像生成与编辑任务优化表征编码器",
        "LLM-as-a-Judge评估方法是否走在正确的道路上？",
        "视觉-语言-动作模型剖析：从模块构成到发展里程碑与挑战",
        "RadarGen：基于多视角摄像头的汽车雷达点云生成方法",
        "Robust-R1：面向鲁棒视觉理解的退化感知推理框架",
        "GroundingME：通过多维评估揭示多模态大语言模型中的视觉定位差距",
        "语言模型的物理学：第4.1部分，架构设计与规范层的神奇之处",
        "Turn-PPO：基于PPO的回合级优势估计以改进智能大语言模型中的多轮强化学习",
        "HERBench：视频问答中多证据整合的基准测试框架",
        "任意世界中的角色动画生成",
        "SWE-Bench++：基于开源仓库的可扩展软件工程基准生成框架",
        "Bolmo：字节化新一代语言模型",
        "StageVAR：面向视觉自回归模型的阶段感知加速方法",
        "元强化学习在语言智能体中引导探索行为",
        "3D-RE-GEN：基于生成式框架的室内场景三维重建",
        "面向长视频全模态推理与工具使用的基准与智能体框架",
        "MineTheGap：文本到图像模型中偏见的自动挖掘方法",
        "DataFlow：以数据为中心的人工智能时代下，由大语言模型驱动的统一数据准备与工作流自动化框架",
        "棱镜假说：通过统一自编码协调语义与像素表示",
        "面向教学视频编辑的区域约束上下文生成方法",
        "QuCo-RAG：基于预训练语料库不确定性量化的动态检索增强生成",
        "无限单应性作为相机控制视频生成的鲁棒条件约束",
        "大语言模型能否评估学生困境？基于能力模拟的人机难度对齐在试题难度预测中的应用",
        "WorldWarp：基于异步视频扩散的三维几何传播框架",
        "LoGoPlanner：基于度量感知视觉几何的定位支撑导航策略",
        "UCoder：基于大语言模型内部探测的无监督代码生成方法",
        "GenEnv：大语言模型智能体与环境模拟器间的难度对齐协同进化",
        "StoryMem：基于记忆机制的多镜头长视频叙事生成",
        "LoPA：基于前瞻并行解码的大规模扩散语言模型推理加速",
        "MobileWorld：在智能体-用户交互及MCP增强环境中的自主移动智能体基准测试",
        "推理调色板：通过潜在情境化调控推理以实现（视觉）语言模型的可控探索",
        "是否存在优于高斯分布的源分布？图像流匹配中源分布的探索",
        "Real2Edit2Real：通过三维控制界面生成机器人演示数据",
        "能否核对无误？风险投资领域自主法律智能体的发展路径",
        "CASA：通过自注意力实现跨模态注意力的高效视觉语言融合",
        "MatSpray：将二维材料世界知识融合至三维几何结构",
        "部件识别：三维部件分割与命名",
        "从形式语言与自然语言视角理解大语言模型的三段论推理能力",
        "Over++：面向图层交互效果的生成式视频合成",
        "基于脑电轴的阅读与调控大语言模型状态方法",
        "SecureCode v2.0：用于训练安全感知代码生成模型的生产级数据集",
        "SemanticGen：语义空间中的视频生成",
        "自底向上策略优化：语言模型策略中潜藏的内部策略",
        "LongVideoAgent：基于多智能体推理的长视频理解框架",
        "SpatialTree：空间能力在多模态大语言模型中的层级化发展探究",
        "MemEvolve：智能体记忆系统的元进化",
        "Step-DeepResearch 技术报告",
        "基于技能库的自进化智能体强化学习方法",
        "SAM Audio：音频任意分割模型",
        "INTELLECT-3：技术报告",
        "C2LLM技术报告：通过自适应交叉注意力池化实现代码检索的新前沿",
        "FaithLens：检测与解释忠实性幻觉",
        "代码的缩放定律：每种编程语言都至关重要",
        "QuantiPhy：评估视觉语言模型物理推理能力的量化基准",
        "Simulstream：流式语音到文本翻译系统评估与演示的开源工具包",
        "基于闭环世界建模的视频数字人主动智能研究",
        "基于双重可靠性度量的多LLM主题分析：结合科恩卡帕与语义相似性验证质性研究",
        "Memory-T1：基于强化学习的多会话智能体时序推理方法",
        "毒性预警：GitHub对话脱轨预测",
        "基于视频扩散模型的图像重聚焦学习方法",
        "TurboDiffusion：将视频扩散模型加速100-200倍",
        "面向视觉语言模型的四维推理学习：动态空间理解研究",
        "DreaMontage：基于任意帧引导的单镜头视频生成框架",
        "T2AV-Compass：迈向文本-音频-视频生成的统一评估",
        "超越记忆：揭示视觉语言模型中流行度偏差的多模态序数回归基准",
        "Nemotron 3 Nano：面向智能体推理的开放高效混合专家Mamba-Transformer模型",
        "HiStream：通过冗余消除流式处理实现高效高分辨率视频生成",
        "NVIDIA Nemotron 3：高效开放的智能模型",
        "TokSuite：衡量分词器选择对语言模型行为的影响",
        "基于下一帧预测的学习：自回归视频建模编码有效表征",
        "从词语到世界：大型语言模型能否成为隐式的基于文本的世界模型？",
        "DramaBench：面向剧本续写的六维评估框架",
        "SWE-EVO：在长周期软件演化场景中对编码智能体进行基准测试",
        "流式视频指令调优",
        "基于早期知识对齐的多跳推理方法",
        "LLM瑞士轮：基于竞争性瑞士制动态的多基准性能聚合",
        "PhononBench：面向晶体生成动态稳定性评估的大规模声子基准测试框架",
        "潜在隐式视觉推理",
        "自回归模型中的涌现时间抽象实现分层强化学习",
        "Spatia：基于可更新空间记忆的视频生成方法",
        "语言模型数学推理的舍恩菲尔德解剖学",
        "视频基础模型编码了多少三维信息？",
        "VA-π：面向像素感知自回归生成的可变分策略对齐方法",
        "GTR-Turbo：融合检查点在智能视觉语言模型训练中悄然成为免费教师",
        "InsertAnywhere：融合4D场景几何与扩散模型实现逼真视频物体插入",
        "基于心智图景感知的检索增强生成技术提升长文本理解能力",
        "MAI-UI技术报告：以现实世界为中心的基础图形用户界面智能体",
        "UniPercept：迈向跨美学、质量、结构与纹理的统一感知级图像理解",
        "ProEdit：基于反演技术的提示驱动编辑方法优化",
        "TimeBill：面向大语言模型的时间预算推理框架",
        "Omni-Weather：面向天气生成与理解的多模态统一基础模型",
        "少看而精看：双向感知塑形在多模态推理中的应用",
        "InSight-o3：以广义视觉搜索增强多模态基础模型能力",
        "SWE-RM：面向软件工程智能体的免执行反馈机制",
        "SlideTailor：面向科研论文的个性化演示文稿幻灯片生成系统",
        "SVBench：视频生成模型在社会推理能力上的评估",
        "基于可验证奖励的强化学习中样本极性再思考",
        "一种适用于通用3×3矩阵乘法的58次加法、秩23算法",
        "遮蔽教师与强化学生：视觉语言模型的知识蒸馏方法",
        "基于辅助损失的专家混合模型中专家与路由器的耦合机制",
        "LiveTalk：基于改进策略蒸馏的实时多模态交互视频扩散模型",
        "Yume-1.5：一种文本控制的交互式世界生成模型",
        "SmartSnap：自验证智能体的主动证据寻求机制",
        "扩散模型通晓透明度：基于视频扩散的透明物体深度与法向估计新范式",
        "Stream-DiffVSR：基于自回归扩散的低延迟可流式视频超分辨率方法",
        "Dream-VL与Dream-VLA：基于扩散语言模型架构的开放视觉-语言及视觉-语言-动作模型",
        "SpotEdit：扩散变换器中的选择性区域编辑",
        "GRAN-TED：为扩散模型生成鲁棒、对齐且细腻的文本嵌入",
        "Act2Goal：从世界模型到通用目标条件策略",
        "Web世界模型",
        "DiRL：一种高效的扩散语言模型后训练框架",
        "基于评分标准奖励的人工智能协研员训练方法研究",
        "YOLO-Master：基于专家混合与专用Transformer增强的实时检测加速框架",
        "Video-BrowseComp：开放网络环境下智能体视频研究基准测试",
        "面向智能信息检索的嵌套式浏览器使用学习",
        "OmniAgent：面向全模态音视频理解的音频引导主动感知智能体",
        "SurgWorld：通过世界建模从视频中学习手术机器人策略",
        "VL-LN基准：面向长视野目标导航与主动对话的研究",
        "单子上下文工程",
        "智能体系统设计的信息论视角",
        "分位数渲染：在3D高斯泼溅中高效嵌入高维特征",
        "Robo-Dopamine：面向高精度机器人操作的通用工序奖励建模",
        "ProGuard：面向主动式多模态安全防护",
        "通过统一导演模型实现音视频生成与用户想象的桥梁构建",
        "Knot Forcing：驯服自回归视频扩散模型以实现实时无限交互式肖像动画",
        "KernelEvolve：面向Meta异构AI加速器的可扩展智能内核编程框架",
        "TrGLUE与SentiTurca的提出：土耳其语通用语言理解与情感分析综合基准",
        "自评估解锁任意步数文本到图像生成",
        "思维形态：推理任务中分布特性比答案正确性更重要的现象研究",
        "逆向个性化",
        "UltraShape 1.0：基于可扩展几何优化的高保真三维形状生成方法",
        "DreamOmni3：基于涂鸦的编辑与生成",
        "面向长上下文建模的端到端测试时训练方法",
        "RLVR中参数高效方法的评估研究",
        "GraphLocator：基于图引导因果推理的问题定位方法",
        "CosineGate：基于余弦不兼容性的残差网络语义动态路由",
        "GateBreaker：基于门控引导的混合专家大语言模型攻击方法",
        "mHC：流形约束超连接架构",
        "Youtu-LLM：解锁轻量级大语言模型的原生智能体潜力",
        "顺势而为：摇滚乐中的能动性塑造——在开放能动学习生态系统中构建ROME模型",
        "GaMO：面向稀疏视图三维重建的几何感知多视角扩散外绘方法",
        "基于协同Transformer的操作系统日志点异常与集体异常统一检测框架",
        "扩展开放式推理以预测未来",
        "PhyGDPO：面向物理一致性文本到视频生成的物理感知分组直接偏好优化",
        "人工智能与大脑的交汇：从认知神经科学到自主智能体的记忆系统",
        "GR-Dexter技术报告",
        "利用扩散变换器内部动力学进行自引导",
        "神奇推理行为及其发现：推理过程的无监督探索",
        "自回归视频记忆压缩中的预训练帧保持技术",
        "SpaceTimePilot：跨时空动态场景的生成式渲染",
        "锻造空间智能：面向自主系统的多模态数据预训练路线图",
        "图形化求解：通过主动视觉思维提升推理前沿性能",
        "JavisGPT：面向音视频理解与生成的统一多模态大语言模型",
        "面向呼吸音分类的几何感知优化：基于SAM优化的音频谱图Transformer提升灵敏度",
        "BEDA：信念估计作为执行策略性对话行为的概率约束",
        "面向时序定位视频-语言模型的因子化学习方法",
        "Valori：面向人工智能系统的确定性内存基板",
        "基于超图记忆的长上下文复杂关系建模多步检索增强生成方法改进",
        "动态大概念模型：自适应语义空间中的潜在推理",
        "DiffThinker：基于扩散模型的生成式多模态推理研究",
        "论离散性在扩散大语言模型中的作用",
        "FlowBlending：面向快速高保真视频生成的阶段感知多模型采样方法",
        "Dream2Flow：通过三维物体流连接视频生成与开放世界操作",
        "面向含噪黑箱问题的禁忌增强仿真优化方法",
        "Youtu-Agent：通过自动化生成与混合策略优化提升智能体生产力",
        "NeoVerse：基于真实世界单目视频增强的4D世界模型",
        "Avatar Forcing：面向自然对话的实时交互式头部虚拟形象生成",
        "驯服幻觉：通过反事实视频生成提升多模态大语言模型的视频理解能力",
        "SenseNova-MARS：基于强化学习的多模态智能体推理与搜索框架",
        "AdaGaR：面向动态场景重建的自适应Gabor表示方法",
        "深度增量学习",
        "嵌套学习：深度学习架构的幻觉",
        "推理与创造力的权衡：迈向创造力驱动的问题解决",
        "通过方向解耦对齐在扩散强化学习中抑制偏好模式坍塌",
        "多样性还是精确性？深度解析下一词元预测",
        "快速权重乘积键记忆",
        "InfoSynth：面向大语言模型的信息引导式基准测试合成方法",
        "MorphAny3D：释放结构化隐空间在三维形变中的潜力",
        "我们能否信任AI的解释？思维链推理中系统性隐瞒的证据",
        "大语言模型能否预测自身失误？基于内部回路的自我感知机制",
        "K-EXAONE 技术报告",
        "NextFlow：统一序列建模激活多模态理解与生成能力",
        "DreamID-V：基于扩散Transformer的高保真人脸视频替换——弥合图像到视频的鸿沟",
        "VAR强化学习的正确实现：解决视觉自回归生成中的异步策略冲突",
        "GARDO：无需奖励破解的扩散模型强化方法",
        "VINO：基于交错式全模态上下文的统一视觉生成器",
        "InfiniteVGGT：面向无限流数据的视觉几何基础Transformer",
        "递归语言模型",
        "Falcon-H1R：通过混合模型推动推理前沿，实现高效测试时扩展",
        "SimpleMem：面向大语言模型智能体的高效终身记忆框架",
        "Talk2Move：基于强化学习的场景中文本指令对象级几何变换方法",
        "多轮交互中大语言模型的置信度估计",
        "KV-Embedding：基于仅解码器大语言模型内部KV重路由的无训练文本嵌入方法",
        "CPPO：面向视觉语言策略优化的对比感知方法",
        "DiffProxy：基于扩散生成密集代理的多视角人体网格重建方法",
        "COMPASS：评估大型语言模型中组织特定政策对齐性的框架",
        "SWE-Lego：探索监督微调在软件问题解决中的性能极限",
        "迈向稳定半监督遥感分割：基于协同引导与协同融合的方法",
        "OpenNovelty：一种基于大语言模型的可验证学术新颖性评估智能体系统",
        "选择性不完美：作为分析、创造与发现的生成框架",
        "IMA++：ISIC档案多标注者皮肤镜皮肤病变分割数据集",
        "Prithvi-互补自适应融合编码器（CAFE）：释放洪水淹没制图的全潜力",
        "阿里阿德涅项目：一种用于审计大语言模型智能体忠实度的结构因果框架",
        "M-ErasureBench：扩散模型概念擦除的多模态综合评估基准",
        "InfiniDepth：基于神经隐式场的任意分辨率与细粒度深度估计",
        "LTX-2：一种高效的联合视听基础模型",
        "MOSS Transcribe Diarize：具备说话人日志功能的精准转录系统",
        "SciEvalKit：面向科学通用智能的开源评估工具包",
        "UniCorn：通过自生成监督实现自增强统一多模态模型",
        "NitroGen：面向通用游戏智能体的开放基础模型",
        "SOP：一种可扩展的视觉-语言-动作模型在线后训练系统",
        "DreamStyle：一种统一的视频风格化框架",
        "MiMo-V2-Flash技术报告",
        "CogFlow：通过知识内化连接感知与推理的视觉数学问题求解框架",
        "数字孪生人工智能：从大语言模型到世界模型的机遇与挑战",
        "WebGym：面向真实任务的视觉网络智能体可扩展训练环境",
        "Muses：无需训练即可设计、组合与生成虚构幻想三维生物的方法",
        "基于系统二策略的大语言模型大规模计数机制可解释性研究",
        "OpenRT：面向多模态大语言模型的开源红队测试框架",
        "MindWatcher：迈向更智能的多模态工具集成推理",
        "大型推理模型（尚未）成为多语言潜在推理者",
        "FFP-300K：面向可泛化视频编辑的首帧传播规模化研究",
        "声纳时刻：音频语言模型在音频地理定位中的基准测试",
        "X-MuTeST：一个面向可解释仇恨言论检测的多语言基准与新型大语言模型咨询解释框架",
        "并行潜在推理在序列推荐中的应用",
        "统一思考者：面向图像生成的通用推理模块化核心",
        "ExposeAnyone：个性化音频到表情扩散模型作为鲁棒的零样本人脸伪造检测器",
        "AceFF：面向小分子的前沿机器学习势函数",
        "基于U-Net架构的脉冲神经网络单幅图像去雾方法",
        "Doc-PP：面向大型视觉语言模型的文档策略保持基准",
        "大语言模型中工具性趋同倾向的可操控性研究",
        "熵自适应微调：解决置信冲突以缓解遗忘",
        "演化式程序化技能网络",
        "Atlas：面向多领域复杂推理的异构模型与工具协同编排框架",
        "Benchmark^2：大语言模型基准测试的系统性评估",
        "ROI-推理：基于预计算元认知的推理过程理性优化",
        "Klear：统一多任务音视频联合生成",
        "动态物体世界的编舞",
        "能动式评估量规作为软件工程智能体的情境化验证工具",
        "MDAgent2：面向分子动力学代码生成与知识问答的大语言模型",
        "E-GRPO：高熵步长驱动流模型的有效强化学习",
        "EpiQAL：面向增强对齐与推理的流行病学问答大语言模型基准评测",
        "RedBench：面向大语言模型全面红队测试的通用数据集",
        "为什么大语言模型尚非科学家：从四次自主科研尝试中汲取的教训",
        "ThinkRL-Edit：基于强化学习的推理中心化图像编辑思维框架",
        "通过语言学习任务预训练增强语言模型的语言能力",
        "Pearmut：简化人工翻译评估的轻量级平台",
        "Gen3R：三维场景生成与前馈式重建的融合",
        "ResTok：面向自回归图像生成的一维视觉分词器层次残差学习",
        "MAGMA：面向智能体的多图驱动记忆架构",
        "RGS-SLAM：基于单次密集初始化的鲁棒高斯溅射SLAM系统"
    ]
}