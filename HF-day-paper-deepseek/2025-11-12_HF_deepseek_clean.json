[
  {
    "title": "Grounding Computer Use Agents on Human Demonstrations",
    "summary": "Building reliable computer-use agents requires grounding: accurately\nconnecting natural language instructions to the correct on-screen elements.\nWhile large datasets exist for web and mobile interactions, high-quality\nresources for desktop environments are limited. To address this gap, we\nintroduce GroundCUA, a large-scale desktop grounding dataset built from expert\nhuman demonstrations. It covers 87 applications across 12 categories and\nincludes 56K screenshots, with every on-screen element carefully annotated for\na total of over 3.56M human-verified annotations. From these demonstrations, we\ngenerate diverse instructions that capture a wide range of real-world tasks,\nproviding high-quality data for model training. Using GroundCUA, we develop the\nGroundNext family of models that map instructions to their target UI elements.\nAt both 3B and 7B scales, GroundNext achieves state-of-the-art results across\nfive benchmarks using supervised fine-tuning, while requiring less than\none-tenth the training data of prior work. Reinforcement learning post-training\nfurther improves performance, and when evaluated in an agentic setting on the\nOSWorld benchmark using o3 as planner, GroundNext attains comparable or\nsuperior results to models trained with substantially more data,. These results\ndemonstrate the critical role of high-quality, expert-driven datasets in\nadvancing general-purpose computer-use agents.",
    "translation": "标题：基于人类示范的计算机使用代理系统基础构建\n\n摘要：构建可靠的计算机使用代理系统需要实现精准的基础关联：将自然语言指令与正确的屏幕元素准确对应。尽管网络和移动端交互已存在大规模数据集，但针对桌面环境的高质量资源仍然有限。为填补这一空白，我们推出GroundCUA——一个基于专家人类示范构建的大规模桌面基础关联数据集。该数据集涵盖12个类别下的87种应用程序，包含5.6万张屏幕截图，每个屏幕元素均经过精细标注，累计获得超过356万条人工验证的标注数据。基于这些示范，我们生成涵盖广泛现实任务场景的多样化指令，为模型训练提供高质量数据支撑。利用GroundCUA数据集，我们开发了GroundNext系列模型，可实现从指令到目标UI元素的精准映射。在30亿和70亿参数规模下，通过监督微调，GroundNext在五项基准测试中均达到最先进水平，且所需训练数据量不足先前工作的十分之一。强化学习后训练进一步提升了模型性能，在OSWorld基准测试中配合o3规划器进行智能体评估时，GroundNext取得了与使用更多数据训练的模型相当或更优的结果。这些发现证实了由专家驱动的高质量数据集在推进通用计算机使用代理系统发展中的关键作用。",
    "url": "https://huggingface.co/papers/2511.07332",
    "arxiv_url": "https://arxiv.org/abs/2511.07332"
  },
  {
    "title": "Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model\n  Reasoning Ability in VibeThinker-1.5B",
    "summary": "Challenging the prevailing consensus that small models inherently lack robust\nreasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense\nmodel developed via our Spectrum-to-Signal Principle (SSP). This challenges the\nprevailing approach of scaling model parameters to enhance capabilities, as\nseen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework\nfirst employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a\nbroad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL)\nto amplify the correct signal. With a total training cost of only $7,800,\nVibeThinker-1.5B demonstrates superior reasoning capabilities compared to\nclosed-source models like Magistral Medium and Claude Opus 4, and performs on\npar with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses\nthe 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8),\nAIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial\nimprovement over its base model (6.7, 4.3, and 0.6, respectively). On\nLiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its\nbase model's 0.0. These findings demonstrate that small models can achieve\nreasoning capabilities comparable to large models, drastically reducing\ntraining and inference costs and thereby democratizing advanced AI research.",
    "translation": "标题：小模型，大逻辑：多样性驱动优化激发VibeThinker-1.5B的大模型推理能力\n\n摘要：本文通过提出VibeThinker-1.5B模型，挑战了当前普遍认为小模型天然缺乏强推理能力的共识。这个拥有15亿参数的稠密模型基于我们提出的频谱-信号原则（SSP）开发，该方案突破了当前通过扩大模型参数提升能力的主流范式（如DeepSeek R1的6710亿参数、Kimi k2的万亿级参数）。SSP框架首先采用两阶段多样性探索蒸馏（SFT）生成广谱解决方案，随后通过最大熵引导策略优化（RL）强化正确信号。在总训练成本仅7800美元的情况下，VibeThinker-1.5B展现出优于闭源模型Magistral Medium和Claude Opus 4的推理能力，并与开源模型GPT OSS-20B Medium表现相当。值得注意的是，在三个数学基准测试中，该模型以400倍小于DeepSeek R1的规模实现超越：AIME24（80.3 vs 79.8）、AIME25（74.4 vs 70.0）和HMMT25（50.4 vs 41.7）。相较于其基础模型（原成绩分别为6.7、4.3和0.6），这是质的飞跃。在LiveCodeBench V6测试中取得51.1分，优于Magistral Medium的50.3分及其基础模型的0分。这些发现证明小模型同样能实现媲美大模型的推理能力，大幅降低训练与推理成本，为推进AI研究的普惠化开辟了新路径。",
    "url": "https://huggingface.co/papers/2511.06221",
    "arxiv_url": "https://arxiv.org/abs/2511.06221"
  },
  {
    "title": "Adaptive Multi-Agent Response Refinement in Conversational Systems",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable success in conversational systems by generating human-like responses. However, they can fall short, especially when required to account for personalization or specific knowledge. In real-life settings, it is impractical to rely on users to detect these errors and request a new response. One way to address this problem is to refine the response before returning it to the user. While existing approaches focus on refining responses within a single LLM, this method struggles to consider diverse aspects needed for effective conversations. In this work, we propose refining responses through a multi-agent framework, where each agent is assigned a specific role for each aspect. We focus on three key aspects crucial to conversational quality: factuality, personalization, and coherence. Each agent is responsible for reviewing and refining one of these aspects, and their feedback is then merged to improve the overall response. To enhance collaboration among them, we introduce a dynamic communication strategy. Instead of following a fixed sequence of agents, our approach adaptively selects and coordinates the most relevant agents based on the specific requirements of each query. We validate our framework on challenging conversational datasets, demonstrating that ours significantly outperforms relevant baselines, particularly in tasks involving knowledge or user's persona, or both.",
    "translation": "标题：对话系统中自适应多智能体响应优化机制研究\n\n摘要：大语言模型通过生成类人化响应在对话系统中展现出卓越成效，然而当涉及个性化需求或特定知识领域时，其表现仍存在局限。现实应用场景中依赖用户主动识别错误并请求重新生成响应显然不具可行性。针对此问题，可在返回响应前进行优化修正。现有研究方法主要集中于单一语言模型内部的响应优化，难以兼顾有效对话所需的多元维度。本研究提出基于多智能体框架的响应优化方案，通过为每个智能体分配特定维度的优化任务，重点针对对话质量至关重要的三个核心维度：事实准确性、个性化适配与逻辑连贯性。各智能体分别负责对应维度的审查与优化，并通过反馈融合机制提升整体响应质量。为强化智能体间的协同效能，我们引入动态通信策略——摒弃固定执行序列，根据查询需求自适应选择并协调最相关的智能体组合。在具有挑战性的对话数据集上的实验表明，本框架显著优于现有基线模型，尤其在涉及知识库与用户画像的复合任务中表现突出。",
    "url": "https://huggingface.co/papers/2511.08319",
    "arxiv_url": "https://arxiv.org/abs/2511.08319"
  },
  {
    "title": "Wasm: A Pipeline for Constructing Structured Arabic Interleaved\n  Multimodal Corpora",
    "summary": "The performance of large language models (LLMs) and large multimodal models\n(LMMs) depends heavily on the quality and scale of their pre-training datasets.\nRecent research shows that large multimodal models trained on natural documents\nwhere images and text are interleaved outperform those trained only on\nimage-text pairs across a wide range of benchmarks, leveraging advanced pre-\ntrained models to enforce semantic alignment, image-sequence consistency, and\ntextual coherence. For Arabic, however, the lack of high-quality multimodal\ndatasets that preserve document structure has limited progress. In this paper,\nwe present our pipeline Wasm for processing the Common Crawl dataset to create\na new Arabic multimodal dataset that uniquely provides markdown output. Unlike\nexisting Arabic corpora that focus solely on text extraction, our approach\npreserves the structural integrity of web content while maintaining flexibility\nfor both text-only and multimodal pre-training scenarios. We provide a\ncomprehensive comparative analysis of our data processing pipeline against\nthose used for major existing datasets, highlighting the convergences in\nfiltering strategies and justifying our specific design choices. To support\nfuture research, we publicly release a representative dataset dump along with\nthe multimodal processing pipeline for Arabic.",
    "translation": "标题：Wasm：构建结构化阿拉伯语交错多模态语料库的流程框架\n\n摘要：大型语言模型（LLM）和大型多模态模型（LMM）的性能在很大程度上取决于其预训练数据集的质量与规模。最新研究表明，在图像与文本交错编排的自然文档上训练的大型多模态模型，通过利用先进的预训练模型强化语义对齐、图像序列一致性和文本连贯性，在广泛基准测试中表现优于仅基于图文对训练的模型。然而对于阿拉伯语而言，缺乏保持文档结构的高质量多模态数据集限制了该领域的发展。本文提出名为Wasm的处理流程，通过对Common Crawl数据集进行加工，构建了首个提供Markdown输出的阿拉伯语多模态数据集。与现有仅关注文本提取的阿拉伯语语料库不同，我们的方法在保持网页内容结构完整性的同时，兼顾纯文本与多模态预训练场景的灵活性。我们通过全面的对比分析，将本数据处理流程与现有主流数据集构建方法进行对比，既揭示了过滤策略的共性特征，也论证了特定设计决策的合理性。为促进后续研究，我们公开发布了具有代表性的数据集样本及完整的阿拉伯语多模态处理流程。",
    "url": "https://huggingface.co/papers/2511.07080",
    "arxiv_url": "https://arxiv.org/abs/2511.07080"
  },
  {
    "title": "KLASS: KL-Guided Fast Inference in Masked Diffusion Models",
    "summary": "Masked diffusion models have demonstrated competitive results on various\ntasks including language generation. However, due to its iterative refinement\nprocess, the inference is often bottlenecked by slow and static sampling speed.\nTo overcome this problem, we introduce `KL-Adaptive Stability Sampling'\n(KLASS), a fast yet effective sampling method that exploits token-level KL\ndivergence to identify stable, high-confidence predictions. By unmasking\nmultiple tokens in each iteration without any additional model training, our\napproach speeds up generation significantly while maintaining sample quality.\nOn reasoning benchmarks, KLASS achieves up to 2.78times wall-clock speedups\nwhile improving performance over standard greedy decoding, attaining\nstate-of-the-art results among diffusion-based samplers. We further validate\nKLASS across diverse domains, including text, image, and molecular generation,\nshowing its effectiveness as a broadly applicable sampler across different\nmodels.",
    "translation": "标题：KLASS：基于KL散度的掩码扩散模型快速推理方法\n\n摘要：掩码扩散模型在语言生成等多项任务中展现出卓越性能。然而受迭代优化机制制约，其推理过程常受限于缓慢且固定的采样速度。为解决此问题，我们提出\"KL自适应稳定性采样\"（KLASS），该方法通过利用词元级KL散度识别稳定高置信度预测，在无需额外模型训练的前提下实现高效采样。通过单次迭代中同步解掩多个词元，本方法在保证生成质量的同时显著提升推理速度。在推理基准测试中，KLASS相比标准贪心解码在保持性能优势的同时实现最高2.78倍的实际加速效果，在基于扩散的采样器中达到最优水平。我们进一步在文本、图像及分子生成等多领域验证KLASS的有效性，证明其可作为跨模型通用采样器广泛应用。",
    "url": "https://huggingface.co/papers/2511.05664",
    "arxiv_url": "https://arxiv.org/abs/2511.05664"
  },
  {
    "title": "VideoSSR: Video Self-Supervised Reinforcement Learning",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has substantially\nadvanced the video understanding capabilities of Multimodal Large Language\nModels (MLLMs). However, the rapid progress of MLLMs is outpacing the\ncomplexity of existing video datasets, while the manual annotation of new,\nhigh-quality data remains prohibitively expensive. This work investigates a\npivotal question: Can the rich, intrinsic information within videos be\nharnessed to self-generate high-quality, verifiable training data? To\ninvestigate this, we introduce three self-supervised pretext tasks: Anomaly\nGrounding, Object Counting, and Temporal Jigsaw. We construct the Video\nIntrinsic Understanding Benchmark (VIUBench) to validate their difficulty,\nrevealing that current state-of-the-art MLLMs struggle significantly on these\ntasks. Building upon these pretext tasks, we develop the VideoSSR-30K dataset\nand propose VideoSSR, a novel video self-supervised reinforcement learning\nframework for RLVR. Extensive experiments across 17 benchmarks, spanning four\nmajor video domains (General Video QA, Long Video QA, Temporal Grounding, and\nComplex Reasoning), demonstrate that VideoSSR consistently enhances model\nperformance, yielding an average improvement of over 5\\%. These results\nestablish VideoSSR as a potent foundational framework for developing more\nadvanced video understanding in MLLMs. The code is available at\nhttps://github.com/lcqysl/VideoSSR.",
    "translation": "标题：VideoSSR：视频自监督强化学习框架\n\n摘要：可验证奖励强化学习（RLVR）显著提升了多模态大语言模型（MLLMs）的视频理解能力。然而，现有视频数据集的复杂度已难以匹配MLLMs的快速发展，而人工标注高质量新数据的成本依然居高不下。本研究探讨了一个关键问题：能否利用视频内蕴的丰富信息自生成高质量可验证训练数据？为此，我们提出三种自监督预训练任务：异常定位、目标计数与时序拼图，并构建视频内在理解基准（VIUBench）验证任务难度。实验表明当前最先进的MLLMs在这些任务上表现欠佳。基于这些预训练任务，我们构建了VideoSSR-30K数据集，提出新型视频自监督强化学习框架VideoSSR。在涵盖四大视频领域（通用视频问答、长视频问答、时序定位和复杂推理）的17个基准测试中，广泛实验表明VideoSSR能持续提升模型性能，平均改进幅度超5%。这些成果确立了VideoSSR作为推动MLLMs视频理解能力发展的基础框架。代码已开源：https://github.com/lcqysl/VideoSSR。",
    "url": "https://huggingface.co/papers/2511.06281",
    "arxiv_url": "https://arxiv.org/abs/2511.06281"
  },
  {
    "title": "Beyond English: Toward Inclusive and Scalable Multilingual Machine Translation with LLMs",
    "summary": "Large language models have significantly advanced Multilingual Machine Translation (MMT), yet the broad language coverage, consistent translation quality, and English-centric bias remain open challenges. To address these challenges, we introduce LMT, a suite of Large-scale Multilingual Translation models centered on both Chinese and English, covering 60 languages and 234 translation directions. During development, we identify a previously overlooked phenomenon of directional degeneration, where symmetric multi-way fine-tuning data overemphasize reverse directions (X to En/Zh), leading to excessive many-to-one mappings and degraded translation quality. We propose Strategic Downsampling, a simple yet effective method to mitigate this degeneration. In addition, we design Parallel Multilingual Prompting (PMP), which leverages typologically related auxiliary languages to enhance cross-lingual transfer. Through rigorous data curation and refined adaptation strategies, LMT achieves SOTA performance among models of comparable language coverage, with our 4B model (LMT-60-4B) surpassing the much larger Aya-101-13B and NLLB-54B models by a substantial margin. We release LMT in four sizes (0.6B/1.7B/4B/8B) to catalyze future research and provide strong baselines for inclusive, scalable, and high-quality MMT \\href{https://github.com/NiuTrans/LMT{https://github.com/NiuTrans/LMT}}.",
    "translation": "标题：超越英语：基于大语言模型构建包容可扩展的多语言机器翻译系统\n\n摘要：大语言模型显著推动了多语言机器翻译的发展，但广泛的语言覆盖、稳定的翻译质量以及英语中心化偏差仍是亟待解决的挑战。为解决这些问题，我们推出了LMT系列模型——一套以中英双语为核心的大规模多语言翻译系统，涵盖60种语言及234个翻译方向。在研发过程中，我们发现了一种被忽视的方向性退化现象：对称多语微调数据过度侧重反向翻译（其他语言至英语/中文），导致过多多对一映射并降低翻译质量。为此我们提出策略性降采样方法，通过简单而有效的技术手段缓解此退化现象。同时，我们设计了并行多语言提示机制，利用类型学相关的辅助语言增强跨语言迁移能力。通过严格的数据筛选和优化的适配策略，LMT在同等语言覆盖规模的模型中实现了最先进的性能，其中40亿参数模型（LMT-60-4B）显著超越了参数量更大的Aya-101-13B和NLLB-54B模型。我们发布四个规模版本（6亿/17亿/40亿/80亿）的LMT模型，旨在推动包容可扩展的高质量多语言机器翻译研究，并为该领域提供强有力的基准参考\\href{https://github.com/NiuTrans/LMT{https://github.com/NiuTrans/LMT}}。",
    "url": "https://huggingface.co/papers/2511.07003",
    "arxiv_url": "https://arxiv.org/abs/2511.07003"
  },
  {
    "title": "The Path Not Taken: RLVR Provably Learns Off the Principals",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) reliably improves the reasoning performance of large language models, yet it appears to modify only a small fraction of parameters. We revisit this paradox and show that sparsity is a surface artifact of a model-conditioned optimization bias: for a fixed pretrained model, updates consistently localize to preferred parameter regions, highly consistent across runs and largely invariant to datasets and RL recipes. We mechanistically explain these dynamics with a Three-Gate Theory: Gate I (KL Anchor) imposes a KL-constrained update; Gate II (Model Geometry) steers the step off principal directions into low-curvature, spectrum-preserving subspaces; and Gate III (Precision) hides micro-updates in non-preferred regions, making the off-principal bias appear as sparsity. We then validate this theory and, for the first time, provide a parameter-level characterization of RLVR's learning dynamics: RLVR learns off principal directions in weight space, achieving gains via minimal spectral drift, reduced principal-subspace rotation, and off-principal update alignment. In contrast, SFT targets principal weights, distorts the spectrum, and even lags RLVR.\n  Together, these results provide the first parameter-space account of RLVR's training dynamics, revealing clear regularities in how parameters evolve. Crucially, we show that RL operates in a distinct optimization regime from SFT, so directly adapting SFT-era parameter-efficient fine-tuning (PEFT) methods can be flawed, as evidenced by our case studies on advanced sparse fine-tuning and LoRA variants. We hope this work charts a path toward a white-box understanding of RLVR and the design of geometry-aware, RLVR-native learning algorithms, rather than repurposed SFT-era heuristics.",
    "translation": "标题：未竟之路：RLVR可证明偏离主方向的学习机制  \n\n摘要：可验证奖励强化学习（RLVR）能够可靠地提升大语言模型的推理性能，但其似乎仅修改了极少部分参数。我们重新审视这一悖论，发现稀疏性实为模型条件优化偏差的表象：对于固定预训练模型，参数更新始终集中于偏好参数区域，该现象在不同实验间高度一致，且对数据集和RL配方具有强不变性。我们通过三闸门理论机制性解释该动态：闸门I（KL锚点）施加KL约束的梯度更新；闸门II（模型几何）将更新步长引导至偏离主方向的低曲率、保谱子空间；闸门III（精度掩码）将非偏好区域的微观更新隐藏，使得偏离主方向的偏差呈现为稀疏性。我们随后验证该理论，并首次给出RLVR学习动态的参数级刻画：RLVR在权重空间中沿非主方向学习，通过最小化谱漂移、减少主空间旋转及实现非主方向更新对齐获得增益。相比之下，监督微调以主权重为目标，会扭曲频谱特征，其效果甚至滞后于RLVR。  \n\n这些发现共同构成了首个针对RLVR训练动态的参数空间阐释，揭示了参数演化过程中的清晰规律。关键的是，我们证明RL运行在不同于监督微调的优化区域中，因此直接套用监督微调时代的参数高效微调方法存在缺陷——我们在先进稀疏微调及LoRA变体的案例研究中证实了这一点。本研究旨在为理解RLVR的白箱机制铺路，推动几何感知的RLVR原生算法设计，而非简单沿用监督微调时代的启发式方法。",
    "url": "https://huggingface.co/papers/2511.08567",
    "arxiv_url": "https://arxiv.org/abs/2511.08567"
  },
  {
    "title": "Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces",
    "summary": "Large Language Models (LLMs) face fundamental challenges in long-context reasoning: many documents exceed their finite context windows, while performance on texts that do fit degrades with sequence length, necessitating their augmentation with external memory frameworks. Current solutions, which have evolved from retrieval using semantic embeddings to more sophisticated structured knowledge graphs representations for improved sense-making and associativity, are tailored for fact-based retrieval and fail to build the space-time-anchored narrative representations required for tracking entities through episodic events. To bridge this gap, we propose the Generative Semantic Workspace (GSW), a neuro-inspired generative memory framework that builds structured, interpretable representations of evolving situations, enabling LLMs to reason over evolving roles, actions, and spatiotemporal contexts. Our framework comprises an Operator, which maps incoming observations to intermediate semantic structures, and a Reconciler, which integrates these into a persistent workspace that enforces temporal, spatial, and logical coherence. On the Episodic Memory Benchmark (EpBench) huet_episodic_2025 comprising corpora ranging from 100k to 1M tokens in length, GSW outperforms existing RAG based baselines by up to 20\\%. Furthermore, GSW is highly efficient, reducing query-time context tokens by 51\\% compared to the next most token-efficient baseline, reducing inference time costs considerably. More broadly, GSW offers a concrete blueprint for endowing LLMs with human-like episodic memory, paving the way for more capable agents that can reason over long horizons.",
    "translation": "标题：超越事实检索：基于生成式语义工作区的RAG情景记忆框架\n\n摘要：大语言模型在长上下文推理中面临根本性挑战：许多文档超出其有限上下文窗口，而适配文本的性能随序列长度增加而下降，这需要通过外部记忆框架进行增强。当前解决方案从基于语义嵌入的检索演变为更复杂的结构化知识图谱表示，虽提升了意义构建与关联能力，但仅适用于事实检索，无法构建时空锚定的叙事表征以追踪情景事件中的实体。为弥补这一差距，我们提出生成式语义工作区——一种受神经科学启发的生成式记忆框架，能构建演化情境的结构化可解释表征，使大语言模型能够对动态角色、行为及时空语境进行推理。该框架包含将观测数据映射为中间语义结构的操作器，以及将这些结构整合至保障时序、空间与逻辑一致性的持久工作区的协调器。在包含10万至100万标记语料的情景记忆基准测试中，本框架相较现有基于RAG的基线模型性能提升达20%。此外，该框架具备高效特性，相比次优基线模型在查询时上下文标记数量减少51%，显著降低推理时间成本。更广泛而言，本框架为赋予大语言模型类人情景记忆提供了具体技术路径，为实现长周期推理的智能体奠定基础。",
    "url": "https://huggingface.co/papers/2511.07587",
    "arxiv_url": "https://arxiv.org/abs/2511.07587"
  },
  {
    "title": "DynaAct: Large Language Model Reasoning with Dynamic Action Spaces",
    "summary": "In modern sequential decision-making systems, the construction of an optimal candidate action space is critical to efficient inference. However, existing approaches either rely on manually defined action spaces that lack scalability or utilize unstructured spaces that render exhaustive search computationally prohibitive. In this paper, we propose a novel framework named DynaAct for automatically constructing a compact action space to enhance sequential reasoning in complex problem-solving scenarios. Our method first estimates a proxy for the complete action space by extracting general sketches observed in a corpus covering diverse complex reasoning problems using large language models. We then formulate a submodular function that jointly evaluates candidate actions based on their utility to the current state and their diversity, and employ a greedy algorithm to select an optimal candidate set. Extensive experiments on six diverse standard benchmarks demonstrate that our approach significantly improves overall performance, while maintaining efficient inference without introducing substantial latency. The implementation is available at https://github.com/zhaoxlpku/DynaAct.",
    "translation": "标题：DynaAct：动态动作空间下的大语言模型推理研究\n\n摘要：在现代序列决策系统中，构建最优候选动作空间对提升推理效率至关重要。然而现有方法要么依赖缺乏可扩展性的人工定义动作空间，要么采用非结构化空间导致穷举搜索的计算成本过高。本文提出名为DynaAct的创新框架，通过自动构建紧凑动作空间来增强复杂问题解决场景中的序列推理能力。我们的方法首先通过大语言模型从涵盖多样化复杂推理问题的语料库中提取通用模式框架，以此估算完整动作空间的代理表征。随后构建一个子模函数，综合评估候选动作对当前状态的效用度及其多样性，并采用贪心算法选择最优候选集。在六个多样化标准基准上的大量实验表明，本方法在保持高效推理且未引入显著延迟的同时，显著提升了整体性能。代码实现已发布于https://github.com/zhaoxlpku/DynaAct。",
    "url": "https://huggingface.co/papers/2511.08043",
    "arxiv_url": "https://arxiv.org/abs/2511.08043"
  },
  {
    "title": "Intelligence per Watt: Measuring Intelligence Efficiency of Local AI",
    "summary": "Large language model (LLM) queries are predominantly processed by frontier models in centralized cloud infrastructure. Rapidly growing demand strains this paradigm, and cloud providers struggle to scale infrastructure at pace. Two advances enable us to rethink this paradigm: small LMs (<=20B active parameters) now achieve competitive performance to frontier models on many tasks, and local accelerators (e.g., Apple M4 Max) run these models at interactive latencies. This raises the question: can local inference viably redistribute demand from centralized infrastructure? Answering this requires measuring whether local LMs can accurately answer real-world queries and whether they can do so efficiently enough to be practical on power-constrained devices (i.e., laptops). We propose intelligence per watt (IPW), task accuracy divided by unit of power, as a metric for assessing capability and efficiency of local inference across model-accelerator pairs. We conduct a large-scale empirical study across 20+ state-of-the-art local LMs, 8 accelerators, and a representative subset of LLM traffic: 1M real-world single-turn chat and reasoning queries. For each query, we measure accuracy, energy, latency, and power. Our analysis reveals 3 findings. First, local LMs can accurately answer 88.7% of single-turn chat and reasoning queries with accuracy varying by domain. Second, from 2023-2025, IPW improved 5.3x and local query coverage rose from 23.2% to 71.3%. Third, local accelerators achieve at least 1.4x lower IPW than cloud accelerators running identical models, revealing significant headroom for optimization. These findings demonstrate that local inference can meaningfully redistribute demand from centralized infrastructure, with IPW serving as the critical metric for tracking this transition. We release our IPW profiling harness for systematic intelligence-per-watt benchmarking.",
    "translation": "标题：[每瓦智能：衡量本地人工智能的智能能效]\n\n摘要：当前大型语言模型的查询处理主要依赖集中式云基础设施中的前沿模型。快速增长的算力需求使该模式面临巨大压力，云服务商难以同步扩展基础设施规模。两项技术进展促使我们重新思考这一范式：小型语言模型（≤200亿活跃参数）已在多数任务中达到与前沿模型相媲美的性能，而本地加速器（如苹果M4 Max）能以交互级延迟运行这些模型。这引出一个关键问题：本地推理能否有效分流集中式基础设施的算力需求？解答该问题需从两个维度进行衡量：本地模型能否准确回答现实世界查询，以及能否在功耗受限设备（如笔记本电脑）上实现足够能效以具备实用性。我们提出“每瓦智能”这一指标——即任务准确率与单位功耗的比值，用于评估不同模型-加速器组合的本地推理能力与能效。通过对20余个前沿本地语言模型、8类加速器以及100万条真实世界单轮对话与推理查询（代表主流LLM流量）的大规模实证研究，我们逐条测量了准确率、能耗、延迟与功耗。研究揭示三大发现：首先，本地模型能准确回答88.7%的单轮对话与推理查询，准确率因领域而异；其次，2023至2025年间，每瓦智能指标提升5.3倍，本地查询覆盖率从23.2%升至71.3%；最后，运行相同模型时，本地加速器的每瓦智能指标较云加速器至少低1.4倍，显示巨大优化空间。这些发现证明本地推理能有效分流集中式基础设施需求，而每瓦智能可作为追踪该转型进程的关键指标。我们同步开源每瓦智能评测工具，为系统性能效基准测试提供支持。",
    "url": "https://huggingface.co/papers/2511.07885",
    "arxiv_url": "https://arxiv.org/abs/2511.07885"
  },
  {
    "title": "BiCA: Effective Biomedical Dense Retrieval with Citation-Aware Hard Negatives",
    "summary": "Hard negatives are essential for training effective retrieval models. Hard-negative mining typically relies on ranking documents using cross-encoders or static embedding models based on similarity metrics such as cosine distance. Hard negative mining becomes challenging for biomedical and scientific domains due to the difficulty in distinguishing between source and hard negative documents. However, referenced documents naturally share contextual relevance with the source document but are not duplicates, making them well-suited as hard negatives. In this work, we propose BiCA: Biomedical Dense Retrieval with Citation-Aware Hard Negatives, an approach for hard-negative mining by utilizing citation links in 20,000 PubMed articles for improving a domain-specific small dense retriever. We fine-tune the GTE_small and GTE_Base models using these citation-informed negatives and observe consistent improvements in zero-shot dense retrieval using nDCG@10 for both in-domain and out-of-domain tasks on BEIR and outperform baselines on long-tailed topics in LoTTE using Success@5. Our findings highlight the potential of leveraging document link structure to generate highly informative negatives, enabling state-of-the-art performance with minimal fine-tuning and demonstrating a path towards highly data-efficient domain adaptation.",
    "translation": "标题：BiCA：基于引文感知困难负样本的生物医学稠密检索方法\n\n摘要：困难负样本对训练高效检索模型至关重要。传统困难负样本挖掘通常依赖交叉编码器或基于余弦距离等相似性度量的静态嵌入模型对文档排序。在生物医学和科学领域，由于源文档与困难负样本文档难以区分，使得困难负样本挖掘面临挑战。然而，被引文献天然与源文档具有上下文关联性且非重复文献，这使其成为理想的困难负样本。本研究提出BiCA：基于引文感知困难负样本的生物医学稠密检索方法，通过利用20,000篇PubMed文献中的引文链接进行困难负样本挖掘，以改进特定领域的小型稠密检索器。我们使用这些引文指导的负样本对GTE_small和GTE_Base模型进行微调，在BEIR基准的领域内和领域外任务中采用nDCG@10评估零样本稠密检索性能均取得稳定提升，并在LoTTE数据集的长尾主题任务中使用Success@5指标超越基线模型。研究结果揭示了利用文档链接结构生成高信息量负样本的潜力，仅需少量微调即可实现最优性能，为高数据效率的领域自适应提供了可行路径。",
    "url": "https://huggingface.co/papers/2511.08029",
    "arxiv_url": "https://arxiv.org/abs/2511.08029"
  },
  {
    "title": "Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective",
    "summary": "Background: Large Language Models emerged with the potential of provoking a revolution in software development (e.g., automating processes, workforce transformation). Although studies have started to investigate the perceived impact of LLMs for software development, there is a need for empirical studies to comprehend how to balance forward and backward effects of using LLMs. Objective: We investigated how LLMs impact software development and how to manage the impact from a software developer's perspective. Method: We conducted 22 interviews with software practitioners across 3 rounds of data collection and analysis, between October (2024) and September (2025). We employed socio-technical grounded theory (STGT) for data analysis to rigorously analyse interview participants' responses. Results: We identified the benefits (e.g., maintain software development flow, improve developers' mental model, and foster entrepreneurship) and disadvantages (e.g., negative impact on developers' personality and damage to developers' reputation) of using LLMs at individual, team, organisation, and society levels; as well as best practices on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that software practitioners, teams, and organisations face in working with LLMs. Our findings are particularly useful for software team leaders and IT managers to assess the viability of LLMs within their specific context.",
    "translation": "标题：软件开发中大型语言模型的平衡之道：从业者视角\n\n摘要：背景：大型语言模型的出现可能引发软件开发领域的革命（例如流程自动化、劳动力转型）。尽管已有研究开始探讨LLM对软件开发的感知影响，但仍需通过实证研究来理解如何平衡使用LLM带来的正向与负向影响。目标：从软件开发者的视角，探究LLM如何影响软件开发及如何管理这些影响。方法：在2024年10月至2025年9月期间，我们通过三轮数据收集与分析，对22位软件从业者进行了访谈。采用社会技术扎根理论（STGT）对访谈参与者的反馈进行严谨分析。结果：我们识别出在个体、团队、组织和社会层面使用LLM的益处（如维持开发流程、改善开发者心智模型、促进创业精神）与弊端（如对开发者个性的负面影响、损害开发者声誉），并总结了LLM应用的最佳实践。结论：我们重点揭示了软件从业者、团队及组织在使用LLM时面临的权衡取舍。本研究结果对软件开发团队负责人和IT管理者评估LLM在其特定环境中的适用性具有重要参考价值。",
    "url": "https://huggingface.co/papers/2511.06428",
    "arxiv_url": "https://arxiv.org/abs/2511.06428"
  },
  {
    "title": "Optimizing Diversity and Quality through Base-Aligned Model Collaboration",
    "summary": "Alignment has greatly improved large language models (LLMs)' output quality at the cost of diversity, yielding highly similar outputs across generations. We propose Base-Aligned Model Collaboration (BACo), an inference-time token-level model collaboration framework that dynamically combines a base LLM with its aligned counterpart to optimize diversity and quality. Inspired by prior work (Fei et al., 2025), BACo employs routing strategies that determine, at each token, from which model to decode based on next-token prediction uncertainty and predicted contents' semantic role. Prior diversity-promoting methods, such as retraining, prompt engineering, and multi-sampling methods, improve diversity but often degrade quality or require costly decoding or post-training. In contrast, BACo achieves both high diversity and quality post hoc within a single pass, while offering strong controllability. We explore a family of routing strategies, across three open-ended generation tasks and 13 metrics covering diversity and quality, BACo consistently surpasses state-of-the-art inference-time baselines. With our best router, BACo achieves a 21.3% joint improvement in diversity and quality. Human evaluations also mirror these improvements. The results suggest that collaboration between base and aligned models can optimize and control diversity and quality.",
    "translation": "标题：基于对齐模型协作的多样性-质量协同优化方法\n\n摘要：对齐技术虽然显著提升了大语言模型的输出质量，却以牺牲多样性为代价，导致生成内容高度同质化。本研究提出基于对齐模型协作框架（BACo），该推理阶段令牌级模型协作框架通过动态融合基础大语言模型与其对齐版本，实现多样性-质量的协同优化。受Fei等人（2025）研究启发，BACo采用路由策略，基于下一令牌预测不确定度与预测内容的语义角色，逐令牌确定解码来源模型。现有提升多样性的方法（如重新训练、提示工程、多采样等）虽能增强多样性，但往往导致质量下降或需要高昂的解码/训练后成本。相比之下，BACo在单次推理中即可实现高质量与高多样性的协同提升，并具备强可控性。我们在三类开放生成任务中系统评估了路由策略族，通过13项涵盖多样性与质量的指标验证，BACo持续超越最先进的推理阶段基线方法。采用最优路由策略时，BACo在多样性-质量综合指标上实现21.3%的相对提升，人工评估结果也印证了这一改进。研究表明基础模型与对齐模型间的协作能有效优化并控制生成内容的多样性-质量平衡。",
    "url": "https://huggingface.co/papers/2511.05650",
    "arxiv_url": "https://arxiv.org/abs/2511.05650"
  },
  {
    "title": "TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning",
    "summary": "Temporal search aims to identify a minimal set of relevant frames from tens of thousands based on a given query, serving as a foundation for accurate long-form video understanding. Existing works attempt to progressively narrow the search space. However, these approaches typically rely on a hand-crafted search process, lacking end-to-end optimization for learning optimal search strategies. In this paper, we propose TimeSearch-R, which reformulates temporal search as interleaved text-video thinking, seamlessly integrating searching video clips into the reasoning process through reinforcement learning (RL). However, applying RL training methods, such as Group Relative Policy Optimization (GRPO), to video reasoning can result in unsupervised intermediate search decisions. This leads to insufficient exploration of the video content and inconsistent logical reasoning. To address these issues, we introduce GRPO with Completeness Self-Verification (GRPO-CSV), which gathers searched video frames from the interleaved reasoning process and utilizes the same policy model to verify the adequacy of searched frames, thereby improving the completeness of video reasoning. Additionally, we construct datasets specifically designed for the SFT cold-start and RL training of GRPO-CSV, filtering out samples with weak temporal dependencies to enhance task difficulty and improve temporal search capabilities. Extensive experiments demonstrate that TimeSearch-R achieves significant improvements on temporal search benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as long-form video understanding benchmarks like VideoMME and MLVU. Notably, TimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1% improvement over the base model Qwen2.5-VL and 2.0% over the advanced video reasoning model Video-R1. Our code is available at https://github.com/Time-Search/TimeSearch-R.",
    "translation": "标题：TimeSearch-R：基于自验证强化学习的自适应时序搜索技术实现长视频理解\n\n摘要：时序搜索旨在根据给定查询从数万帧视频中定位最小相关帧集合，为长视频精准理解提供基础支撑。现有研究尝试逐步缩小搜索范围，但这类方法通常依赖人工设计的搜索流程，缺乏对最优搜索策略的端到端优化。本文提出TimeSearch-R框架，将时序搜索重构为文本-视频交错思考过程，通过强化学习将视频片段搜索无缝集成到推理链路中。然而，将群体相对策略优化等强化学习训练方法应用于视频推理会导致无监督的中间搜索决策，进而引发视频内容探索不足与逻辑推理不一致问题。为此，我们提出带完整性自验证的GRPO方法，通过收集交错推理过程中的视频帧，利用同一策略模型验证已搜索帧的充分性，从而提升视频推理的完整性。此外，我们构建了专用于GRPO-CSV的SFT冷启动与强化学习训练数据集，通过筛选时序依赖性弱的样本增强任务难度以提升时序搜索能力。大量实验表明，TimeSearch-R在Haystack-LVBench、Haystack-Ego4D等时序搜索基准，以及VideoMME、MLVU等长视频理解基准上均取得显著提升。特别值得注意的是，TimeSearch-R在LongVideoBench上创造了最新纪录，较基础模型Qwen2.5-VL提升4.1%，较先进视频推理模型Video-R1提升2.0%。代码已开源：https://github.com/Time-Search/TimeSearch-R。",
    "url": "https://huggingface.co/papers/2511.05489",
    "arxiv_url": "https://arxiv.org/abs/2511.05489"
  }
]