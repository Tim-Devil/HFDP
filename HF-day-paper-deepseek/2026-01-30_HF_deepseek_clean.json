[
  {
    "title": "Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives",
    "summary": "Autonomous scientific discovery with large language model (LLM)-based agents has recently made substantial progress, demonstrating the ability to automate end-to-end research workflows. However, existing systems largely rely on runtime-centric execution paradigms, repeatedly reading, summarizing, and reasoning over large volumes of scientific literature online. This on-the-spot computation strategy incurs high computational cost, suffers from context window limitations, and often leads to brittle reasoning and hallucination. We propose Idea2Story, a pre-computation-driven framework for autonomous scientific discovery that shifts literature understanding from online reasoning to offline knowledge construction. Idea2Story continuously collects peer-reviewed papers together with their review feedback, extracts core methodological units, composes reusable research patterns, and organizes them into a structured methodological knowledge graph. At runtime, underspecified user research intents are aligned to established research paradigms, enabling efficient retrieval and reuse of high-quality research patterns instead of open-ended generation and trial-and-error. By grounding research planning and execution in a pre-built knowledge graph, Idea2Story alleviates the context window bottleneck of LLMs and substantially reduces repeated runtime reasoning over literature. We conduct qualitative analyses and preliminary empirical studies demonstrating that Idea2Story can generate coherent, methodologically grounded, and novel research patterns, and can produce several high-quality research demonstrations in an end-to-end setting. These results suggest that offline knowledge construction provides a practical and scalable foundation for reliable autonomous scientific discovery.",
    "translation": "标题：Idea2Story：将研究概念转化为完整科学叙事的自动化流程\n\n摘要：基于大语言模型（LLM）的智能体在自主科学发现领域近期取得显著进展，展现出自动化端到端研究流程的能力。然而，现有系统主要依赖以运行时为中心的执行范式，需反复在线读取、总结并推理大量科学文献。这种即时计算策略计算成本高昂，受限于上下文窗口长度，且常导致推理过程脆弱并产生幻觉。本文提出Idea2Story——一种以预计算驱动的自主科学发现框架，将文献理解从在线推理转向离线知识构建。Idea2Story持续收集经同行评审的论文及其审稿反馈，提取核心方法单元，组合可复用的研究模式，并将其组织为结构化的方法知识图谱。在运行时，未充分明确的用户研究意图可与既定的研究范式对齐，从而实现高质量研究模式的高效检索与复用，而非依赖开放式生成与试错。通过将研究规划与执行建立在预构建的知识图谱基础上，Idea2Story缓解了LLM的上下文窗口瓶颈，并大幅减少了对文献的重复运行时推理。我们通过定性分析与初步实证研究表明，Idea2Story能够生成连贯、方法可靠且新颖的研究模式，并可在端到端场景中产出多项高质量研究范例。这些结果表明，离线知识构建为可靠的自主科学发现提供了实用且可扩展的基础。",
    "url": "https://huggingface.co/papers/2601.20833",
    "arxiv_url": "https://arxiv.org/abs/2601.20833"
  },
  {
    "title": "Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models",
    "summary": "Text-to-image (T2I) models have achieved remarkable success in generating high-fidelity images, but they often fail in handling complex spatial relationships, e.g., spatial perception, reasoning, or interaction. These critical aspects are largely overlooked by current benchmarks due to their short or information-sparse prompt design. In this paper, we introduce SpatialGenEval, a new benchmark designed to systematically evaluate the spatial intelligence of T2I models, covering two key aspects: (1) SpatialGenEval involves 1,230 long, information-dense prompts across 25 real-world scenes. Each prompt integrates 10 spatial sub-domains and corresponding 10 multi-choice question-answer pairs, ranging from object position and layout to occlusion and causality. Our extensive evaluation of 21 state-of-the-art models reveals that higher-order spatial reasoning remains a primary bottleneck. (2) To demonstrate that the utility of our information-dense design goes beyond simple evaluation, we also construct the SpatialT2I dataset. It contains 15,400 text-image pairs with rewritten prompts to ensure image consistency while preserving information density. Fine-tuned results on current foundation models (i.e., Stable Diffusion-XL, Uniworld-V1, OmniGen2) yield consistent performance gains (+4.2%, +5.7%, +4.4%) and more realistic effects in spatial relations, highlighting a data-centric paradigm to achieve spatial intelligence in T2I models.",
    "translation": "标题：各得其所：文本到图像模型空间智能基准测试\n\n摘要：文本到图像（T2I）模型在生成高保真图像方面取得了显著成功，但在处理复杂空间关系（如空间感知、推理或交互）时仍存在明显不足。由于现有基准测试普遍采用简短或信息稀疏的提示设计，这些关键维度长期被忽视。本文提出SpatialGenEval基准测试，旨在系统评估T2I模型的空间智能，涵盖两大核心维度：（1）该基准包含25个真实场景下的1,230条长文本密集提示，每条提示整合10个空间子领域及对应的10组多选题对，涵盖物体位置、布局、遮挡关系与因果推理等维度。通过对21个前沿模型的广泛测试，我们发现高阶空间推理仍是当前模型的主要瓶颈。（2）为证明信息密集设计的价值超越单纯评估，我们同步构建了SpatialT2I数据集。该数据集包含15,400个文本-图像对，通过提示词重写在保持信息密度的同时确保图像一致性。基于当前基础模型（包括Stable Diffusion-XL、Uniworld-V1、OmniGen2）的微调实验显示，模型在空间关系表现上获得稳定性能提升（+4.2%、+5.7%、+4.4%）并生成更符合真实空间逻辑的图像，这为通过数据中心化范式实现T2I模型空间智能提供了新路径。",
    "url": "https://huggingface.co/papers/2601.20354",
    "arxiv_url": "https://arxiv.org/abs/2601.20354"
  },
  {
    "title": "Scaling Embeddings Outperforms Scaling Experts in Language Models",
    "summary": "While Mixture-of-Experts (MoE) architectures have become the standard for sparsity scaling in large language models, they increasingly face diminishing returns and system-level bottlenecks. In this work, we explore embedding scaling as a potent, orthogonal dimension for scaling sparsity. Through a comprehensive analysis and experiments, we identify specific regimes where embedding scaling achieves a superior Pareto frontier compared to expert scaling. We systematically characterize the critical architectural factors governing this efficacy -- ranging from parameter budgeting to the interplay with model width and depth. Moreover, by integrating tailored system optimizations and speculative decoding, we effectively convert this sparsity into tangible inference speedups. Guided by these insights, we introduce LongCat-Flash-Lite, a 68.5B parameter model with ~3B activated trained from scratch. Despite allocating over 30B parameters to embeddings, LongCat-Flash-Lite not only surpasses parameter-equivalent MoE baselines but also exhibits exceptional competitiveness against existing models of comparable scale, particularly in agentic and coding domains.",
    "translation": "标题：语言模型中扩展嵌入优于扩展专家模型\n\n摘要：尽管专家混合架构已成为大型语言模型稀疏扩展的标准方案，但其边际效益递减与系统级瓶颈问题日益凸显。本研究探索了嵌入扩展作为稀疏化扩展中一个高效且正交的维度。通过系统分析与实验验证，我们发现了嵌入扩展在特定条件下能获得优于专家扩展的帕累托前沿。我们系统性地揭示了影响该方案效能的关键架构因素——涵盖参数分配策略、模型宽度与深度的协同机制等维度。通过整合定制化系统优化与推测解码技术，我们成功将这种稀疏性转化为可观的推理加速。基于这些发现，我们提出了LongCat-Flash-Lite模型：该68.5B参数模型在训练中激活约3B参数，虽分配超过300亿参数至嵌入层，但其性能不仅超越参数规模相当的专家混合基线模型，更在智能体与代码生成领域展现出与同规模现有模型相匹敌的卓越竞争力。\n\n摘要：[中文摘要]",
    "url": "https://huggingface.co/papers/2601.21204",
    "arxiv_url": "https://arxiv.org/abs/2601.21204"
  },
  {
    "title": "DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation",
    "summary": "Manipulating dynamic objects remains an open challenge for Vision-Language-Action (VLA) models, which, despite strong generalization in static manipulation, struggle in dynamic scenarios requiring rapid perception, temporal anticipation, and continuous control. We present DynamicVLA, a framework for dynamic object manipulation that integrates temporal reasoning and closed-loop adaptation through three key designs: 1) a compact 0.4B VLA using a convolutional vision encoder for spatially efficient, structurally faithful encoding, enabling fast multimodal inference; 2) Continuous Inference, enabling overlapping reasoning and execution for lower latency and timely adaptation to object motion; and 3) Latent-aware Action Streaming, which bridges the perception-execution gap by enforcing temporally aligned action execution. To fill the missing foundation of dynamic manipulation data, we introduce the Dynamic Object Manipulation (DOM) benchmark, built from scratch with an auto data collection pipeline that efficiently gathers 200K synthetic episodes across 2.8K scenes and 206 objects, and enables fast collection of 2K real-world episodes without teleoperation. Extensive evaluations demonstrate remarkable improvements in response speed, perception, and generalization, positioning DynamicVLA as a unified framework for general dynamic object manipulation across embodiments.",
    "translation": "标题：DynamicVLA：一种用于动态物体操作的视觉-语言-动作模型\n\n摘要：对于视觉-语言-动作模型而言，操作动态物体仍是一个开放性的挑战。尽管此类模型在静态操作任务中展现出强大的泛化能力，但在需要快速感知、时序预测与持续控制的动态场景中却表现不佳。本文提出DynamicVLA，一个用于动态物体操作的框架，通过三项关键设计整合了时序推理与闭环适应能力：1）采用卷积视觉编码器构建了一个紧凑的0.4B参数VLA模型，实现了空间高效且结构保真的编码，支持快速多模态推理；2）连续推理机制，允许推理与执行过程重叠，以降低延迟并及时适应物体运动；3）潜在感知的动作流式执行，通过强制时序对齐的动作执行来弥合感知与执行之间的间隙。为填补动态操作数据基础的缺失，我们构建了动态物体操作基准数据集，该数据集通过自动数据采集流程从零创建，高效收集了涵盖2.8K个场景、206个物体的20万条合成交互轨迹，并无需遥操作即可快速采集2K条真实世界交互轨迹。大量实验评估表明，该框架在响应速度、感知能力与泛化性能上均取得显著提升，使DynamicVLA成为一个可跨越不同实体形态的通用动态物体操作统一框架。",
    "url": "https://huggingface.co/papers/2601.22153",
    "arxiv_url": "https://arxiv.org/abs/2601.22153"
  },
  {
    "title": "OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models",
    "summary": "The development of large vision language models drives the demand for managing, and applying massive amounts of multimodal data, making OCR technology, which extracts information from visual images, increasingly popular. However, existing OCR methods primarily focus on recognizing text elements from images or scanned documents (Text-centric OCR), neglecting the identification of visual elements from visually information-dense image sources (Vision-centric OCR), such as charts, web pages and science plots. In reality, these visually information-dense images are widespread on the internet and have significant real-world application value, such as data visualization and web page analysis. In this technical report, we propose OCRVerse, the first holistic OCR method in end-to-end manner that enables unified text-centric OCR and vision-centric OCR. To this end, we constructe comprehensive data engineering to cover a wide range of text-centric documents, such as newspapers, magazines and books, as well as vision-centric rendered composites, including charts, web pages and scientific plots. Moreover, we propose a two-stage SFT-RL multi-domain training method for OCRVerse. SFT directly mixes cross-domain data to train and establish initial domain knowledge, while RL focuses on designing personalized reward strategies for the characteristics of each domain. Specifically, since different domains require various output formats and expected outputs, we provide sufficient flexibility in the RL stage to customize flexible reward signals for each domain, thereby improving cross-domain fusion and avoiding data conflicts. Experimental results demonstrate the effectiveness of OCRVerse, achieving competitive results across text-centric and vision-centric data types, even comparable to large-scale open-source and closed-source models.",
    "translation": "标题：OCRVerse：面向端到端视觉语言模型的全方位OCR技术\n\n摘要：大规模视觉语言模型的发展推动了对海量多模态数据管理及应用的需求，使得从视觉图像中提取信息的OCR技术日益受到关注。然而，现有OCR方法主要集中于从图像或扫描文档中识别文本元素（以文本为中心的OCR），而忽视了从视觉信息密集的图像源（如图表、网页和科学图表）中识别视觉元素（以视觉为中心的OCR）。实际上，这类视觉信息密集的图像在互联网中广泛存在，并具有重要的实际应用价值，例如数据可视化和网页分析。本技术报告提出了OCRVerse，这是首个以端到端方式实现统一文本中心OCR与视觉中心OCR的全方位OCR方法。为此，我们构建了全面的数据工程，涵盖广泛的文本中心文档（如报纸、杂志和书籍）以及视觉中心渲染复合图像（包括图表、网页和科学图表）。此外，我们为OCRVerse提出了一种两阶段的SFT-RL多领域训练方法。SFT直接混合跨领域数据进行训练以建立初始领域知识，而RL则侧重于针对各领域特点设计个性化奖励策略。具体而言，由于不同领域需要多样化的输出格式和预期结果，我们在RL阶段提供了充分的灵活性，为每个领域定制灵活的奖励信号，从而提升跨领域融合能力并避免数据冲突。实验结果表明，OCRVerse在文本中心与视觉中心数据类型上均取得了具有竞争力的效果，甚至可与大规模开源及闭源模型相媲美。",
    "url": "https://huggingface.co/papers/2601.21639",
    "arxiv_url": "https://arxiv.org/abs/2601.21639"
  },
  {
    "title": "MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods",
    "summary": "Recent advances in Vision Language Models (VLMs) have driven significant progress in visual reasoning. However, open-source VLMs still lag behind proprietary systems, largely due to the lack of high-quality reasoning data. Existing datasets offer limited coverage of challenging domains such as STEM diagrams and visual puzzles, and lack consistent, long-form Chain-of-Thought (CoT) annotations essential for eliciting strong reasoning capabilities. To bridge this gap, we introduce MMFineReason, a large-scale multimodal reasoning dataset comprising 1.8M samples and 5.1B solution tokens, featuring high-quality reasoning annotations distilled from Qwen3-VL-235B-A22B-Thinking. The dataset is established via a systematic three-stage pipeline: (1) large-scale data collection and standardization, (2) CoT rationale generation, and (3) comprehensive selection based on reasoning quality and difficulty awareness. The resulting dataset spans STEM problems, visual puzzles, games, and complex diagrams, with each sample annotated with visually grounded reasoning traces. We fine-tune Qwen3-VL-Instruct on MMFineReason to develop MMFineReason-2B/4B/8B versions. Our models establish new state-of-the-art results for their size class. Notably, MMFineReason-4B succesfully surpasses Qwen3-VL-8B-Thinking, and MMFineReason-8B even outperforms Qwen3-VL-30B-A3B-Thinking while approaching Qwen3-VL-32B-Thinking, demonstrating remarkable parameter efficiency. Crucially, we uncover a \"less is more\" phenomenon via our difficulty-aware filtering strategy: a subset of just 7\\% (123K samples) achieves performance comparable to the full dataset. Notably, we reveal a synergistic effect where reasoning-oriented data composition simultaneously boosts general capabilities.",
    "translation": "标题：MMFineReason：通过开放式数据驱动方法弥合多模态推理鸿沟\n\n摘要：视觉语言模型（VLMs）的最新进展显著推动了视觉推理领域的发展。然而，开源视觉语言模型仍落后于专有系统，这主要归因于高质量推理数据的缺乏。现有数据集在STEM图表、视觉谜题等复杂领域的覆盖范围有限，且缺乏能够激发强大推理能力所必需的一致、长形式的思维链标注。为弥合这一鸿沟，我们提出了MMFineReason——一个包含180万样本和51亿解答标记的大规模多模态推理数据集，其高质量推理标注提炼自Qwen3-VL-235B-A22B-Thinking模型。该数据集通过系统化的三阶段流程构建：（1）大规模数据收集与标准化，（2）思维链原理生成，（3）基于推理质量与难度感知的综合筛选。最终数据集涵盖STEM问题、视觉谜题、游戏及复杂图表，每个样本均配有基于视觉的推理轨迹标注。我们在MMFineReason上对Qwen3-VL-Instruct进行微调，开发出MMFineReason-2B/4B/8B系列模型。这些模型在其规模类别中取得了最新的最优性能。值得注意的是，MMFineReason-4B成功超越了Qwen3-VL-8B-Thinking，而MMFineReason-8B甚至优于Qwen3-VL-30B-A3B-Thinking，并接近Qwen3-VL-32B-Thinking的性能，展现出卓越的参数效率。关键的是，我们通过难度感知筛选策略发现了“少即是多”的现象：仅使用7%（12.3万样本）的数据子集即可达到与完整数据集相当的性能。尤为重要的是，我们揭示了以推理为导向的数据组合能同步提升模型通用能力的协同效应。",
    "url": "https://huggingface.co/papers/2601.21821",
    "arxiv_url": "https://arxiv.org/abs/2601.21821"
  },
  {
    "title": "ConceptMoE: Adaptive Token-to-Concept Compression for Implicit Compute Allocation",
    "summary": "Large language models allocate uniform computation across all tokens, ignoring that some sequences are trivially predictable while others require deep reasoning. We introduce ConceptMoE, which dynamically merges semantically similar tokens into concept representations, performing implicit token-level compute allocation. A learnable chunk module identifies optimal boundaries by measuring inter-token similarity, compressing sequences by a target ratio R before they enter the compute-intensive concept model. Crucially, the MoE architecture enables controlled evaluation: we reallocate saved computation to match baseline activated FLOPs (excluding attention map computation) and total parameters, isolating genuine architectural benefits. Under these conditions, ConceptMoE consistently outperforms standard MoE across language and vision-language tasks, achieving +0.9 points on language pretraining, +2.3 points on long context understanding, and +0.6 points on multimodal benchmarks. When converting pretrained MoE during continual training with layer looping, gains reach +5.5 points, demonstrating practical applicability. Beyond performance, ConceptMoE reduces attention computation by up to R^2times and KV cache by Rtimes. At R=2, empirical measurements show prefill speedups reaching 175\\% and decoding speedups up to 117\\% on long sequences. The minimal architectural modifications enable straightforward integration into existing MoE, demonstrating that adaptive concept-level processing fundamentally improves both effectiveness and efficiency of large language models.",
    "translation": "标题：ConceptMoE：面向隐式计算分配的自适应令牌到概念压缩方法\n\n摘要：大型语言模型通常对所有令牌分配均匀的计算量，忽略了某些序列易于预测而另一些则需要深度推理的事实。本文提出ConceptMoE模型，该模型能够动态地将语义相似的令牌合并为概念表示，从而实现隐式的令牌级计算分配。通过可学习的分块模块测量令牌间相似度以确定最优边界，在序列进入计算密集型概念模型前按目标压缩比R进行压缩。关键的是，混合专家（MoE）架构支持受控评估：我们将节省的计算量重新分配，以匹配基线激活的浮点运算量（不含注意力图计算）和总参数量，从而分离出纯架构优势。在此条件下，ConceptMoE在语言和视觉-语言任务中持续超越标准MoE模型，在语言预训练中提升0.9个点，在长上下文理解中提升2.3个点，在多模态基准测试中提升0.6个点。当在持续训练中通过层循环转换预训练的MoE模型时，性能增益可达5.5个点，证明了其实用价值。除性能提升外，ConceptMoE可将注意力计算量降低至R^2倍，KV缓存降低至R倍。在R=2时，实际测量显示长序列的预填充速度最高提升175%，解码速度最高提升117%。该架构仅需最小改动即可直接集成到现有MoE模型中，表明自适应概念级处理能够从根本上提升大型语言模型的效能与效率。",
    "url": "https://huggingface.co/papers/2601.21420",
    "arxiv_url": "https://arxiv.org/abs/2601.21420"
  },
  {
    "title": "PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction",
    "summary": "Streaming reconstruction from monocular image sequences remains challenging, as existing methods typically favor either high-quality rendering or accurate geometry, but rarely both. We present PLANING, an efficient on-the-fly reconstruction framework built on a hybrid representation that loosely couples explicit geometric primitives with neural Gaussians, enabling geometry and appearance to be modeled in a decoupled manner. This decoupling supports an online initialization and optimization strategy that separates geometry and appearance updates, yielding stable streaming reconstruction with substantially reduced structural redundancy. PLANING improves dense mesh Chamfer-L2 by 18.52% over PGSR, surpasses ARTDECO by 1.31 dB PSNR, and reconstructs ScanNetV2 scenes in under 100 seconds, over 5x faster than 2D Gaussian Splatting, while matching the quality of offline per-scene optimization. Beyond reconstruction quality, the structural clarity and computational efficiency of \\modelname~make it well suited for a broad range of downstream applications, such as enabling large-scale scene modeling and simulation-ready environments for embodied AI. Project page: https://city-super.github.io/PLANING/ .",
    "translation": "标题：PLANING：一种面向流式三维重建的松耦合三角-高斯框架\n\n摘要：基于单目图像序列的流式三维重建仍面临挑战，现有方法通常难以兼顾高质量渲染与精确几何重建。本文提出PLANING，一种基于混合表征的高效实时重建框架，通过将显式几何基元与神经高斯场进行松耦合，实现了几何与外观建模的解耦。这种解耦机制支持分离几何更新与外观优化的在线初始化与优化策略，能够在显著降低结构冗余度的同时实现稳定的流式重建。实验表明，PLANING在稠密网格Chamfer-L2指标上较PGSR提升18.52%，PSNR指标超越ARTDECO达1.31 dB，重建ScanNetV2场景耗时低于100秒（比二维高斯泼溅提速5倍以上），且重建质量达到离线逐场景优化的水准。除重建质量外，该框架具备清晰的结构层次与高效的计算性能，可广泛适用于大规模场景建模、具身智能仿真环境构建等下游任务。项目页面：https://city-super.github.io/PLANING/。",
    "url": "https://huggingface.co/papers/2601.22046",
    "arxiv_url": "https://arxiv.org/abs/2601.22046"
  },
  {
    "title": "Qwen3-ASR Technical Report",
    "summary": "In this report, we introduce Qwen3-ASR family, which includes two powerful all-in-one speech recognition models and a novel non-autoregressive speech forced alignment model. Qwen3-ASR-1.7B and Qwen3-ASR-0.6B are ASR models that support language identification and ASR for 52 languages and dialects. Both of them leverage large-scale speech training data and the strong audio understanding ability of their foundation model Qwen3-Omni. We conduct comprehensive internal evaluation besides the open-sourced benchmarks as ASR models might differ little on open-sourced benchmark scores but exhibit significant quality differences in real-world scenarios. The experiments reveal that the 1.7B version achieves SOTA performance among open-sourced ASR models and is competitive with the strongest proprietary APIs while the 0.6B version offers the best accuracy-efficiency trade-off. Qwen3-ASR-0.6B can achieve an average TTFT as low as 92ms and transcribe 2000 seconds speech in 1 second at a concurrency of 128. Qwen3-ForcedAligner-0.6B is an LLM based NAR timestamp predictor that is able to align text-speech pairs in 11 languages. Timestamp accuracy experiments show that the proposed model outperforms the three strongest force alignment models and takes more advantages in efficiency and versatility. To further accelerate the community research of ASR and audio understanding, we release these models under the Apache 2.0 license.",
    "translation": "标题：Qwen3-ASR技术报告\n\n摘要：本报告介绍了Qwen3-ASR系列模型，包括两款强大的一体化语音识别模型和一种新颖的非自回归语音强制对齐模型。Qwen3-ASR-1.7B与Qwen3-ASR-0.6B是支持52种语言与方言的语音识别模型，兼具语言识别功能。两款模型均利用大规模语音训练数据及其基础模型Qwen3-Omni强大的音频理解能力。由于语音识别模型在开源基准测试中可能表现相近，但在实际场景中却存在显著质量差异，我们在开源基准之外进行了全面的内部评估。实验表明，1.7B版本在开源语音识别模型中达到最先进性能，并与最强的商业API模型具有竞争力；而0.6B版本在准确性与效率之间实现了最佳平衡。Qwen3-ASR-0.6B的平均首次响应时间可低至92毫秒，在128并发条件下能以1秒完成2000秒语音的转写。Qwen3-ForcedAligner-0.6B是基于大语言模型的非自回归时间戳预测器，可对11种语言的文本-语音对进行对齐。时间戳准确性实验显示，该模型性能超越当前三种最强的强制对齐模型，并在效率与泛用性方面更具优势。为加速语音识别与音频理解领域的社区研究，我们已将上述模型基于Apache 2.0许可证开源发布。",
    "url": "https://huggingface.co/papers/2601.21337",
    "arxiv_url": "https://arxiv.org/abs/2601.21337"
  },
  {
    "title": "AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts",
    "summary": "The evolution of Large Language Models (LLMs) into autonomous agents necessitates the management of extensive, dynamic contexts. Current benchmarks, however, remain largely static, relying on passive retrieval tasks that fail to simulate the complexities of agent-environment interaction, such as non-linear reasoning and iterative feedback. To address this, we introduce AgentLongBench, which evaluates agents through simulated environment rollouts based on Lateral Thinking Puzzles. This framework generates rigorous interaction trajectories across knowledge-intensive and knowledge-free scenarios. Experiments with state-of-the-art models and memory systems (32K to 4M tokens) expose a critical weakness: while adept at static retrieval, agents struggle with the dynamic information synthesis essential for workflows. Our analysis indicates that this degradation is driven by the minimum number of tokens required to resolve a query. This factor explains why the high information density inherent in massive tool responses poses a significantly greater challenge than the memory fragmentation typical of long-turn dialogues.",
    "translation": "标题：AgentLongBench：一种通过环境推演实现长上下文智能体可控评估的长基准框架\n\n摘要：大型语言模型向自主智能体的演进要求其能够处理广泛且动态变化的上下文信息。然而，现有基准测试大多保持静态，依赖于被动检索任务，无法模拟智能体与环境交互中的复杂特性，如非线性推理与迭代反馈。为此，我们提出了AgentLongBench，该框架基于横向思维谜题，通过模拟环境推演来评估智能体性能。该框架能够在知识密集与知识无关的场景中生成严格的交互轨迹。通过对先进模型与记忆系统（32K至4M词元）的实验，我们揭示了一个关键缺陷：尽管智能体擅长静态检索，但在工作流所必需的动态信息整合方面表现欠佳。分析表明，性能下降主要受解决查询所需的最小词元数量驱动。这一因素解释了为何海量工具响应中固有的高信息密度，比长轮对话中典型的内存碎片化问题，构成了更为严峻的挑战。",
    "url": "https://huggingface.co/papers/2601.20730",
    "arxiv_url": "https://arxiv.org/abs/2601.20730"
  },
  {
    "title": "Exploring Reasoning Reward Model for Agents",
    "summary": "Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a multi-faceted reward model that produces structured feedback for agentic trajectories, including (1) an explicit reasoning trace , (2) a focused critique that provides refinement guidance by highlighting reasoning flaws, and (3) an overall score that evaluates process performance. Leveraging these signals, we systematically investigate three integration strategies: Reagent-C (text-augmented refinement), Reagent-R (reward-augmented guidance), and Reagent-U (unified feedback integration). Extensive evaluations across 12 diverse benchmarks demonstrate that Reagent-U yields substantial performance leaps, achieving 43.7% on GAIA and 46.2% on WebWalkerQA, validating the effectiveness of our reasoning reward model and training schemes. Code, models, and datasets are all released to facilitate future research.",
    "translation": "标题：探索智能体推理奖励模型\n\n摘要：智能体强化学习在实现复杂推理与工具使用方面已取得显著成功。然而，现有方法仍主要依赖基于结果的稀疏奖励进行训练。此类反馈无法区分中间推理过程的质量，导致训练效果欠佳。本文提出智能体推理奖励模型，该多维度奖励模型可为智能体行为轨迹提供结构化反馈，包括：（1）显式推理轨迹；（2）聚焦式评析，通过指出推理缺陷提供改进指导；（3）评估过程表现的综合评分。基于这些反馈信号，我们系统研究了三种集成策略：文本增强改进型、奖励增强指导型与统一反馈集成型。在12个多样化基准测试中的广泛评估表明，统一反馈集成型方案实现了性能飞跃，在GAIA和WebWalkerQA基准上分别达到43.7%和46.2%的得分，验证了所提推理奖励模型与训练方案的有效性。代码、模型与数据集均已开源以促进后续研究。",
    "url": "https://huggingface.co/papers/2601.22154",
    "arxiv_url": "https://arxiv.org/abs/2601.22154"
  },
  {
    "title": "LoL: Longer than Longer, Scaling Video Generation to Hour",
    "summary": "Recent research in long-form video generation has shifted from bidirectional to autoregressive models, yet these methods commonly suffer from error accumulation and a loss of long-term coherence. While attention sink frames have been introduced to mitigate this performance decay, they often induce a critical failure mode we term sink-collapse: the generated content repeatedly reverts to the sink frame, resulting in abrupt scene resets and cyclic motion patterns. Our analysis reveals that sink-collapse originates from an inherent conflict between the periodic structure of Rotary Position Embedding (RoPE) and the multi-head attention mechanisms prevalent in current generative models. To address it, we propose a lightweight, training-free approach that effectively suppresses this behavior by introducing multi-head RoPE jitter that breaks inter-head attention homogenization and mitigates long-horizon collapse. Extensive experiments show that our method successfully alleviates sink-collapse while preserving generation quality. To the best of our knowledge, this work achieves the first demonstration of real-time, streaming, and infinite-length video generation with little quality decay. As an illustration of this robustness, we generate continuous videos up to 12 hours in length, which, to our knowledge, is among the longest publicly demonstrated results in streaming video generation.",
    "translation": "标题：LoL：更长再长，将视频生成扩展至小时级\n\n摘要：近期长视频生成研究已从双向模型转向自回归模型，但这些方法普遍存在误差累积与长期连贯性丧失的问题。尽管注意力汇聚帧被引入以缓解性能衰减，但其常引发我们称为“汇聚塌缩”的关键失效模式：生成内容反复回归至汇聚帧，导致场景突变重置与循环运动模式。我们的分析表明，汇聚塌缩源于旋转位置编码的周期结构与当前生成模型中普遍采用的多头注意力机制之间的内在冲突。为解决该问题，我们提出一种轻量级、无需训练的方法，通过引入打破头间注意力同质化的多头旋转位置编码扰动，有效抑制该行为并缓解长时程塌缩。大量实验表明，我们的方法在保持生成质量的同时成功缓解了汇聚塌缩。据我们所知，本研究首次实现了质量衰减极低的实时、流式、无限长度视频生成。为证明其鲁棒性，我们生成了长达12小时的连续视频，这据我们所知是当前流式视频生成领域公开演示的最长结果之一。",
    "url": "https://huggingface.co/papers/2601.16914",
    "arxiv_url": "https://arxiv.org/abs/2601.16914"
  },
  {
    "title": "Language-based Trial and Error Falls Behind in the Era of Experience",
    "summary": "While Large Language Models (LLMs) excel in language-based agentic tasks, their applicability to unseen, nonlinguistic environments (e.g., symbolic or spatial tasks) remains limited. Previous work attributes this performance gap to the mismatch between the pretraining distribution and the testing distribution. In this work, we demonstrate the primary bottleneck is the prohibitive cost of exploration: mastering these tasks requires extensive trial-and-error, which is computationally unsustainable for parameter-heavy LLMs operating in a high dimensional semantic space. To address this, we propose SCOUT (Sub-Scale Collaboration On Unseen Tasks), a novel framework that decouples exploration from exploitation. We employ lightweight \"scouts\" (e.g., small MLPs) to probe environmental dynamics at a speed and scale far exceeding LLMs. The collected trajectories are utilized to bootstrap the LLM via Supervised Fine-Tuning (SFT), followed by multi-turn Reinforcement Learning (RL) to activate its latent world knowledge. Empirically, SCOUT enables a Qwen2.5-3B-Instruct model to achieve an average score of 0.86, significantly outperforming proprietary models, including Gemini-2.5-Pro (0.60), while saving about 60% GPU hours consumption.",
    "translation": "标题：基于语言的试错法在经验时代已显滞后\n\n摘要：尽管大语言模型在基于语言的代理任务中表现出色，但其在未见过的非语言环境（如符号或空间任务）中的适用性仍然有限。先前研究将这种性能差距归因于预训练分布与测试分布之间的不匹配。本文论证其主要瓶颈在于探索成本过高：掌握这些任务需要大量试错，这对于在高维语义空间中运行的重参数大语言模型而言，在计算上是不可持续的。为解决这一问题，我们提出SCOUT（未见任务下的子尺度协作）这一创新框架，将探索与利用过程解耦。我们采用轻量级“侦察器”（如小型多层感知机）以远超大语言模型的速度和规模探测环境动态，收集的轨迹通过监督微调用于引导大语言模型，再经过多轮强化学习激活其潜在的世界知识。实验表明，SCOUT使Qwen2.5-3B-Instruct模型平均得分达到0.86，显著优于包括Gemini-2.5-Pro（0.60）在内的专有模型，同时节省约60%的GPU时耗。",
    "url": "https://huggingface.co/papers/2601.21754",
    "arxiv_url": "https://arxiv.org/abs/2601.21754"
  },
  {
    "title": "Discovering Hidden Gems in Model Repositories",
    "summary": "Public repositories host millions of fine-tuned models, yet community usage remains disproportionately concentrated on a small number of foundation checkpoints. We investigate whether this concentration reflects efficient market selection or if superior models are systematically overlooked. Through an extensive evaluation of over 2,000 models, we show the prevalence of \"hidden gems\", unpopular fine-tunes that significantly outperform their popular counterparts. Notably, within the Llama-3.1-8B family, we find rarely downloaded checkpoints that improve math performance from 83.2% to 96.0% without increasing inference costs. However, discovering these models through exhaustive evaluation of every uploaded model is computationally infeasible. We therefore formulate model discovery as a Multi-Armed Bandit problem and accelerate the Sequential Halving search algorithm by using shared query sets and aggressive elimination schedules. Our method retrieves top models with as few as 50 queries per candidate, accelerating discovery by over 50x.",
    "translation": "标题：模型仓库中隐藏瑰宝的发现机制研究\n\n摘要：公共模型仓库托管了数百万个微调模型，但社区使用量仍过度集中于少数基础检查点。本研究旨在探究这种集中现象究竟反映了有效的市场选择机制，还是存在优质模型被系统性忽视的问题。通过对超过2000个模型进行大规模评估，我们揭示了“隐藏瑰宝”现象的普遍性——这些不受关注的微调模型在性能上显著优于主流模型。以Llama-3.1-8B模型家族为例，我们发现某些极少被下载的检查点能将数学推理性能从83.2%提升至96.0%，且无需增加推理成本。然而，通过对每个上传模型进行穷举评估来发现这些优质模型在计算上是不可行的。为此，我们将模型发现问题建模为多臂老虎机问题，通过采用共享查询集和激进淘汰策略，对序列二分搜索算法进行加速优化。该方法仅需对每个候选模型进行50次查询即可定位最优模型，实现超过50倍的发现效率提升。",
    "url": "https://huggingface.co/papers/2601.22157",
    "arxiv_url": "https://arxiv.org/abs/2601.22157"
  },
  {
    "title": "Latent Adversarial Regularization for Offline Preference Optimization",
    "summary": "Learning from human feedback typically relies on preference optimization that constrains policy updates through token-level regularization. However, preference optimization for language models is particularly challenging because token-space similarity does not imply semantic or behavioral similarity. To address this challenge, we leverage latent-space regularization for language model preference optimization. We introduce GANPO, which achieves latent-space regularization by penalizing divergence between the internal representations of a policy model and a reference model. Given that latent representations are not associated with explicit probability densities, we adopt an adversarial approach inspired by GANs to minimize latent-space divergence. We integrate GANPO as a regularizer into existing offline preference optimization objectives. Experiments across multiple model architectures and tasks show consistent improvements from latent-space regularization. Further, by comparing GANPO-induced inferential biases with those from token-level regularization, we find that GANPO provides more robust structural feedback under distributional shift and noise while maintaining comparable downstream performance with minor computational overhead.",
    "translation": "标题：基于隐空间对抗正则化的离线偏好优化\n\n摘要：基于人类反馈的学习通常依赖于偏好优化方法，该方法通过词元级正则化约束策略更新。然而，语言模型的偏好优化面临特殊挑战，因为词元空间的相似性并不等同于语义或行为层面的相似性。为解决这一问题，我们提出在语言模型偏好优化中引入隐空间正则化方法。我们设计了GANPO框架，通过惩罚策略模型与参考模型内部表征之间的差异来实现隐空间正则化。鉴于隐空间表征缺乏显式概率密度定义，我们借鉴生成对抗网络的对抗训练思想来最小化隐空间差异。我们将GANPO作为正则化模块集成到现有离线偏好优化目标函数中。在多模型架构与多任务场景下的实验表明，隐空间正则化能带来持续的性能提升。进一步通过对比GANPO与词元级正则化引发的推理偏差，我们发现GANPO在数据分布偏移和噪声干扰下能提供更稳健的结构化反馈，同时以微小的计算开销保持与基线相当的下游任务性能。",
    "url": "https://huggingface.co/papers/2601.22083",
    "arxiv_url": "https://arxiv.org/abs/2601.22083"
  },
  {
    "title": "Scalable Power Sampling: Unlocking Efficient, Training-Free Reasoning for LLMs via Distribution Sharpening",
    "summary": "Reinforcement learning (RL) post-training is a dominant approach for improving the reasoning performance of large language models (LLMs), yet growing evidence suggests that its gains arise primarily from distribution sharpening rather than the acquisition of new capabilities. Recent work has shown that sampling from the power distribution of LLMs using Markov chain Monte Carlo (MCMC) can recover performance comparable to RL post-training without relying on external rewards; however, the high computational cost of MCMC makes such approaches impractical for widespread adoption. In this work, we propose a theoretically grounded alternative that eliminates the need for iterative MCMC. We derive a novel formulation showing that the global power distribution can be approximated by a token-level scaled low-temperature one, where the scaling factor captures future trajectory quality. Leveraging this insight, we introduce a training-free and verifier-free algorithm that sharpens the base model's generative distribution autoregressively. Empirically, we evaluate our method on math, QA, and code tasks across four LLMs, and show that our method matches or surpasses one-shot GRPO without relying on any external rewards, while reducing inference latency by over 10x compared to MCMC-based sampling.",
    "translation": "标题：可扩展的幂采样：通过分布锐化实现大语言模型高效免训练推理\n\n摘要：强化学习后训练是提升大语言模型推理性能的主流方法，但越来越多的证据表明其效果提升主要源于分布锐化而非新能力的获得。近期研究表明，通过马尔可夫链蒙特卡洛方法从大语言模型的幂分布中采样，可在不依赖外部奖励的情况下达到与强化学习后训练相当的性能；然而，马尔可夫链蒙特卡洛的高计算成本限制了此类方法的广泛应用。本研究提出一种理论完备的替代方案，无需依赖迭代式马尔可夫链蒙特卡洛过程。我们推导出一种新颖的数学表述，证明全局幂分布可通过词元级别的缩放低温分布来近似，其中缩放因子能够捕捉未来轨迹的质量。基于这一发现，我们提出一种免训练且无需验证器的自回归算法，能够逐级锐化基础模型的生成分布。实验部分，我们在四个大语言模型上对数学、问答及代码生成任务进行评估，结果表明：该方法在不依赖任何外部奖励的情况下，性能达到或超越单次GRPO方法，同时相比基于马尔可夫链蒙特卡洛的采样方法将推理延迟降低了10倍以上。",
    "url": "https://huggingface.co/papers/2601.21590",
    "arxiv_url": "https://arxiv.org/abs/2601.21590"
  },
  {
    "title": "Shaping capabilities with token-level data filtering",
    "summary": "Current approaches to reducing undesired capabilities in language models are largely post hoc, and can thus be easily bypassed by adversaries. A natural alternative is to shape capabilities during pretraining itself. On the proxy task of removing medical capabilities, we show that the simple intervention of filtering pretraining data is highly effective, robust, and inexpensive at scale. Inspired by work on data attribution, we show that filtering tokens is more effective than filtering documents, achieving the same hit to undesired capabilities at a lower cost to benign ones. Training models spanning two orders of magnitude, we then demonstrate that filtering gets more effective with scale: for our largest models, token filtering leads to a 7000x compute slowdown on the forget domain. We also show that models trained with token filtering can still be aligned on the forget domain. Along the way, we introduce a methodology for labeling tokens with sparse autoencoders and distilling cheap, high-quality classifiers. We also demonstrate that filtering can be robust to noisy labels with sufficient pretraining compute.",
    "translation": "标题：通过词元级数据过滤塑造模型能力\n\n摘要：当前减少语言模型中不良能力的方法大多属于事后干预，因此容易被对抗性攻击绕过。一种自然的替代方案是在预训练阶段直接塑造模型能力。以消除医学能力为代理任务，我们证明简单的预训练数据过滤干预方法具有高度有效性、鲁棒性且易于大规模实施。受数据归因研究的启发，我们发现词元级过滤比文档级过滤更有效，能在降低对良性能力损害的同时达到同等的不良能力抑制效果。通过训练跨越两个数量级的模型，我们进一步证明过滤效果随模型规模扩大而增强：对于最大规模模型，词元过滤可使目标遗忘领域的计算效率降低7000倍。研究还表明，经过词元过滤训练的模型仍可在遗忘领域进行对齐优化。在此过程中，我们提出了一种基于稀疏自编码器的词元标注方法，并实现了低成本高质量分类器的知识蒸馏。实验同时证明，在充足预训练计算资源支持下，过滤方法对噪声标签具有良好鲁棒性。",
    "url": "https://huggingface.co/papers/2601.21571",
    "arxiv_url": "https://arxiv.org/abs/2601.21571"
  },
  {
    "title": "Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B Technical Report",
    "summary": "We present Foundation-Sec-8B-Reasoning, the first open-source native reasoning model for cybersecurity. Built upon our previously released Foundation-Sec-8B base model (derived from Llama-3.1-8B-Base), the model is trained through a two-stage process combining supervised fine-tuning (SFT) and reinforcement learning from verifiable rewards (RLVR). Our training leverages proprietary reasoning data spanning cybersecurity analysis, instruction-following, and mathematical reasoning. Evaluation across 10 cybersecurity benchmarks and 10 general-purpose benchmarks demonstrates performance competitive with significantly larger models on cybersecurity tasks while maintaining strong general capabilities. The model shows effective generalization on multi-hop reasoning tasks and strong safety performance when deployed with appropriate system prompts and guardrails. This work demonstrates that domain-specialized reasoning models can achieve strong performance on specialized tasks while maintaining broad general capabilities. We release the model publicly at https://huggingface.co/fdtn-ai/Foundation-Sec-8B-Reasoning.",
    "translation": "标题：Llama-3.1-FoundationAI-SecurityLLM-Reasoning-8B 技术报告\n\n摘要：我们推出 Foundation-Sec-8B-Reasoning，这是首个面向网络安全领域的开源原生推理模型。该模型基于我们先前发布的 Foundation-Sec-8B 基础模型（源自 Llama-3.1-8B-Base），通过结合监督微调（SFT）和可验证奖励强化学习（RLVR）的两阶段训练流程构建。我们的训练利用了涵盖网络安全分析、指令遵循和数学推理的专有推理数据。在 10 项网络安全基准测试和 10 项通用基准测试上的评估表明，该模型在网络安全任务中展现出与规模显著更大的模型相竞争的性能，同时保持了强大的通用能力。该模型在多跳推理任务上表现出有效的泛化能力，并在部署适当的系统提示和防护机制时展现出优异的安全性能。本研究表明，领域专用推理模型能够在保持广泛通用能力的同时，在专业任务上实现强劲性能。我们已通过 https://huggingface.co/fdtn-ai/Foundation-Sec-8B-Reasoning 公开释放该模型。",
    "url": "https://huggingface.co/papers/2601.21051",
    "arxiv_url": "https://arxiv.org/abs/2601.21051"
  },
  {
    "title": "Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models",
    "summary": "Large language models (LLMs) have progressed rapidly; however, most state-of-the-art models are trained and evaluated primarily in high-resource languages such as English and Chinese, and are often developed by a small number of organizations with access to large-scale compute and data. This gatekeeping creates a practical barrier for sovereign settings in which a regional- or national-scale institution or domain owner must retain control and understanding of model weights, training data, and deployment while operating under limited resources and strict transparency constraints. To this end, we identify two core requirements: (1) adoptability, the ability to transform a base model into a general-purpose assistant, and (2) sovereign capability, the ability to perform high-stakes, region-specific tasks (e.g., legal reasoning in local languages and cultural knowledge). We investigate whether these requirements can be achieved without scaling massive instruction corpora or relying on complex preference tuning pipelines and large-scale reinforcement fine-tuning (RFT). We present Typhoon S, a minimal and open post-training recipe that combines supervised fine-tuning, on-policy distillation, and small-scale RFT. Using Thai as a representative case study, we demonstrate that our approach transforms both sovereign-adapted and general-purpose base models into instruction-tuned models with strong general performance. We further show that small-scale RFT with InK-GRPO -- an extension of GRPO that augments the GRPO loss with a next-word prediction loss -- improves Thai legal reasoning and Thai-specific knowledge while preserving general capabilities. Our results suggest that a carefully designed post-training strategy can reduce the required scale of instruction data and computation, providing a practical path toward high-quality sovereign LLMs under academic-scale resources.",
    "translation": "标题：台风-S：主权大语言模型的最小化开放式后训练方法\n\n摘要：大语言模型（LLM）发展迅速，然而当前最先进的模型主要基于英语、汉语等高资源语言进行训练与评估，且通常由少数能够获取大规模计算资源与数据的机构开发。这种技术壁垒为主权应用场景带来了实际障碍：在资源有限且透明度要求严格的条件下，区域或国家层面的机构及领域所有者需保持对模型权重、训练数据及部署流程的控制权与可解释性。为此，我们提出两大核心需求：（1）可适配性——将基础模型转化为通用助手的能；（2）主权能力——执行高风险、区域特定任务（如本地语言法律推理与文化知识应用）的能力。本研究探讨能否在不依赖大规模指令数据扩展、复杂偏好调优流程或大规模强化微调的前提下实现这些目标。我们提出台风-S，一种最小化开放式后训练方案，融合监督微调、同策略蒸馏与小规模强化微调。以泰语作为代表性案例，我们证明该方法可将主权适配型与通用型基础模型转化为具备强大通用性能的指令调优模型。进一步研究发现，采用InK-GRPO（通过在GRPO损失函数中融入下一词预测损失进行扩展）的小规模强化微调，能在保持通用能力的同时显著提升泰语法律推理与泰国本土知识处理能力。实验结果表明，精心设计的后训练策略可降低对指令数据规模与计算资源的需求，为在学术级资源条件下构建高质量主权大语言模型提供了可行路径。",
    "url": "https://huggingface.co/papers/2601.18129",
    "arxiv_url": "https://arxiv.org/abs/2601.18129"
  },
  {
    "title": "VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning",
    "summary": "Long-context reasoning has significantly empowered large language models (LLMs) to tackle complex tasks, yet it introduces severe efficiency bottlenecks due to the computational complexity. Existing efficient approaches often rely on complex additional training or external models for compression, which limits scalability and discards critical fine-grained information. In this paper, we propose VTC-R1, a new efficient reasoning paradigm that integrates vision-text compression into the reasoning process. Instead of processing lengthy textual traces, VTC-R1 renders intermediate reasoning segments into compact images, which are iteratively fed back into vision-language models as \"optical memory.\" We construct a training dataset based on OpenR1-Math-220K achieving 3.4x token compression and fine-tune representative VLMs-Glyph and Qwen3-VL. Extensive experiments on benchmarks such as MATH500, AIME25, AMC23 and GPQA-D demonstrate that VTC-R1 consistently outperforms standard long-context reasoning. Furthermore, our approach significantly improves inference efficiency, achieving 2.7x speedup in end-to-end latency, highlighting its potential as a scalable solution for reasoning-intensive applications. Our code is available at https://github.com/w-yibo/VTC-R1.",
    "translation": "标题：VTC-R1：面向高效长上下文推理的视觉-文本压缩方法\n\n摘要：长上下文推理显著增强了大语言模型处理复杂任务的能力，但因其计算复杂性也带来了严重的效率瓶颈。现有高效方法通常依赖复杂的额外训练或外部模型进行压缩，这限制了可扩展性并丢弃了关键的细粒度信息。本文提出VTC-R1——一种集成视觉-文本压缩的新型高效推理范式。该方法将冗长的文本推理轨迹转化为紧凑的图像片段，作为“光学记忆”迭代反馈给视觉-语言模型，而非直接处理原始长文本。基于OpenR1-Math-220K构建的训练数据集实现了3.4倍的token压缩率，并以此微调了代表性视觉语言模型Glyph与Qwen3-VL。在MATH500、AIME25、AMC23及GPQA-D等基准测试上的大量实验表明，VTC-R1持续优于标准长上下文推理方法。此外，本方法显著提升了推理效率，端到端延迟降低至原来的2.7倍，凸显了其作为推理密集型应用可扩展解决方案的潜力。代码已开源：https://github.com/w-yibo/VTC-R1。",
    "url": "https://huggingface.co/papers/2601.22069",
    "arxiv_url": "https://arxiv.org/abs/2601.22069"
  },
  {
    "title": "MAD: Modality-Adaptive Decoding for Mitigating Cross-Modal Hallucinations in Multimodal Large Language Models",
    "summary": "Multimodal Large Language Models (MLLMs) suffer from cross-modal hallucinations, where one modality inappropriately influences generation about another, leading to fabricated output. This exposes a more fundamental deficiency in modality-interaction control. To address this, we propose Modality-Adaptive Decoding (MAD), a training-free method that adaptively weights modality-specific decoding branches based on task requirements. MAD leverages the model's inherent ability to self-assess modality relevance by querying which modalities are needed for each task. The extracted modality probabilities are then used to adaptively weight contrastive decoding branches, enabling the model to focus on relevant information while suppressing cross-modal interference. Extensive experiments on CMM and AVHBench demonstrate that MAD significantly reduces cross-modal hallucinations across multiple audio-visual language models (7.8\\% and 2.0\\% improvements for VideoLLaMA2-AV, 8.7\\% and 4.7\\% improvements for Qwen2.5-Omni). Our approach demonstrates that explicit modality awareness through self-assessment is crucial for robust multimodal reasoning, offering a principled extension to existing contrastive decoding methods. Our code is available at https://github.com/top-yun/MAD{https://github.com/top-yun/MAD}",
    "translation": "标题：MAD：模态自适应解码——缓解多模态大语言模型中的跨模态幻觉问题\n\n摘要：多模态大语言模型（MLLMs）存在跨模态幻觉问题，即某一模态不适当地影响对其他模态内容的生成，导致输出结果失真。这暴露出模型在模态交互控制方面存在更深层的缺陷。为解决这一问题，我们提出模态自适应解码（MAD），一种无需训练的方法，能够根据任务需求自适应地加权特定模态的解码分支。MAD利用模型固有的自评估能力，通过查询每个任务所需的模态来判定模态相关性。提取的模态概率随后用于自适应加权对比解码分支，使模型能够聚焦相关信息并抑制跨模态干扰。在CMM和AVHBench数据集上的大量实验表明，MAD显著降低了多种视听语言模型的跨模态幻觉（VideoLLaMA2-AV模型提升7.8%和2.0%，Qwen2.5-Omni模型提升8.7%和4.7%）。我们的方法证明，通过自评估实现的显式模态感知对鲁棒的多模态推理至关重要，为现有对比解码方法提供了理论扩展。代码已开源：https://github.com/top-yun/MAD",
    "url": "https://huggingface.co/papers/2601.21181",
    "arxiv_url": "https://arxiv.org/abs/2601.21181"
  },
  {
    "title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems",
    "summary": "Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.",
    "translation": "标题：脑电图基础模型：进展、基准测试与开放性问题\n\n摘要：脑电图基础模型作为脑机接口领域新兴的前沿范式，旨在通过大规模异质性脑电记录学习可迁移的神经表征。尽管该领域发展迅速，但由于预训练目标、预处理流程与下游评估协议缺乏统一标准，现有模型尚未形成公平全面的性能比较。本文系统填补了这一空白：首先回顾了50个代表性模型，将其设计选择归纳为包含数据标准化、模型架构与自监督预训练策略的统一分类框架；进而选取12个开源基础模型与具有竞争力的专业基线模型，在涵盖九类脑机接口范式的13个脑电数据集上进行评估。为贴近实际部署场景，我们同时考察留一被试协议下的跨被试泛化能力与被试内少样本场景下的快速校准性能。通过对比全参数微调与线性探测方法，评估了预训练表征的可迁移性，并探究了模型规模与下游性能的关联规律。实验结果表明：1）线性探测方法常表现不足；2）从头训练的专业模型在多类任务中仍具竞争力；3）在当前数据规模与训练范式下，扩大基础模型规模未必能提升泛化性能。",
    "url": "https://huggingface.co/papers/2601.17883",
    "arxiv_url": "https://arxiv.org/abs/2601.17883"
  },
  {
    "title": "DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents",
    "summary": "We introduce DeepSearchQA, a 900-prompt benchmark for evaluating agents on difficult multi-step information-seeking tasks across 17 different fields. Unlike traditional benchmarks that target single answer retrieval or broad-spectrum factuality, DeepSearchQA features a dataset of challenging, handcrafted tasks designed to evaluate an agent's ability to execute complex search plans to generate exhaustive answer lists. This shift in design explicitly tests three critical, yet under-evaluated capabilities: 1) systematic collation of fragmented information from disparate sources, 2) de-duplication and entity resolution to ensure precision, and 3) the ability to reason about stopping criteria within an open-ended search space. Each task is structured as a causal chain, where discovering information for one step is dependent on the successful completion of the previous one, stressing long-horizon planning and context retention. All tasks are grounded in the open web with objectively verifiable answer sets. Our comprehensive evaluation of state-of-the-art agent architectures reveals significant performance limitations: even the most advanced models struggle to balance high recall with precision. We observe distinct failure modes ranging from premature stopping (under-retrieval) to hedging behaviors, where agents cast an overly wide net of low-confidence answers to artificially boost recall. These findings highlight critical headroom in current agent designs and position DeepSearchQA as an essential diagnostic tool for driving future research toward more robust, deep-research capabilities.",
    "translation": "标题：DeepSearchQA：弥合深度研究智能体综合能力差距的基准框架\n\n摘要：本文提出DeepSearchQA，这是一个包含900个提示任务的基准测试集，用于评估智能体在17个不同领域中执行复杂多步骤信息检索任务的能力。与传统聚焦单一答案检索或宽泛事实性验证的基准不同，DeepSearchQA通过精心设计的高难度任务数据集，专门评估智能体执行复杂搜索计划以生成穷尽式答案列表的能力。该设计范式转变明确测试了三个关键但长期未被充分评估的能力：1）从分散来源系统整合碎片化信息；2）通过去重与实体消歧确保结果精确性；3）在开放式搜索空间中合理判断检索终止条件。每个任务均构建为因果链式结构，后续步骤的信息发现依赖于前序步骤的成功完成，从而强调长程规划与上下文保持能力。所有任务均基于开放网络环境构建，并配备可客观验证的答案集。通过对前沿智能体架构的全面评估，我们发现了显著的性能局限：即使最先进的模型也难以平衡高召回率与精确度。我们观察到从过早终止检索（检索不足）到防御性检索行为等多种失效模式——后者表现为智能体通过提交大量低置信度答案人为提高召回率。这些发现揭示了当前智能体设计中的关键提升空间，并使DeepSearchQA成为推动未来研究向更鲁棒的深度研究能力发展的重要诊断工具。",
    "url": "https://huggingface.co/papers/2601.20975",
    "arxiv_url": "https://arxiv.org/abs/2601.20975"
  },
  {
    "title": "Beyond Imitation: Reinforcement Learning for Active Latent Planning",
    "summary": "Aiming at efficient and dense chain-of-thought (CoT) reasoning, latent reasoning methods fine-tune Large Language Models (LLMs) to substitute discrete language tokens with continuous latent tokens. These methods consume fewer tokens compared to the conventional language CoT reasoning and have the potential to plan in a dense latent space. However, current latent tokens are generally supervised based on imitating language labels. Considering that there can be multiple equivalent but diverse CoT labels for a question, passively imitating an arbitrary one may lead to inferior latent token representations and latent reasoning policies, undermining the potential planning ability and resulting in clear gaps between training and testing. In this work, we emphasize the importance of active planning over the representation space of latent tokens in achieving the optimal latent reasoning policy. So, we propose the Active Latent Planning method (ATP-Latent), which models the supervision process of latent tokens as a conditional variational auto-encoder (VAE) to obtain a smoother latent space. Moreover, to facilitate the most reasonable latent reasoning policy, ATP-Latent conducts reinforcement learning (RL) with an auxiliary coherence reward, which is calculated based on the consistency between VAE-decoded contents of latent tokens, enabling a guided RL process. In experiments on LLaMA-1B, ATP-Latent demonstrates +4.1\\% accuracy and -3.3\\% tokens on four benchmarks compared to advanced baselines. Codes are available on https://github.com/zz1358m/ATP-Latent-master.",
    "translation": "标题：超越模仿：基于强化学习的主动潜在规划\n\n摘要：为实现高效且密集的思维链推理，潜在推理方法通过微调大语言模型，将离散的语言标记替换为连续的潜在标记。相较于传统的语言思维链推理，这类方法消耗的标记更少，并具备在密集潜在空间中进行规划的潜力。然而，当前潜在标记的监督通常基于对语言标签的模仿。考虑到同一问题可能存在多个等价但形式各异的思维链标签，被动模仿任意标签可能导致次优的潜在标记表示与推理策略，从而削弱潜在规划能力，并造成训练与测试阶段的明显差距。本研究强调在潜在标记表示空间中进行主动规划对实现最优潜在推理策略的重要性。为此，我们提出主动潜在规划方法，该方法将潜在标记的监督过程建模为条件变分自编码器，以获得更平滑的潜在空间。此外，为构建最合理的潜在推理策略，该方法引入基于一致性的辅助奖励进行强化学习——该奖励通过计算潜在标记经变分自编码器解码内容的一致性获得，从而实现有导向的强化学习过程。在LLaMA-1B模型上的实验表明，相较于先进基线方法，该方法在四个基准测试中实现了准确率提升4.1%、标记消耗降低3.3%的效果。代码已发布于https://github.com/zz1358m/ATP-Latent-master。",
    "url": "https://huggingface.co/papers/2601.21598",
    "arxiv_url": "https://arxiv.org/abs/2601.21598"
  },
  {
    "title": "One-step Latent-free Image Generation with Pixel Mean Flows",
    "summary": "Modern diffusion/flow-based models for image generation typically exhibit two core characteristics: (i) using multi-step sampling, and (ii) operating in a latent space. Recent advances have made encouraging progress on each aspect individually, paving the way toward one-step diffusion/flow without latents. In this work, we take a further step towards this goal and propose \"pixel MeanFlow\" (pMF). Our core guideline is to formulate the network output space and the loss space separately. The network target is designed to be on a presumed low-dimensional image manifold (i.e., x-prediction), while the loss is defined via MeanFlow in the velocity space. We introduce a simple transformation between the image manifold and the average velocity field. In experiments, pMF achieves strong results for one-step latent-free generation on ImageNet at 256x256 resolution (2.22 FID) and 512x512 resolution (2.48 FID), filling a key missing piece in this regime. We hope that our study will further advance the boundaries of diffusion/flow-based generative models.",
    "translation": "标题：基于像素均值流的单步无潜变量图像生成方法\n\n摘要：现代基于扩散/流模型的图像生成方法通常具有两个核心特征：(1)采用多步采样策略，(2)在潜空间中进行操作。近期研究已在这两个独立方面取得显著进展，为无需潜空间的单步扩散/流模型开辟了道路。本研究朝着该目标迈出关键一步，提出\"像素均值流\"方法。我们的核心设计原则是将网络输出空间与损失空间分别进行建模：网络输出目标被设计在预设的低维图像流形上（即x-预测），而损失函数则通过速度空间中的均值流进行定义。我们引入了图像流形与平均速度场之间的简易转换机制。实验结果表明，在256×256分辨率（FID 2.22）和512×512分辨率（FID 2.48）的ImageNet数据集上，像素均值流方法实现了单步无潜变量生成的优异性能，填补了该领域的关键技术空白。本研究有望进一步拓展基于扩散/流模型的生成式人工智能技术边界。",
    "url": "https://huggingface.co/papers/2601.22158",
    "arxiv_url": "https://arxiv.org/abs/2601.22158"
  },
  {
    "title": "Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts",
    "summary": "Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RNN blocks through parameter transfer and knowledge distillation. However, these transfer methods require substantial amounts of training data (more than 10B tokens), and the resulting hybrid models also exhibit poor long-context performance, which is the scenario where hybrid models enjoy significant inference speedups over Transformer-based models. In this paper, we present HALO (Hybrid Attention via Layer Optimization), a pipeline for distilling Transformer models into RNN-attention hybrid models. We then present HypeNet, a hybrid architecture with superior length generalization enabled by a novel position encoding scheme (named HyPE) and various architectural modifications. We convert the Qwen3 series into HypeNet using HALO, achieving performance comparable to the original Transformer models while enjoying superior long-context performance and efficiency. The conversion requires just 2.3B tokens, less than 0.01% of their pre-training data",
    "translation": "标题：混合线性注意力机制的正确实现：面向超长上下文的高效蒸馏与有效架构\n\n摘要：混合Transformer架构通过结合softmax注意力模块与循环神经网络（RNN），已在长上下文建模中展现出理想的性能与计算效率平衡，但其大规模从头预训练所需的巨大成本阻碍了该架构的广泛应用与研究。近期研究表明，预训练的softmax注意力模块可通过参数迁移与知识蒸馏转化为RNN模块。然而，现有迁移方法需要海量训练数据（超过100亿词元），且所得混合模型在长上下文场景中表现欠佳——而这正是混合模型相比传统Transformer模型具有显著推理加速优势的场景。本文提出HALO（基于层优化的混合注意力），一种将Transformer模型蒸馏为RNN-注意力混合模型的流程。进而提出HypeNet混合架构，该架构通过新颖的位置编码方案（命名为HyPE）及多项结构改进，实现了卓越的长度泛化能力。我们使用HALO将Qwen3系列模型转化为HypeNet，在保持与原Transformer模型相当性能的同时，获得了更优异的长上下文处理能力与计算效率。该转化过程仅需23亿词元，不足其预训练数据量的0.01%。",
    "url": "https://huggingface.co/papers/2601.22156",
    "arxiv_url": "https://arxiv.org/abs/2601.22156"
  },
  {
    "title": "FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale",
    "summary": "Due to limited supervised training data, large language models (LLMs) are typically pre-trained via a self-supervised \"predict the next word\" objective on a vast amount of unstructured text data. To make the resulting model useful to users, it is further trained on a far smaller amount of \"instruction-tuning\" data comprised of supervised training examples of instructions and responses. To overcome the limited amount of supervised data, we propose a procedure that can transform the knowledge in internet-scale pre-training documents into billions of synthetic instruction and answer training pairs. The resulting dataset, called FineInstructions, uses ~18M instruction templates created from real user-written queries and prompts. These instruction templates are matched to and instantiated with human-written source documents from unstructured pre-training corpora. With \"supervised\" synthetic training data generated at this scale, an LLM can be pre-trained from scratch solely with the instruction-tuning objective, which is far more in-distribution with the expected downstream usage of LLMs (responding to user prompts). We conduct controlled token-for-token training experiments and find pre-training on FineInstructions outperforms standard pre-training and other proposed synthetic pre-training techniques on standard benchmarks measuring free-form response quality. Our resources can be found at https://huggingface.co/fineinstructions .",
    "translation": "标题：FineInstructions：将合成指令扩展至预训练规模\n\n摘要：由于监督训练数据有限，大型语言模型通常通过自监督的“预测下一个词”目标在海量非结构化文本数据上进行预训练。为使所得模型对用户有用，还需在规模小得多的“指令调优”数据上进行进一步训练，该数据由指令与响应的监督训练样本构成。为克服监督数据量的限制，我们提出一种方法，能够将互联网规模预训练文档中的知识转化为数十亿条合成指令与答案训练对。所得数据集名为FineInstructions，使用了基于真实用户编写的查询和提示创建的约1800万条指令模板。这些指令模板与非结构化预训练语料库中人工撰写的源文档进行匹配并实例化。借助此规模生成的“监督式”合成训练数据，大型语言模型可完全基于指令调优目标从头开始预训练，该目标与大型语言模型的下游预期用途（响应用户提示）具有更高的分布一致性。我们进行了严格的逐词训练对照实验，发现在衡量自由形式响应质量的标准基准测试中，基于FineInstructions的预训练表现优于标准预训练及其他已提出的合成预训练技术。相关资源可在 https://huggingface.co/fineinstructions 获取。",
    "url": "https://huggingface.co/papers/2601.22146",
    "arxiv_url": "https://arxiv.org/abs/2601.22146"
  },
  {
    "title": "KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices",
    "summary": "The success of Hyper-Connections (HC) in neural networks (NN) has also highlighted issues related to its training instability and restricted scalability. The Manifold-Constrained Hyper-Connections (mHC) mitigate these challenges by projecting the residual connection space onto a Birkhoff polytope, however, it faces two issues: 1) its iterative Sinkhorn-Knopp (SK) algorithm does not always yield exact doubly stochastic residual matrices; 2) mHC incurs a prohibitive O(n^3C) parameter complexity with n as the width of the residual stream and C as the feature dimension. The recently proposed mHC-lite reparametrizes the residual matrix via the Birkhoff-von-Neumann theorem to guarantee double stochasticity, but also faces a factorial explosion in its parameter complexity, O left( nC cdot n! right). To address both challenges, we propose KromHC, which uses the Kronecker products of smaller doubly stochastic matrices to parametrize the residual matrix in mHC. By enforcing manifold constraints across the factor residual matrices along each mode of the tensorized residual stream, KromHC guarantees exact double stochasticity of the residual matrices while reducing parameter complexity to O(n^2C). Comprehensive experiments demonstrate that KromHC matches or even outperforms state-of-the-art (SOTA) mHC variants, while requiring significantly fewer trainable parameters. The code is available at https://github.com/wz1119/KromHC.",
    "translation": "标题：KromHC：基于克罗内克积残差矩阵的流形约束超连接\n\n摘要：超连接（HC）在神经网络（NN）中的成功应用，也凸显了其训练不稳定性和可扩展性受限的问题。流形约束超连接（mHC）通过将残差连接空间投影到Birkhoff多胞体上缓解了这些挑战，但仍面临两个问题：1）其迭代Sinkhorn-Knopp（SK）算法并不总能产生精确的双随机残差矩阵；2）mHC的参数复杂度高达O(n^3C)，其中n为残差流的宽度，C为特征维度。近期提出的mHC-lite通过Birkhoff-von-Neumann定理对残差矩阵进行重参数化以保证双随机性，但其参数复杂度也面临阶乘爆炸问题，达到O(nC·n!)。为同时解决这两大挑战，本文提出KromHC方法，该方法利用较小双随机矩阵的克罗内克积来参数化mHC中的残差矩阵。通过对张量化残差流各模态上的因子残差矩阵施加流形约束，KromHC在保证残差矩阵精确双随机性的同时，将参数复杂度降低至O(n^2C)。综合实验表明，KromHC在性能上匹配甚至超越最先进的mHC变体，且所需可训练参数显著减少。代码已发布于https://github.com/wz1119/KromHC。",
    "url": "https://huggingface.co/papers/2601.21579",
    "arxiv_url": "https://arxiv.org/abs/2601.21579"
  },
  {
    "title": "Self-Improving Pretraining: using post-trained models to pretrain better models",
    "summary": "Ensuring safety, factuality and overall quality in the generations of large language models is a critical challenge, especially as these models are increasingly deployed in real-world applications. The prevailing approach to addressing these issues involves collecting expensive, carefully curated datasets and applying multiple stages of fine-tuning and alignment. However, even this complex pipeline cannot guarantee the correction of patterns learned during pretraining. Therefore, addressing these issues during pretraining is crucial, as it shapes a model's core behaviors and prevents unsafe or hallucinated outputs from becoming deeply embedded. To tackle this issue, we introduce a new pretraining method that streams documents and uses reinforcement learning (RL) to improve the next K generated tokens at each step. A strong, post-trained model judges candidate generations -- including model rollouts, the original suffix, and a rewritten suffix -- for quality, safety, and factuality. Early in training, the process relies on the original and rewritten suffixes; as the model improves, RL rewards high-quality rollouts. This approach builds higher quality, safer, and more factual models from the ground up. In experiments, our method gives 36.2% and 18.5% relative improvements over standard pretraining in terms of factuality and safety, and up to 86.3% win rate improvements in overall generation quality.",
    "translation": "标题：自改进预训练：利用后训练模型预训练更优模型\n\n摘要：确保大语言模型生成内容的安全性、事实性与整体质量是一项关键挑战，尤其在模型日益广泛应用于现实场景的背景下。当前主流解决方案依赖于收集成本高昂、精心标注的数据集，并进行多阶段的微调与对齐处理。然而，即使采用如此复杂的流程，仍无法完全修正模型在预训练阶段习得的不良模式。因此，在预训练阶段解决这些问题至关重要，因为这一阶段塑造了模型的核心行为模式，能从根本上防止不安全或虚构内容被深度固化。为此，我们提出一种新型预训练方法：该方法通过流式处理文档数据，并运用强化学习技术逐步优化后续K个生成标记。在这一过程中，一个经过充分后训练的强模型将对候选生成内容（包括模型自生成序列、原始后缀文本及重写后缀文本）进行质量、安全性与事实性评估。训练初期，系统主要依赖原始文本与重写后缀；随着模型性能提升，强化学习机制将给予高质量自生成序列正向奖励。该方法能够从底层构建质量更高、更安全且更符合事实的模型。实验结果表明，相较于标准预训练方法，本方案在事实性与安全性指标上分别实现36.2%和18.5%的相对提升，在整体生成质量方面最高可获得86.3%的胜率改进。",
    "url": "https://huggingface.co/papers/2601.21343",
    "arxiv_url": "https://arxiv.org/abs/2601.21343"
  },
  {
    "title": "ECO: Quantized Training without Full-Precision Master Weights",
    "summary": "Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely on accumulating their updates in high-precision: concretely, gradient updates must be applied to a high-precision weight buffer, known as master weights. This buffer introduces substantial memory overhead, particularly for Sparse Mixture of Experts (SMoE) models, where model parameters and optimizer states dominate memory usage. To address this, we introduce the Error-Compensating Optimizer (ECO), which eliminates master weights by applying updates directly to quantized parameters. ECO quantizes weights after each step and carefully injects the resulting quantization error into the optimizer momentum, forming an error-feedback loop with no additional memory. We prove that, under standard assumptions and a decaying learning rate, ECO converges to a constant-radius neighborhood of the optimum, while naive master-weight removal can incur an error that is inversely proportional to the learning rate. We show empirical results for pretraining small Transformers (30-800M), a Gemma-3 1B model, and a 2.1B parameter Sparse MoE model with FP8 quantization, and fine-tuning DeepSeek-MoE-16B in INT4 precision. Throughout, ECO matches baselines with master weights up to near-lossless accuracy, significantly shifting the static memory vs validation loss Pareto frontier.",
    "translation": "标题：ECO：无需全精度主权重的量化训练方法\n\n摘要：量化技术已显著提升大语言模型（LLL）训练的计算与内存效率。然而，现有方法仍需依赖高精度累积更新：具体而言，梯度更新必须作用于高精度权重缓冲区（即主权重）。该缓冲区会带来显著的内存开销，尤其对于稀疏专家混合模型（SMoE）而言，模型参数与优化器状态占据了内存使用的主要部分。为解决此问题，我们提出误差补偿优化器（ECO），该方法通过直接将更新应用于量化参数来消除主权重。ECO在每一步训练后对权重进行量化，并将产生的量化误差精准注入优化器动量中，形成一个无需额外内存的误差反馈循环。我们证明，在标准假设与递减学习率条件下，ECO能够收敛至最优解固定半径邻域内，而简单移除主权重可能导致误差与学习率成反比。我们通过预训练小型Transformer模型（30-800M参数）、Gemma-3 1B模型及采用FP8量化的2.1B参数稀疏MoE模型，并在INT4精度下对DeepSeek-MoE-16B进行微调，展示了实证结果。在所有实验中，ECO在保持近乎无损精度的前提下，与使用主权重的基线方法性能相当，显著改善了静态内存与验证损失的帕累托前沿边界。\n\n请按照以下格式返回：\n标题：ECO：无需全精度主权重的量化训练方法\n摘要：量化技术已显著提升大语言模型（LLL）训练的计算与内存效率。然而，现有方法仍需依赖高精度累积更新：具体而言，梯度更新必须作用于高精度权重缓冲区（即主权重）。该缓冲区会带来显著的内存开销，尤其对于稀疏专家混合模型（SMoE）而言，模型参数与优化器状态占据了内存使用的主要部分。为解决此问题，我们提出误差补偿优化器（ECO），该方法通过直接将更新应用于量化参数来消除主权重。ECO在每一步训练后对权重进行量化，并将产生的量化误差精准注入优化器动量中，形成一个无需额外内存的误差反馈循环。我们证明，在标准假设与递减学习率条件下，ECO能够收敛至最优解固定半径邻域内，而简单移除主权重可能导致误差与学习率成反比。我们通过预训练小型Transformer模型（30-800M参数）、Gemma-3 1B模型及采用FP8量化的2.1B参数稀疏MoE模型，并在INT4精度下对DeepSeek-MoE-16B进行微调，展示了实证结果。在所有实验中，ECO在保持近乎无损精度的前提下，与使用主权重的基线方法性能相当，显著改善了静态内存与验证损失的帕累托前沿边界。",
    "url": "https://huggingface.co/papers/2601.22101",
    "arxiv_url": "https://arxiv.org/abs/2601.22101"
  },
  {
    "title": "MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources",
    "summary": "Scaling has powered recent advances in vision foundation models, yet extending this paradigm to metric depth estimation remains challenging due to heterogeneous sensor noise, camera-dependent biases, and metric ambiguity in noisy cross-source 3D data. We introduce Metric Anything, a simple and scalable pretraining framework that learns metric depth from noisy, diverse 3D sources without manually engineered prompts, camera-specific modeling, or task-specific architectures. Central to our approach is the Sparse Metric Prompt, created by randomly masking depth maps, which serves as a universal interface that decouples spatial reasoning from sensor and camera biases. Using about 20M image-depth pairs spanning reconstructed, captured, and rendered 3D data across 10000 camera models, we demonstrate-for the first time-a clear scaling trend in the metric depth track. The pretrained model excels at prompt-driven tasks such as depth completion, super-resolution and Radar-camera fusion, while its distilled prompt-free student achieves state-of-the-art results on monocular depth estimation, camera intrinsics recovery, single/multi-view metric 3D reconstruction, and VLA planning. We also show that using pretrained ViT of Metric Anything as a visual encoder significantly boosts Multimodal Large Language Model capabilities in spatial intelligence. These results show that metric depth estimation can benefit from the same scaling laws that drive modern foundation models, establishing a new path toward scalable and efficient real-world metric perception. We open-source MetricAnything at http://metric-anything.github.io/metric-anything-io/ to support community research.",
    "translation": "标题：Metric Anything：利用异构噪声源实现度量深度预训练的规模化扩展\n\n摘要：规模化推动了视觉基础模型的近期进展，但将这一范式扩展到度量深度估计领域仍面临挑战，原因在于异构传感器噪声、相机相关偏差以及跨来源噪声三维数据中的度量模糊性。我们提出了Metric Anything，一个简单且可扩展的预训练框架，能够从噪声多样化的三维数据源中学习度量深度，无需人工设计提示、相机特定建模或任务专用架构。我们方法的核心是稀疏度量提示——通过随机掩码深度图生成，它作为一种通用接口，将空间推理与传感器及相机偏差解耦。利用涵盖重建、采集和渲染三维数据的大约2000万张图像-深度对（涉及10000种相机型号），我们首次在度量深度研究方向上展示了清晰的规模化扩展趋势。预训练模型在提示驱动任务（如深度补全、超分辨率及雷达-相机融合）中表现优异，而其蒸馏出的无提示学生模型在单目深度估计、相机内参恢复、单/多视角度量三维重建以及视觉语言动作规划任务中达到了最先进水平。我们还证明，使用Metric Anything的预训练视觉变换器作为视觉编码器，能显著提升多模态大语言模型在空间智能方面的能力。这些结果表明，度量深度估计能够受益于驱动现代基础模型的相同扩展定律，为可扩展、高效的真实世界度量感知开辟了新路径。我们在http://metric-anything.github.io/metric-anything-io/开源Metric Anything以支持社区研究。",
    "url": "https://huggingface.co/papers/2601.22054",
    "arxiv_url": "https://arxiv.org/abs/2601.22054"
  },
  {
    "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units",
    "summary": "While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.",
    "translation": "标题：机制化数据归因：追溯可解释大语言模型单元的训源\n\n摘要：尽管机制可解释性研究已在大语言模型中识别出可解释电路，但其在训练数据中的因果起源仍不明确。本文提出机制化数据归因框架，该可扩展框架运用影响函数将可解释单元溯源至具体训练样本。通过对Pythia模型系列的系列实验，我们因果验证了定向干预——即移除或增强少量高影响力样本——能显著调控可解释注意力头的形成，而随机干预则无此效果。分析表明重复性结构化数据（如LaTeX、XML）发挥着机制催化作用。进一步研究发现，针对归纳头形成的干预会同步改变模型的上下文学习能力，这为归纳头与上下文学习功能关联的长期假设提供了直接因果证据。最后，我们提出一种机制化数据增强流程，该流程能跨模型规模持续加速电路收敛，为引导大语言模型发展轨迹提供了系统化方法论。",
    "url": "https://huggingface.co/papers/2601.21996",
    "arxiv_url": "https://arxiv.org/abs/2601.21996"
  },
  {
    "title": "Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation",
    "summary": "Unified Multimodal Models (UMMs) integrate both visual understanding and generation within a single framework. Their ultimate aspiration is to create a cycle where understanding and generation mutually reinforce each other. While recent post-training methods have successfully leveraged understanding to enhance generation, the reverse direction of utilizing generation to improve understanding remains largely unexplored. In this work, we propose UniMRG (Unified Multi-Representation Generation), a simple yet effective architecture-agnostic post-training method. UniMRG enhances the understanding capabilities of UMMs by incorporating auxiliary generation tasks. Specifically, we train UMMs to generate multiple intrinsic representations of input images, namely pixel (reconstruction), depth (geometry), and segmentation (structure), alongside standard visual understanding objectives. By synthesizing these diverse representations, UMMs capture complementary information regarding appearance, spatial relations, and structural layout. Consequently, UMMs develop a deeper and more comprehensive understanding of visual inputs. Extensive experiments across diverse UMM architectures demonstrate that our method notably enhances fine-grained perception, reduces hallucinations, and improves spatial understanding, while simultaneously boosting generation capabilities.",
    "translation": "标题：多表征生成增强统一多模态模型的理解能力\n\n摘要：统一多模态模型（UMMs）将视觉理解与生成功能整合于单一框架中，其最终目标是构建理解与生成相互强化的循环机制。尽管近期后训练方法已成功利用理解能力提升生成质量，但利用生成任务增强理解能力的反向路径仍鲜有探索。本研究提出UniMRG（统一多表征生成）——一种简洁高效且与模型架构无关的后训练方法。该方法通过引入辅助生成任务来增强UMMs的理解能力。具体而言，我们在标准视觉理解任务基础上，训练UMMs同步生成输入图像的多种内在表征：像素级（重建）、深度（几何）与分割（结构）信息。通过合成这些多样化表征，UMMs能够捕捉关于外观特征、空间关系与结构布局的互补信息，从而实现对视觉输入更深入、更全面的理解。跨多种UMM架构的大规模实验表明，本方法显著提升了模型的细粒度感知能力，减少了幻觉现象，增强了空间理解性能，同时同步强化了生成能力。",
    "url": "https://huggingface.co/papers/2601.21406",
    "arxiv_url": "https://arxiv.org/abs/2601.21406"
  },
  {
    "title": "BMAM: Brain-inspired Multi-Agent Memory Framework",
    "summary": "Language-model-based agents operating over extended interaction horizons face persistent challenges in preserving temporally grounded information and maintaining behavioral consistency across sessions, a failure mode we term soul erosion. We present BMAM (Brain-inspired Multi-Agent Memory), a general-purpose memory architecture that models agent memory as a set of functionally specialized subsystems rather than a single unstructured store. Inspired by cognitive memory systems, BMAM decomposes memory into episodic, semantic, salience-aware, and control-oriented components that operate at complementary time scales. To support long-horizon reasoning, BMAM organizes episodic memories along explicit timelines and retrieves evidence by fusing multiple complementary signals. Experiments on the LoCoMo benchmark show that BMAM achieves 78.45 percent accuracy under the standard long-horizon evaluation setting, and ablation analyses confirm that the hippocampus-inspired episodic memory subsystem plays a critical role in temporal reasoning.",
    "translation": "标题：BMAM：类脑多智能体记忆框架\n\n摘要：基于语言模型的智能体在长程交互中持续面临两大挑战：难以维持基于时间线的信息保存，以及无法在多次会话间保持行为一致性——我们将这种失效模式称为“灵魂侵蚀”。本文提出BMAM（类脑多智能体记忆框架），这是一种通用记忆架构，其将智能体记忆建模为功能专化的子系统集合，而非单一非结构化存储。受认知记忆系统启发，BMAM将记忆解构为情景记忆、语义记忆、显著性感知记忆与控制导向记忆四个在互补时间尺度上运作的组件。为支持长程推理，BMAM沿显式时间线组织情景记忆，并通过融合多重互补信号进行记忆检索。在LoCoMo基准测试中，BMAM在标准长程评估设定下达到78.45%的准确率，消融实验证实受海马体启发的的情景记忆子系统在时序推理中起着关键作用。",
    "url": "https://huggingface.co/papers/2601.20465",
    "arxiv_url": "https://arxiv.org/abs/2601.20465"
  },
  {
    "title": "JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion",
    "summary": "Audio-Visual Foundation Models, which are pretrained to jointly generate sound and visual content, have recently shown an unprecedented ability to model multi-modal generation and editing, opening new opportunities for downstream tasks. Among these tasks, video dubbing could greatly benefit from such priors, yet most existing solutions still rely on complex, task-specific pipelines that struggle in real-world settings. In this work, we introduce a single-model approach that adapts a foundational audio-video diffusion model for video-to-video dubbing via a lightweight LoRA. The LoRA enables the model to condition on an input audio-video while jointly generating translated audio and synchronized facial motion. To train this LoRA, we leverage the generative model itself to synthesize paired multilingual videos of the same speaker. Specifically, we generate multilingual videos with language switches within a single clip, and then inpaint the face and audio in each half to match the language of the other half. By leveraging the rich generative prior of the audio-visual model, our approach preserves speaker identity and lip synchronization while remaining robust to complex motion and real-world dynamics. We demonstrate that our approach produces high-quality dubbed videos with improved visual fidelity, lip synchronization, and robustness compared to existing dubbing pipelines.",
    "translation": "标题：JUST-DUB-IT：基于联合视听扩散模型的视频配音方法\n\n摘要：视听基础模型通过预训练联合生成声音与视觉内容，近期在多模态生成与编辑任务中展现出前所未有的建模能力，为下游应用开辟了新机遇。视频配音任务尤其能够受益于此先验知识，然而现有解决方案大多依赖复杂且任务特定的流程，在真实场景中常面临挑战。本研究提出一种单模型方法，通过轻量级LoRA适配基础音视频扩散模型，实现视频到视频的配音转换。该LoRA使模型能够以输入音视频为条件，同步生成翻译后的音频与协调的面部动作。为训练此LoRA，我们利用生成模型自身合成同一发言者的多语言配对视频：首先生成包含单片段内语言切换的多语言视频，随后对每半段视频进行面部与音频修复，使其语言特征与另半段匹配。通过充分挖掘视听模型的丰富生成先验，本方法在保持说话者身份特征与唇形同步的同时，对复杂动作和真实场景动态具有强鲁棒性。实验表明，相较于现有配音流程，本方法生成的配音视频在视觉保真度、唇形同步性与鲁棒性方面均表现出更优质量。",
    "url": "https://huggingface.co/papers/2601.22143",
    "arxiv_url": "https://arxiv.org/abs/2601.22143"
  },
  {
    "title": "FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning",
    "summary": "We propose FROST, an attention-aware method for efficient reasoning. Unlike traditional approaches, FROST leverages attention weights to prune uncritical reasoning paths, yielding shorter and more reliable reasoning trajectories. Methodologically, we introduce the concept of reasoning outliers and design an attention-based mechanism to remove them. Theoretically, FROST preserves and enhances the model's reasoning capacity while eliminating outliers at the sentence level. Empirically, we validate FROST on four benchmarks using two strong reasoning models (Phi-4-Reasoning and GPT-OSS-20B), outperforming state-of-the-art methods such as TALE and ThinkLess. Notably, FROST achieves an average 69.68% reduction in token usage and a 26.70% improvement in accuracy over the base model. Furthermore, in evaluations of attention outlier metrics, FROST reduces the maximum infinity norm by 15.97% and the average kurtosis by 91.09% compared to the base model. Code is available at https://github.com/robinzixuan/FROST",
    "translation": "标题：FROST：基于注意力机制过滤推理异常值的高效推理方法\n\n摘要：本文提出FROST——一种基于注意力感知的高效推理方法。与传统方法不同，FROST通过注意力权重剪枝非关键推理路径，从而生成更简短且更可靠的推理轨迹。在方法论层面，我们提出推理异常值的概念，并设计基于注意力的机制予以剔除。理论上，FROST在保持并增强模型推理能力的同时，实现了句子层级的异常值消除。实证研究中，我们使用两个强推理模型（Phi-4-Reasoning与GPT-OSS-20B）在四个基准测试上验证FROST，其性能优于TALE、ThinkLess等前沿方法。值得注意的是，相较于基础模型，FROST平均降低69.68%的令牌使用量，并提升26.70%的准确率。此外，在注意力异常值指标评估中，FROST将最大无穷范数降低15.97%，平均峰度减少91.09%。代码已开源：https://github.com/robinzixuan/FROST",
    "url": "https://huggingface.co/papers/2601.19001",
    "arxiv_url": "https://arxiv.org/abs/2601.19001"
  },
  {
    "title": "Reinforcement Learning from Meta-Evaluation: Aligning Language Models Without Ground-Truth Labels",
    "summary": "Most reinforcement learning (RL) methods for training large language models (LLMs) require ground-truth labels or task-specific verifiers, limiting scalability when correctness is ambiguous or expensive to obtain. We introduce Reinforcement Learning from Meta-Evaluation (RLME), which optimizes a generator using reward derived from an evaluator's answers to natural-language meta-questions (e.g., \"Is the answer correct?\" or \"Is the reasoning logically consistent?\"). RLME treats the evaluator's probability of a positive judgment as a reward and updates the generator via group-relative policy optimization, enabling learning without labels. Across a suite of experiments, we show that RLME achieves accuracy and sample efficiency comparable to label-based training, enables controllable trade-offs among multiple objectives, steers models toward reliable reasoning patterns rather than post-hoc rationalization, and generalizes to open-domain settings where ground-truth labels are unavailable, broadening the domains in which LLMs may be trained with RL.",
    "translation": "标题：基于元评估的强化学习：无需真实标签的语言模型对齐方法\n\n摘要：当前大多数用于训练大语言模型的强化学习方法需要真实标签或特定任务验证器，当正确性难以界定或获取成本高昂时，这种方法会限制模型的可扩展性。本文提出基于元评估的强化学习方法，该方法通过评估者对自然语言元问题的回答生成奖励信号来优化生成模型。元问题包括“该答案是否正确？”或“推理过程是否逻辑一致？”等类型。该方法将评估者给出肯定判断的概率作为奖励信号，并通过组间相对策略优化更新生成器，从而实现无需标签的学习。一系列实验表明：该方法在准确性和样本效率上达到与基于标签训练相当的水平；支持多目标间的可控权衡；能够引导模型形成可靠的推理模式而非事后合理化；在缺乏真实标签的开放域场景中具有良好的泛化能力，从而拓展了强化学习在大语言模型训练中的应用领域。",
    "url": "https://huggingface.co/papers/2601.21268",
    "arxiv_url": "https://arxiv.org/abs/2601.21268"
  },
  {
    "title": "Benchmarking Reward Hack Detection in Code Environments via Contrastive Analysis",
    "summary": "Recent advances in reinforcement learning for code generation have made robust environments essential to prevent reward hacking. As LLMs increasingly serve as evaluators in code-based RL, their ability to detect reward hacking remains understudied. In this paper, we propose a novel taxonomy of reward exploits spanning across 54 categories and introduce TRACE (Testing Reward Anomalies in Code Environments), a synthetically curated and human-verified benchmark containing 517 testing trajectories. Unlike prior work that evaluates reward hack detection in isolated classification scenarios, we contrast these evaluations with a more realistic, contrastive anomaly detection setup on TRACE. Our experiments reveal that models capture reward hacks more effectively in contrastive settings than in isolated classification settings, with GPT-5.2 with highest reasoning mode achieving the best detection rate at 63%, up from 45% in isolated settings on TRACE. Building on this insight, we demonstrate that state-of-the-art models struggle significantly more with semantically contextualized reward hacks compared to syntactically contextualized ones. We further conduct qualitative analyses of model behaviors, as well as ablation studies showing that the ratio of benign to hacked trajectories and analysis cluster sizes substantially impact detection performance. We release the benchmark and evaluation harness to enable the community to expand TRACE and evaluate their models.",
    "translation": "标题：基于对比分析的代码环境奖励攻击检测基准测试\n\n摘要：代码生成强化学习的最新进展使得鲁棒环境对于防止奖励攻击变得至关重要。随着大语言模型日益成为基于代码的强化学习评估工具，其检测奖励攻击的能力仍未得到充分研究。本文提出了一种涵盖54个类别的奖励攻击新型分类法，并引入了TRACE（代码环境奖励异常测试基准）——一个包含517条测试轨迹的合成构建且经人工验证的基准集。与以往在孤立分类场景中评估奖励攻击检测的研究不同，我们在TRACE基准上采用更贴近实际的对比式异常检测框架进行对比评估。实验表明，模型在对比设置下比孤立分类设置能更有效地识别奖励攻击：在TRACE基准上，GPT-5.2最高推理模式的检测率从孤立设置的45%提升至63%。基于此发现，我们论证了当前最先进模型对语义语境化奖励攻击的检测难度显著高于句法语境化攻击。我们进一步对模型行为进行了定性分析，并通过消融实验证明良性轨迹与攻击轨迹的比例及分析聚类规模会显著影响检测性能。本研究公开了基准数据集与评估框架，以推动学界扩展TRACE基准并评估相关模型。\n\n---\n**改写说明**：\n- 规范并统一了相关学术术语和表达方式\n- 调整句式结构，使中文表达更符合学术语境和习惯\n- 优化技术细节和逻辑关系的呈现，确保专业性和准确性\n\n如果您需要更简洁或侧重不同技术细节的译法，我可以继续为您优化调整。",
    "url": "https://huggingface.co/papers/2601.20103",
    "arxiv_url": "https://arxiv.org/abs/2601.20103"
  },
  {
    "title": "Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance",
    "summary": "Audio fingerprinting provides an identifiable representation of acoustic signals, which can be later used for identification and retrieval systems. To obtain a discriminative representation, the input audio is usually segmented into shorter time intervals, allowing local acoustic features to be extracted and analyzed. Modern neural approaches typically operate on short, fixed-duration audio segments, yet the choice of segment duration is often made heuristically and rarely examined in depth. In this paper, we study how segment length affects audio fingerprinting performance. We extend an existing neural fingerprinting architecture to adopt various segment lengths and evaluate retrieval accuracy across different segment lengths and query durations. Our results show that short segment lengths (0.5-second) generally achieve better performance. Moreover, we evaluate LLM capacity in recommending the best segment length, which shows that GPT-5-mini consistently gives the best suggestions across five considerations among three studied LLMs. Our findings provide practical guidance for selecting segment duration in large-scale neural audio retrieval systems.",
    "translation": "标题：分段长度的重要性：音频指纹识别性能中分段长度的研究\n\n摘要：音频指纹识别为声学信号提供了一种可识别的表征方式，该表征后续可用于识别与检索系统。为获得具有区分性的表征，输入音频通常被分割为较短的时间区间，以便提取和分析局部声学特征。现代神经网络方法通常在固定时长的短音频片段上操作，但片段时长的选择往往基于启发式方法，鲜有深入研究。本文系统研究了分段长度对音频指纹识别性能的影响。我们扩展了一种现有的神经指纹识别架构，使其能够适配不同分段长度，并评估了不同分段长度与查询时长下的检索准确率。实验结果表明，较短的分段长度（0.5秒）通常能获得更优的性能。此外，我们评估了大语言模型在推荐最佳分段长度方面的能力，发现在所研究的三种大语言模型中，GPT-5-mini在五项评估维度上均能给出最佳建议。本研究结果为大规模神经音频检索系统中分段时长的选择提供了实践指导。",
    "url": "https://huggingface.co/papers/2601.17690",
    "arxiv_url": "https://arxiv.org/abs/2601.17690"
  },
  {
    "title": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement",
    "summary": "Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design data -- a collection of real-world designs that implicitly capture designer's principles -- to learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies a design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within a style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.",
    "translation": "标题：PRISM：从数据中学习设计知识以提升风格化设计水平\n\n摘要：平面设计通常需要探索不同的风格方向，这对非专业人士而言往往耗时费力。本文针对基于自然语言指令进行风格化设计改进的问题展开研究。尽管视觉语言模型在平面设计领域已取得初步成果，但其预训练的风格知识通常过于笼统，且与特定领域数据存在偏差。例如，视觉语言模型可能将极简主义与抽象设计相关联，而设计师更注重形状与色彩的选择。我们的核心思路是借助设计数据——即隐含设计师原则的真实设计案例集合——来学习设计知识并指导风格化改进。我们提出PRISM（先验信息驱动的风格化修改）框架，通过三个阶段构建并应用设计知识库：（1）对高方差设计进行聚类以捕捉风格内部的多样性；（2）将每个聚类总结为可操作的设计知识；（3）在推理过程中检索相关知识以实现风格感知的优化。在Crello数据集上的实验表明，PRISM在风格对齐任务中以1.49的平均排名（越接近1越好）超越基线方法。用户研究进一步验证了该结果，显示设计师持续倾向于选择PRISM生成的设计方案。",
    "url": "https://huggingface.co/papers/2601.11747",
    "arxiv_url": "https://arxiv.org/abs/2601.11747"
  },
  {
    "title": "WebArbiter: A Principle-Guided Reasoning Process Reward Model for Web Agents",
    "summary": "Web agents hold great potential for automating complex computer tasks, yet their interactions involve long-horizon, sequential decision-making with irreversible actions. In such settings, outcome-based supervision is sparse and delayed, often rewarding incorrect trajectories and failing to support inference-time scaling. This motivates the use of Process Reward Models (WebPRMs) for web navigation, but existing approaches remain limited: scalar WebPRMs collapse progress into coarse, weakly grounded signals, while checklist-based WebPRMs rely on brittle template matching that fails under layout or semantic changes and often mislabels superficially correct actions as successful, providing little insight or interpretability. To address these challenges, we introduce WebArbiter, a reasoning-first, principle-inducing WebPRM that formulates reward modeling as text generation, producing structured justifications that conclude with a preference verdict and identify the action most conducive to task completion under the current context. Training follows a two-stage pipeline: reasoning distillation equips the model with coherent principle-guided reasoning, and reinforcement learning corrects teacher biases by directly aligning verdicts with correctness, enabling stronger generalization. To support systematic evaluation, we release WebPRMBench, a comprehensive benchmark spanning four diverse web environments with rich tasks and high-quality preference annotations. On WebPRMBench, WebArbiter-7B outperforms the strongest baseline, GPT-5, by 9.1 points. In reward-guided trajectory search on WebArena-Lite, it surpasses the best prior WebPRM by up to 7.2 points, underscoring its robustness and practical value in real-world complex web tasks.",
    "translation": "标题：WebArbiter：一种面向网络智能体的原则引导推理过程奖励模型\n\n摘要：网络智能体在自动化复杂计算机任务方面具有巨大潜力，但其交互过程涉及长周期、序列化的决策，且包含不可逆操作。在此类场景中，基于结果的监督信号稀疏且延迟，常常错误奖励无效轨迹，且无法支持推理时的扩展需求。这促使了过程奖励模型在网络导航任务中的应用，但现有方法仍存在局限：标量化WebPRM将进展压缩为粗糙且缺乏依据的信号，而基于清单的WebPRM依赖脆弱的模板匹配机制，在界面布局或语义变化时容易失效，并常将表面正确的动作误判为成功，导致模型可解释性与洞察力不足。为解决这些挑战，我们提出WebArbiter——一种推理优先、原则引导的WebPRM框架，将奖励建模转化为文本生成任务，生成包含偏好判定结论的结构化论证，并识别当前情境下最有利于任务完成的动作。训练采用两阶段流程：推理蒸馏使模型掌握连贯的原则引导推理能力，强化学习则通过直接对齐判定结果与正确性来修正教师模型偏差，从而提升泛化性能。为支持系统化评估，我们发布了WebPRMBench基准测试集，涵盖四个多样化网络环境，包含丰富任务场景与高质量偏好标注。在WebPRMBench上，WebArbiter-7B以9.1分的优势超越最强基线模型GPT-5。在WebArena-Lite的奖励引导轨迹搜索任务中，其表现较现有最优WebPRM提升最高达7.2分，彰显了该模型在现实复杂网络任务中的鲁棒性与实用价值。",
    "url": "https://huggingface.co/papers/2601.21872",
    "arxiv_url": "https://arxiv.org/abs/2601.21872"
  },
  {
    "title": "Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation",
    "summary": "The generalization capabilities of robotic manipulation policies are heavily influenced by the choice of visual representations. Existing approaches typically rely on representations extracted from pre-trained encoders, using two dominant types of features: global features, which summarize an entire image via a single pooled vector, and dense features, which preserve a patch-wise embedding from the final encoder layer. While widely used, both feature types mix task-relevant and irrelevant information, leading to poor generalization under distribution shifts, such as changes in lighting, textures, or the presence of distractors. In this work, we explore an intermediate structured alternative: Slot-Based Object-Centric Representations (SBOCR), which group dense features into a finite set of object-like entities. This representation permits to naturally reduce the noise provided to the robotic manipulation policy while keeping enough information to efficiently perform the task. We benchmark a range of global and dense representations against intermediate slot-based representations, across a suite of simulated and real-world manipulation tasks ranging from simple to complex. We evaluate their generalization under diverse visual conditions, including changes in lighting, texture, and the presence of distractors. Our findings reveal that SBOCR-based policies outperform dense and global representation-based policies in generalization settings, even without task-specific pretraining. These insights suggest that SBOCR is a promising direction for designing visual systems that generalize effectively in dynamic, real-world robotic environments.",
    "translation": "标题：聚焦任务相关特征：以物体为中心的表示方法提升机器人操作泛化能力\n\n摘要：机器人操作策略的泛化能力在很大程度上受视觉表示选择的影响。现有方法通常依赖于预训练编码器提取的表示，主要采用两种特征类型：全局特征（通过单一池化向量概括整幅图像）和密集特征（保留编码器最后一层的分块嵌入）。尽管广泛应用，这两种特征类型均混合了任务相关与无关信息，导致在光照、纹理变化或存在干扰物等分布偏移情况下泛化性能较差。本研究探索了一种中间结构化替代方案：基于槽位的物体中心表示（SBOCR），该方法将密集特征分组为有限个类物体实体。这种表示能够自然减少提供给机器人操作策略的噪声，同时保留足够信息以高效执行任务。我们在从简单到复杂的一系列仿真与真实世界操作任务中，系统比较了多种全局表示、密集表示与基于槽位的中间表示。通过评估它们在光照、纹理变化及存在干扰物等多种视觉条件下的泛化能力，发现基于SBOCR的策略在泛化场景中优于基于密集表示和全局表示的策略，且无需任务特定预训练。这些结果表明，SBOCR为设计能在动态真实世界机器人环境中有效泛化的视觉系统提供了有前景的研究方向。",
    "url": "https://huggingface.co/papers/2601.21416",
    "arxiv_url": "https://arxiv.org/abs/2601.21416"
  },
  {
    "title": "WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models",
    "summary": "Recent advances in generative foundational models, often termed \"world models,\" have propelled interest in applying them to critical tasks like robotic planning and autonomous system training. For reliable deployment, these models must exhibit high physical fidelity, accurately simulating real-world dynamics. Existing physics-based video benchmarks, however, suffer from entanglement, where a single test simultaneously evaluates multiple physical laws and concepts, fundamentally limiting their diagnostic capability. We introduce WorldBench, a novel video-based benchmark specifically designed for concept-specific, disentangled evaluation, allowing us to rigorously isolate and assess understanding of a single physical concept or law at a time. To make WorldBench comprehensive, we design benchmarks at two different levels: 1) an evaluation of intuitive physical understanding with concepts such as object permanence or scale/perspective, and 2) an evaluation of low-level physical constants and material properties such as friction coefficients or fluid viscosity. When SOTA video-based world models are evaluated on WorldBench, we find specific patterns of failure in particular physics concepts, with all tested models lacking the physical consistency required to generate reliable real-world interactions. Through its concept-specific evaluation, WorldBench offers a more nuanced and scalable framework for rigorously evaluating the physical reasoning capabilities of video generation and world models, paving the way for more robust and generalizable world-model-driven learning.",
    "translation": "标题：WorldBench：面向世界模型诊断性评估的物理概念解耦基准\n\n摘要：生成式基础模型（常被称为“世界模型”）的最新进展激发了将其应用于机器人规划与自主系统训练等关键任务的兴趣。为确保可靠部署，此类模型必须具备高物理保真度，能够准确模拟真实世界动态。然而，现有基于物理的视频基准普遍存在概念耦合问题——单个测试同时评估多项物理定律与概念，这从根本上限制了其诊断能力。我们提出WorldBench，这是一个专为概念特异性解耦评估设计的新型视频基准，能够严格隔离并逐项评估对单一物理概念或定律的理解。为构建全面评估体系，我们设计了两个层级的基准：1）针对物体恒存性、尺度/透视等概念的直观物理理解评估；2）针对摩擦系数、流体黏度等底层物理常数与材料属性的评估。通过对当前最先进的视频世界模型进行WorldBench测试，我们发现所有被测模型均存在特定物理概念上的系统性缺陷，缺乏生成可靠真实世界交互所需的物理一致性。WorldBench通过其概念特异性评估机制，为视频生成与世界模型的物理推理能力提供了更精细、可扩展的严谨评估框架，为开发更鲁棒、更具泛化能力的世界模型驱动学习开辟了新路径。",
    "url": "https://huggingface.co/papers/2601.21282",
    "arxiv_url": "https://arxiv.org/abs/2601.21282"
  },
  {
    "title": "STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation",
    "summary": "Visual foundation models provide strong perceptual features for robotics, but their dense representations lack explicit object-level structure, limiting robustness and contractility in manipulation tasks. We propose STORM (Slot-based Task-aware Object-centric Representation for robotic Manipulation), a lightweight object-centric adaptation module that augments frozen visual foundation models with a small set of semantic-aware slots for robotic manipulation. Rather than retraining large backbones, STORM employs a multi-phase training strategy: object-centric slots are first stabilized through visual--semantic pretraining using language embeddings, then jointly adapted with a downstream manipulation policy. This staged learning prevents degenerate slot formation and preserves semantic consistency while aligning perception with task objectives. Experiments on object discovery benchmarks and simulated manipulation tasks show that STORM improves generalization to visual distractors, and control performance compared to directly using frozen foundation model features or training object-centric representations end-to-end. Our results highlight multi-phase adaptation as an efficient mechanism for transforming generic foundation model features into task-aware object-centric representations for robotic control.",
    "translation": "标题：STORM：面向机器人操作的基于槽位的任务感知物体中心表征\n\n摘要：视觉基础模型为机器人学提供了强大的感知特征，但其稠密表征缺乏显式的物体级结构，限制了操作任务中的鲁棒性与可泛化性。本文提出STORM（面向机器人操作的基于槽位的任务感知物体中心表征），这是一种轻量级的物体中心自适应模块，通过为机器人操作引入少量语义感知槽位来增强冻结的视觉基础模型。STORM采用多阶段训练策略而非重新训练大型骨干网络：首先通过语言嵌入的视觉-语义预训练稳定物体中心槽位，随后与下游操作策略联合自适应。这种分阶段学习避免了槽位退化形成，在保持语义一致性的同时将感知与任务目标对齐。在物体发现基准测试与仿真操作任务上的实验表明，相较于直接使用冻结基础模型特征或端到端训练物体中心表征，STORM能有效提升对视觉干扰的泛化能力与控制性能。我们的研究结果凸显了多阶段自适应作为一种高效机制，可将通用基础模型特征转化为适用于机器人控制的任务感知物体中心表征。",
    "url": "https://huggingface.co/papers/2601.20381",
    "arxiv_url": "https://arxiv.org/abs/2601.20381"
  },
  {
    "title": "Flow-based Extremal Mathematical Structure Discovery",
    "summary": "The discovery of extremal structures in mathematics requires navigating vast and nonconvex landscapes where analytical methods offer little guidance and brute-force search becomes intractable. We introduce FlowBoost, a closed-loop generative framework that learns to discover rare and extremal geometric structures by combining three components: (i) a geometry-aware conditional flow-matching model that learns to sample high-quality configurations, (ii) reward-guided policy optimization with action exploration that directly optimizes the generation process toward the objective while maintaining diversity, and (iii) stochastic local search for both training-data generation and final refinement. Unlike prior open-loop approaches, such as PatternBoost that retrains on filtered discrete samples, or AlphaEvolve which relies on frozen Large Language Models (LLMs) as evolutionary mutation operators, FlowBoost enforces geometric feasibility during sampling, and propagates reward signal directly into the generative model, closing the optimization loop and requiring much smaller training sets and shorter training times, and reducing the required outer-loop iterations by orders of magnitude, while eliminating dependence on LLMs. We demonstrate the framework on four geometric optimization problems: sphere packing in hypercubes, circle packing maximizing sum of radii, the Heilbronn triangle problem, and star discrepancy minimization. In several cases, FlowBoost discovers configurations that match or exceed the best known results. For circle packings, we improve the best known lower bounds, surpassing the LLM-based system AlphaEvolve while using substantially fewer computational resources.",
    "translation": "标题：基于流模型的极值数学结构发现\n\n摘要：数学中极值结构的发现需要在广阔且非凸的搜索空间中探索，分析方法难以提供有效指导，而暴力搜索又不可行。本文提出FlowBoost，一种闭环生成框架，通过整合三个核心组件学习发现稀有且极值的几何结构：（一）几何感知的条件流匹配模型，学习采样高质量构型；（二）奖励引导的策略优化与动作探索机制，在保持多样性的同时直接优化生成过程以趋近目标；（三）用于训练数据生成与最终优化的随机局部搜索。与以往开环方法（如依赖过滤离散样本重训练的PatternBoost，或依靠冻结大语言模型作为进化变异算子的AlphaEvolve）不同，FlowBoost在采样过程中强制保证几何可行性，并将奖励信号直接反馈至生成模型，从而形成闭环优化。该方法大幅减少所需训练集规模与训练时间，将外层循环迭代次数降低数个数量级，同时消除对大语言模型的依赖。我们在四个几何优化问题上验证了该框架：超立方体中的球体填充、半径和最大化的圆盘填充、Heilbronn三角形问题以及星形差异最小化。在多个案例中，FlowBoost发现的构型达到或超越了已知最佳结果。针对圆盘填充问题，我们提升了已知下界，在显著减少计算资源消耗的同时，超越了基于大语言模型的AlphaEvolve系统。",
    "url": "https://huggingface.co/papers/2601.18005",
    "arxiv_url": "https://arxiv.org/abs/2601.18005"
  }
]