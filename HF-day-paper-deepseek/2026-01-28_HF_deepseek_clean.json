[
  {
    "title": "AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security",
    "summary": "The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.",
    "translation": "标题：AgentDoG：面向AI智能体安全与防护的诊断性护栏框架\n\n摘要：AI智能体的兴起，因其自主使用工具并与环境交互的特性，带来了复杂的安全与防护挑战。当前护栏模型缺乏对智能体风险的感知能力，且在风险诊断方面透明度不足。为构建一个能够覆盖复杂且大量风险行为的智能体护栏，我们首先提出了一种统一的三维分类法，从风险来源（何处）、失效模式（如何）及后果（何种）三个正交维度对智能体风险进行分类。在这一结构化、层次化的分类法指导下，我们引入了一个新的细粒度智能体安全基准（ATBench）以及一个面向智能体安全与防护的诊断性护栏框架（AgentDoG）。AgentDoG能够对智能体运行轨迹进行细粒度、上下文感知的监控。更为关键的是，AgentDoG能够诊断不安全行为及看似安全但不合理行为的根本原因，提供超越二元标签的溯源信息和透明度，从而促进有效的智能体对齐。AgentDoG提供了基于Qwen和Llama模型系列的三种参数规模（4B、7B和8B）的变体。大量实验结果表明，AgentDoG在多样且复杂的交互场景中，实现了智能体安全管控方面的最先进性能。所有模型与数据集均已开源发布。",
    "url": "https://huggingface.co/papers/2601.18491",
    "arxiv_url": "https://arxiv.org/abs/2601.18491"
  },
  {
    "title": "AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning",
    "summary": "When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce AdaReasoner, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.",
    "translation": "标题：AdaReasoner：面向迭代视觉推理的动态工具编排框架\n\n摘要：当人类面临超出自身即时能力的问题时，常借助工具解决，这为提升多模态大语言模型（MLLMs）的视觉推理能力提供了可行范式。有效的推理关键在于：即使面对新工具或新任务，模型仍需掌握在何时调用何种工具，以及如何在多步骤中组合使用工具。本文提出AdaReasoner系列多模态模型，其将工具使用作为一种通用推理技能进行学习，而非局限于特定工具或依赖显式监督。AdaReasoner的实现基于三大核心机制：（一）可扩展的数据构建流程，使模型接触长跨度、多步骤的工具交互场景；（二）Tool-GRPO强化学习算法，根据终端任务成功率优化工具选择与序列规划；（三）自适应学习机制，动态调节工具使用策略。这些组件协同工作，使模型能够从任务上下文与中间结果推断工具效用，实现多工具协调运作，并泛化至未见过的工具。实验表明，AdaReasoner展现出强大的工具适应与泛化能力：尽管从未接受相关显式训练，它能自主采用有益工具、抑制无关工具，并依据任务需求动态调整工具使用频率。这些能力使其在多项挑战性基准测试中取得领先性能，使7B基础模型平均提升24.9%，并在VSP、Jigsaw等多项任务上超越GPT-5等强竞争力闭源系统。",
    "url": "https://huggingface.co/papers/2601.18631",
    "arxiv_url": "https://arxiv.org/abs/2601.18631"
  },
  {
    "title": "A Pragmatic VLA Foundation Model",
    "summary": "Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8times (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.",
    "translation": "标题：一种实用的视觉-语言-动作基础模型\n\n摘要：视觉-语言-动作基础模型在机器人操作领域展现出巨大潜力，理想的模型应能准确泛化至不同任务与平台，同时确保成本效益（如适应所需的数据与GPU计算时间）。为此，我们基于9种主流双机械臂配置采集的约20,000小时真实世界数据，开发了LingBot-VLA模型。通过在3个机器人平台上进行系统评估（每个平台完成100项任务，每项任务包含130次训练后测试），该模型显著优于现有方法，展现出卓越的性能与广泛的泛化能力。我们还构建了高效代码库，在8 GPU训练配置下可实现每秒每GPU处理261个样本的吞吐量，相比现有面向VLA的代码库加速1.5~2.8倍（具体取决于所基于的视觉语言模型）。上述特性确保本模型适用于实际场景部署。为推进机器人学习领域发展，我们公开提供代码、基础模型与基准数据，致力于支持更具挑战性的任务并推动建立科学的评估标准。",
    "url": "https://huggingface.co/papers/2601.18692",
    "arxiv_url": "https://arxiv.org/abs/2601.18692"
  },
  {
    "title": "Youtu-VL: Unleashing Visual Potential via Unified Vision-Language Supervision",
    "summary": "Despite the significant advancements represented by Vision-Language Models (VLMs), current architectures often exhibit limitations in retaining fine-grained visual information, leading to coarse-grained multimodal comprehension. We attribute this deficiency to a suboptimal training paradigm inherent in prevailing VLMs, which exhibits a text-dominant optimization bias by conceptualizing visual signals merely as passive conditional inputs rather than supervisory targets. To mitigate this, we introduce Youtu-VL, a framework leveraging the Vision-Language Unified Autoregressive Supervision (VLUAS) paradigm, which fundamentally shifts the optimization objective from ``vision-as-input'' to ``vision-as-target.'' By integrating visual tokens directly into the prediction stream, Youtu-VL applies unified autoregressive supervision to both visual details and linguistic content. Furthermore, we extend this paradigm to encompass vision-centric tasks, enabling a standard VLM to perform vision-centric tasks without task-specific additions. Extensive empirical evaluations demonstrate that Youtu-VL achieves competitive performance on both general multimodal tasks and vision-centric tasks, establishing a robust foundation for the development of comprehensive generalist visual agents.",
    "translation": "标题：Youtu-VL：通过统一的视觉-语言监督释放视觉潜能\n\n摘要：尽管视觉-语言模型（VLMs）取得了显著进展，但当前架构在保留细粒度视觉信息方面往往存在局限，导致多模态理解停留在粗粒度层面。我们将此不足归因于主流VLMs固有的次优训练范式，该范式表现出文本主导的优化偏差，仅将视觉信号视为被动的条件输入而非监督目标。为缓解这一问题，我们提出了Youtu-VL框架，其采用视觉-语言统一自回归监督（VLUAS）范式，从根本上将优化目标从“视觉作为输入”转变为“视觉作为目标”。通过将视觉标记直接整合到预测流中，Youtu-VL对视觉细节与语言内容同时施加统一的自回归监督。此外，我们将该范式扩展至以视觉为中心的任务，使标准VLM无需任务特定修改即可执行此类任务。大量实证评估表明，Youtu-VL在通用多模态任务和以视觉为中心的任务上均展现出竞争力，为开发全面的通用视觉智能体奠定了坚实基础。",
    "url": "https://huggingface.co/papers/2601.19798",
    "arxiv_url": "https://arxiv.org/abs/2601.19798"
  },
  {
    "title": "AVMeme Exam: A Multimodal Multilingual Multicultural Benchmark for LLMs' Contextual and Cultural Knowledge and Thinking",
    "summary": "Internet audio-visual clips convey meaning through time-varying sound and motion, which extend beyond what text alone can represent. To examine whether AI models can understand such signals in human cultural contexts, we introduce AVMeme Exam, a human-curated benchmark of over one thousand iconic Internet sounds and videos spanning speech, songs, music, and sound effects. Each meme is paired with a unique Q&A assessing levels of understanding from surface content to context and emotion to usage and world knowledge, along with metadata such as original year, transcript, summary, and sensitivity. We systematically evaluate state-of-the-art multimodal large language models (MLLMs) alongside human participants using this benchmark. Our results reveal a consistent limitation: current models perform poorly on textless music and sound effects, and struggle to think in context and in culture compared to surface content. These findings highlight a key gap in human-aligned multimodal intelligence and call for models that can perceive contextually and culturally beyond the surface of what they hear and see. Project page: avmemeexam.github.io/public",
    "translation": "标题：AVMeme Exam：面向大语言模型情境与文化知识与思维的多模态多语言多文化基准测试\n\n摘要：网络视听片段通过随时间变化的声音与动作传递意义，其内涵远超纯文本所能涵盖。为探究人工智能模型能否在人类文化语境中理解此类信号，我们提出了AVMeme Exam——一个由人工精心构建的基准测试集，包含千余个标志性网络声音与视频片段，涵盖语音、歌曲、音乐及音效等多种形式。每个模因均配有专属问答，评估维度从表层内容理解延伸至语境与情感解析，再到使用场景与世界知识关联，同时附带原始年份、文字转录、内容摘要及敏感度等元数据。基于此基准，我们系统评估了当前前沿的多模态大语言模型（MLLMs）并与人类参与者进行对比。研究结果揭示了一个持续性局限：相较于表层内容理解，现有模型在无文本音乐与音效理解方面表现欠佳，且在情境化思维与文化语境思维方面存在明显不足。这些发现凸显了人类对齐多模态智能发展的关键缺口，呼吁开发能够超越视听表层、实现情境与文化深度感知的模型。项目主页：avmemeexam.github.io/public",
    "url": "https://huggingface.co/papers/2601.17645",
    "arxiv_url": "https://arxiv.org/abs/2601.17645"
  },
  {
    "title": "Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models",
    "summary": "Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-level performance in formal and abstract domains such as mathematics and programming has been achieved in current systems by relying predominantly on verbal reasoning. However, they still lag far behind humans in domains like physical and spatial intelligence, which require richer representations and prior knowledge. The emergence of unified multimodal models (UMMs) capable of both verbal and visual generation has therefore sparked interest in more human-like reasoning grounded in complementary multimodal pathways, though their benefits remain unclear. From a world-model perspective, this paper presents the first principled study of when and how visual generation benefits reasoning. Our key position is the visual superiority hypothesis: for certain tasks--particularly those grounded in the physical world--visual generation more naturally serves as world models, whereas purely verbal world models encounter bottlenecks arising from representational limitations or insufficient prior knowledge. Theoretically, we formalize internal world modeling as a core component of CoT reasoning and analyze distinctions among different forms of world models. Empirically, we identify tasks that necessitate interleaved visual-verbal CoT reasoning, constructing a new evaluation suite, VisWorld-Eval. Controlled experiments on a state-of-the-art UMM show that interleaved CoT significantly outperforms purely verbal CoT on tasks that favor visual world modeling, but offers no clear advantage otherwise. Together, this work clarifies the potential of multimodal world modeling for more powerful, human-like multimodal AI.",
    "translation": "标题：视觉生成通过多模态世界模型解锁类人推理能力\n\n摘要：人类通过构建内部世界模型并操纵其中的概念进行推理。人工智能的最新进展，特别是思维链推理方法，近似实现了这种人类认知能力——世界模型被认为嵌入于大语言模型之中。当前系统主要依赖语言推理，已在数学、编程等抽象领域达到专家水平，但在需要丰富表征与先验知识的物理空间智能等领域仍远落后于人类。兼具语言与视觉生成能力的统一多模态模型的出现，引发了基于互补多模态通路的类人推理研究热潮，但其实际效益尚不明确。本文从世界模型视角出发，首次系统探究视觉生成在何种情境及如何提升推理能力。核心观点是视觉优势假说：对于物理世界相关任务，视觉生成能更自然地构建世界模型，而纯语言世界模型会受限于表征能力不足或先验知识匮乏。理论上，我们将内部世界建模形式化为思维链推理的核心组件，并分析不同世界模型形式的差异。实证方面，我们识别出需要视觉-语言交错推理的任务，构建了新型评估框架VisWorld-Eval。在先进统一多模态模型上的对照实验表明：在适合视觉世界建模的任务中，交错式思维链推理显著优于纯语言推理，而在其他任务中未显现明显优势。本研究阐明了多模态世界模型在构建更强大、更类人的多模态人工智能方面的潜力。",
    "url": "https://huggingface.co/papers/2601.19834",
    "arxiv_url": "https://arxiv.org/abs/2601.19834"
  },
  {
    "title": "World Craft: Agentic Framework to Create Visualizable Worlds via Text",
    "summary": "Large Language Models (LLMs) motivate generative agent simulation (e.g., AI Town) to create a ``dynamic world'', holding immense value across entertainment and research. However, for non-experts, especially those without programming skills, it isn't easy to customize a visualizable environment by themselves. In this paper, we introduce World Craft, an agentic world creation framework to create an executable and visualizable AI Town via user textual descriptions. It consists of two main modules, World Scaffold and World Guild. World Scaffold is a structured and concise standardization to develop interactive game scenes, serving as an efficient scaffolding for LLMs to customize an executable AI Town-like environment. World Guild is a multi-agent framework to progressively analyze users' intents from rough descriptions, and synthesizes required structured contents (\\eg environment layout and assets) for World Scaffold . Moreover, we construct a high-quality error-correction dataset via reverse engineering to enhance spatial knowledge and improve the stability and controllability of layout generation, while reporting multi-dimensional evaluation metrics for further analysis. Extensive experiments demonstrate that our framework significantly outperforms existing commercial code agents (Cursor and Antigravity) and LLMs (Qwen3 and Gemini-3-Pro). in scene construction and narrative intent conveyance, providing a scalable solution for the democratization of environment creation.",
    "translation": "标题：World Craft：基于文本构建可视化世界的智能体框架\n\n摘要：大型语言模型（LLM）推动了生成式智能体仿真（如AI Town）的发展，以构建“动态世界”，在娱乐与研究领域具有重要价值。然而，对于非专业人士，尤其是缺乏编程技能的用户而言，自行定制可视化环境存在困难。本文提出World Craft，一种基于用户文本描述构建可执行、可视化AI Town的智能体世界创建框架。该框架包含两大核心模块：World Scaffold与World Guild。World Scaffold是一种结构化、简洁的交互式游戏场景开发标准化方案，为LLM定制可执行的类AI Town环境提供高效脚手架。World Guild则是一个多智能体框架，能够逐步解析用户粗略描述中的意图，并为World Scaffold合成所需的结构化内容（如环境布局与资源素材）。此外，我们通过逆向工程构建高质量纠错数据集，以增强空间知识理解，提升布局生成的稳定性与可控性，同时提供多维评估指标以供深入分析。大量实验表明，本框架在场景构建与叙事意图传达方面显著优于现有商业代码智能体（Cursor与Antigravity）及大型语言模型（Qwen3与Gemini-3-Pro），为环境创建的普及化提供了可扩展的解决方案。",
    "url": "https://huggingface.co/papers/2601.09150",
    "arxiv_url": "https://arxiv.org/abs/2601.09150"
  },
  {
    "title": "Post-LayerNorm Is Back: Stable, ExpressivE, and Deep",
    "summary": "Large language model (LLM) scaling is hitting a wall. Widening models yields diminishing returns, and extending context length does not improve fundamental expressivity. In contrast, depth scaling offers theoretically superior expressivity, yet current Transformer architectures struggle to train reliably at extreme depths. We revisit the Post-LayerNorm (Post-LN) formulation, whose instability at scale caused its replacement by Pre-LN in modern LLMs. We show that the central failure mode of Post-LN arises from the ResNet-style residual pathway, which introduces gradient vanishing in deep networks. We present Keel, a Post-LN Transformer that replaces this residual path with a Highway-style connection. This modification preserves the gradient flow through the residual branch, preventing signal vanishing from the top layers to the bottom. Unlike prior methods, Keel enables stable training at extreme depths without requiring specialized initialization or complex optimization tricks. Keel trains robustly at depths exceeding 1000 layers and consistently improves perplexity and depth-scaling characteristics over Pre-LN. These findings indicate that Post-LN, when paired with a Highway-style connection, provides a simple and effective foundation for building deeply scalable LLMs, opening the possibility for future infinite-depth architectures.",
    "translation": "标题：后层归一化回归：稳定、高表达力与深度扩展\n\n摘要：大语言模型的规模扩展正面临瓶颈。模型宽度的增加带来收益递减，而上下文长度的延伸并未提升其根本表达能力。相比之下，深度扩展在理论上具备更优的表达潜力，然而当前Transformer架构在极端深度下难以实现稳定训练。本研究重新审视后层归一化架构——因其在大规模训练中的不稳定性，已被前层归一化方案取代。我们发现后层归一化的核心缺陷源于残差网络式的连接路径，该设计会导致深层网络中的梯度消失问题。为此，我们提出Keel架构：一种采用高速公路式连接替代传统残差路径的后层归一化Transformer。这种改进保持了残差分支的梯度流动，防止顶层信号向底层传递时的衰减现象。与现有方法不同，Keel无需特殊初始化或复杂优化技巧即可实现极端深度下的稳定训练。实验表明，Keel在超过1000层的深度下仍能稳健训练，其困惑度与深度扩展特性持续优于前层归一化架构。这些发现证明，当后层归一化与高速公路式连接结合时，可为构建深度可扩展的大语言模型提供简洁有效的框架，为未来无限深度架构的探索开辟了新路径。",
    "url": "https://huggingface.co/papers/2601.19895",
    "arxiv_url": "https://arxiv.org/abs/2601.19895"
  },
  {
    "title": "FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning",
    "summary": "The rapid expansion of long-context Large Language Models (LLMs) has reignited debate on whether Retrieval-Augmented Generation (RAG) remains necessary. However, empirical evidence reveals persistent limitations of long-context inference, including the lost-in-the-middle phenomenon, high computational cost, and poor scalability for multi-document reasoning. Conversely, traditional RAG systems, while efficient, are constrained by flat chunk-level retrieval that introduces semantic noise and fails to support structured cross-document synthesis.\n  We present FABLE, a Forest-based Adaptive Bi-path LLM-Enhanced retrieval framework that integrates LLMs into both knowledge organization and retrieval. FABLE constructs LLM-enhanced hierarchical forest indexes with multi-granularity semantic structures, then employs a bi-path strategy combining LLM-guided hierarchical traversal with structure-aware propagation for fine-grained evidence acquisition, with explicit budget control for adaptive efficiency trade-offs.\n  Extensive experiments demonstrate that FABLE consistently outperforms SOTA RAG methods and achieves comparable accuracy to full-context LLM inference with up to 94\\% token reduction, showing that long-context LLMs amplify rather than fully replace the need for structured retrieval.",
    "translation": "标题：FABLE：基于森林的自适应双路径LLM增强检索用于多文档推理\n\n摘要：长上下文大语言模型（LLM）的快速发展重新引发了关于检索增强生成（RAG）是否仍有必要的讨论。然而，实证研究表明，长上下文推理仍存在持续性的局限，包括“中间迷失”现象、高昂的计算成本以及多文档推理的可扩展性不足。相反，传统的RAG系统虽然高效，但受限于平面化的分块检索机制，这种机制会引入语义噪声且无法支持结构化的跨文档综合。\n\n我们提出了FABLE，一种基于森林的自适应双路径LLM增强检索框架，它将LLM同时整合到知识组织和检索过程中。FABLE构建了具有多粒度语义结构的LLM增强分层森林索引，随后采用双路径策略，结合LLM引导的分层遍历与结构感知传播，以进行细粒度证据获取，并通过显式的预算控制实现自适应效率权衡。\n\n大量实验表明，FABLE持续优于当前最先进的RAG方法，并在实现与全上下文LLM推理相当的准确率的同时，最高可减少94%的令牌消耗。这证明长上下文LLM放大了而非完全取代了对结构化检索的需求。",
    "url": "https://huggingface.co/papers/2601.18116",
    "arxiv_url": "https://arxiv.org/abs/2601.18116"
  },
  {
    "title": "TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment",
    "summary": "In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.",
    "translation": "标题：TriPlay-RL：面向大语言模型安全对齐的三角色自博弈强化学习框架\n\n摘要：近年来，大语言模型的安全风险日益凸显，亟需有效抑制其生成有害内容。当前主流的安全对齐范式通常采用包含三种角色的协作框架：负责生成对抗性提示的攻击者、承担安全防御任务的防御者，以及进行响应评估的评判者。本文提出一种名为TriPlay-RL的闭环强化学习框架，能够在近乎无需人工标注的条件下实现三角色迭代式协同优化。实验结果表明：攻击者在保持高输出多样性的同时，对抗效果提升20%-50%；防御者在未损害通用推理能力的情况下，安全性能获得10%-30%的增益；评判者通过迭代持续优化其细粒度判别能力，能准确区分不安全回答、简单拒绝与有效指导。总体而言，本框架为大语言模型安全对齐建立了一个高效可扩展的范式，实现了在统一学习闭环内的持续协同进化。",
    "url": "https://huggingface.co/papers/2601.18292",
    "arxiv_url": "https://arxiv.org/abs/2601.18292"
  },
  {
    "title": "Towards Pixel-Level VLM Perception via Simple Points Prediction",
    "summary": "We present SimpleSeg, a strikingly simple yet highly effective approach to endow Multimodal Large Language Models (MLLMs) with native pixel-level perception. Our method reframes segmentation as a simple sequence generation problem: the model directly predicts sequences of points (textual coordinates) delineating object boundaries, entirely within its language space. To achieve high fidelity, we introduce a two-stage SFtoRL training pipeline, where Reinforcement Learning with an IoU-based reward refines the point sequences to accurately match ground-truth contours. We find that the standard MLLM architecture possesses a strong, inherent capacity for low-level perception that can be unlocked without any specialized architecture. On segmentation benchmarks, SimpleSeg achieves performance that is comparable to, and often surpasses, methods relying on complex, task-specific designs. This work lays out that precise spatial understanding can emerge from simple point prediction, challenging the prevailing need for auxiliary components and paving the way for more unified and capable VLMs. Homepage: https://simpleseg.github.io/",
    "translation": "标题：通过简单点预测实现像素级视觉语言模型感知\n\n摘要：我们提出SimpleSeg，一种极其简洁却高效的方法，旨在赋予多模态大语言模型（MLLMs）原生的像素级感知能力。该方法将分割任务重新定义为简单的序列生成问题：模型直接在其语言空间内预测描述物体边界的点序列（文本坐标）。为实现高精度，我们引入了两阶段SFtoRL训练流程，其中基于交并比（IoU）奖励的强化学习对点序列进行优化，使其精确匹配真实轮廓。研究发现，标准MLLM架构本身具备强大的底层感知能力，无需任何专用架构即可激活。在分割基准测试中，SimpleSeg取得了与依赖复杂任务专用设计的方法相当甚至更优的性能。这项工作表明，精确的空间理解能力可以通过简单的点预测实现，这挑战了当前对辅助组件的普遍依赖，并为构建更统一、更强大的视觉语言模型开辟了新路径。项目主页：https://simpleseg.github.io/",
    "url": "https://huggingface.co/papers/2601.19228",
    "arxiv_url": "https://arxiv.org/abs/2601.19228"
  },
  {
    "title": "Selective Steering: Norm-Preserving Control Through Discriminative Layer Selection",
    "summary": "Despite significant progress in alignment, large language models (LLMs) remain vulnerable to adversarial attacks that elicit harmful behaviors. Activation steering techniques offer a promising inference-time intervention approach, but existing methods suffer from critical limitations: activation addition requires careful coefficient tuning and is sensitive to layer-specific norm variations, while directional ablation provides only binary control. Recent work on Angular Steering introduces continuous control via rotation in a 2D subspace, but its practical implementation violates norm preservation, causing distribution shift and generation collapse, particularly in models below 7B parameters. We propose Selective Steering, which addresses these limitations through two key innovations: (1) a mathematically rigorous norm-preserving rotation formulation that maintains activation distribution integrity, and (2) discriminative layer selection that applies steering only where feature representations exhibit opposite-signed class alignment. Experiments across nine models demonstrate that Selective Steering achieves 5.5x higher attack success rates than prior methods while maintaining zero perplexity violations and approximately 100\\% capability retention on standard benchmarks. Our approach provides a principled, efficient framework for controllable and stable LLM behavior modification. Code: https://github.com/knoveleng/steering",
    "translation": "标题：选择性导向：通过判别性层选择实现范数保持控制\n\n摘要：尽管在对齐方面取得了显著进展，大型语言模型（LLM）仍然容易受到诱导有害行为的对抗性攻击。激活导向技术提供了一种有前景的推理时干预方法，但现有方法存在关键局限：激活加法需要仔细调整系数且对特定层的范数变化敏感，而方向性消融仅能提供二元控制。最近的角向导向研究通过在二维子空间中进行旋转实现了连续控制，但其实际实施破坏了范数保持特性，导致分布偏移和生成崩溃，尤其是在参数量低于70亿的模型中。我们提出了选择性导向方法，通过两项关键创新解决了这些局限：（1）一种数学上严格的范数保持旋转公式，可维持激活分布的完整性；（2）判别性层选择机制，仅在特征表示呈现相反符号类别对齐的层中应用导向。在九个模型上的实验表明，选择性导向的攻击成功率比现有方法提高了5.5倍，同时在标准基准测试中保持零困惑度违规和约100%的能力保留率。我们的方法为可控且稳定的大型语言模型行为修正提供了一个原则性、高效的框架。代码地址：https://github.com/knoveleng/steering",
    "url": "https://huggingface.co/papers/2601.19375",
    "arxiv_url": "https://arxiv.org/abs/2601.19375"
  },
  {
    "title": "Revisiting Parameter Server in LLM Post-Training",
    "summary": "Modern data parallel (DP) training favors collective communication over parameter servers (PS) for its simplicity and efficiency under balanced workloads. However, the balanced workload assumption no longer holds in large language model (LLM) post-training due to the high variance in sequence lengths. Under imbalanced workloads, collective communication creates synchronization barriers, leading to under-utilization of devices with smaller workloads. This change in training dynamics calls for a revisit of the PS paradigm for its robustness to such imbalance. We propose On-Demand Communication (ODC), which adapts PS into Fully Sharded Data Parallel (FSDP) by replacing collective all-gather and reduce-scatter with direct point-to-point communication. Compared to FSDP, ODC reduces the synchronization barrier from once per layer to once per minibatch and decouples the workload on each device so that faster workers are not stalled. It also enables simpler and more effective load balancing at the minibatch level. Across diverse LLM post-training tasks, ODC consistently improves device utilization and training throughput, achieving up to a 36\\% speedup over standard FSDP. These results demonstrate that ODC is a superior fit for the prevalent imbalanced workloads in LLM post-training. Our implementation of ODC and integration with FSDP is open-sourced at https://github.com/sail-sg/odc.",
    "translation": "标题：重探大语言模型后训练中的参数服务器范式\n\n摘要：现代数据并行训练因其在均衡负载下的简洁性与高效性，通常采用集体通信而非参数服务器范式。然而，在大语言模型后训练中，由于序列长度的高方差性，负载均衡的假设不再成立。在负载不均衡的情况下，集体通信会形成同步屏障，导致负载较轻的设备利用率不足。这种训练动态的变化促使我们重新审视参数服务器范式对其不均衡性的鲁棒性。我们提出按需通信机制，通过以直接点对点通信替代集体全收集与规约分散操作，将参数服务器思想融入全分片数据并行框架中。相较于全分片数据并行，该机制将同步屏障从每层一次减少为每小批次一次，并解耦各设备的工作负载，使得运算更快的设备无需等待。同时，该机制支持在小批次层面实现更简洁高效的负载均衡。在多样化的大语言模型后训练任务中，按需通信机制持续提升了设备利用率和训练吞吐量，较标准全分片数据并行最高可实现36%的加速效果。这些结果表明，该机制能更好地适应大语言模型后训练中普遍存在的负载不均衡场景。我们在https://github.com/sail-sg/odc开源了按需通信机制的实现及其与全分片数据并行的集成代码。",
    "url": "https://huggingface.co/papers/2601.19362",
    "arxiv_url": "https://arxiv.org/abs/2601.19362"
  },
  {
    "title": "HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences",
    "summary": "Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as \"HalluCitation\" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.",
    "translation": "标题：HalluCitation问题：基于ACL会议300篇幻觉论文揭示虚构参考文献的影响\n\n摘要：近期，我们在审稿论文、预印本及已发表文献中频繁观察到虚构引用现象，即论文中引用的参考文献对应不到任何现有研究成果。此类虚构引用严重威胁科学研究的可靠性。当这类引用出现在已录用论文中时，还可能对学术会议的公信力产生负面影响。本研究将此类虚构引用定义为“HalluCitation”，并系统性地探究其普遍性与影响范围。通过对ACL、NAACL和EMNLP会议在2024年与2025年发表的全部论文（包括主会论文、Findings论文集及研讨会论文）进行分析，我们发现近300篇论文至少包含一处HalluCitation，其中绝大多数发表于2025年。值得注意的是，半数存在该问题的论文出现在最新举办的EMNLP 2025会议上，表明该现象正呈快速增长趋势。更值得关注的是，在EMNLP 2025会议中，有超过100篇包含虚构引用的论文被主会和Findings论文集收录，这对学术公信力造成了实质性影响。",
    "url": "https://huggingface.co/papers/2601.18724",
    "arxiv_url": "https://arxiv.org/abs/2601.18724"
  },
  {
    "title": "HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models",
    "summary": "Diffusion models achieve state-of-the-art performance but often fail to generate outputs that align with human preferences and intentions, resulting in images with poor aesthetic quality and semantic inconsistencies. Existing alignment methods present a difficult trade-off: fine-tuning approaches suffer from loss of diversity with reward over-optimization, while test-time scaling methods introduce significant computational overhead and tend to under-optimize. To address these limitations, we propose HyperAlign, a novel framework that trains a hypernetwork for efficient and effective test-time alignment. Instead of modifying latent states, HyperAlign dynamically generates low-rank adaptation weights to modulate the diffusion model's generation operators. This allows the denoising trajectory to be adaptively adjusted based on input latents, timesteps and prompts for reward-conditioned alignment. We introduce multiple variants of HyperAlign that differ in how frequently the hypernetwork is applied, balancing between performance and efficiency. Furthermore, we optimize the hypernetwork using a reward score objective regularized with preference data to reduce reward hacking. We evaluate HyperAlign on multiple extended generative paradigms, including Stable Diffusion and FLUX. It significantly outperforms existing fine-tuning and test-time scaling baselines in enhancing semantic consistency and visual appeal.",
    "translation": "标题：HyperAlign：基于超网络实现扩散模型高效测试时对齐的方法\n\n摘要：扩散模型虽已达到最先进的生成性能，但常难以生成符合人类偏好与意图的输出，导致图像美学质量欠佳且语义不一致。现有对齐方法面临两难权衡：微调方法因奖励过优化而导致多样性丧失，而测试时缩放方法则带来显著计算开销且易优化不足。为克服这些局限，我们提出HyperAlign——一种通过训练超网络实现高效测试时对齐的新框架。该方法不直接修改隐状态，而是动态生成低秩自适应权重以调制扩散模型的生成算子，从而能够根据输入隐变量、时间步和提示词自适应调整去噪轨迹，实现奖励条件对齐。我们设计了多种HyperAlign变体，通过调整超网络的应用频率来平衡性能与效率。此外，我们采用基于偏好数据正则化的奖励评分目标对超网络进行优化，以减少奖励欺骗现象。我们在包括Stable Diffusion和FLUX在内的多种扩展生成范式中评估HyperAlign，其在提升语义一致性与视觉吸引力方面显著优于现有的微调及测试时缩放基线方法。",
    "url": "https://huggingface.co/papers/2601.15968",
    "arxiv_url": "https://arxiv.org/abs/2601.15968"
  },
  {
    "title": "Self-Distillation Enables Continual Learning",
    "summary": "Continual learning, enabling models to acquire new skills and knowledge without degrading existing capabilities, remains a fundamental challenge for foundation models. While on-policy reinforcement learning can reduce forgetting, it requires explicit reward functions that are often unavailable. Learning from expert demonstrations, the primary alternative, is dominated by supervised fine-tuning (SFT), which is inherently off-policy. We introduce Self-Distillation Fine-Tuning (SDFT), a simple method that enables on-policy learning directly from demonstrations. SDFT leverages in-context learning by using a demonstration-conditioned model as its own teacher, generating on-policy training signals that preserve prior capabilities while acquiring new skills. Across skill learning and knowledge acquisition tasks, SDFT consistently outperforms SFT, achieving higher new-task accuracy while substantially reducing catastrophic forgetting. In sequential learning experiments, SDFT enables a single model to accumulate multiple skills over time without performance regression, establishing on-policy distillation as a practical path to continual learning from demonstrations.",
    "translation": "标题：自蒸馏实现持续学习\n\n摘要：持续学习使模型能够在不削弱现有能力的前提下获取新技能与知识，这始终是基础模型面临的核心挑战。虽然同策略强化学习能够减少遗忘，但其需要明确的奖励函数，而此类函数往往难以获得。从专家示范中学习作为主要替代方案，目前主要依赖于监督微调，而该方法本质上是异策略的。我们提出自蒸馏微调方法，这是一种能够直接从示范中进行同策略学习的简洁方法。该方法通过使用示范条件模型作为自身的教师模型，利用上下文学习能力生成同策略训练信号，从而在掌握新技能的同时保持原有能力。在技能学习与知识获取任务中，自蒸馏微调方法始终优于监督微调，在获得更高新任务准确率的同时显著降低灾难性遗忘。在序列学习实验中，该方法使单一模型能够随时间累积多项技能且不发生性能衰退，从而确立了基于示范的同策略蒸馏作为持续学习的可行路径。\n\n摘要：持续学习使模型能够在不削弱现有能力的前提下获取新技能与知识，这始终是基础模型面临的核心挑战。虽然同策略强化学习能够减少遗忘，但其需要明确的奖励函数，而此类函数往往难以获得。从专家示范中学习作为主要替代方案，目前主要依赖于监督微调，而该方法本质上是异策略的。我们提出自蒸馏微调方法，这是一种能够直接从示范中进行同策略学习的简洁方法。该方法通过使用示范条件模型作为自身的教师模型，利用上下文学习能力生成同策略训练信号，从而在掌握新技能的同时保持原有能力。在技能学习与知识获取任务中，自蒸馏微调方法始终优于监督微调，在获得更高新任务准确率的同时显著降低灾难性遗忘。在序列学习实验中，该方法使单一模型能够随时间累积多项技能且不发生性能衰退，从而确立了基于示范的同策略蒸馏作为持续学习的可行路径。",
    "url": "https://huggingface.co/papers/2601.19897",
    "arxiv_url": "https://arxiv.org/abs/2601.19897"
  },
  {
    "title": "Benchmarks Saturate When The Model Gets Smarter Than The Judge",
    "summary": "Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset (n{=}4181) and a tagged, non-standard subset (n{=}247). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in 96.4% of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance.",
    "translation": "标题：当模型比评估者更智能时基准测试趋于饱和\n\n摘要：基准测试是追踪大语言模型发展进程的重要工具，但数据集与评估方法中的不准确性持续削弱其有效性。本文提出Omni-MATH-2数据集——这是对Omni-MATH数据集进行人工修订的版本，包含精确答案子集（n=4181）和带标签的非标准子集（n=247）。我们逐题审核以确保LaTeX可编译性、可解性与可验证性，具体措施包括补充缺失图表信息、标注需证明/估算/图像辅助的问题，并清理冗余内容。该流程显著降低了数据集本身引入的噪声，从而为模型性能提供更精准的评估。通过标注数据集，我们对比GPT-5 mini与原始Omni-Judge评估系统，在清洁子集与标签子集上均发现评估者导致的显著差异。专家标注显示，在评估分歧案例中Omni-Judge的错误率高达96.4%，表明其无法有效区分模型能力差异，这种现象甚至在基准测试饱和前就已显现。随着问题难度提升，我们发现必须采用能力更强的评估者，以防止评估错误掩盖模型间的真实差异。最后，两种评估方式均未能识别标签问题子集的当前失效模式，这证明数据集质量与评估者可靠性对于建立精准的模型性能基准同等重要。",
    "url": "https://huggingface.co/papers/2601.19532",
    "arxiv_url": "https://arxiv.org/abs/2601.19532"
  },
  {
    "title": "GPCR-Filter: a deep learning framework for efficient and precise GPCR modulator discovery",
    "summary": "G protein-coupled receptors (GPCRs) govern diverse physiological processes and are central to modern pharmacology. Yet discovering GPCR modulators remains challenging because receptor activation often arises from complex allosteric effects rather than direct binding affinity, and conventional assays are slow, costly, and not optimized for capturing these dynamics. Here we present GPCR-Filter, a deep learning framework specifically developed for GPCR modulator discovery. We assembled a high-quality dataset of over 90,000 experimentally validated GPCR-ligand pairs, providing a robust foundation for training and evaluation. GPCR-Filter integrates the ESM-3 protein language model for high-fidelity GPCR sequence representations with graph neural networks that encode ligand structures, coupled through an attention-based fusion mechanism that learns receptor-ligand functional relationships. Across multiple evaluation settings, GPCR-Filter consistently outperforms state-of-the-art compound-protein interaction models and exhibits strong generalization to unseen receptors and ligands. Notably, the model successfully identified micromolar-level agonists of the 5-HT1A receptor with distinct chemical frameworks. These results establish GPCR-Filter as a scalable and effective computational approach for GPCR modulator discovery, advancing AI-assisted drug development for complex signaling systems.",
    "translation": "标题：GPCR-Filter：一种用于高效精准发现GPCR调节剂的深度学习框架\n\n摘要：G蛋白偶联受体（GPCRs）调控多种生理过程，是现代药理学研究的核心。然而，GPCR调节剂的发现仍面临挑战，因为受体激活通常源于复杂的变构效应而非直接结合亲和力，且传统检测方法速度慢、成本高，难以有效捕捉这些动态过程。本文提出GPCR-Filter——一个专门为GPCR调节剂发现而开发的深度学习框架。我们构建了一个包含超过90,000个经实验验证的GPCR-配体对的高质量数据集，为模型训练与评估提供了坚实基础。该框架整合了ESM-3蛋白质语言模型（用于高保真GPCR序列表征）与图神经网络（用于编码配体结构），并通过基于注意力的融合机制学习受体-配体功能关系。在多种评估场景中，GPCR-Filter始终优于当前最先进的化合物-蛋白质相互作用模型，并对未见过的受体与配体表现出强大的泛化能力。值得注意的是，该模型成功识别出具有不同化学结构的5-HT1A受体微摩尔级激动剂。这些成果确立了GPCR-Filter作为一种可扩展且高效的计算方法，可用于GPCR调节剂发现，推动了针对复杂信号系统的AI辅助药物研发进程。",
    "url": "https://huggingface.co/papers/2601.19149",
    "arxiv_url": "https://arxiv.org/abs/2601.19149"
  },
  {
    "title": "DeFM: Learning Foundation Representations from Depth for Robotics",
    "summary": "Depth sensors are widely deployed across robotic platforms, and advances in fast, high-fidelity depth simulation have enabled robotic policies trained on depth observations to achieve robust sim-to-real transfer for a wide range of tasks. Despite this, representation learning for depth modality remains underexplored compared to RGB, where large-scale foundation models now define the state of the art. To address this gap, we present DeFM, a self-supervised foundation model trained entirely on depth images for robotic applications. Using a DINO-style self-distillation objective on a curated dataset of 60M depth images, DeFM learns geometric and semantic representations that generalize to diverse environments, tasks, and sensors. To retain metric awareness across multiple scales, we introduce a novel input normalization strategy. We further distill DeFM into compact models suitable for resource-constrained robotic systems. When evaluated on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks, DeFM achieves state-of-the-art performance and demonstrates strong generalization from simulation to real-world environments. We release all our pretrained models, which can be adopted off-the-shelf for depth-based robotic learning without task-specific fine-tuning. Webpage: https://de-fm.github.io/",
    "translation": "标题：DeFM：从深度信息中学习机器人学基础表征\n\n摘要：深度传感器已在各类机器人平台上广泛应用，快速高保真深度模拟技术的进步使得基于深度观测训练的机器人策略能够在广泛任务中实现稳健的仿真到实物的迁移。尽管如此，与已由大规模基础模型定义技术前沿的RGB模态相比，深度模态的表征学习仍处于探索不足的状态。为填补这一空白，我们提出DeFM——一个完全基于深度图像训练的自监督基础模型，专为机器人应用设计。通过在包含6000万张深度图像的精选数据集上采用DINO风格的自蒸馏目标，DeFM学习到的几何与语义表征能够泛化至多样化的环境、任务及传感器。为在多尺度下保持度量感知能力，我们提出了一种新颖的输入归一化策略。我们进一步将DeFM蒸馏为适用于资源受限机器人系统的紧凑模型。在基于深度信息的分类、分割、导航、运动与操作基准测试中，DeFM实现了最先进的性能，并展现出从仿真环境到真实场景的强泛化能力。我们公开了所有预训练模型，这些模型可直接用于基于深度信息的机器人学习而无需任务特定微调。项目主页：https://de-fm.github.io/",
    "url": "https://huggingface.co/papers/2601.18923",
    "arxiv_url": "https://arxiv.org/abs/2601.18923"
  },
  {
    "title": "EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization",
    "summary": "Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.",
    "translation": "标题：EvolVE：基于大语言模型的Verilog生成与优化进化搜索方法\n\n摘要：Verilog的设计流程本质上是劳动密集型的，且需要深厚的领域专业知识。尽管大语言模型为实现自动化提供了可行路径，但其有限的训练数据和固有的顺序推理能力难以捕捉硬件系统严格的形化逻辑与并发特性。为突破这些限制，我们提出了EvolVE框架——首个在芯片设计任务中系统分析多种进化策略的研究，结果表明蒙特卡洛树搜索在最大化功能正确性方面表现卓越，而思想引导优化在性能提升方面更具优势。我们进一步采用结构化测试平台生成技术以加速进化过程。针对复杂优化基准缺失的问题，我们推出了源自全国集成电路设计竞赛的工业级问题集IC-RTL。实验评估表明EvolVE达到了当前最优水平：在VerilogEval v2上获得98.1%的准确率，在RTLLM v2上达到92%的准确率。在工业级IC-RTL测试集中，本框架超越了竞赛参与者编写的参考实现：在哈夫曼编码任务中将功耗、性能、面积综合指标降低达66%，所有问题的几何平均指标提升17%。IC-RTL基准测试源代码已发布于https://github.com/weiber2002/ICRTL。",
    "url": "https://huggingface.co/papers/2601.18067",
    "arxiv_url": "https://arxiv.org/abs/2601.18067"
  },
  {
    "title": "CooperBench: Why Coding Agents Cannot be Your Teammates Yet",
    "summary": "Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.",
    "translation": "标题：CooperBench：为何编码智能体尚不能成为你的团队成员\n\n摘要：解决团队冲突不仅需要任务特定的能力，更需具备寻找共同点并建立共识的社会智能。随着人工智能智能体在复杂工作中日益频繁地协作，它们必须发展协调能力以成为有效的团队成员。然而，我们假设当前智能体尚缺乏这些能力。为验证此假设，我们提出了CooperBench——一个包含4种编程语言、12个库中超过600项协作编码任务的基准测试集。每项任务为两个智能体分配不同的功能模块，这些模块可独立实现，但若缺乏适当协调则可能产生冲突。所有任务均基于真实开源代码库，并配有专家编写的测试用例。通过对前沿编码智能体的评估，我们观察到“协调困境”：智能体协作时的平均成功率比各自独立完成两项任务低30%。这与人类团队形成鲜明对比——增加团队成员通常能提升整体效率。我们的分析揭示了三个关键问题：（1）沟通渠道常被模糊、时机不当且不准确的信息阻塞；（2）即使沟通有效，智能体仍会偏离其承诺；（3）智能体常对他人的计划与沟通持有错误预期。通过大规模模拟，我们也观察到罕见但有趣的涌现协调行为，包括角色分工、资源分配和协商机制。本研究提出了协作编码领域的新型基准，并呼吁从追求个体智能体能力转向发展社会智能。\n\n请按照以下格式返回：\n标题：CooperBench：为何编码智能体尚不能成为你的团队成员\n摘要：解决团队冲突不仅需要任务特定的能力，更需具备寻找共同点并建立共识的社会智能。随着人工智能智能体在复杂工作中日益频繁地协作，它们必须发展协调能力以成为有效的团队成员。然而，我们假设当前智能体尚缺乏这些能力。为验证此假设，我们提出了CooperBench——一个包含4种编程语言、12个库中超过600项协作编码任务的基准测试集。每项任务为两个智能体分配不同的功能模块，这些模块可独立实现，但若缺乏适当协调则可能产生冲突。所有任务均基于真实开源代码库，并配有专家编写的测试用例。通过对前沿编码智能体的评估，我们观察到“协调困境”：智能体协作时的平均成功率比各自独立完成两项任务低30%。这与人类团队形成鲜明对比——增加团队成员通常能提升整体效率。我们的分析揭示了三个关键问题：（1）沟通渠道常被模糊、时机不当且不准确的信息阻塞；（2）即使沟通有效，智能体仍会偏离其承诺；（3）智能体常对他人的计划与沟通持有错误预期。通过大规模模拟，我们也观察到罕见但有趣的涌现协调行为，包括角色分工、资源分配和协商机制。本研究提出了协作编码领域的新型基准，并呼吁从追求个体智能体能力转向发展社会智能。",
    "url": "https://huggingface.co/papers/2601.13295",
    "arxiv_url": "https://arxiv.org/abs/2601.13295"
  }
]