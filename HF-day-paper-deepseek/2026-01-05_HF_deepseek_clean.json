[
  {
    "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization",
    "summary": "Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose Youtu-Agent, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a Workflow mode for standard tasks and a Meta-Agent mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an Agent Practice module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an Agent RL module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\\%) and GAIA (72.8\\%) using open-weight models. Our automated generation pipeline achieves over 81\\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\\% and +5.4\\% respectively. Moreover, our Agent RL training achieves 40\\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\\% and 21\\% on Maths and general/multi-hop QA benchmarks.",
    "translation": "标题：Youtu-Agent：通过自动化生成与混合策略优化提升智能体生产力\n\n摘要：现有的大语言模型（LLM）智能体框架面临两大挑战：高昂的配置成本与静态的能力局限。构建高质量智能体通常需要在工具集成与提示工程上投入大量人工，而已部署的智能体难以适应动态环境，往往需要昂贵的微调。为解决这些问题，我们提出了Youtu-Agent，一个面向LLM智能体自动化生成与持续演进的模块化框架。Youtu-Agent采用结构化配置系统，将执行环境、工具集与上下文管理解耦，支持灵活复用与自动化合成。我们引入了两种生成范式：面向标准任务的工作流模式，以及面向复杂、非标准需求的元智能体模式，能够自动生成工具代码、提示词与配置。此外，Youtu-Agent建立了一套混合策略优化系统：（1）智能体实践模块，使智能体能够通过上下文优化积累经验、提升性能，无需参数更新；（2）智能体强化学习模块，与分布式训练框架集成，支持以端到端、大规模方式对任意Youtu-Agent进行可扩展且稳定的强化学习。实验表明，Youtu-Agent在WebWalkerQA（71.47%）和GAIA（72.8%）基准上使用开放权重模型达到了最先进的性能。我们的自动化生成流程实现了超过81%的工具合成成功率，而实践模块在AIME 2024/2025上的性能分别提升了+2.7%与+5.4%。此外，我们的智能体强化学习训练在7B参数LLM上实现了40%的加速，且性能稳定提升，在数学与通用/多跳问答基准上，分别将编码/推理与搜索能力最高提升了35%和21%。",
    "url": "https://huggingface.co/papers/2512.24615",
    "arxiv_url": "https://arxiv.org/abs/2512.24615"
  },
  {
    "title": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos",
    "summary": "In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io",
    "translation": "标题：NeoVerse：基于真实世界单目视频增强的4D世界模型\n\n摘要：本文提出NeoVerse，一种多功能4D世界模型，能够实现4D重建、新轨迹视频生成及丰富的下游应用。我们首先指出当前4D世界建模方法普遍存在的可扩展性局限，其根源在于依赖昂贵且专业的多视角4D数据或繁琐的训练预处理流程。相比之下，NeoVerse基于核心设计理念，使完整流程能够灵活适配多样化的真实世界单目视频。具体而言，NeoVerse具备无需姿态估计的前馈式4D重建、在线单目退化模式模拟等高度协同的技术特性。这些设计使NeoVerse在跨领域应用中展现出卓越的泛化能力与多功能性。同时，该模型在标准重建与生成基准测试中取得了最先进的性能表现。项目页面详见：https://neoverse-4d.github.io",
    "url": "https://huggingface.co/papers/2601.00393",
    "arxiv_url": "https://arxiv.org/abs/2601.00393"
  },
  {
    "title": "Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation",
    "summary": "Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.",
    "translation": "标题：Avatar Forcing：面向自然对话的实时交互式头部虚拟形象生成\n\n摘要：说话头部生成技术旨在从静态肖像中创建逼真的虚拟形象，以支持虚拟交流与内容创作。然而，现有模型尚无法传递真正交互式沟通的体验，其生成结果多为单向响应，缺乏情感互动。为实现真正交互式的虚拟形象，我们指出两大关键挑战：在因果约束下实现实时运动生成，以及在不依赖额外标注数据的情况下学习富有表现力且生动的反应。为应对这些挑战，我们提出Avatar Forcing——一种基于扩散强迫机制的交互式头部虚拟形象生成新框架。该设计使虚拟形象能够以低延迟处理实时多模态输入（包括用户音频与动作），即时响应言语与非言语线索（如语音、点头、笑声等）。此外，我们引入一种直接偏好优化方法，通过丢弃用户条件构建合成负样本，实现无需标注的表现力交互学习。实验结果表明，本框架支持低延迟（约500毫秒）实时交互，相比基线模型加速6.8倍，并能生成具有反应力与表现力的虚拟形象动作，在超过80%的对比评估中优于基线方法。",
    "url": "https://huggingface.co/papers/2601.00664",
    "arxiv_url": "https://arxiv.org/abs/2601.00664"
  },
  {
    "title": "Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation",
    "summary": "Multimodal Large Language Models (MLLMs) have made remarkable progress in video understanding. However, they suffer from a critical vulnerability: an over-reliance on language priors, which can lead to visual ungrounded hallucinations, especially when processing counterfactual videos that defy common sense. This limitation, stemming from the intrinsic data imbalance between text and video, is challenging to address due to the substantial cost of collecting and annotating counterfactual data. To address this, we introduce DualityForge, a novel counterfactual data synthesis framework that employs controllable, diffusion-based video editing to transform real-world videos into counterfactual scenarios. By embedding structured contextual information into the video editing and QA generation processes, the framework automatically produces high-quality QA pairs together with original-edited video pairs for contrastive training. Based on this, we build DualityVidQA, a large-scale video dataset designed to reduce MLLM hallucinations. In addition, to fully exploit the contrastive nature of our paired data, we propose Duality-Normalized Advantage Training (DNA-Train), a two-stage SFT-RL training regime where the RL phase applies pair-wise ell_1 advantage normalization, thereby enabling a more stable and efficient policy optimization. Experiments on DualityVidQA-Test demonstrate that our method substantially reduces model hallucinations on counterfactual videos, yielding a relative improvement of 24.0% over the Qwen2.5-VL-7B baseline. Moreover, our approach achieves significant gains across both hallucination and general-purpose benchmarks, indicating strong generalization capability. We will open-source our dataset and code.",
    "translation": "标题：驯服幻觉：通过反事实视频生成提升多模态大语言模型的视频理解能力\n\n摘要：多模态大语言模型（MLLMs）在视频理解领域取得了显著进展。然而，它们存在一个关键缺陷：过度依赖语言先验，这可能导致视觉信息失真的幻觉现象，尤其是在处理违背常识的反事实视频时。这一局限性源于文本与视频数据之间的内在不平衡，且由于收集和标注反事实数据成本高昂，该问题难以解决。为此，我们提出了DualityForge，一种新颖的反事实数据合成框架，该框架利用可控的、基于扩散模型的视频编辑技术，将真实世界视频转化为反事实场景。通过将结构化上下文信息嵌入视频编辑和问答生成过程，该框架能够自动生成高质量的问答对以及用于对比训练的原始-编辑视频对。基于此，我们构建了DualityVidQA，一个旨在减少MLLM幻觉的大规模视频数据集。此外，为充分利用配对数据的对比特性，我们提出了Duality-Normalized Advantage Training（DNA-Train），一种两阶段的监督微调-强化学习训练机制，其中强化学习阶段应用了配对间的ℓ₁优势归一化，从而实现更稳定高效的政策优化。在DualityVidQA-Test上的实验表明，我们的方法显著降低了模型在反事实视频上的幻觉，相比Qwen2.5-VL-7B基线实现了24.0%的相对提升。此外，我们的方法在幻觉评估和通用基准测试中均取得了显著进步，显示出强大的泛化能力。我们将开源数据集和代码。",
    "url": "https://huggingface.co/papers/2512.24271",
    "arxiv_url": "https://arxiv.org/abs/2512.24271"
  },
  {
    "title": "SenseNova-MARS: Empowering Multimodal Agentic Reasoning and Search via Reinforcement Learning",
    "summary": "While Vision-Language Models (VLMs) can solve complex tasks through agentic reasoning, their capabilities remain largely constrained to text-oriented chain-of-thought or isolated tool invocation. They fail to exhibit the human-like proficiency required to seamlessly interleave dynamic tool manipulation with continuous reasoning, particularly in knowledge-intensive and visually complex scenarios that demand coordinated external tools such as search and image cropping. In this work, we introduce SenseNova-MARS, a novel Multimodal Agentic Reasoning and Search framework that empowers VLMs with interleaved visual reasoning and tool-use capabilities via reinforcement learning (RL). Specifically, SenseNova-MARS dynamically integrates the image search, text search, and image crop tools to tackle fine-grained and knowledge-intensive visual understanding challenges. In the RL stage, we propose the Batch-Normalized Group Sequence Policy Optimization (BN-GSPO) algorithm to improve the training stability and advance the model's ability to invoke tools and reason effectively. To comprehensively evaluate the agentic VLMs on complex visual tasks, we introduce the HR-MMSearch benchmark, the first search-oriented benchmark composed of high-resolution images with knowledge-intensive and search-driven questions. Experiments demonstrate that SenseNova-MARS achieves state-of-the-art performance on open-source search and fine-grained image understanding benchmarks. Specifically, on search-oriented benchmarks, SenseNova-MARS-8B scores 67.84 on MMSearch and 41.64 on HR-MMSearch, surpassing proprietary models such as Gemini-3-Flash and GPT-5. SenseNova-MARS represents a promising step toward agentic VLMs by providing effective and robust tool-use capabilities. To facilitate further research in this field, we will release all code, models, and datasets.",
    "translation": "标题：SenseNova-MARS：基于强化学习的多模态智能体推理与搜索框架\n\n摘要：尽管视觉-语言模型（VLMs）能够通过智能体推理解决复杂任务，但其能力仍主要局限于文本导向的思维链或孤立工具调用。这些模型未能展现出类人的熟练度，无法将动态工具操作与连续推理无缝交织，尤其是在需要协调使用搜索、图像裁剪等外部工具的知识密集型与视觉复杂场景中。本研究提出SenseNova-MARS，一种基于强化学习（RL）的新型多模态智能体推理与搜索框架，旨在赋予VLMs交织式视觉推理与工具使用能力。具体而言，SenseNova-MARS动态整合图像搜索、文本搜索与图像裁剪工具，以应对细粒度、知识密集型的视觉理解挑战。在强化学习阶段，我们提出批量归一化分组序列策略优化（BN-GSPO）算法，以提升训练稳定性并增强模型调用工具与有效推理的能力。为全面评估智能体VLMs在复杂视觉任务上的表现，我们构建了HR-MMSearch基准测试集——首个由高分辨率图像构成、包含知识密集型与搜索驱动问题的搜索导向基准。实验表明，SenseNova-MARS在开源搜索与细粒度图像理解基准上取得了最先进的性能。具体而言，在搜索导向基准测试中，SenseNova-MARS-8B在MMSearch上获得67.84分，在HR-MMSearch上获得41.64分，超越了Gemini-3-Flash、GPT-5等专有模型。SenseNova-MARS通过提供高效稳健的工具使用能力，为智能体VLMs的发展迈出了重要一步。为促进该领域进一步研究，我们将公开全部代码、模型与数据集。",
    "url": "https://huggingface.co/papers/2512.24330",
    "arxiv_url": "https://arxiv.org/abs/2512.24330"
  },
  {
    "title": "AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction",
    "summary": "Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/",
    "translation": "标题：AdaGaR：面向动态场景重建的自适应Gabor表示方法\n\n摘要：从单目视频重建动态三维场景需要同时捕获高频外观细节与时间连续运动。现有基于单一高斯基元的方法受限于其低通滤波特性，而标准Gabor函数存在能量不稳定问题。此外，时间连续性约束的缺失常导致插值过程中的运动伪影。本文提出AdaGaR统一框架，在显式动态场景建模中同时解决频率自适应性与时间连续性问题。我们引入自适应Gabor表示方法，通过可学习频率权重与自适应能量补偿扩展高斯函数，以平衡细节捕获与稳定性。针对时间连续性，采用结合时间曲率正则化的三次Hermite样条来确保平滑运动演化。通过融合深度估计、点跟踪与前景掩码的自适应初始化机制，在训练初期建立稳定的点云分布。在Tap-Vid DAVIS数据集上的实验表明，该方法取得了最优性能（PSNR 35.49、SSIM 0.9433、LPIPS 0.0723），并在帧插值、深度一致性、视频编辑与立体视图合成等任务中展现出强大泛化能力。项目页面：https://jiewenchan.github.io/AdaGaR/",
    "url": "https://huggingface.co/papers/2601.00796",
    "arxiv_url": "https://arxiv.org/abs/2601.00796"
  },
  {
    "title": "Deep Delta Learning",
    "summary": "The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector k(X) and a gating scalar β(X). We provide a spectral analysis of this operator, demonstrating that the gate β(X) enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.",
    "translation": "标题：深度增量学习\n\n摘要：深度残差网络的有效性本质上基于恒等快捷连接机制。虽然该机制有效缓解了梯度消失问题，但它对特征变换施加了严格的加性归纳偏置，从而限制了网络建模复杂状态转移的能力。本文提出深度增量学习（DDL）这一新型架构，通过使用可学习的、数据依赖的几何变换对恒等快捷连接进行调制，从而推广了标准残差连接。该变换被称为增量算子，由反射方向向量k(X)和门控标量β(X)参数化，构成单位矩阵的秩-1扰动。我们对该算子进行谱分析，证明门控β(X)能够实现恒等映射、正交投影与几何反射之间的动态插值。进一步地，我们将残差更新重构为同步秩-1注入，其中门控作为动态步长，同时控制旧信息的擦除与新特征的写入。这种统一设计使网络能够显式控制其逐层转移算子的谱空间，在保持门控残差架构稳定训练特性的同时，实现对复杂非单调动态过程的建模。",
    "url": "https://huggingface.co/papers/2601.00417",
    "arxiv_url": "https://arxiv.org/abs/2601.00417"
  },
  {
    "title": "Nested Learning: The Illusion of Deep Learning Architectures",
    "summary": "Despite the recent progresses, particularly in developing Language Models, there are fundamental challenges and unanswered questions about how such models can continually learn/memorize, self-improve, and find effective solutions. In this paper, we present a new learning paradigm, called Nested Learning (NL), that coherently represents a machine learning model with a set of nested, multi-level, and/or parallel optimization problems, each of which with its own context flow. Through the lenses of NL, existing deep learning methods learns from data through compressing their own context flow, and in-context learning naturally emerges in large models. NL suggests a philosophy to design more expressive learning algorithms with more levels, resulting in higher-order in-context learning and potentially unlocking effective continual learning capabilities. We advocate for NL by presenting three core contributions: (1) Expressive Optimizers: We show that known gradient-based optimizers, such as Adam, SGD with Momentum, etc., are in fact associative memory modules that aim to compress the gradients' information (by gradient descent). Building on this insight, we present other more expressive optimizers with deep memory and/or more powerful learning rules; (2) Self-Modifying Learning Module: Taking advantage of NL's insights on learning algorithms, we present a sequence model that learns how to modify itself by learning its own update algorithm; and (3) Continuum Memory System: We present a new formulation for memory system that generalizes the traditional viewpoint of long/short-term memory. Combining our self-modifying sequence model with the continuum memory system, we present a continual learning module, called Hope, showing promising results in language modeling, knowledge incorporation, and few-shot generalization tasks, continual learning, and long-context reasoning tasks.",
    "translation": "标题：嵌套学习：深度学习架构的幻觉\n\n摘要：尽管近年来取得了显著进展，特别是在语言模型开发领域，但关于此类模型如何实现持续学习/记忆、自我改进及寻找有效解决方案等根本性挑战与未解问题依然存在。本文提出一种称为嵌套学习（NL）的新学习范式，该范式通过一组具有独立上下文流的嵌套式、多层级和/或并行优化问题来连贯地表征机器学习模型。通过NL视角分析，现有深度学习方法通过压缩自身上下文流从数据中学习，而上下文学习能力在大模型中自然涌现。NL提出了一种设计理念：通过构建更多层级来开发更具表达力的学习算法，从而实现高阶上下文学习，并有望解锁有效的持续学习能力。我们通过三项核心贡献论证NL的价值：（1）表达性优化器：研究表明，已知的基于梯度的优化器（如Adam、带动量的SGD等）本质上是旨在通过梯度下降压缩梯度信息的关联记忆模块。基于此洞见，我们提出了具有深度记忆和/或更强学习规则的其他高表达力优化器；（2）自修正学习模块：利用NL对学习算法的深刻理解，我们构建了一种通过学习自身更新算法来实现自我修正的序列模型；（3）连续记忆系统：提出了一种超越传统长/短期记忆框架的新型记忆系统表述。将自修正序列模型与连续记忆系统相结合，我们开发出名为“Hope”的持续学习模块，在语言建模、知识融合、小样本泛化任务、持续学习及长上下文推理任务中展现出卓越性能。",
    "url": "https://huggingface.co/papers/2512.24695",
    "arxiv_url": "https://arxiv.org/abs/2512.24695"
  },
  {
    "title": "The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving",
    "summary": "State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.",
    "translation": "标题：推理与创造力的权衡：迈向创造力驱动的问题解决\n\n摘要：当前最先进的大语言模型（LLM）流程依赖于自举推理循环：通过采样多样化的思维链并强化得分最高的路径，主要优化正确性。本文分析了这种设计选择如何导致模型在推理路径上的分布崩溃，从而削减语义熵并削弱创造性问题解决能力。为解析这一失效机制，我们提出了分布化创造性推理（DCR）——一种统一的变分目标框架，将训练过程建模为在解轨迹概率测度上的梯度流。STaR、GRPO、DPO以及熵奖励等现有方法均可视为该损失函数的特例。该框架得出三项核心成果：（一）多样性衰减定理，阐释了基于正确性的目标如何导致STaR、GRPO和DPO产生不同模式的多样性衰减；（二）确保收敛至稳定且多样化策略的设计方案，有效防止分布崩溃；（三）可在实践中实现的简洁可行方案。DCR由此为同时保持正确性与创造性的大语言模型提供了首个原则性方法。",
    "url": "https://huggingface.co/papers/2601.00747",
    "arxiv_url": "https://arxiv.org/abs/2601.00747"
  },
  {
    "title": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning",
    "summary": "Recent studies have demonstrated significant progress in aligning text-to-image diffusion models with human preference via Reinforcement Learning from Human Feedback. However, while existing methods achieve high scores on automated reward metrics, they often lead to Preference Mode Collapse (PMC)-a specific form of reward hacking where models converge on narrow, high-scoring outputs (e.g., images with monolithic styles or pervasive overexposure), severely degrading generative diversity. In this work, we introduce and quantify this phenomenon, proposing DivGenBench, a novel benchmark designed to measure the extent of PMC. We posit that this collapse is driven by over-optimization along the reward model's inherent biases. Building on this analysis, we propose Directional Decoupling Alignment (D^2-Align), a novel framework that mitigates PMC by directionally correcting the reward signal. Specifically, our method first learns a directional correction within the reward model's embedding space while keeping the model frozen. This correction is then applied to the reward signal during the optimization process, preventing the model from collapsing into specific modes and thereby maintaining diversity. Our comprehensive evaluation, combining qualitative analysis with quantitative metrics for both quality and diversity, reveals that D^2-Align achieves superior alignment with human preference.",
    "translation": "标题：通过方向解耦对齐在扩散强化学习中抑制偏好模式坍塌\n\n摘要：近期研究表明，通过人类反馈强化学习技术，文本到图像扩散模型与人类偏好的对齐已取得显著进展。然而，现有方法虽然在自动化奖励指标上获得高分，却常导致偏好模式坍塌——这是一种特定形式的奖励破解现象，表现为模型收敛于狭窄的高分输出模式（例如单一风格图像或普遍过曝的图像），严重损害了生成多样性。本研究首次系统界定并量化了这一现象，提出专用于测量偏好模式坍塌程度的新基准DivGenBench。我们认为这种坍塌是由奖励模型固有偏差的过度优化所驱动的。基于此分析，我们提出方向解耦对齐框架，该框架通过方向性修正奖励信号来缓解偏好模式坍塌。具体而言，我们的方法首先在冻结模型参数的状态下，于奖励模型的嵌入空间中学习方向修正量，随后在优化过程中将此修正应用于奖励信号，从而防止模型坍缩至特定模式以保持多样性。通过结合质量与多样性的定性分析与定量指标的综合评估表明，方向解耦对齐框架在实现与人类偏好的对齐方面具有显著优势。",
    "url": "https://huggingface.co/papers/2512.24146",
    "arxiv_url": "https://arxiv.org/abs/2512.24146"
  },
  {
    "title": "Diversity or Precision? A Deep Dive into Next Token Prediction",
    "summary": "Recent advancements have shown that reinforcement learning (RL) can substantially improve the reasoning abilities of large language models (LLMs). The effectiveness of such RL training, however, depends critically on the exploration space defined by the pre-trained model's token-output distribution. In this paper, we revisit the standard cross-entropy loss, interpreting it as a specific instance of policy gradient optimization applied within a single-step episode. To systematically study how the pre-trained distribution shapes the exploration potential for subsequent RL, we propose a generalized pre-training objective that adapts on-policy RL principles to supervised learning. By framing next-token prediction as a stochastic decision process, we introduce a reward-shaping strategy that explicitly balances diversity and precision. Our method employs a positive reward scaling factor to control probability concentration on ground-truth tokens and a rank-aware mechanism that treats high-ranking and low-ranking negative tokens asymmetrically. This allows us to reshape the pre-trained token-output distribution and investigate how to provide a more favorable exploration space for RL, ultimately enhancing end-to-end reasoning performance. Contrary to the intuition that higher distribution entropy facilitates effective exploration, we find that imposing a precision-oriented prior yields a superior exploration space for RL.",
    "translation": "标题：多样性还是精确性？深度解析下一词元预测\n\n摘要：近期研究表明，强化学习（RL）能显著提升大语言模型（LLM）的推理能力。然而，此类强化学习训练的有效性关键取决于预训练模型的词元输出分布所定义的探索空间。本文重新审视标准交叉熵损失，将其解释为应用于单步决策过程的策略梯度优化的一个特例。为系统研究预训练分布如何塑造后续强化学习的探索潜力，我们提出一种广义预训练目标，将同策略强化学习原理适配至监督学习框架。通过将下一词元预测构建为随机决策过程，我们引入一种显式平衡多样性与精确性的奖励塑造策略。该方法采用正向奖励缩放因子控制对真实标注词元的概率集中度，并引入排名感知机制对高排名与低排名负样本词元进行非对称处理。这使我们能够重塑预训练的词元输出分布，探究如何为强化学习提供更有利的探索空间，最终提升端到端推理性能。与“更高分布熵有助于有效探索”的直觉相反，我们发现施加以精确性为导向的先验分布能为强化学习提供更优越的探索空间。",
    "url": "https://huggingface.co/papers/2512.22955",
    "arxiv_url": "https://arxiv.org/abs/2512.22955"
  },
  {
    "title": "Fast-weight Product Key Memory",
    "summary": "Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, \"fast-weight\" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.",
    "translation": "标题：快速权重乘积键记忆\n\n摘要：现代语言模型中的序列建模层通常面临存储容量与计算效率之间的权衡。Softmax注意力机制虽能提供无界存储，却需付出二次方计算的昂贵代价；线性变体虽计算高效，但其存储容量有限且固定。本文提出快速权重乘积键记忆（FwPKM），该新型架构通过将稀疏的乘积键记忆从静态模块转化为动态的“快速权重”情景记忆，有效解决了这一矛盾。与乘积键记忆不同，FwPKM在训练和推理阶段均通过局部块级梯度下降动态更新参数，使模型能够快速记忆并检索输入序列中的新键值对。实验表明，FwPKM作为一种高效的情景记忆模块，能够与标准模型的语义记忆形成互补，在长上下文数据集上显著降低困惑度。值得注意的是，在“大海捞针”评估中，FwPKM仅使用4K词元序列训练即可泛化至128K词元的长上下文场景。",
    "url": "https://huggingface.co/papers/2601.00671",
    "arxiv_url": "https://arxiv.org/abs/2601.00671"
  },
  {
    "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs",
    "summary": "Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/",
    "translation": "标题：InfoSynth：面向大语言模型的信息引导式基准测试合成方法\n\n摘要：大语言模型在推理与代码生成方面已展现出显著进步，然而高效创建用于评估这些能力的新基准测试仍面临挑战。传统的基准构建依赖人工完成，这一过程成本高昂且耗时。此外，现有基准测试常会污染大语言模型的训练数据，因此需要新颖且多样化的基准以准确评估其真实能力。本研究提出InfoSynth，一种基于信息论原理自动生成与评估推理基准的新框架。我们提出基于KL散度与熵的度量指标，无需依赖高成本的模型评估即可量化基准的新颖性与多样性。基于此框架，我们开发了一套端到端流程，通过遗传算法与迭代式代码反馈，从种子数据集中合成稳健的Python编程问题。该方法在97%的情况下能为新问题生成准确的测试用例与解决方案，且合成基准相较于原始种子数据集持续表现出更高的新颖性与多样性。此外，我们的算法提供了一种控制生成问题新颖性/多样性与难度的方法。InfoSynth为构建高质量、新颖且多样化的大语言模型基准测试提供了一个可扩展、可自我验证的完整流程。项目页面：https://ishirgarg.github.io/infosynth_web/",
    "url": "https://huggingface.co/papers/2601.00575",
    "arxiv_url": "https://arxiv.org/abs/2601.00575"
  },
  {
    "title": "MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing",
    "summary": "3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.",
    "translation": "标题：MorphAny3D：释放结构化隐空间在三维形变中的潜力\n\n摘要：三维形变技术因难以生成语义一致且时序平滑的变形序列而持续面临挑战，在跨类别形变任务中尤为突出。本文提出MorphAny3D——一种基于结构化隐空间表征的无训练框架，可实现高质量三维形变。我们的核心发现是：通过在三维生成器的注意力机制中智能融合源目标对象的SLAT特征，能够自然生成符合物理规律的形变序列。为此，我们设计了形变交叉注意力模块，通过融合源目标特征保持结构连贯性；并提出时序融合自注意力模块，通过引入相邻帧特征增强时序一致性。此外，我们采用方向校正策略以缓解形变过程中的姿态歧义问题。大量实验表明，本方法生成的形变序列达到当前最优水平，即使在极具挑战性的跨类别形变任务中亦表现出色。MorphAny3D进一步支持解耦形变与三维风格迁移等高级应用，并可推广至其他基于SLAT的生成模型。项目主页：https://xiaokunsun.github.io/MorphAny3D.github.io/。",
    "url": "https://huggingface.co/papers/2601.00204",
    "arxiv_url": "https://arxiv.org/abs/2601.00204"
  },
  {
    "title": "Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning",
    "summary": "When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.",
    "translation": "标题：我们能否信任AI的解释？思维链推理中系统性隐瞒的证据\n\n摘要：当人工智能系统逐步解释其推理过程时，从业者通常认为这些解释揭示了实际影响AI答案的因素。我们通过将提示信息嵌入问题并测量模型是否提及这些信息来验证这一假设。在对11个主流AI模型超过9000个测试案例的研究中，我们发现了一个令人担忧的模式：模型几乎从不主动提及提示信息，但当被直接询问时，它们会承认注意到了这些提示。这表明模型能够识别关键信息却选择不报告。告知模型其行为正在被监控并无改善效果。强制模型报告提示信息虽然有效，但会导致其在无提示时误报，并降低回答准确率。我们还发现，迎合用户偏好的提示尤其危险——模型最常遵循这类提示却最少报告其影响。这些发现表明，仅观察AI的推理过程不足以发现其隐藏的影响因素。",
    "url": "https://huggingface.co/papers/2601.00830",
    "arxiv_url": "https://arxiv.org/abs/2601.00830"
  }
]