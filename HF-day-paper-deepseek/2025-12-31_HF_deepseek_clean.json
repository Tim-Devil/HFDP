[
  {
    "title": "UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement",
    "summary": "In this report, we introduce UltraShape 1.0, a scalable 3D diffusion framework for high-fidelity 3D geometry generation. The proposed approach adopts a two-stage generation pipeline: a coarse global structure is first synthesized and then refined to produce detailed, high-quality geometry. To support reliable 3D generation, we develop a comprehensive data processing pipeline that includes a novel watertight processing method and high-quality data filtering. This pipeline improves the geometric quality of publicly available 3D datasets by removing low-quality samples, filling holes, and thickening thin structures, while preserving fine-grained geometric details. To enable fine-grained geometry refinement, we decouple spatial localization from geometric detail synthesis in the diffusion process. We achieve this by performing voxel-based refinement at fixed spatial locations, where voxel queries derived from coarse geometry provide explicit positional anchors encoded via RoPE, allowing the diffusion model to focus on synthesizing local geometric details within a reduced, structured solution space. Our model is trained exclusively on publicly available 3D datasets, achieving strong geometric quality despite limited training resources. Extensive evaluations demonstrate that UltraShape 1.0 performs competitively with existing open-source methods in both data processing quality and geometry generation. All code and trained models will be released to support future research.",
    "translation": "标题：UltraShape 1.0：基于可扩展几何优化的高保真三维形状生成\n\n摘要：本报告介绍了UltraShape 1.0，一个可扩展的三维扩散框架，用于实现高保真的三维几何形状生成。该方法采用两阶段生成流程：首先生成粗略的全局结构，随后通过细化处理生成细节丰富的高质量几何形状。为支持可靠的三维生成，我们开发了完整的数据处理流程，包括新颖的封闭化处理方法与高质量数据筛选机制。该流程通过剔除低质量样本、填补孔洞及加厚薄壁结构，在保留细粒度几何细节的同时，显著提升了公开三维数据集的几何质量。为实现细粒度几何优化，我们在扩散过程中将空间定位与几何细节合成进行解耦：通过在固定空间位置执行基于体素的细化操作，利用粗粒度几何生成的体素查询提供通过RoPE编码的显式位置锚点，使扩散模型能够聚焦于在结构化压缩解空间中合成局部几何细节。我们的模型完全基于公开三维数据集进行训练，在有限训练资源下仍实现了优异的几何质量。大量实验评估表明，UltraShape 1.0在数据处理质量与几何生成能力方面均与现有开源方法具有竞争优势。所有代码与训练模型将公开发布以支持后续研究。",
    "url": "https://huggingface.co/papers/2512.21185",
    "arxiv_url": "https://arxiv.org/abs/2512.21185"
  },
  {
    "title": "DreamOmni3: Scribble-based Editing and Generation",
    "summary": "Recently unified generation and editing models have achieved remarkable success with their impressive performance. These models rely mainly on text prompts for instruction-based editing and generation, but language often fails to capture users intended edit locations and fine-grained visual details. To this end, we propose two tasks: scribble-based editing and generation, that enables more flexible creation on graphical user interface (GUI) combining user textual, images, and freehand sketches. We introduce DreamOmni3, tackling two challenges: data creation and framework design. Our data synthesis pipeline includes two parts: scribble-based editing and generation. For scribble-based editing, we define four tasks: scribble and instruction-based editing, scribble and multimodal instruction-based editing, image fusion, and doodle editing. Based on DreamOmni2 dataset, we extract editable regions and overlay hand-drawn boxes, circles, doodles or cropped image to construct training data. For scribble-based generation, we define three tasks: scribble and instruction-based generation, scribble and multimodal instruction-based generation, and doodle generation, following similar data creation pipelines. For the framework, instead of using binary masks, which struggle with complex edits involving multiple scribbles, images, and instructions, we propose a joint input scheme that feeds both the original and scribbled source images into the model, using different colors to distinguish regions and simplify processing. By applying the same index and position encodings to both images, the model can precisely localize scribbled regions while maintaining accurate editing. Finally, we establish comprehensive benchmarks for these tasks to promote further research. Experimental results demonstrate that DreamOmni3 achieves outstanding performance, and models and code will be publicly released.",
    "translation": "标题：DreamOmni3：基于涂鸦的编辑与生成\n\n摘要：近期，统一的生成与编辑模型凭借其卓越性能取得了显著成功。这些模型主要依赖文本提示进行基于指令的编辑与生成，但语言往往难以准确捕捉用户期望的编辑位置及细粒度视觉细节。为此，我们提出两项任务：基于涂鸦的编辑与生成，以结合用户文本、图像和手绘草图在图形用户界面（GUI）上实现更灵活的创作。我们推出DreamOmni3模型，重点解决两大挑战：数据构建与框架设计。我们的数据合成流程包含两部分：基于涂鸦的编辑与生成。在基于涂鸦的编辑方面，我们定义了四项子任务：基于涂鸦与指令的编辑、基于涂鸦与多模态指令的编辑、图像融合以及涂鸦编辑。基于DreamOmni2数据集，我们提取可编辑区域并叠加手绘框、圆形、涂鸦或裁剪图像以构建训练数据。在基于涂鸦的生成方面，我们定义了基于涂鸦与指令的生成、基于涂鸦与多模态指令的生成以及涂鸦生成三项子任务，并采用类似的数据构建流程。在框架设计上，针对传统二值掩码难以处理涉及多重涂鸦、图像及指令的复杂编辑任务，我们提出一种联合输入方案：将原始图像与涂鸦后的源图像同时输入模型，通过不同颜色区分区域以简化处理流程。通过对两幅图像施加相同的索引与位置编码，模型能够精确定位涂鸦区域并保持编辑准确性。最后，我们为这些任务建立了综合评估基准以推动后续研究。实验结果表明，DreamOmni3取得了优异性能，相关模型与代码将公开释放。",
    "url": "https://huggingface.co/papers/2512.22525",
    "arxiv_url": "https://arxiv.org/abs/2512.22525"
  },
  {
    "title": "End-to-End Test-Time Training for Long Context",
    "summary": "We formulate long-context language modeling as a problem in continual learning rather than architecture design. Under this formulation, we only use a standard architecture -- a Transformer with sliding-window attention. However, our model continues learning at test time via next-token prediction on the given context, compressing the context it reads into its weights. In addition, we improve the model's initialization for learning at test time via meta-learning at training time. Overall, our method, a form of Test-Time Training (TTT), is End-to-End (E2E) both at test time (via next-token prediction) and training time (via meta-learning), in contrast to previous forms. We conduct extensive experiments with a focus on scaling properties. In particular, for 3B models trained with 164B tokens, our method (TTT-E2E) scales with context length in the same way as Transformer with full attention, while others, such as Mamba 2 and Gated DeltaNet, do not. However, similar to RNNs, TTT-E2E has constant inference latency regardless of context length, making it 2.7 times faster than full attention for 128K context. Our code is publicly available.",
    "translation": "标题：面向长上下文的端到端测试时训练\n\n摘要：本文将长上下文语言建模构建为一个持续学习问题而非架构设计问题。在此框架下，我们仅采用标准架构——基于滑动窗口注意力的Transformer模型。然而，该模型在测试时通过给定上下文中的下一词元预测持续学习，将其读取的上下文信息压缩至权重参数中。此外，我们通过在训练阶段引入元学习策略，优化模型在测试时学习的初始化状态。总体而言，本方法作为一种测试时训练形式，在测试阶段（通过下一词元预测）与训练阶段（通过元学习）均实现端到端处理，这与既有方法形成鲜明对比。我们开展了系统性实验，重点关注方法的扩展特性。具体而言，对于使用1640亿词元训练的30亿参数模型，本方法（TTT-E2E）在上下文长度扩展方面展现出与完全注意力Transformer相同的特性，而其他方法（如Mamba 2和门控DeltaNet）则不具备该特性。值得注意的是，与循环神经网络类似，TTT-E2E的推理延迟不受上下文长度影响，在处理128K上下文时比完全注意力机制快2.7倍。相关代码已公开。",
    "url": "https://huggingface.co/papers/2512.23675",
    "arxiv_url": "https://arxiv.org/abs/2512.23675"
  },
  {
    "title": "Evaluating Parameter Efficient Methods for RLVR",
    "summary": "We systematically evaluate Parameter-Efficient Fine-Tuning (PEFT) methods under the paradigm of Reinforcement Learning with Verifiable Rewards (RLVR). RLVR incentivizes language models to enhance their reasoning capabilities through verifiable feedback; however, while methods like LoRA are commonly used, the optimal PEFT architecture for RLVR remains unidentified. In this work, we conduct the first comprehensive evaluation of over 12 PEFT methodologies across the DeepSeek-R1-Distill families on mathematical reasoning benchmarks. Our empirical results challenge the default adoption of standard LoRA with three main findings. First, we demonstrate that structural variants, such as DoRA, AdaLoRA, and MiSS, consistently outperform LoRA. Second, we uncover a spectral collapse phenomenon in SVD-informed initialization strategies (e.g., PiSSA, MiLoRA), attributing their failure to a fundamental misalignment between principal-component updates and RL optimization. Furthermore, our ablations reveal that extreme parameter reduction (e.g., VeRA, Rank-1) severely bottlenecks reasoning capacity. We further conduct ablation studies and scaling experiments to validate our findings. This work provides a definitive guide for advocating for more exploration for parameter-efficient RL methods.",
    "translation": "标题：RLVR中参数高效方法的评估研究\n\n摘要：本研究在可验证奖励强化学习（RLVR）范式下，系统评估了参数高效微调（PEFT）方法。RLVR通过可验证反馈机制激励语言模型提升推理能力；然而，尽管LoRA等方法被广泛采用，适用于RLVR的最佳PEFT架构仍未明确。本文首次在数学推理基准上对DeepSeek-R1-Distill系列模型的12种PEFT方法进行了全面评估。实证结果对标准LoRA的默认使用提出了挑战，主要发现如下：首先，结构变体方法（如DoRA、AdaLoRA和MiSS）持续优于标准LoRA；其次，我们揭示了基于SVD的初始化策略（如PiSSA、MiLoRA）存在谱崩溃现象，其失效归因于主成分更新与RL优化的根本性错配；此外，消融实验表明极端参数压缩（如VeRA、Rank-1）会严重制约推理能力。我们通过系列消融实验与规模扩展研究验证了上述结论。本研究为倡导参数高效强化学习方法的深入探索提供了权威指导。",
    "url": "https://huggingface.co/papers/2512.23165",
    "arxiv_url": "https://arxiv.org/abs/2512.23165"
  },
  {
    "title": "GraphLocator: Graph-guided Causal Reasoning for Issue Localization",
    "summary": "The issue localization task aims to identify the locations in a software repository that requires modification given a natural language issue description. This task is fundamental yet challenging in automated software engineering due to the semantic gap between issue description and source code implementation. This gap manifests as two mismatches:(1) symptom-to-cause mismatches, where descriptions do not explicitly reveal underlying root causes; (2) one-to-many mismatches, where a single issue corresponds to multiple interdependent code entities. To address these two mismatches, we propose GraphLocator, an approach that mitigates symptom-to-cause mismatches through causal structure discovering and resolves one-to-many mismatches via dynamic issue disentangling. The key artifact is the causal issue graph (CIG), in which vertices represent discovered sub-issues along with their associated code entities, and edges encode the causal dependencies between them. The workflow of GraphLocator consists of two phases: symptom vertices locating and dynamic CIG discovering; it first identifies symptom locations on the repository graph, then dynamically expands the CIG by iteratively reasoning over neighboring vertices. Experiments on three real-world datasets demonstrates the effectiveness of GraphLocator: (1) Compared with baselines, GraphLocator achieves more accurate localization with average improvements of +19.49% in function-level recall and +11.89% in precision. (2) GraphLocator outperforms baselines on both symptom-to-cause and one-to-many mismatch scenarios, achieving recall improvement of +16.44% and +19.18%, precision improvement of +7.78% and +13.23%, respectively. (3) The CIG generated by GraphLocator yields the highest relative improvement, resulting in a 28.74% increase in performance on downstream resolving task.",
    "translation": "标题：GraphLocator：基于图引导因果推理的缺陷定位方法\n\n摘要：缺陷定位任务旨在根据自然语言缺陷描述，识别软件代码库中需要修改的位置。由于缺陷描述与源代码实现之间存在语义鸿沟，该任务在自动化软件工程中既是基础性工作又极具挑战性。这种鸿沟具体表现为两种不匹配现象：（1）症状与原因不匹配，即缺陷描述未明确揭示潜在的根本原因；（2）一对多不匹配，即单个缺陷对应多个相互依赖的代码实体。为应对这两种不匹配，本文提出GraphLocator方法，通过因果结构发现缓解症状与原因不匹配问题，并借助动态缺陷解耦机制解决一对多不匹配问题。该方法的核心构件是因果缺陷图，其中顶点表示已发现的子缺陷及其关联代码实体，边则编码它们之间的因果依赖关系。GraphLocator的工作流程包含两个阶段：症状顶点定位与动态因果缺陷图发现；该方法首先在代码库图中定位症状位置，随后通过迭代推理相邻顶点动态扩展因果缺陷图。在三个真实数据集上的实验验证了GraphLocator的有效性：（1）与基线方法相比，GraphLocator实现了更精确的定位，在函数级召回率上平均提升19.49%，精确率平均提升11.89%；（2）在症状与原因不匹配及一对多不匹配场景中，GraphLocator均优于基线方法，召回率分别提升16.44%和19.18%，精确率分别提升7.78%和13.23%；（3）GraphLocator生成的因果缺陷图带来最高相对性能提升，使下游缺陷修复任务的性能提高28.74%。",
    "url": "https://huggingface.co/papers/2512.22469",
    "arxiv_url": "https://arxiv.org/abs/2512.22469"
  },
  {
    "title": "CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks",
    "summary": "Modern deep residual networks perform substantial redundant computation by evaluating all residual blocks for every input, even when identity mappings suffice. We introduce CosineGate, an end-to-end differentiable architecture for dynamic routing in residual networks that uses cosine incompatibility between identity and residual feature representations as a self-supervised skip signal. CosineGate measures semantic redundancy through the Cosine Incompatibility Ratio (CIR), defined as 1 - cos(x, F(x)), and uses Gumbel-Softmax relaxation to enable per-sample, per-block gating during training. A progressive FLOPs regularization term controls average compute usage without destabilizing optimization. On CIFAR-10, CosineGate spans the accuracy-efficiency Pareto frontier: an aggressive configuration achieves 89.9 percent accuracy with 24.1 percent FLOPs savings, a balanced configuration achieves 91.3 percent accuracy with 28.5 percent savings at epoch 160, and a conservative configuration reaches a peak of 93.2 percent accuracy with minimal compute reduction. These results match or exceed ResNet-20 (91.3 percent) while reducing computation, without auxiliary supervision, distillation, or task-specific heuristics. Our results demonstrate that simple geometric measures of feature incompatibility provide a principled and effective signal for dynamic residual routing.",
    "translation": "标题：CosineGate：基于余弦不兼容性的残差网络语义动态路由机制\n\n摘要：现代深度残差网络在处理每个输入时均需评估所有残差块，即使恒等映射已足够，这导致了大量冗余计算。本文提出CosineGate——一种端到端可微分的残差网络动态路由架构，该架构利用恒等特征表示与残差特征表示之间的余弦不兼容性作为自监督跳跃信号。CosineGate通过余弦不兼容比（CIR，定义为 1 - cos(x, F(x))）度量语义冗余，并采用Gumbel-Softmax松弛方法实现训练过程中逐样本、逐块的门控机制。渐进式浮点运算正则化项可在不破坏优化稳定性的前提下控制平均计算量。在CIFAR-10数据集上的实验表明，CosineGate能够覆盖精度-效率的帕累托前沿：激进配置在节省24.1%浮点运算量的同时达到89.9%准确率；平衡配置在第160轮训练时以28.5%的运算量节省实现91.3%准确率；保守配置则以最小计算量削减达到93.2%的峰值准确率。这些结果在减少计算量的同时达到或超越了ResNet-20基准性能（91.3%），且无需辅助监督、知识蒸馏或任务特定启发式方法。我们的研究证明，基于特征不兼容性的简单几何度量可为动态残差路由提供原理清晰且高效的信令机制。",
    "url": "https://huggingface.co/papers/2512.22206",
    "arxiv_url": "https://arxiv.org/abs/2512.22206"
  },
  {
    "title": "GateBreaker: Gate-Guided Attacks on Mixture-of-Expert LLMs",
    "summary": "Mixture-of-Experts (MoE) architectures have advanced the scaling of Large Language Models (LLMs) by activating only a sparse subset of parameters per input, enabling state-of-the-art performance with reduced computational cost. As these models are increasingly deployed in critical domains, understanding and strengthening their alignment mechanisms is essential to prevent harmful outputs. However, existing LLM safety research has focused almost exclusively on dense architectures, leaving the unique safety properties of MoEs largely unexamined. The modular, sparsely-activated design of MoEs suggests that safety mechanisms may operate differently than in dense models, raising questions about their robustness.\n  In this paper, we present GateBreaker, the first training-free, lightweight, and architecture-agnostic attack framework that compromises the safety alignment of modern MoE LLMs at inference time. GateBreaker operates in three stages: (i) gate-level profiling, which identifies safety experts disproportionately routed on harmful inputs, (ii) expert-level localization, which localizes the safety structure within safety experts, and (iii) targeted safety removal, which disables the identified safety structure to compromise the safety alignment. Our study shows that MoE safety concentrates within a small subset of neurons coordinated by sparse routing. Selective disabling of these neurons, approximately 3% of neurons in the targeted expert layers, significantly increases the averaged attack success rate (ASR) from 7.4% to 64.9% against the eight latest aligned MoE LLMs with limited utility degradation. These safety neurons transfer across models within the same family, raising ASR from 17.9% to 67.7% with one-shot transfer attack. Furthermore, GateBreaker generalizes to five MoE vision language models (VLMs) with 60.9% ASR on unsafe image inputs.",
    "translation": "标题：GateBreaker：基于门控引导的混合专家大语言模型攻击方法\n\n摘要：混合专家（MoE）架构通过仅激活每个输入对应的稀疏参数子集，推动了大语言模型（LLM）的规模化发展，在降低计算成本的同时实现了先进的性能。随着此类模型在关键领域日益广泛部署，理解并强化其对齐机制对于防止有害输出至关重要。然而，现有的大语言模型安全研究几乎完全集中于密集架构，对MoE模型独特的安全特性尚未充分探究。MoE模块化、稀疏激活的设计特点意味着其安全机制的运行方式可能与密集模型存在差异，这引发了对其鲁棒性的质疑。\n\n本文提出GateBreaker，这是首个无需训练、轻量级且架构无关的攻击框架，能够在推理阶段破坏现代MoE大语言模型的安全对齐机制。GateBreaker包含三个阶段：（1）门控层分析：识别在有害输入上被过度路由的安全专家；（2）专家层定位：在安全专家内部定位安全结构；（3）定向安全移除：通过禁用已识别的安全结构来破坏安全对齐。研究表明，MoE模型的安全机制集中于由稀疏路由协调的少量神经元子集中。选择性禁用目标专家层中约3%的神经元，可使针对八种最新对齐MoE大语言模型的平均攻击成功率从7.4%显著提升至64.9%，且模型效用损失有限。这些安全神经元在同系列模型间具有可迁移性，通过单次迁移攻击可将攻击成功率从17.9%提升至67.7%。此外，GateBreaker可泛化至五种MoE视觉语言模型，在不安全图像输入上达到60.9%的攻击成功率。",
    "url": "https://huggingface.co/papers/2512.21008",
    "arxiv_url": "https://arxiv.org/abs/2512.21008"
  }
]