[
  {
    "title": "Controlled Self-Evolution for Algorithmic Code Optimization",
    "summary": "Self-evolution methods enhance code generation through iterative \"generate-verify-refine\" cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks. To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components. Diversified Planning Initialization generates structurally distinct algorithmic strategies for broad solution space coverage. Genetic Evolution replaces stochastic operations with feedback-guided mechanisms, enabling targeted mutation and compositional crossover. Hierarchical Evolution Memory captures both successful and failed experiences at inter-task and intra-task levels. Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones. Furthermore, CSE achieves higher efficiency from early generations and maintains continuous improvement throughout evolution. Our code is publicly available at https://github.com/QuantaAlpha/EvoControl.",
    "translation": "标题：面向算法代码优化的受控自演化方法\n\n摘要：自演化方法通过迭代式的“生成-验证-精炼”循环增强代码生成能力，但现有方法存在探索效率低下的问题，难以在有限资源约束下发现具有更优复杂度的解决方案。这种低效性源于三方面瓶颈：初始化偏差使演化过程陷入次优解区域、缺乏反馈引导的随机操作难以控制，以及跨任务经验利用不足。为解决这些问题，本文提出受控自演化方法，其包含三个核心组件：多样化规划初始化通过生成结构差异化的算法策略实现广阔解空间覆盖；遗传演化以反馈引导机制替代随机操作，实现定向变异与组合交叉；分层演化记忆在任务间与任务内层级同时捕获成功与失败经验。在EffiBench-X基准上的实验表明，CSE在不同大语言模型基座上均持续优于所有基线方法。此外，CSE从演化早期即展现更高效率，并在整个演化过程中保持持续改进能力。代码已开源：https://github.com/QuantaAlpha/EvoControl。",
    "url": "https://huggingface.co/papers/2601.07348",
    "arxiv_url": "https://arxiv.org/abs/2601.07348"
  },
  {
    "title": "DeepResearchEval: An Automated Framework for Deep Research Task Construction and Agentic Evaluation",
    "summary": "Deep research systems are widely used for multi-step web research, analysis, and cross-source synthesis, yet their evaluation remains challenging. Existing benchmarks often require annotation-intensive task construction, rely on static evaluation dimensions, or fail to reliably verify facts when citations are missing. To bridge these gaps, we introduce DeepResearchEval, an automated framework for deep research task construction and agentic evaluation. For task construction, we propose a persona-driven pipeline generating realistic, complex research tasks anchored in diverse user profiles, applying a two-stage filter Task Qualification and Search Necessity to retain only tasks requiring multi-source evidence integration and external retrieval. For evaluation, we propose an agentic pipeline with two components: an Adaptive Point-wise Quality Evaluation that dynamically derives task-specific evaluation dimensions, criteria, and weights conditioned on each generated task, and an Active Fact-Checking that autonomously extracts and verifies report statements via web search, even when citations are missing.",
    "translation": "标题：DeepResearchEval：一种用于深度研究任务构建与智能体评估的自动化框架\n\n摘要：深度研究系统被广泛用于多步骤网络研究、分析与跨来源综合，但其评估仍面临挑战。现有基准测试通常需要大量标注的任务构建，依赖静态评估维度，或在引用缺失时无法可靠验证事实。为弥补这些不足，本文提出DeepResearchEval——一种用于深度研究任务构建与智能体评估的自动化框架。在任务构建方面，我们设计了一种基于人物角色的流程，通过多样化用户画像生成真实且复杂的研究任务，并应用包含“任务资格”与“搜索必要性”的两阶段筛选机制，仅保留需要多源证据整合与外部检索的任务。在评估方面，我们提出了一种智能体评估流程，包含两个核心组件：一是“自适应点式质量评估”，能够根据每个生成的任务动态推导任务特定的评估维度、标准与权重；二是“主动事实核查”，即使引用缺失，也能通过网络搜索自主提取并验证报告中的陈述。",
    "url": "https://huggingface.co/papers/2601.09688",
    "arxiv_url": "https://arxiv.org/abs/2601.09688"
  },
  {
    "title": "MAXS: Meta-Adaptive Exploration with LLM Agents",
    "summary": "Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths. These issues make it difficult to balance global effectiveness and computational efficiency. To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, we introduce a trajectory convergence mechanism that controls computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of our lookahead strategy and tool usage.",
    "translation": "标题：MAXS：基于大语言模型智能体的元自适应探索框架\n\n摘要：大语言模型智能体通过多工具协作展现出固有的推理能力。然而在智能体推理过程中，现有方法常存在两大问题：（一）因缺乏前瞻性而导致的局部短视生成；（二）轨迹不稳定性，即早期微小误差可能演变为发散推理路径。这些问题使得全局效能与计算效率难以平衡。为应对上述挑战，我们提出基于大语言模型智能体的元自适应探索框架（MAXS，项目地址：https://github.com/exoskeletonzj/MAXS），该元自适应推理框架能灵活整合工具执行与推理规划。MAXS采用前瞻策略将推理路径延伸若干步骤，评估工具使用的优势值，并结合步骤一致性方差与跨步骤趋势斜率联合选择稳定、一致且高价值的推理步骤。此外，我们引入轨迹收敛机制，在达成路径一致性时停止进一步推演以控制计算成本，从而实现多工具推理中资源效率与全局效能的平衡。我们在三个基础模型（MiMo-VL-7B、Qwen2.5-VL-7B、Qwen2.5-VL-32B）和五个数据集上进行了广泛实证研究，结果表明MAXS在性能与推理效率方面均持续优于现有方法。进一步分析验证了我们前瞻策略与工具使用机制的有效性。",
    "url": "https://huggingface.co/papers/2601.09259",
    "arxiv_url": "https://arxiv.org/abs/2601.09259"
  },
  {
    "title": "A^3-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation",
    "summary": "Scientific reasoning relies not only on logical inference but also on activating prior knowledge and experiential structures. Memory can efficiently reuse knowledge and enhance reasoning consistency and stability. However, existing benchmarks mainly evaluate final answers or step-by-step coherence, overlooking the memory-driven mechanisms that underlie human reasoning, which involves activating anchors and attractors, then integrating them into multi-step inference. To address this gap, we propose A^3-Bench~ https://a3-bench.github.io, a benchmark designed to evaluate scientific reasoning through dual-scale memory-driven activation, grounded in Anchor and Attractor Activation. First, we annotate 2,198 science reasoning problems across domains using the SAPM process(subject, anchor & attractor, problem, and memory developing). Second, we introduce a dual-scale memory evaluation framework utilizing anchors and attractors, along with the AAUI(Anchor--Attractor Utilization Index) metric to measure memory activation rates. Finally, through experiments with various base models and paradigms, we validate A^3-Bench and analyze how memory activation impacts reasoning performance, providing insights into memory-driven scientific reasoning.",
    "translation": "标题：A^3-Bench：基于锚点与吸引子激活的记忆驱动科学推理基准测试\n\n摘要：科学推理不仅依赖于逻辑推断，还需要激活先验知识与经验结构。记忆能够高效复用知识，并提升推理的一致性与稳定性。然而，现有基准测试主要评估最终答案或逐步推理的连贯性，忽视了人类推理背后基于记忆驱动的机制——该机制涉及激活锚点与吸引子，并将其整合至多步推理中。为填补这一空白，我们提出A^3-Bench（https://a3-bench.github.io），这是一个基于锚点与吸引子激活理论构建的双尺度记忆驱动激活科学推理评估基准。首先，我们采用SAPM流程（主体、锚点与吸引子、问题及记忆发展）对跨领域的2,198个科学推理问题进行了系统标注。其次，我们引入一个利用锚点与吸引子的双尺度记忆评估框架，并提出AAUI（锚点—吸引子利用指数）指标以量化记忆激活率。最后，通过对多种基础模型与推理范式的实验，我们验证了A^3-Bench的有效性，分析了记忆激活如何影响推理性能，从而为记忆驱动的科学推理研究提供了新的见解。",
    "url": "https://huggingface.co/papers/2601.09274",
    "arxiv_url": "https://arxiv.org/abs/2601.09274"
  },
  {
    "title": "Distribution-Aligned Sequence Distillation for Superior Long-CoT Reasoning",
    "summary": "In this report, we introduce DASD-4B-Thinking, a lightweight yet highly capable, fully open-source reasoning model. It achieves SOTA performance among open-source models of comparable scale across challenging benchmarks in mathematics, scientific reasoning, and code generation -- even outperforming several larger models. We begin by critically reexamining a widely adopted distillation paradigm in the community: SFT on teacher-generated responses, also known as sequence-level distillation. Although a series of recent works following this scheme have demonstrated remarkable efficiency and strong empirical performance, they are primarily grounded in the SFT perspective. Consequently, these approaches focus predominantly on designing heuristic rules for SFT data filtering, while largely overlooking the core principle of distillation itself -- enabling the student model to learn the teacher's full output distribution so as to inherit its generalization capability. Specifically, we identify three critical limitations in current practice: i) Inadequate representation of the teacher's sequence-level distribution; ii) Misalignment between the teacher's output distribution and the student's learning capacity; and iii) Exposure bias arising from teacher-forced training versus autoregressive inference. In summary, these shortcomings reflect a systemic absence of explicit teacher-student interaction throughout the distillation process, leaving the essence of distillation underexploited. To address these issues, we propose several methodological innovations that collectively form an enhanced sequence-level distillation training pipeline. Remarkably, DASD-4B-Thinking obtains competitive results using only 448K training samples -- an order of magnitude fewer than those employed by most existing open-source efforts. To support community research, we publicly release our models and the training dataset.",
    "translation": "标题：分布对齐序列蒸馏：实现卓越的长链思维推理\n\n摘要：本报告介绍了DASD-4B-Thinking——一个轻量级但能力卓越、完全开源的推理模型。该模型在数学、科学推理和代码生成等具有挑战性的基准测试中，取得了同规模开源模型中最先进的性能表现，甚至超越了若干更大规模的模型。我们首先批判性地重新审视了当前社区广泛采用的一种蒸馏范式：基于教师生成响应的监督微调，亦称为序列级蒸馏。尽管近期一系列遵循此方案的研究展现了显著的效率优势和强大的实证性能，但这些方法主要基于监督微调的视角。因此，现有研究多聚焦于设计启发式的监督微调数据过滤规则，却很大程度上忽视了蒸馏的核心原则——使学生模型能够学习教师模型的完整输出分布，从而继承其泛化能力。具体而言，我们识别出现行实践中的三个关键局限：i）教师序列级分布的表征不足；ii）教师输出分布与学生学习能力之间的错位；iii）教师强制训练与自回归推理之间的曝光偏差。总之，这些缺陷反映了蒸馏过程中缺乏明确的师生交互机制，导致蒸馏的本质未能得到充分挖掘。为解决这些问题，我们提出了多项方法论创新，共同构建了一个增强的序列级蒸馏训练流程。值得注意的是，DASD-4B-Thinking仅使用44.8万训练样本就获得了具有竞争力的结果——这比大多数现有开源工作使用的数据量少一个数量级。为支持社区研究，我们公开发布了模型及训练数据集。",
    "url": "https://huggingface.co/papers/2601.09088",
    "arxiv_url": "https://arxiv.org/abs/2601.09088"
  },
  {
    "title": "Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning",
    "summary": "Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3\\% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.",
    "translation": "标题：Fast-ThinkAct：通过可言语化潜在规划实现高效视觉-语言-动作推理\n\n摘要：视觉-语言-动作任务需要在动态环境中对复杂视觉场景进行推理并执行适应性动作。尽管近期关于推理型视觉-语言-动作模型的研究表明，显式的思维链能够提升泛化能力，但由于冗长的推理轨迹，这些方法存在推理延迟较高的问题。本文提出Fast-ThinkAct——一种通过可言语化潜在推理实现紧凑高效规划的推理框架。该方法通过从教师模型蒸馏学习，在偏好引导目标的驱动下对齐操作轨迹，从而学习利用潜在思维链进行高效推理，同时迁移语言与视觉规划能力以实现具身控制。这种机制实现了推理增强的策略学习，有效将紧凑推理与动作执行相连接。在多样化的具身操作与推理基准测试中进行的广泛实验表明，Fast-ThinkAct在保持有效长程规划、少样本适应及故障恢复能力的同时，以最高降低89.3%推理延迟的显著优势，在性能上超越了当前最先进的推理型视觉-语言-动作模型。",
    "url": "https://huggingface.co/papers/2601.09708",
    "arxiv_url": "https://arxiv.org/abs/2601.09708"
  },
  {
    "title": "SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL",
    "summary": "General-purpose Large Vision-Language Models (LVLMs), despite their massive scale, often falter in dermatology due to \"diffuse attention\" - the inability to disentangle subtle pathological lesions from background noise. In this paper, we challenge the assumption that parameter scaling is the only path to medical precision. We introduce SkinFlow, a framework that treats diagnosis as an optimization of visual information transmission efficiency. Our approach utilizes a Virtual-Width Dynamic Vision Encoder (DVE) to \"unfold\" complex pathological manifolds without physical parameter expansion, coupled with a two-stage Reinforcement Learning strategy. This strategy sequentially aligns explicit medical descriptions (Stage I) and reconstructs implicit diagnostic textures (Stage II) within a constrained semantic space. Furthermore, we propose a clinically grounded evaluation protocol that prioritizes diagnostic safety and hierarchical relevance over rigid label matching. Empirical results are compelling: our 7B model establishes a new state-of-the-art on the Fitzpatrick17k benchmark, achieving a +12.06% gain in Top-1 accuracy and a +28.57% boost in Top-6 accuracy over the massive general-purpose models (e.g., Qwen3VL-235B and GPT-5.2). These findings demonstrate that optimizing geometric capacity and information flow yields superior diagnostic reasoning compared to raw parameter scaling.",
    "translation": "标题：SkinFlow：基于动态视觉编码与分阶段强化学习的开放性皮肤病诊断高效信息传输框架\n\n摘要：通用大规模视觉语言模型尽管参数规模庞大，但在皮肤病学领域常因\"注意力弥散\"现象而表现不佳——即难以从背景噪声中分离出细微的病理特征。本文挑战了\"参数扩展是提升医学精度的唯一路径\"这一固有认知，提出SkinFlow框架，将诊断过程重新定义为视觉信息传输效率的优化问题。该框架采用虚拟宽度动态视觉编码器，在不增加实体参数的前提下实现复杂病理流形的\"展开\"表征，并结合两阶段强化学习策略：第一阶段在受限语义空间内对齐显性医学描述，第二阶段重构隐性诊断纹理特征。此外，我们建立了基于临床实践的评价体系，强调诊断安全性与层次化关联性优先于僵化的标签匹配。实验结果表明：我们的70亿参数模型在Fitzpatrick17k基准测试中取得突破性进展，相较于通用大模型（如Qwen3VL-235B与GPT-5.2），Top-1准确率提升12.06%，Top-6准确率提升28.57%。这些发现证明，通过优化几何表征能力与信息流传输机制，能够比单纯扩展参数规模产生更卓越的诊断推理性能。",
    "url": "https://huggingface.co/papers/2601.09136",
    "arxiv_url": "https://arxiv.org/abs/2601.09136"
  },
  {
    "title": "OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG",
    "summary": "The development of large language models (LLMs) has achieved superior performance in a range of downstream tasks, including LLM-based retrieval-augmented generation (RAG). The quality of generated content heavily relies on the usefulness of the retrieved information and the capacity of LLMs' internal information processing mechanism to incorporate it in answer generation. It is generally assumed that the retrieved information is relevant to the question. However, the retrieved information may have a variable degree of relevance and usefulness, depending on the question and the document collection. It is important to take into account the relevance of the retrieved information in answer generation. In this paper, we propose OpenDecoder, a new approach that leverages explicit evaluation of the retrieved information as quality indicator features for generation. We aim to build a RAG model that is more robust to varying levels of noisy context. Three types of explicit evaluation information are considered: relevance score, ranking score, and QPP (query performance prediction) score. The experimental results on five benchmark datasets demonstrate the effectiveness and better robustness of OpenDecoder by outperforming various baseline methods. Importantly, this paradigm is flexible to be integrated with the post-training of LLMs for any purposes and incorporated with any type of external indicators.",
    "translation": "标题：OpenDecoder：开放大语言模型解码以在检索增强生成中融入文档质量评估\n\n摘要：大语言模型（LLM）的发展在一系列下游任务中取得了卓越性能，包括基于LLM的检索增强生成（RAG）。生成内容的质量高度依赖于检索信息的有用性，以及LLM内部信息处理机制在答案生成中融合这些信息的能力。现有研究通常假设检索信息与问题相关，然而实际检索信息的关联性与实用性可能因具体问题及文档集合而异。在答案生成中考虑检索信息的相关性至关重要。本文提出OpenDecoder，这是一种通过显式评估检索信息作为生成质量指示特征的新方法。我们旨在构建一个对不同程度噪声上下文具有更强鲁棒性的RAG模型。该方法综合考虑三类显式评估信息：相关性评分、排序评分及查询性能预测评分。在五个基准数据集上的实验结果表明，OpenDecoder在超越多种基线方法的同时，展现出显著的有效性与更优的鲁棒性。值得注意的是，该范式具有高度灵活性，既可适配于各类目标的LLM后训练，也能与任意类型的外部指示特征相结合。",
    "url": "https://huggingface.co/papers/2601.09028",
    "arxiv_url": "https://arxiv.org/abs/2601.09028"
  },
  {
    "title": "OpenVoxel: Training-Free Grouping and Captioning Voxels for Open-Vocabulary 3D Scene Understanding",
    "summary": "We propose OpenVoxel, a training-free algorithm for grouping and captioning sparse voxels for the open-vocabulary 3D scene understanding tasks. Given the sparse voxel rasterization (SVR) model obtained from multi-view images of a 3D scene, our OpenVoxel is able to produce meaningful groups that describe different objects in the scene. Also, by leveraging powerful Vision Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), our OpenVoxel successfully build an informative scene map by captioning each group, enabling further 3D scene understanding tasks such as open-vocabulary segmentation (OVS) or referring expression segmentation (RES). Unlike previous methods, our method is training-free and does not introduce embeddings from a CLIP/BERT text encoder. Instead, we directly proceed with text-to-text search using MLLMs. Through extensive experiments, our method demonstrates superior performance compared to recent studies, particularly in complex referring expression segmentation (RES) tasks. The code will be open.",
    "translation": "标题：OpenVoxel：面向开放词汇3D场景理解的免训练体素分组与描述方法\n\n摘要：本文提出OpenVoxel，一种免训练算法，用于为开放词汇3D场景理解任务进行稀疏体素的分组与描述。给定从3D场景的多视角图像中获得的稀疏体素栅格化（SVR）模型，我们的OpenVoxel能够生成描述场景中不同物体的有意义分组。同时，通过利用强大的视觉语言模型（VLMs）和多模态大语言模型（MLLMs），OpenVoxel成功通过对每个分组进行描述来构建信息丰富的场景地图，从而支持进一步的3D场景理解任务，如开放词汇分割（OVS）或指代表达分割（RES）。与先前方法不同，我们的方法无需训练，且不引入CLIP/BERT文本编码器的嵌入向量。相反，我们直接使用MLLMs进行文本到文本的搜索。通过大量实验验证，我们的方法在多项任务中展现出优于近期研究的性能，尤其在复杂的指代表达分割（RES）任务中表现突出。代码将开源发布。",
    "url": "https://huggingface.co/papers/2601.09575",
    "arxiv_url": "https://arxiv.org/abs/2601.09575"
  },
  {
    "title": "ExpSeek: Self-Triggered Experience Seeking for Web Agents",
    "summary": "Experience intervention in web agents emerges as a promising technical paradigm, enhancing agent interaction capabilities by providing valuable insights from accumulated experiences. However, existing methods predominantly inject experience passively as global context before task execution, struggling to adapt to dynamically changing contextual observations during agent-environment interaction. We propose ExpSeek, which shifts experience toward step-level proactive seeking: (1) estimating step-level entropy thresholds to determine intervention timing using the model's intrinsic signals; (2) designing step-level tailor-designed experience content. Experiments on Qwen3-8B and 32B models across four challenging web agent benchmarks demonstrate that ExpSeek achieves absolute improvements of 9.3% and 7.5%, respectively. Our experiments validate the feasibility and advantages of entropy as a self-triggering signal, reveal that even a 4B small-scale experience model can significantly boost the performance of larger agent models.",
    "translation": "标题：ExpSeek：面向网络智能体的自触发经验寻求机制\n\n摘要：经验干预在网络智能体中作为一种前景广阔的技术范式，通过利用积累的经验提供有价值的洞察，从而增强智能体的交互能力。然而，现有方法主要在任务执行前将经验作为全局上下文被动注入，难以适应智能体与环境交互过程中动态变化的上下文观察。我们提出ExpSeek，将经验干预转向步骤级的主动寻求机制：（1）利用模型内在信号估计步骤级熵阈值以确定干预时机；（2）设计步骤级定制化的经验内容。在四个具有挑战性的网络智能体基准测试中，基于Qwen3-8B和32B模型的实验表明，ExpSeek分别实现了9.3%和7.5%的绝对性能提升。我们的实验验证了熵作为自触发信号的可行性及优势，并揭示即使仅使用4B规模的小型经验模型也能显著提升大型智能体模型的性能。",
    "url": "https://huggingface.co/papers/2601.08605",
    "arxiv_url": "https://arxiv.org/abs/2601.08605"
  },
  {
    "title": "EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines",
    "summary": "While LLM-based agents have shown promise for deep research, most existing approaches rely on fixed workflows that struggle to adapt to real-world, open-ended queries. Recent work therefore explores self-evolution by allowing agents to rewrite their own code or prompts to improve problem-solving ability, but unconstrained optimization often triggers instability, hallucinations, and instruction drift. We propose EvoFSM, a structured self-evolving framework that achieves both adaptability and control by evolving an explicit Finite State Machine (FSM) instead of relying on free-form rewriting. EvoFSM decouples the optimization space into macroscopic Flow (state-transition logic) and microscopic Skill (state-specific behaviors), enabling targeted improvements under clear behavioral boundaries. Guided by a critic mechanism, EvoFSM refines the FSM through a small set of constrained operations, and further incorporates a self-evolving memory that distills successful trajectories as reusable priors and failure patterns as constraints for future queries. Extensive evaluations on five multi-hop QA benchmarks demonstrate the effectiveness of EvoFSM. In particular, EvoFSM reaches 58.0% accuracy on the DeepSearch benchmark. Additional results on interactive decision-making tasks further validate its generalization.",
    "translation": "标题：EvoFSM：基于有限状态机的可控自进化深度研究框架\n\n摘要：尽管基于大语言模型的智能体在深度研究中展现出潜力，但现有方法大多依赖固定工作流程，难以适应现实世界中开放式的查询需求。为此，近期研究开始探索通过让智能体重写自身代码或提示词以实现自我进化，从而提升问题解决能力。然而，无约束的优化常导致系统不稳定、产生幻觉或偏离原始指令。本文提出EvoFSM，一种结构化的自进化框架，通过演化显式的有限状态机而非依赖自由形式的重写，在实现适应性的同时保持可控性。EvoFSM将优化空间解耦为宏观的流程（状态转移逻辑）与微观的技能（状态特定行为），从而在清晰的行为边界内实现针对性改进。在评估机制的引导下，EvoFSM通过一组受限操作对有限状态机进行优化，并进一步引入自进化记忆模块，将成功轨迹提炼为可复用的先验知识，将失败模式转化为未来查询的约束条件。在五个多跳问答基准上的广泛实验证明了EvoFSM的有效性，其中在DeepSearch基准上达到了58.0%的准确率。在交互式决策任务上的额外实验结果进一步验证了其泛化能力。",
    "url": "https://huggingface.co/papers/2601.09465",
    "arxiv_url": "https://arxiv.org/abs/2601.09465"
  },
  {
    "title": "FocusUI: Efficient UI Grounding via Position-Preserving Visual Token Selection",
    "summary": "Vision-Language Models (VLMs) have shown remarkable performance in User Interface (UI) grounding tasks, driven by their ability to process increasingly high-resolution screenshots. However, screenshots are tokenized into thousands of visual tokens (e.g., about 4700 for 2K resolution), incurring significant computational overhead and diluting attention. In contrast, humans typically focus on regions of interest when interacting with UI. In this work, we pioneer the task of efficient UI grounding. Guided by practical analysis of the task's characteristics and challenges, we propose FocusUI, an efficient UI grounding framework that selects patches most relevant to the instruction while preserving positional continuity for precise grounding. FocusUI addresses two key challenges: (1) Eliminating redundant tokens in visual encoding. We construct patch-level supervision by fusing an instruction-conditioned score with a rule-based UI-graph score that down-weights large homogeneous regions to select distinct and instruction-relevant visual tokens. (2) Preserving positional continuity during visual token selection. We find that general visual token pruning methods suffer from severe accuracy degradation on UI grounding tasks due to broken positional information. We introduce a novel PosPad strategy, which compresses each contiguous sequence of dropped visual tokens into a single special marker placed at the sequence's last index to preserve positional continuity. Comprehensive experiments on four grounding benchmarks demonstrate that FocusUI surpasses GUI-specific baselines. On the ScreenSpot-Pro benchmark, FocusUI-7B achieves a performance improvement of 3.7% over GUI-Actor-7B. Even with only 30% visual token retention, FocusUI-7B drops by only 3.2% while achieving up to 1.44x faster inference and 17% lower peak GPU memory.",
    "translation": "标题：FocusUI：基于位置保持视觉标记选择的高效用户界面定位方法\n\n摘要：视觉语言模型在用户界面定位任务中展现出卓越性能，这得益于其处理日益高分辨率截图的能力。然而，截图被分割为数千个视觉标记（例如2K分辨率下约4700个），导致显著的计算开销并分散注意力机制。相比之下，人类在与用户界面交互时通常聚焦于感兴趣区域。本研究开创性地探索高效用户界面定位任务。通过对任务特性与挑战的实际分析，我们提出FocusUI框架，该框架在保持位置连续性的同时筛选与指令最相关的图像区块，从而实现精确定位。FocusUI解决了两大核心挑战：（1）消除视觉编码中的冗余标记。我们通过融合指令条件评分与基于规则的用户界面图评分构建区块级监督机制，该机制通过降低大范围同质区域的权重来筛选具有区分度且与指令相关的视觉标记。（2）在视觉标记选择过程中保持位置连续性。研究发现，通用视觉标记剪枝方法会因位置信息断裂导致用户界面定位任务准确率严重下降。为此，我们提出创新的位置填充策略，将每个连续丢弃的视觉标记序列压缩为置于序列末位索引的特殊标记，从而保持位置连续性。在四个定位基准测试上的综合实验表明，FocusUI优于专用图形用户界面基线模型。在ScreenSpot-Pro基准测试中，FocusUI-7B相较于GUI-Actor-7B实现3.7%的性能提升。即使在仅保留30%视觉标记的情况下，FocusUI-7B仅下降3.2%的准确率，同时实现高达1.44倍的推理加速与17%的峰值GPU内存降低。",
    "url": "https://huggingface.co/papers/2601.03928",
    "arxiv_url": "https://arxiv.org/abs/2601.03928"
  },
  {
    "title": "Are LLMs Vulnerable to Preference-Undermining Attacks (PUA)? A Factorial Analysis Methodology for Diagnosing the Trade-off between Preference Alignment and Real-World Validity",
    "summary": "Large Language Model (LLM) training often optimizes for preference alignment, rewarding outputs that are perceived as helpful and interaction-friendly. However, this preference-oriented objective can be exploited: manipulative prompts can steer responses toward user-appeasing agreement and away from truth-oriented correction. In this work, we investigate whether aligned models are vulnerable to Preference-Undermining Attacks (PUA), a class of manipulative prompting strategies designed to exploit the model's desire to please user preferences at the expense of truthfulness. We propose a diagnostic methodology that provides a finer-grained and more directive analysis than aggregate benchmark scores, using a factorial evaluation framework to decompose prompt-induced shifts into interpretable effects of system objectives (truth- vs. preference-oriented) and PUA-style dialogue factors (directive control, personal derogation, conditional approval, reality denial) within a controlled 2 times 2^4 design. Surprisingly, more advanced models are sometimes more susceptible to manipulative prompts. Beyond the dominant reality-denial factor, we observe model-specific sign reversals and interactions with PUA-style factors, suggesting tailored defenses rather than uniform robustness. These findings offer a novel, reproducible factorial evaluation methodology that provides finer-grained diagnostics for post-training processes like RLHF, enabling better trade-offs in the product iteration of LLMs by offering a more nuanced understanding of preference alignment risks and the impact of manipulative prompts.",
    "translation": "标题：大语言模型是否易受偏好削弱攻击？一种诊断偏好对齐与现实有效性权衡的析因分析方法\n\n摘要：大语言模型的训练通常以偏好对齐为优化目标，奖励那些被认为有帮助且交互友好的输出。然而，这种以偏好为导向的目标可能被利用：操纵性提示可以引导模型倾向于取悦用户的附和回应，而非基于事实的修正。本研究探讨经过对齐的模型是否易受偏好削弱攻击——这类操纵性提示策略旨在利用模型取悦用户偏好的倾向，从而牺牲其真实性。我们提出一种诊断方法，通过析因评估框架在受控的2×2⁴设计中将提示引发的响应变化分解为系统目标（以真实性为导向 vs. 以偏好为导向）与PUA式对话因素（指令控制、人身贬损、条件性认可、现实否认）的可解释效应，该方法比聚合基准分数能提供更细粒度、更具指向性的分析。令人惊讶的是，更先进的模型有时反而更容易受到操纵性提示的影响。除了占主导地位的现实否认因素外，我们还观察到模型特定的符号反转以及与PUA式因素的交互作用，这表明需要针对性的防御策略而非统一的鲁棒性方案。这些发现提出了一种新颖、可复现的析因评估方法，为RLHF等训练后过程提供更细粒度的诊断，通过对偏好对齐风险与操纵性提示影响的更细致理解，助力大语言模型在产品迭代中实现更优的权衡。",
    "url": "https://huggingface.co/papers/2601.06596",
    "arxiv_url": "https://arxiv.org/abs/2601.06596"
  },
  {
    "title": "TranslateGemma Technical Report",
    "summary": "We present TranslateGemma, a suite of open machine translation models based on the Gemma 3 foundation models. To enhance the inherent multilingual capabilities of Gemma 3 for the translation task, we employ a two-stage fine-tuning process. First, supervised fine-tuning is performed using a rich mixture of high-quality large-scale synthetic parallel data generated via state-of-the-art models and human-translated parallel data. This is followed by a reinforcement learning phase, where we optimize translation quality using an ensemble of reward models, including MetricX-QE and AutoMQM, targeting translation quality. We demonstrate the effectiveness of TranslateGemma with human evaluation on the WMT25 test set across 10 language pairs and with automatic evaluation on the WMT24++ benchmark across 55 language pairs. Automatic metrics show consistent and substantial gains over the baseline Gemma 3 models across all sizes. Notably, smaller TranslateGemma models often achieve performance comparable to larger baseline models, offering improved efficiency. We also show that TranslateGemma models retain strong multimodal capabilities, with enhanced performance on the Vistra image translation benchmark. The release of the open TranslateGemma models aims to provide the research community with powerful and adaptable tools for machine translation.",
    "translation": "标题：TranslateGemma技术报告\n\n摘要：本文介绍了TranslateGemma，一套基于Gemma 3基础模型的开源机器翻译模型。为增强Gemma 3模型在翻译任务中固有的多语言能力，我们采用了两阶段微调方法。首先，使用通过先进模型生成的大规模高质量合成平行数据与人工翻译平行数据构成的丰富混合数据集进行监督式微调。随后进行强化学习阶段，通过集成包括MetricX-QE和AutoMQM在内的奖励模型，以翻译质量为目标进行优化。我们在WMT25测试集的10个语言对上通过人工评估，以及在WMT24++基准测试的55个语言对上通过自动评估，验证了TranslateGemma的有效性。自动评估指标显示，所有规模的TranslateGemma模型相较于基线Gemma 3模型均取得了一致且显著的性能提升。值得注意的是，较小规模的TranslateGemma模型常能达到与较大规模基线模型相当的性能，同时提升了效率。我们还证明TranslateGemma模型保留了强大的多模态能力，在Vistra图像翻译基准测试中表现出增强的性能。开源TranslateGemma模型的发布旨在为研究社区提供强大且适应性强的机器翻译工具。",
    "url": "https://huggingface.co/papers/2601.09012",
    "arxiv_url": "https://arxiv.org/abs/2601.09012"
  },
  {
    "title": "Imagine-then-Plan: Agent Learning from Adaptive Lookahead with World Models",
    "summary": "Recent advances in world models have shown promise for modeling future dynamics of environmental states, enabling agents to reason and act without accessing real environments. Current methods mainly perform single-step or fixed-horizon rollouts, leaving their potential for complex task planning under-exploited. We propose Imagine-then-Plan (ITP), a unified framework for agent learning via lookahead imagination, where an agent's policy model interacts with the learned world model, yielding multi-step ``imagined'' trajectories. Since the imagination horizon may vary by tasks and stages, we introduce a novel adaptive lookahead mechanism by trading off the ultimate goal and task progress. The resulting imagined trajectories provide rich signals about future consequences, such as achieved progress and potential conflicts, which are fused with current observations, formulating a partially observable and imaginable Markov decision process to guide policy learning. We instantiate ITP with both training-free and reinforcement-trained variants. Extensive experiments across representative agent benchmarks demonstrate that ITP significantly outperforms competitive baselines. Further analyses validate that our adaptive lookahead largely enhances agents' reasoning capability, providing valuable insights into addressing broader, complex tasks.",
    "translation": "标题：想象而后规划：基于世界模型的自适应前瞻智能体学习\n\n摘要：世界模型的最新进展为环境状态的未来动态建模提供了可能，使智能体能够在无需访问真实环境的情况下进行推理与决策。现有方法主要执行单步或固定步长的轨迹推演，其在复杂任务规划中的潜力尚未得到充分挖掘。本文提出“想象而后规划”框架，该统一框架通过前瞻想象实现智能体学习，使策略模型与习得的世界模型交互，生成多步“想象”轨迹。鉴于想象步长可能随任务和阶段动态变化，我们引入一种新颖的自适应前瞻机制，通过权衡最终目标与任务进度实现动态调整。生成的想象轨迹提供了关于未来结果的丰富信号（如已达成进度与潜在冲突），这些信号与当前观测信息相融合，构建出部分可观测且可想象的马尔可夫决策过程以指导策略学习。我们通过免训练和强化训练两种变体实现了该框架。在代表性智能体基准测试上的大量实验表明，本方法显著优于现有基线模型。进一步分析验证了自适应前瞻机制能有效增强智能体的推理能力，为应对更广泛的复杂任务提供了重要启示。",
    "url": "https://huggingface.co/papers/2601.08955",
    "arxiv_url": "https://arxiv.org/abs/2601.08955"
  },
  {
    "title": "Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering",
    "summary": "Modern video generative models based on diffusion models can produce very realistic clips, but they are computationally inefficient, often requiring minutes of GPU time for just a few seconds of video. This inefficiency poses a critical barrier to deploying generative video in applications that require real-time interactions, such as embodied AI and VR/AR. This paper explores a new strategy for camera-conditioned video generation of static scenes: using diffusion-based generative models to generate a sparse set of keyframes, and then synthesizing the full video through 3D reconstruction and rendering. By lifting keyframes into a 3D representation and rendering intermediate views, our approach amortizes the generation cost across hundreds of frames while enforcing geometric consistency. We further introduce a model that predicts the optimal number of keyframes for a given camera trajectory, allowing the system to adaptively allocate computation. Our final method, SRENDER, uses very sparse keyframes for simple trajectories and denser ones for complex camera motion. This results in video generation that is more than 40 times faster than the diffusion-based baseline in generating 20 seconds of video, while maintaining high visual fidelity and temporal stability, offering a practical path toward efficient and controllable video synthesis.",
    "translation": "标题：基于稀疏扩散与三维渲染的静态场景高效相机控制视频生成\n\n摘要：基于扩散模型的现代视频生成模型能够生成高度逼真的视频片段，但其计算效率低下，通常需要数分钟GPU时间才能生成数秒视频。这种低效性对在需要实时交互的应用（如具身人工智能和虚拟/增强现实）中部署生成式视频构成了关键障碍。本文探索了一种静态场景相机条件视频生成的新策略：利用基于扩散的生成模型生成稀疏关键帧集合，随后通过三维重建与渲染合成完整视频。通过将关键帧提升至三维表征并渲染中间视图，我们的方法在确保几何一致性的同时，将生成成本分摊至数百帧。我们进一步提出一种预测给定相机轨迹最优关键帧数量的模型，使系统能够自适应分配计算资源。我们的最终方法SRENDER针对简单轨迹使用极稀疏关键帧，针对复杂相机运动则采用更密集的关键帧分布。该方法在生成20秒视频时，比基于扩散的基线方法提速超过40倍，同时保持高视觉保真度与时间稳定性，为高效可控的视频合成提供了可行路径。",
    "url": "https://huggingface.co/papers/2601.09697",
    "arxiv_url": "https://arxiv.org/abs/2601.09697"
  },
  {
    "title": "Geometric Stability: The Missing Axis of Representations",
    "summary": "Analysis of learned representations has a blind spot: it focuses on similarity, measuring how closely embeddings align with external references, but similarity reveals only what is represented, not whether that structure is robust. We introduce geometric stability, a distinct dimension that quantifies how reliably representational geometry holds under perturbation, and present Shesha, a framework for measuring it. Across 2,463 configurations in seven domains, we show that stability and similarity are empirically uncorrelated (ρapprox 0.01) and mechanistically distinct: similarity metrics collapse after removing the top principal components, while stability retains sensitivity to fine-grained manifold structure. This distinction yields actionable insights: for safety monitoring, stability acts as a functional geometric canary, detecting structural drift nearly 2times more sensitively than CKA while filtering out the non-functional noise that triggers false alarms in rigid distance metrics; for controllability, supervised stability predicts linear steerability (ρ= 0.89-0.96); for model selection, stability dissociates from transferability, revealing a geometric tax that transfer optimization incurs. Beyond machine learning, stability predicts CRISPR perturbation coherence and neural-behavioral coupling. By quantifying how reliably systems maintain structure, geometric stability provides a necessary complement to similarity for auditing representations across biological and computational systems.",
    "translation": "标题：几何稳定性：表征分析中缺失的维度\n\n摘要：现有学习表征分析存在盲区：其聚焦于相似性度量，即衡量嵌入与外部参考的对齐程度，但相似性仅能揭示表征内容，无法判断该结构是否具有鲁棒性。本文提出几何稳定性这一全新维度，用于量化表征几何在扰动下的保持可靠性，并构建Shesha框架进行测量。通过在七个领域的2463种配置实验中，我们发现稳定性与相似性在经验上无相关性（ρ≈0.01）且机制相异：移除主要主成分后相似性度量会失效，而稳定性仍对细粒度流形结构保持敏感。这种差异产生可操作的洞见：在安全监控方面，稳定性可作为功能性几何预警指标，其检测结构漂移的灵敏度比CKA提升近2倍，同时能过滤刚性距离度量中引发误报的非功能性噪声；在可控性方面，监督稳定性可预测线性可操控性（ρ=0.89-0.96）；在模型选择方面，稳定性与可迁移性解耦，揭示了迁移优化所产生的几何代价。超越机器学习领域，稳定性可预测CRISPR扰动一致性与神经行为耦合度。通过量化系统维持结构的可靠性，几何稳定性为生物与计算系统的表征审计提供了相似性度量不可或缺的补充维度。",
    "url": "https://huggingface.co/papers/2601.09173",
    "arxiv_url": "https://arxiv.org/abs/2601.09173"
  },
  {
    "title": "The AI Hippocampus: How Far are We From Human Memory?",
    "summary": "Memory plays a foundational role in augmenting the reasoning, adaptability, and contextual fidelity of modern Large Language Models and Multi-Modal LLMs. As these models transition from static predictors to interactive systems capable of continual learning and personalized inference, the incorporation of memory mechanisms has emerged as a central theme in their architectural and functional evolution. This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organizing the literature into a cohesive taxonomy comprising implicit, explicit, and agentic memory paradigms. Specifically, the survey delineates three primary memory frameworks. Implicit memory refers to the knowledge embedded within the internal parameters of pre-trained transformers, encompassing their capacity for memorization, associative retrieval, and contextual reasoning. Recent work has explored methods to interpret, manipulate, and reconfigure this latent memory. Explicit memory involves external storage and retrieval components designed to augment model outputs with dynamic, queryable knowledge representations, such as textual corpora, dense vectors, and graph-based structures, thereby enabling scalable and updatable interaction with information sources. Agentic memory introduces persistent, temporally extended memory structures within autonomous agents, facilitating long-term planning, self-consistency, and collaborative behavior in multi-agent systems, with relevance to embodied and interactive AI. Extending beyond text, the survey examines the integration of memory within multi-modal settings, where coherence across vision, language, audio, and action modalities is essential. Key architectural advances, benchmark tasks, and open challenges are discussed, including issues related to memory capacity, alignment, factual consistency, and cross-system interoperability.",
    "translation": "标题：人工智能海马体：我们距离人类记忆还有多远？\n\n摘要：记忆在增强现代大语言模型与多模态大语言模型的推理能力、适应性与情境保真度方面发挥着基础性作用。随着这些模型从静态预测器向具备持续学习与个性化推理能力的交互式系统演进，记忆机制的整合已成为其架构与功能发展的核心议题。本文对LLMs与MLLMs中的记忆研究进行了全面而结构化的梳理，将现有文献整合为涵盖隐性记忆、显性记忆与智能体记忆范式的统一分类体系。具体而言，本文系统阐述了三类主要记忆框架：隐性记忆指预训练Transformer内部参数所蕴含的知识，包括其记忆存储、关联检索与情境推理能力，近期研究聚焦于对这一潜在记忆进行解释、操控与重构的方法；显性记忆通过外部存储与检索组件（如文本语料库、稠密向量与图结构等动态可查询知识表征）增强模型输出，从而实现与信息源的可扩展、可更新交互；智能体记忆在自主智能体中引入持久化、时序延展的记忆结构，促进多智能体系统中的长期规划、自我一致性与协作行为，对具身交互人工智能具有重要意义。本文进一步超越文本范畴，探讨了多模态场景中记忆机制的整合，其中视觉、语言、音频与行为模态间的协调一致性至关重要。文中系统评述了关键架构进展、基准任务与开放挑战，涉及记忆容量、对齐机制、事实一致性及跨系统互操作性等核心议题。",
    "url": "https://huggingface.co/papers/2601.09113",
    "arxiv_url": "https://arxiv.org/abs/2601.09113"
  },
  {
    "title": "Flow Equivariant World Models: Memory for Partially Observed Dynamic Environments",
    "summary": "Embodied systems experience the world as 'a symphony of flows': a combination of many continuous streams of sensory input coupled to self-motion, interwoven with the dynamics of external objects. These streams obey smooth, time-parameterized symmetries, which combine through a precisely structured algebra; yet most neural network world models ignore this structure and instead repeatedly re-learn the same transformations from data. In this work, we introduce 'Flow Equivariant World Models', a framework in which both self-motion and external object motion are unified as one-parameter Lie group 'flows'. We leverage this unification to implement group equivariance with respect to these transformations, thereby providing a stable latent world representation over hundreds of timesteps. On both 2D and 3D partially observed video world modeling benchmarks, we demonstrate that Flow Equivariant World Models significantly outperform comparable state-of-the-art diffusion-based and memory-augmented world modeling architectures -- particularly when there are predictable world dynamics outside the agent's current field of view. We show that flow equivariance is particularly beneficial for long rollouts, generalizing far beyond the training horizon. By structuring world model representations with respect to internal and external motion, flow equivariance charts a scalable route to data efficient, symmetry-guided, embodied intelligence. Project link: https://flowequivariantworldmodels.github.io.",
    "translation": "标题：流等变世界模型：面向部分可观测动态环境的记忆机制\n\n摘要：具身系统将世界体验为“流动的交响曲”：即多种连续感官输入流与自身运动耦合，并与外部物体动力学交织形成的组合。这些数据流遵循平滑的时间参数化对称性，并通过精确结构化的代数进行组合；然而大多数神经网络世界模型忽略此结构，转而反复从数据中重新学习相同的变换。本研究提出“流等变世界模型”框架，将自身运动与外部物体运动统一建模为单参数李群“流”。我们利用这种统一性实现对变换的群等变性，从而在数百个时间步长上提供稳定的潜在世界表征。在2D与3D部分可观测视频世界建模基准测试中，流等变世界模型显著优于当前基于扩散和记忆增强的先进世界建模架构——尤其在智能体当前视野外存在可预测世界动力学时表现突出。研究表明流等变性对长序列推演尤为有益，其泛化能力远超训练时域。通过基于内外运动构建世界模型表征，流等变性为数据高效、对称性引导的具身智能开辟了可扩展路径。项目链接：https://flowequivariantworldmodels.github.io。",
    "url": "https://huggingface.co/papers/2601.01075",
    "arxiv_url": "https://arxiv.org/abs/2601.01075"
  },
  {
    "title": "DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing",
    "summary": "Reinforcement learning (RL)-based enhancement of large language models (LLMs) often leads to reduced output diversity, undermining their utility in open-ended tasks like creative writing. Current methods lack explicit mechanisms for guiding diverse exploration and instead prioritize optimization efficiency and performance over diversity. This paper proposes an RL framework structured around a semi-structured long Chain-of-Thought (CoT), in which the generation process is decomposed into explicitly planned intermediate steps. We introduce a Diverse Planning Branching method that strategically introduces divergence at the planning phase based on diversity variation, alongside a group-aware diversity reward to encourage distinct trajectories. Experimental results on creative writing benchmarks demonstrate that our approach significantly improves output diversity without compromising generation quality, consistently outperforming existing baselines.",
    "translation": "标题：DPWriter：基于多样化规划分支强化学习的创意写作方法\n\n摘要：基于强化学习的大语言模型增强方法常导致输出多样性下降，削弱了其在创意写作等开放式任务中的实用性。现有方法缺乏引导多样化探索的显式机制，往往优先考虑优化效率与性能而忽视多样性。本文提出一种围绕半结构化长链思维构建的强化学习框架，该框架将生成过程分解为显式规划的中间步骤。我们引入一种多样化规划分支方法，该方法基于多样性变化在规划阶段策略性地引入分岔，并结合群体感知多样性奖励以激励差异化轨迹生成。在创意写作基准测试上的实验结果表明，该方法在保持生成质量的同时显著提升了输出多样性，各项指标持续优于现有基线模型。",
    "url": "https://huggingface.co/papers/2601.09609",
    "arxiv_url": "https://arxiv.org/abs/2601.09609"
  },
  {
    "title": "Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning",
    "summary": "Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning. More recent studies have incorporated multimodal information into the reasoning steps; however, they often follow a single task-specific reasoning pattern, which limits their generalizability across various multimodal tasks. In fact, there are numerous multimodal tasks requiring diverse reasoning skills, such as zooming in on a specific region or marking an object within an image. To address this, we propose unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. We instantiate this paradigm with Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, thereby enabling functional image generation. Additionally, we introduce Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting a promising direction for generative multimodal reasoning.",
    "translation": "标题：Omni-R1：迈向统一生成式多模态推理范式\n\n摘要：多模态大语言模型（MLLMs）在多模态推理领域正取得显著进展。早期方法主要关注纯文本推理。近期研究虽已将多模态信息融入推理步骤，但通常遵循单一任务特定的推理模式，这限制了其在各类多模态任务中的泛化能力。实际上，众多多模态任务需要多样化的推理技能，例如聚焦图像特定区域或在图像中标记对象。为解决这一问题，我们提出统一生成式多模态推理范式，通过在推理过程中生成中间图像来统一多样的多模态推理能力。我们通过Omni-R1实例化这一范式，该框架采用两阶段监督微调与强化学习架构，引入感知对齐损失和感知奖励机制，从而实现功能性图像生成。此外，我们提出Omni-R1-Zero，该方法通过从纯文本推理数据中自举逐步可视化信息，无需依赖多模态标注。实验结果表明，Omni-R1能够在广泛的多模态任务中实现统一的生成式推理，而Omni-R1-Zero在整体表现上可达到甚至超越Omni-R1，这为生成式多模态推理指明了具有前景的发展方向。",
    "url": "https://huggingface.co/papers/2601.09536",
    "arxiv_url": "https://arxiv.org/abs/2601.09536"
  },
  {
    "title": "No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning",
    "summary": "Critique-guided reinforcement learning (RL) has emerged as a powerful paradigm for training LLM agents by augmenting sparse outcome rewards with natural-language feedback. However, current methods often rely on static or offline critic models, which fail to adapt as the policy evolves. In on-policy RL, the agent's error patterns shift over time, causing stationary critics to become stale and providing feedback of diminishing utility. To address this, we introduce ECHO (Evolving Critic for Hindsight-Guided Optimization)}, a framework that jointly optimizes the policy and critic through a synchronized co-evolutionary loop. ECHO utilizes a cascaded rollout mechanism where the critic generates multiple diagnoses for an initial trajectory, followed by policy refinement to enable group-structured advantage estimation. We address the challenge of learning plateaus via a saturation-aware gain shaping objective, which rewards the critic for inducing incremental improvements in high-performing trajectories. By employing dual-track GRPO updates, ECHO ensures the critic's feedback stays synchronized with the evolving policy. Experimental results show that ECHO yields more stable training and higher long-horizon task success across open-world environments.",
    "translation": "标题：告别陈旧反馈：面向开放世界智能体学习的协同演化批评器\n\n摘要：基于批评的强化学习已成为通过自然语言反馈增强稀疏结果奖励来训练大语言模型智能体的重要范式。然而，现有方法通常依赖静态或离线批评模型，无法随策略演化而动态调整。在同策略强化学习中，智能体的错误模式会随时间变化，导致固定批评器逐渐失效，其反馈效用随之衰减。为此，我们提出ECHO（面向后见指导优化的演化批评器）框架，通过同步协同演化循环实现策略与批评器的联合优化。ECHO采用级联推演机制：批评器对初始轨迹生成多重诊断，继而通过策略精调实现群体结构化优势估计。针对学习平台期问题，我们提出饱和度感知增益塑形目标，通过奖励批评器在高性能轨迹中诱导渐进式改进来突破瓶颈。通过双轨GRPO更新机制，ECHO确保批评反馈与演化策略保持同步。实验结果表明，ECHO在开放世界环境中能实现更稳定的训练过程，并在长周期任务中取得更高的成功率。",
    "url": "https://huggingface.co/papers/2601.06794",
    "arxiv_url": "https://arxiv.org/abs/2601.06794"
  },
  {
    "title": "SCALER:Synthetic Scalable Adaptive Learning Environment for Reasoning",
    "summary": "Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while preserving strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward sparsity, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.",
    "translation": "标题：SCALER：面向推理任务的合成式可扩展自适应学习环境\n\n摘要：强化学习为提升大语言模型的推理能力提供了一种理论化方法，但其有效性依赖于能够随模型演化而持续提供信息的训练信号。实践中，当任务难度与模型能力不匹配，或训练过程被少量重复出现的问题模式主导时，强化学习的进展往往会放缓。为协同解决这些问题，我们提出SCALER（面向推理任务的合成式可扩展自适应学习环境），该框架通过自适应环境设计来维持有效的学习信号。SCALER引入了一个可扩展的合成流程，能够将现实世界的编程问题转化为具有可控难度和无限实例生成能力的可验证推理环境，从而在保持强正确性保证的前提下，实现超越有限数据集的强化学习训练。在此基础上，SCALER进一步采用一种自适应多环境强化学习策略，动态调整实例难度并筛选活跃环境集合，以追踪模型能力边界并保持分布多样性。这种协同适应机制避免了奖励稀疏性，缓解了对狭窄任务模式的过拟合，并支持训练过程中的持续改进。大量实验表明，SCALER在多种推理基准测试中始终优于基于数据集的强化学习基线方法，并展现出更稳定、更长周期的训练动态。",
    "url": "https://huggingface.co/papers/2601.04809",
    "arxiv_url": "https://arxiv.org/abs/2601.04809"
  },
  {
    "title": "Focal Guidance: Unlocking Controllability from Semantic-Weak Layers in Video Diffusion Models",
    "summary": "The task of Image-to-Video (I2V) generation aims to synthesize a video from a reference image and a text prompt. This requires diffusion models to reconcile high-frequency visual constraints and low-frequency textual guidance during the denoising process. However, while existing I2V models prioritize visual consistency, how to effectively couple this dual guidance to ensure strong adherence to the text prompt remains underexplored. In this work, we observe that in Diffusion Transformer (DiT)-based I2V models, certain intermediate layers exhibit weak semantic responses (termed Semantic-Weak Layers), as indicated by a measurable drop in text-visual similarity. We attribute this to a phenomenon called Condition Isolation, where attention to visual features becomes partially detached from text guidance and overly relies on learned visual priors. To address this, we propose Focal Guidance (FG), which enhances the controllability from Semantic-Weak Layers. FG comprises two mechanisms: (1) Fine-grained Semantic Guidance (FSG) leverages CLIP to identify key regions in the reference frame and uses them as anchors to guide Semantic-Weak Layers. (2) Attention Cache transfers attention maps from semantically responsive layers to Semantic-Weak Layers, injecting explicit semantic signals and alleviating their over-reliance on the model's learned visual priors, thereby enhancing adherence to textual instructions. To further validate our approach and address the lack of evaluation in this direction, we introduce a benchmark for assessing instruction following in I2V models. On this benchmark, Focal Guidance proves its effectiveness and generalizability, raising the total score on Wan2.1-I2V to 0.7250 (+3.97\\%) and boosting the MMDiT-based HunyuanVideo-I2V to 0.5571 (+7.44\\%).",
    "translation": "标题：焦点引导：从视频扩散模型的语义弱层中解锁可控性\n\n摘要：图像到视频（I2V）生成任务旨在根据参考图像和文本提示合成视频。这要求扩散模型在去噪过程中协调高频视觉约束与低频文本引导。然而，尽管现有I2V模型优先考虑视觉一致性，如何有效耦合这种双重引导以确保对文本提示的严格遵循仍待深入探索。本研究观察到，在基于扩散Transformer（DiT）的I2V模型中，某些中间层表现出较弱的语义响应（称为语义弱层），其表现为文本-视觉相似度的可测量下降。我们将此归因于一种称为“条件隔离”的现象，即对视觉特征的注意力部分脱离文本引导，并过度依赖模型学习到的视觉先验。为解决此问题，我们提出焦点引导（FG）方法，以增强语义弱层的可控性。FG包含两种机制：（1）细粒度语义引导（FSG）利用CLIP识别参考帧中的关键区域，并将其作为锚点引导语义弱层；（2）注意力缓存将语义响应层的注意力图传递至语义弱层，注入显式语义信号，减轻其对模型学习视觉先验的过度依赖，从而提升对文本指令的遵循能力。为进一步验证本方法并弥补该方向评估体系的缺失，我们引入了一个用于评估I2V模型指令遵循能力的基准测试。在此基准上，焦点引导证明了其有效性和泛化能力：将Wan2.1-I2V的总分提升至0.7250（+3.97%），并将基于MMDiT的HunyuanVideo-I2V得分提升至0.5571（+7.44%）。",
    "url": "https://huggingface.co/papers/2601.07287",
    "arxiv_url": "https://arxiv.org/abs/2601.07287"
  },
  {
    "title": "Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing",
    "summary": "Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.",
    "translation": "标题：集群工作负载分配：基于自然语言处理的语义软亲和性\n\n摘要：集群工作负载分配通常需要复杂的配置，导致可用性差距。本文提出一种基于自然语言处理的语义化、意图驱动的集群系统调度范式。该系统通过集成大型语言模型（LLM）至Kubernetes调度器扩展程序，以解析用于软亲和性偏好的自然语言分配提示注解。研究开发了包含集群状态缓存和意图分析器（使用AWS Bedrock）的原型系统。实证评估表明，在评估基准数据集上，Amazon Nova Pro/Premier和Mistral Pixtral Large等顶级模型的LLM解析准确率较高（子集准确率>95%），显著优于基线引擎。在六种场景下的调度质量测试显示，与标准Kubernetes配置相比，该原型实现了更优或同等的资源分配效果，尤其在复杂场景、量化场景及冲突软偏好处理方面表现突出。结果验证了利用LLM实现可访问调度的可行性，但也揭示了同步LLM延迟等局限性，建议采用异步处理以满足生产环境要求。本研究证实了语义软亲和性在简化工作负载编排方面的实用价值。",
    "url": "https://huggingface.co/papers/2601.09282",
    "arxiv_url": "https://arxiv.org/abs/2601.09282"
  },
  {
    "title": "sui-1: Grounded and Verifiable Long-Form Summarization",
    "summary": "Large language models frequently generate plausible but unfaithful summaries that users cannot verify against source text, a critical limitation in compliance-sensitive domains such as government and legal analysis. We present sui-1, a 24B parameter model that produces abstractive summaries with inline citations, enabling users to trace each claim to its source sentence. Our synthetic data pipeline combines chain-of-thought prompting with multi-stage verification, generating over 22,000 high-quality training examples across five languages from diverse sources including parliamentary documents, web text, and Wikipedia. Evaluation shows sui-1 significantly outperforms all tested open-weight baselines, including models with 3x more parameters. These results demonstrate that task-specific training substantially outperforms scale alone for citation-grounded summarization. Model weights and an interactive demo are publicly available.",
    "translation": "标题：sui-1：基于引证且可验证的长文本摘要生成模型\n\n摘要：大型语言模型常生成看似合理但无法忠实反映原文的摘要，用户难以依据源文本进行验证，这在政府与法律分析等对合规性要求严格的领域构成关键局限。本文提出sui-1模型，该模型拥有240亿参数，能够生成包含文中引证的抽象摘要，使用户能够将每个主张追溯至源语句。我们通过结合思维链提示与多阶段验证的合成数据流程，从议会文件、网络文本及维基百科等多样化来源中，生成了涵盖五种语言超过22,000个高质量训练样本。评估表明，sui-1在各项指标上显著优于所有测试的开源基线模型，包括参数量为其三倍的模型。这些结果证明，针对引证型摘要任务的专业化训练能够显著超越单纯扩大模型规模的效果。模型权重及交互演示已公开发布。",
    "url": "https://huggingface.co/papers/2601.08472",
    "arxiv_url": "https://arxiv.org/abs/2601.08472"
  },
  {
    "title": "SampoNLP: A Self-Referential Toolkit for Morphological Analysis of Subword Tokenizers",
    "summary": "The quality of subword tokenization is critical for Large Language Models, yet evaluating tokenizers for morphologically rich Uralic languages is hampered by the lack of clean morpheme lexicons.\n  We introduce SampoNLP, a corpus-free toolkit for morphological lexicon creation using MDL-inspired Self-Referential Atomicity Scoring, which filters composite forms through internal structural cues - suited for low-resource settings.\n  Using the high-purity lexicons generated by SampoNLP for Finnish, Hungarian, and Estonian, we conduct a systematic evaluation of BPE tokenizers across a range of vocabulary sizes (8k-256k). We propose a unified metric, the Integrated Performance Score (IPS), to navigate the trade-off between morpheme coverage and over-splitting. By analyzing the IPS curves, we identify the \"elbow points\" of diminishing returns and provide the first empirically grounded recommendations for optimal vocabulary sizes (k) in these languages. Our study not only offers practical guidance but also quantitatively demonstrates the limitations of standard BPE for highly agglutinative languages. The SampoNLP library and all generated resources are made publicly available: https://github.com/AragonerUA/SampoNLP",
    "translation": "标题：SampoNLP：一种用于子词分词器形态学分析的自参照工具包\n\n摘要：子词分词的质量对大语言模型至关重要，然而，对形态丰富的乌拉尔语系语言进行分词器评估，常因缺乏清晰的语素词典而受阻。本文介绍SampoNLP，一种无需语料库的形态学词典构建工具包，其采用受最小描述长度启发的自参照原子性评分方法，通过内部结构线索过滤复合形式，适用于低资源场景。利用SampoNLP为芬兰语、匈牙利语和爱沙尼亚语生成的高纯度词典，我们对BPE分词器在不同词汇表规模（8k-256k）下进行了系统评估。我们提出统一指标——综合性能得分，以权衡语素覆盖与过度切分之间的平衡。通过分析综合性能得分曲线，我们确定了收益递减的“拐点”，并为这些语言首次提供了基于实证的最优词汇表规模建议。本研究不仅提供了实用指导，还定量证明了标准BPE对高度黏着性语言的局限性。SampoNLP库及所有生成资源已公开：https://github.com/AragonerUA/SampoNLP",
    "url": "https://huggingface.co/papers/2601.04469",
    "arxiv_url": "https://arxiv.org/abs/2601.04469"
  }
]