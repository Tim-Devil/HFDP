[
  {
    "title": "Controlled Self-Evolution for Algorithmic Code Optimization",
    "summary": "Self-evolution methods enhance code generation through iterative \"generate-verify-refine\" cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks. To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components. Diversified Planning Initialization generates structurally distinct algorithmic strategies for broad solution space coverage. Genetic Evolution replaces stochastic operations with feedback-guided mechanisms, enabling targeted mutation and compositional crossover. Hierarchical Evolution Memory captures both successful and failed experiences at inter-task and intra-task levels. Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones. Furthermore, CSE achieves higher efficiency from early generations and maintains continuous improvement throughout evolution. Our code is publicly available at https://github.com/QuantaAlpha/EvoControl.",
    "translation": "标题：面向算法代码优化的受控自演化方法\n\n摘要：自演化方法通过\"生成-验证-精化\"的迭代循环增强代码生成能力，但现有方法存在探索效率低下的问题，难以在有限资源约束下发现具有更优复杂度的解决方案。这种低效性源于三个核心瓶颈：初始化偏差使演化过程陷入次优解区域、缺乏反馈引导的随机操作难以控制，以及跨任务经验利用不足。为解决这些瓶颈，我们提出受控自演化框架，该框架包含三个关键组件：多样化规划初始化生成结构相异的算法策略以实现广阔解空间覆盖；遗传演化机制以反馈引导的定向突变与组合交叉替代随机操作；分层演化记忆系统在任务间与任务内层面同时捕获成功与失败经验。在EffiBench-X基准上的实验表明，CSE在不同大语言模型基座上均持续优于所有基线方法。此外，CSE在演化早期即展现出更高效率，并在整个演化过程中保持持续改进能力。代码已开源：https://github.com/QuantaAlpha/EvoControl。",
    "url": "https://huggingface.co/papers/2601.07348",
    "arxiv_url": "https://arxiv.org/abs/2601.07348"
  },
  {
    "title": "DeepResearchEval: An Automated Framework for Deep Research Task Construction and Agentic Evaluation",
    "summary": "Deep research systems are widely used for multi-step web research, analysis, and cross-source synthesis, yet their evaluation remains challenging. Existing benchmarks often require annotation-intensive task construction, rely on static evaluation dimensions, or fail to reliably verify facts when citations are missing. To bridge these gaps, we introduce DeepResearchEval, an automated framework for deep research task construction and agentic evaluation. For task construction, we propose a persona-driven pipeline generating realistic, complex research tasks anchored in diverse user profiles, applying a two-stage filter Task Qualification and Search Necessity to retain only tasks requiring multi-source evidence integration and external retrieval. For evaluation, we propose an agentic pipeline with two components: an Adaptive Point-wise Quality Evaluation that dynamically derives task-specific evaluation dimensions, criteria, and weights conditioned on each generated task, and an Active Fact-Checking that autonomously extracts and verifies report statements via web search, even when citations are missing.",
    "translation": "标题：DeepResearchEval：一种用于深度研究任务构建与智能体评估的自动化框架\n\n摘要：深度研究系统广泛用于多步骤网络研究、分析与跨来源信息整合，但其评估仍面临挑战。现有基准测试通常需要大量人工标注的任务构建，依赖静态评估维度，或在缺乏引用时无法可靠验证事实。为弥补这些不足，我们提出了DeepResearchEval——一种用于深度研究任务构建与智能体评估的自动化框架。在任务构建方面，我们设计了一种基于人物角色的流程，通过多样化用户画像生成真实且复杂的研究任务，并应用任务资格筛选与搜索必要性检验的两阶段过滤机制，仅保留需要多源证据整合与外部检索的任务。在评估方面，我们提出了一种智能体评估流程，包含两个核心组件：自适应点式质量评估——能够根据每个生成的任务动态推导任务特定的评估维度、标准与权重；以及主动事实核查——即使在没有引用的情况下，也能通过网络搜索自主提取并验证报告中的陈述。",
    "url": "https://huggingface.co/papers/2601.09688",
    "arxiv_url": "https://arxiv.org/abs/2601.09688"
  },
  {
    "title": "MAXS: Meta-Adaptive Exploration with LLM Agents",
    "summary": "Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths. These issues make it difficult to balance global effectiveness and computational efficiency. To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, we introduce a trajectory convergence mechanism that controls computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of our lookahead strategy and tool usage.",
    "translation": "标题：MAXS：基于大语言模型智能体的元自适应探索框架\n\n摘要：大语言模型智能体通过多工具协作展现出固有的推理能力。然而在智能体推理过程中，现有方法常面临两大问题：（一）因缺乏前瞻性而导致的局部短视生成；（二）轨迹不稳定性，即早期微小误差可能演变为发散推理路径。这些问题使得全局有效性与计算效率难以兼顾。为应对上述挑战，我们提出基于大语言模型智能体的元自适应探索框架MAXS（https://github.com/exoskeletonzj/MAXS），该元自适应推理框架能灵活整合工具执行与推理规划。MAXS采用前瞻策略将推理路径延伸若干步骤，评估工具使用的优势值，并结合步骤一致性方差与跨步骤趋势斜率联合选择稳定、一致且高价值的推理步骤。此外，我们引入轨迹收敛机制，在达成路径一致性时停止进一步推演以控制计算成本，从而实现多工具推理中资源效率与全局有效性的平衡。我们在三个基础模型（MiMo-VL-7B、Qwen2.5-VL-7B、Qwen2.5-VL-32B）和五个数据集上进行了广泛实验，结果表明MAXS在性能与推理效率方面均持续优于现有方法。进一步分析验证了我们前瞻策略与工具使用机制的有效性。",
    "url": "https://huggingface.co/papers/2601.09259",
    "arxiv_url": "https://arxiv.org/abs/2601.09259"
  },
  {
    "title": "A^3-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation",
    "summary": "Scientific reasoning relies not only on logical inference but also on activating prior knowledge and experiential structures. Memory can efficiently reuse knowledge and enhance reasoning consistency and stability. However, existing benchmarks mainly evaluate final answers or step-by-step coherence, overlooking the memory-driven mechanisms that underlie human reasoning, which involves activating anchors and attractors, then integrating them into multi-step inference. To address this gap, we propose A^3-Bench~ https://a3-bench.github.io, a benchmark designed to evaluate scientific reasoning through dual-scale memory-driven activation, grounded in Anchor and Attractor Activation. First, we annotate 2,198 science reasoning problems across domains using the SAPM process(subject, anchor & attractor, problem, and memory developing). Second, we introduce a dual-scale memory evaluation framework utilizing anchors and attractors, along with the AAUI(Anchor--Attractor Utilization Index) metric to measure memory activation rates. Finally, through experiments with various base models and paradigms, we validate A^3-Bench and analyze how memory activation impacts reasoning performance, providing insights into memory-driven scientific reasoning.",
    "translation": "标题：A^3-Bench：基于锚点与吸引子激活的记忆驱动科学推理基准测试\n\n摘要：科学推理不仅依赖于逻辑推断，还需要激活先验知识与经验结构。记忆能够高效复用知识并增强推理的一致性与稳定性。然而，现有基准测试主要评估最终答案或逐步推理的连贯性，忽视了人类推理背后基于记忆驱动的机制——该机制通过激活锚点与吸引子，并将其整合至多步推理中实现。为填补这一空白，我们提出A^3-Bench（https://a3-bench.github.io），这是一个基于锚点与吸引子激活理论构建的双尺度记忆驱动激活科学推理评估基准。首先，我们采用SAPM流程（主体、锚点与吸引子、问题及记忆发展）对跨领域的2,198个科学推理问题进行了系统标注。其次，我们引入基于锚点与吸引子的双尺度记忆评估框架，并提出AAUI（锚点-吸引子利用指数）指标以量化记忆激活率。最后，通过对多种基础模型与推理范式的实验，我们验证了A^3-Bench的有效性，分析了记忆激活如何影响推理性能，从而为记忆驱动的科学推理机制提供了新的研究视角。",
    "url": "https://huggingface.co/papers/2601.09274",
    "arxiv_url": "https://arxiv.org/abs/2601.09274"
  },
  {
    "title": "Distribution-Aligned Sequence Distillation for Superior Long-CoT Reasoning",
    "summary": "In this report, we introduce DASD-4B-Thinking, a lightweight yet highly capable, fully open-source reasoning model. It achieves SOTA performance among open-source models of comparable scale across challenging benchmarks in mathematics, scientific reasoning, and code generation -- even outperforming several larger models. We begin by critically reexamining a widely adopted distillation paradigm in the community: SFT on teacher-generated responses, also known as sequence-level distillation. Although a series of recent works following this scheme have demonstrated remarkable efficiency and strong empirical performance, they are primarily grounded in the SFT perspective. Consequently, these approaches focus predominantly on designing heuristic rules for SFT data filtering, while largely overlooking the core principle of distillation itself -- enabling the student model to learn the teacher's full output distribution so as to inherit its generalization capability. Specifically, we identify three critical limitations in current practice: i) Inadequate representation of the teacher's sequence-level distribution; ii) Misalignment between the teacher's output distribution and the student's learning capacity; and iii) Exposure bias arising from teacher-forced training versus autoregressive inference. In summary, these shortcomings reflect a systemic absence of explicit teacher-student interaction throughout the distillation process, leaving the essence of distillation underexploited. To address these issues, we propose several methodological innovations that collectively form an enhanced sequence-level distillation training pipeline. Remarkably, DASD-4B-Thinking obtains competitive results using only 448K training samples -- an order of magnitude fewer than those employed by most existing open-source efforts. To support community research, we publicly release our models and the training dataset.",
    "translation": "标题：面向卓越长链思维推理的分布对齐序列蒸馏方法\n\n摘要：本报告提出DASD-4B-Thinking——一个轻量级但能力卓越、完全开源的推理模型。该模型在数学、科学推理和代码生成等具有挑战性的基准测试中，取得了同规模开源模型中最先进的性能表现，甚至超越多个更大规模的模型。我们首先对学界广泛采用的蒸馏范式进行批判性重审：基于教师模型生成响应的监督微调，即序列级蒸馏。尽管近期一系列遵循此方案的研究展现了显著的效率优势与强大的实证性能，但这些方法主要基于监督微调视角。因此，现有研究多聚焦于设计启发式的监督微调数据过滤规则，却普遍忽视了蒸馏的核心原则——使学生模型能够学习教师模型的完整输出分布，从而继承其泛化能力。具体而言，我们指出当前实践存在的三个关键局限：1）教师模型序列级分布的表征不足；2）教师输出分布与学生模型学习能力之间的错位；3）教师强制训练与自回归推理产生的曝光偏差。总之，这些缺陷反映出蒸馏过程中系统性缺乏明确的师生交互机制，导致蒸馏的本质未能得到充分发掘。为解决这些问题，我们提出多项方法论创新，共同构建了增强型序列级蒸馏训练流程。值得注意的是，DASD-4B-Thinking仅使用44.8万训练样本就获得了具有竞争力的结果——这比现有大多数开源工作采用的训练数据量少一个数量级。为支持社区研究，我们公开发布了模型与训练数据集。",
    "url": "https://huggingface.co/papers/2601.09088",
    "arxiv_url": "https://arxiv.org/abs/2601.09088"
  },
  {
    "title": "Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning",
    "summary": "Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3\\% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.",
    "translation": "标题：Fast-ThinkAct：基于可言语化潜在规划的高效视觉-语言-动作推理框架\n\n摘要：视觉-语言-动作任务需要在动态环境中对复杂视觉场景进行推理并执行适应性动作。尽管近期关于推理型视觉-语言-动作模型的研究表明，显式的思维链能够提升泛化能力，但冗长的推理轨迹会导致高推理延迟。本文提出Fast-ThinkAct——一种通过可言语化潜在推理实现紧凑高效规划的推理框架。该方法通过从教师模型蒸馏学习，在偏好引导目标的驱动下对齐操作轨迹，从而学习基于潜在思维链的高效推理机制，同时迁移语言与视觉规划能力以实现具身控制。这种设计实现了推理增强的策略学习，有效连接了紧凑推理与动作执行。在多种具身操作与推理基准测试上的广泛实验表明，Fast-ThinkAct在保持有效长程规划、少样本适应及故障恢复能力的同时，相比最先进的推理型视觉-语言-动作模型最高可降低89.3%的推理延迟，并展现出卓越的性能。",
    "url": "https://huggingface.co/papers/2601.09708",
    "arxiv_url": "https://arxiv.org/abs/2601.09708"
  },
  {
    "title": "SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL",
    "summary": "General-purpose Large Vision-Language Models (LVLMs), despite their massive scale, often falter in dermatology due to \"diffuse attention\" - the inability to disentangle subtle pathological lesions from background noise. In this paper, we challenge the assumption that parameter scaling is the only path to medical precision. We introduce SkinFlow, a framework that treats diagnosis as an optimization of visual information transmission efficiency. Our approach utilizes a Virtual-Width Dynamic Vision Encoder (DVE) to \"unfold\" complex pathological manifolds without physical parameter expansion, coupled with a two-stage Reinforcement Learning strategy. This strategy sequentially aligns explicit medical descriptions (Stage I) and reconstructs implicit diagnostic textures (Stage II) within a constrained semantic space. Furthermore, we propose a clinically grounded evaluation protocol that prioritizes diagnostic safety and hierarchical relevance over rigid label matching. Empirical results are compelling: our 7B model establishes a new state-of-the-art on the Fitzpatrick17k benchmark, achieving a +12.06% gain in Top-1 accuracy and a +28.57% boost in Top-6 accuracy over the massive general-purpose models (e.g., Qwen3VL-235B and GPT-5.2). These findings demonstrate that optimizing geometric capacity and information flow yields superior diagnostic reasoning compared to raw parameter scaling.",
    "translation": "标题：SkinFlow：基于动态视觉编码与分阶段强化学习的开放性皮肤病诊断高效信息传输框架\n\n摘要：通用大规模视觉-语言模型尽管参数量庞大，但在皮肤病学领域常因“注意力弥散”现象而表现不佳——即难以从背景噪声中分离出细微的病理特征。本文挑战了“参数扩展是提升医学精度的唯一路径”这一固有认知，提出SkinFlow框架，将诊断任务重构为视觉信息传输效率的优化问题。该框架采用虚拟宽度动态视觉编码器，在不增加实体参数的前提下实现复杂病理流形的“展开”，并结合两阶段强化学习策略：第一阶段在受限语义空间中对齐显性医学描述，第二阶段重建隐性的诊断纹理特征。此外，我们设计了基于临床实践的评价协议，优先考量诊断安全性与层级化相关性，而非僵化的标签匹配。实验结果表明：我们提出的70亿参数模型在Fitzpatrick17k基准测试中刷新了最高性能记录，相较于通用大模型（如Qwen3VL-235B与GPT-5.2），其Top-1准确率提升12.06%，Top-6准确率提升28.57%。这些发现证明，通过优化几何容量与信息流路径，能够比单纯扩展参数规模产生更优越的诊断推理能力。",
    "url": "https://huggingface.co/papers/2601.09136",
    "arxiv_url": "https://arxiv.org/abs/2601.09136"
  },
  {
    "title": "OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG",
    "summary": "The development of large language models (LLMs) has achieved superior performance in a range of downstream tasks, including LLM-based retrieval-augmented generation (RAG). The quality of generated content heavily relies on the usefulness of the retrieved information and the capacity of LLMs' internal information processing mechanism to incorporate it in answer generation. It is generally assumed that the retrieved information is relevant to the question. However, the retrieved information may have a variable degree of relevance and usefulness, depending on the question and the document collection. It is important to take into account the relevance of the retrieved information in answer generation. In this paper, we propose OpenDecoder, a new approach that leverages explicit evaluation of the retrieved information as quality indicator features for generation. We aim to build a RAG model that is more robust to varying levels of noisy context. Three types of explicit evaluation information are considered: relevance score, ranking score, and QPP (query performance prediction) score. The experimental results on five benchmark datasets demonstrate the effectiveness and better robustness of OpenDecoder by outperforming various baseline methods. Importantly, this paradigm is flexible to be integrated with the post-training of LLMs for any purposes and incorporated with any type of external indicators.",
    "translation": "标题：OpenDecoder：开放大语言模型解码以在检索增强生成中融入文档质量评估\n\n摘要：大语言模型的发展已在一系列下游任务中取得优异性能，包括基于大语言模型的检索增强生成。生成内容的质量高度依赖于检索信息的有用性，以及大语言模型内部信息处理机制将其整合到答案生成中的能力。通常假设检索信息与问题相关，然而检索信息的相关性和有用性可能因问题与文档集合的不同而存在差异。在答案生成中考虑检索信息的相关性至关重要。本文提出OpenDecoder，这是一种新方法，通过显式评估检索信息并将其作为生成过程中的质量指示特征。我们的目标是构建一个对不同程度噪声上下文具有更强鲁棒性的检索增强生成模型。研究考虑了三种显式评估信息：相关性评分、排序评分和查询性能预测评分。在五个基准数据集上的实验结果表明，OpenDecoder通过超越多种基线方法，展现出卓越的有效性和更好的鲁棒性。重要的是，该范式具有高度灵活性，可与大语言模型针对任意目的的后训练相结合，并能整合任意类型的外部指示特征。",
    "url": "https://huggingface.co/papers/2601.09028",
    "arxiv_url": "https://arxiv.org/abs/2601.09028"
  },
  {
    "title": "OpenVoxel: Training-Free Grouping and Captioning Voxels for Open-Vocabulary 3D Scene Understanding",
    "summary": "We propose OpenVoxel, a training-free algorithm for grouping and captioning sparse voxels for the open-vocabulary 3D scene understanding tasks. Given the sparse voxel rasterization (SVR) model obtained from multi-view images of a 3D scene, our OpenVoxel is able to produce meaningful groups that describe different objects in the scene. Also, by leveraging powerful Vision Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), our OpenVoxel successfully build an informative scene map by captioning each group, enabling further 3D scene understanding tasks such as open-vocabulary segmentation (OVS) or referring expression segmentation (RES). Unlike previous methods, our method is training-free and does not introduce embeddings from a CLIP/BERT text encoder. Instead, we directly proceed with text-to-text search using MLLMs. Through extensive experiments, our method demonstrates superior performance compared to recent studies, particularly in complex referring expression segmentation (RES) tasks. The code will be open.",
    "translation": "标题：OpenVoxel：面向开放词汇3D场景理解的免训练体素分组与描述方法\n\n摘要：本文提出OpenVoxel，一种面向开放词汇3D场景理解任务的免训练算法，用于对稀疏体素进行分组与描述。给定从三维场景多视角图像中获得的稀疏体素栅格化模型，OpenVoxel能够生成描述场景中不同物体的有意义分组。通过利用强大的视觉语言模型与多模态大语言模型，本方法通过对每个分组进行语义描述成功构建信息丰富的场景地图，从而支持开放词汇分割与指代表达分割等进阶三维场景理解任务。与现有方法不同，本方法无需训练过程，且不依赖CLIP/BERT文本编码器生成的嵌入向量，而是直接采用多模态大语言模型进行文本到文本的检索。大量实验表明，本方法在多项指标上优于近期研究成果，尤其在复杂指代表达分割任务中表现突出。相关代码将开源发布。",
    "url": "https://huggingface.co/papers/2601.09575",
    "arxiv_url": "https://arxiv.org/abs/2601.09575"
  },
  {
    "title": "ExpSeek: Self-Triggered Experience Seeking for Web Agents",
    "summary": "Experience intervention in web agents emerges as a promising technical paradigm, enhancing agent interaction capabilities by providing valuable insights from accumulated experiences. However, existing methods predominantly inject experience passively as global context before task execution, struggling to adapt to dynamically changing contextual observations during agent-environment interaction. We propose ExpSeek, which shifts experience toward step-level proactive seeking: (1) estimating step-level entropy thresholds to determine intervention timing using the model's intrinsic signals; (2) designing step-level tailor-designed experience content. Experiments on Qwen3-8B and 32B models across four challenging web agent benchmarks demonstrate that ExpSeek achieves absolute improvements of 9.3% and 7.5%, respectively. Our experiments validate the feasibility and advantages of entropy as a self-triggering signal, reveal that even a 4B small-scale experience model can significantly boost the performance of larger agent models.",
    "translation": "标题：ExpSeek：面向网络智能体的自触发经验寻求机制\n\n摘要：经验干预作为一种新兴技术范式，在网络智能体中展现出巨大潜力，其通过积累的经验为智能体提供有价值的洞察，从而增强其交互能力。然而，现有方法主要在任务执行前将经验作为全局上下文被动注入，难以适应智能体与环境交互过程中动态变化的上下文观察。本文提出ExpSeek，将经验干预转向步骤级的主动寻求模式：（1）利用模型内在信号估计步骤级熵阈值以确定干预时机；（2）设计步骤级定制化的经验内容。在四个具有挑战性的网络智能体基准测试中，基于Qwen3-8B和32B模型的实验表明，ExpSeek分别实现了9.3%和7.5%的绝对性能提升。实验验证了熵作为自触发信号的可行性及优势，并揭示即使仅使用4B规模的小型经验模型，也能显著提升更大规模智能体模型的性能。",
    "url": "https://huggingface.co/papers/2601.08605",
    "arxiv_url": "https://arxiv.org/abs/2601.08605"
  },
  {
    "title": "EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines",
    "summary": "While LLM-based agents have shown promise for deep research, most existing approaches rely on fixed workflows that struggle to adapt to real-world, open-ended queries. Recent work therefore explores self-evolution by allowing agents to rewrite their own code or prompts to improve problem-solving ability, but unconstrained optimization often triggers instability, hallucinations, and instruction drift. We propose EvoFSM, a structured self-evolving framework that achieves both adaptability and control by evolving an explicit Finite State Machine (FSM) instead of relying on free-form rewriting. EvoFSM decouples the optimization space into macroscopic Flow (state-transition logic) and microscopic Skill (state-specific behaviors), enabling targeted improvements under clear behavioral boundaries. Guided by a critic mechanism, EvoFSM refines the FSM through a small set of constrained operations, and further incorporates a self-evolving memory that distills successful trajectories as reusable priors and failure patterns as constraints for future queries. Extensive evaluations on five multi-hop QA benchmarks demonstrate the effectiveness of EvoFSM. In particular, EvoFSM reaches 58.0% accuracy on the DeepSearch benchmark. Additional results on interactive decision-making tasks further validate its generalization.",
    "translation": "标题：EvoFSM：基于有限状态机的可控自演化深度研究框架\n\n摘要：尽管基于大语言模型的智能体在深度研究任务中展现出潜力，但现有方法大多依赖固定工作流程，难以适应现实世界中开放式的查询需求。为此，近期研究开始探索通过让智能体重写自身代码或提示来实现自我演化以提升问题解决能力，然而无约束的优化往往引发不稳定性、幻觉及指令偏移等问题。本文提出EvoFSM，一种结构化的自演化框架，通过演化显式的有限状态机而非依赖自由形式的重写，实现了适应性与可控性的统一。EvoFSM将优化空间解耦为宏观的流程（状态转移逻辑）与微观的技能（状态特定行为），从而在清晰的行为边界下实现针对性改进。在评估机制的引导下，EvoFSM通过一组受限操作对有限状态机进行细化，并进一步引入自演化记忆模块，将成功轨迹提炼为可复用的先验知识，将失败模式转化为未来查询的约束条件。在五个多跳问答基准上的广泛实验证明了EvoFSM的有效性。具体而言，EvoFSM在DeepSearch基准上达到了58.0%的准确率。在交互式决策任务上的附加实验结果进一步验证了其泛化能力。",
    "url": "https://huggingface.co/papers/2601.09465",
    "arxiv_url": "https://arxiv.org/abs/2601.09465"
  },
  {
    "title": "FocusUI: Efficient UI Grounding via Position-Preserving Visual Token Selection",
    "summary": "Vision-Language Models (VLMs) have shown remarkable performance in User Interface (UI) grounding tasks, driven by their ability to process increasingly high-resolution screenshots. However, screenshots are tokenized into thousands of visual tokens (e.g., about 4700 for 2K resolution), incurring significant computational overhead and diluting attention. In contrast, humans typically focus on regions of interest when interacting with UI. In this work, we pioneer the task of efficient UI grounding. Guided by practical analysis of the task's characteristics and challenges, we propose FocusUI, an efficient UI grounding framework that selects patches most relevant to the instruction while preserving positional continuity for precise grounding. FocusUI addresses two key challenges: (1) Eliminating redundant tokens in visual encoding. We construct patch-level supervision by fusing an instruction-conditioned score with a rule-based UI-graph score that down-weights large homogeneous regions to select distinct and instruction-relevant visual tokens. (2) Preserving positional continuity during visual token selection. We find that general visual token pruning methods suffer from severe accuracy degradation on UI grounding tasks due to broken positional information. We introduce a novel PosPad strategy, which compresses each contiguous sequence of dropped visual tokens into a single special marker placed at the sequence's last index to preserve positional continuity. Comprehensive experiments on four grounding benchmarks demonstrate that FocusUI surpasses GUI-specific baselines. On the ScreenSpot-Pro benchmark, FocusUI-7B achieves a performance improvement of 3.7% over GUI-Actor-7B. Even with only 30% visual token retention, FocusUI-7B drops by only 3.2% while achieving up to 1.44x faster inference and 17% lower peak GPU memory.",
    "translation": "标题：FocusUI：通过位置保持的视觉标记选择实现高效用户界面定位\n\n摘要：视觉语言模型在用户界面定位任务中展现出卓越性能，这得益于其处理日益高分辨率截图的能力。然而，截图被分割为数千个视觉标记（例如2K分辨率下约4700个），导致显著的计算开销并稀释了注意力机制。相比之下，人类在与用户界面交互时通常聚焦于感兴趣区域。本研究开创性地探索高效用户界面定位任务。通过对任务特性与挑战的实际分析，我们提出FocusUI框架——该框架在保持位置连续性的前提下，选择与指令最相关的图像块以实现精确定位。FocusUI解决了两个关键挑战：（1）消除视觉编码中的冗余标记。我们通过融合指令条件评分与基于规则的用户界面图评分（该评分通过降低大范围同质区域的权重来选择具有区分度且与指令相关的视觉标记）构建图像块级监督机制。（2）在视觉标记选择过程中保持位置连续性。我们发现通用视觉标记剪枝方法会因位置信息断裂而导致用户界面定位任务精度严重下降。为此，我们提出创新的位置填充策略，将每个连续被丢弃的视觉标记序列压缩为置于该序列末位索引的特殊标记，从而保持位置连续性。在四个定位基准测试上的综合实验表明，FocusUI超越了专用图形用户界面基线模型。在ScreenSpot-Pro基准测试中，FocusUI-7B较GUI-Actor-7B实现3.7%的性能提升。即使仅保留30%的视觉标记，FocusUI-7B性能仅下降3.2%，同时推理速度提升达1.44倍，峰值GPU内存降低17%。",
    "url": "https://huggingface.co/papers/2601.03928",
    "arxiv_url": "https://arxiv.org/abs/2601.03928"
  },
  {
    "title": "Are LLMs Vulnerable to Preference-Undermining Attacks (PUA)? A Factorial Analysis Methodology for Diagnosing the Trade-off between Preference Alignment and Real-World Validity",
    "summary": "Large Language Model (LLM) training often optimizes for preference alignment, rewarding outputs that are perceived as helpful and interaction-friendly. However, this preference-oriented objective can be exploited: manipulative prompts can steer responses toward user-appeasing agreement and away from truth-oriented correction. In this work, we investigate whether aligned models are vulnerable to Preference-Undermining Attacks (PUA), a class of manipulative prompting strategies designed to exploit the model's desire to please user preferences at the expense of truthfulness. We propose a diagnostic methodology that provides a finer-grained and more directive analysis than aggregate benchmark scores, using a factorial evaluation framework to decompose prompt-induced shifts into interpretable effects of system objectives (truth- vs. preference-oriented) and PUA-style dialogue factors (directive control, personal derogation, conditional approval, reality denial) within a controlled 2 times 2^4 design. Surprisingly, more advanced models are sometimes more susceptible to manipulative prompts. Beyond the dominant reality-denial factor, we observe model-specific sign reversals and interactions with PUA-style factors, suggesting tailored defenses rather than uniform robustness. These findings offer a novel, reproducible factorial evaluation methodology that provides finer-grained diagnostics for post-training processes like RLHF, enabling better trade-offs in the product iteration of LLMs by offering a more nuanced understanding of preference alignment risks and the impact of manipulative prompts.",
    "translation": "标题：大语言模型是否易受偏好削弱攻击？一种诊断偏好对齐与现实有效性权衡的析因分析方法论\n\n摘要：大语言模型的训练通常以偏好对齐为优化目标，奖励那些被认为有益且交互友好的输出。然而，这种以偏好为导向的目标可能被利用：操纵性提示可以引导模型倾向于取悦用户的附和，而非基于事实的修正。本研究探讨经过对齐的模型是否易受偏好削弱攻击的影响——这类操纵性提示策略旨在利用模型取悦用户偏好的倾向，却以牺牲真实性为代价。我们提出一种诊断方法论，相比聚合基准分数，该方法能提供更细粒度、更具指向性的分析。通过采用析因评估框架，在受控的2×2⁴实验设计中，我们将提示引发的输出变化分解为系统目标（以事实为导向 vs 以偏好为导向）与PUA式对话因素（指令控制、人格贬损、条件性认可、现实否认）的可解释效应。令人惊讶的是，更先进的模型有时反而更容易受到操纵性提示的影响。除了占主导地位的现实否认因素外，我们还观察到模型特定的效应符号反转以及与PUA式因素的交互作用，这表明需要针对性的防御策略而非统一的鲁棒性方案。这些发现提出了一种新颖、可复现的析因评估方法论，为RLHF等训练后过程提供更细粒度的诊断，通过更细致地理解偏好对齐风险及操纵性提示的影响，助力大语言模型在产品迭代中实现更优的权衡。",
    "url": "https://huggingface.co/papers/2601.06596",
    "arxiv_url": "https://arxiv.org/abs/2601.06596"
  },
  {
    "title": "TranslateGemma Technical Report",
    "summary": "We present TranslateGemma, a suite of open machine translation models based on the Gemma 3 foundation models. To enhance the inherent multilingual capabilities of Gemma 3 for the translation task, we employ a two-stage fine-tuning process. First, supervised fine-tuning is performed using a rich mixture of high-quality large-scale synthetic parallel data generated via state-of-the-art models and human-translated parallel data. This is followed by a reinforcement learning phase, where we optimize translation quality using an ensemble of reward models, including MetricX-QE and AutoMQM, targeting translation quality. We demonstrate the effectiveness of TranslateGemma with human evaluation on the WMT25 test set across 10 language pairs and with automatic evaluation on the WMT24++ benchmark across 55 language pairs. Automatic metrics show consistent and substantial gains over the baseline Gemma 3 models across all sizes. Notably, smaller TranslateGemma models often achieve performance comparable to larger baseline models, offering improved efficiency. We also show that TranslateGemma models retain strong multimodal capabilities, with enhanced performance on the Vistra image translation benchmark. The release of the open TranslateGemma models aims to provide the research community with powerful and adaptable tools for machine translation.",
    "translation": "标题：TranslateGemma技术报告\n\n摘要：本文介绍了TranslateGemma——一套基于Gemma 3基础模型的开源机器翻译模型。为增强Gemma 3模型在翻译任务中固有的多语言能力，我们采用两阶段微调方法。首先，通过融合前沿模型生成的大规模高质量合成平行数据与人工翻译平行数据，进行监督式微调。随后实施强化学习阶段，采用包含MetricX-QE与AutoMQM在内的奖励模型集成方案，针对翻译质量进行优化。我们在WMT25测试集的10个语言对上通过人工评估，以及在WMT24++基准测试的55个语言对上通过自动评估，验证了TranslateGemma的有效性。自动评估指标显示，所有规模的TranslateGemma模型相较于基线Gemma 3模型均取得持续且显著的性能提升。值得注意的是，较小规模的TranslateGemma模型常能达到与较大规模基线模型相当的性能，同时具备更优的效率。我们还证明TranslateGemma模型保持了强大的多模态能力，在Vistra图像翻译基准测试中表现出增强性能。本次开源TranslateGemma模型旨在为研究社区提供强大且适应性强的机器翻译工具。",
    "url": "https://huggingface.co/papers/2601.09012",
    "arxiv_url": "https://arxiv.org/abs/2601.09012"
  },
  {
    "title": "Imagine-then-Plan: Agent Learning from Adaptive Lookahead with World Models",
    "summary": "Recent advances in world models have shown promise for modeling future dynamics of environmental states, enabling agents to reason and act without accessing real environments. Current methods mainly perform single-step or fixed-horizon rollouts, leaving their potential for complex task planning under-exploited. We propose Imagine-then-Plan (ITP), a unified framework for agent learning via lookahead imagination, where an agent's policy model interacts with the learned world model, yielding multi-step ``imagined'' trajectories. Since the imagination horizon may vary by tasks and stages, we introduce a novel adaptive lookahead mechanism by trading off the ultimate goal and task progress. The resulting imagined trajectories provide rich signals about future consequences, such as achieved progress and potential conflicts, which are fused with current observations, formulating a partially observable and imaginable Markov decision process to guide policy learning. We instantiate ITP with both training-free and reinforcement-trained variants. Extensive experiments across representative agent benchmarks demonstrate that ITP significantly outperforms competitive baselines. Further analyses validate that our adaptive lookahead largely enhances agents' reasoning capability, providing valuable insights into addressing broader, complex tasks.",
    "translation": "标题：想象而后规划：基于世界模型的自适应前瞻智能体学习\n\n摘要：世界模型的最新进展为环境状态的未来动态建模提供了可能，使智能体能够在无需访问真实环境的情况下进行推理与决策。现有方法主要执行单步或固定步长的轨迹推演，其在复杂任务规划中的潜力尚未得到充分挖掘。本文提出“想象而后规划”统一框架，通过前瞻想象实现智能体学习。在该框架中，智能体的策略模型与习得的世界模型交互，生成多步“想象”轨迹。由于想象步长可能随任务类型与阶段动态变化，我们引入一种创新的自适应前瞻机制，通过权衡终极目标与任务进展来调节想象深度。生成的想象轨迹蕴含丰富的未来状态信息（如已达成进度与潜在冲突），这些信息与当前观测相融合，构建出兼具部分可观测性与可想象性的马尔可夫决策过程以指导策略学习。我们通过免训练与强化训练两种变体实现该框架。在代表性智能体基准测试中的大量实验表明，该方法显著优于现有基线模型。进一步分析验证了自适应前瞻机制能有效增强智能体的推理能力，为应对更广泛复杂任务提供了重要启示。",
    "url": "https://huggingface.co/papers/2601.08955",
    "arxiv_url": "https://arxiv.org/abs/2601.08955"
  },
  {
    "title": "Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering",
    "summary": "Modern video generative models based on diffusion models can produce very realistic clips, but they are computationally inefficient, often requiring minutes of GPU time for just a few seconds of video. This inefficiency poses a critical barrier to deploying generative video in applications that require real-time interactions, such as embodied AI and VR/AR. This paper explores a new strategy for camera-conditioned video generation of static scenes: using diffusion-based generative models to generate a sparse set of keyframes, and then synthesizing the full video through 3D reconstruction and rendering. By lifting keyframes into a 3D representation and rendering intermediate views, our approach amortizes the generation cost across hundreds of frames while enforcing geometric consistency. We further introduce a model that predicts the optimal number of keyframes for a given camera trajectory, allowing the system to adaptively allocate computation. Our final method, SRENDER, uses very sparse keyframes for simple trajectories and denser ones for complex camera motion. This results in video generation that is more than 40 times faster than the diffusion-based baseline in generating 20 seconds of video, while maintaining high visual fidelity and temporal stability, offering a practical path toward efficient and controllable video synthesis.",
    "translation": "标题：基于稀疏扩散与三维渲染的静态场景高效相机控制视频生成\n\n摘要：基于扩散模型的现代视频生成模型能够生成高度逼真的视频片段，但其计算效率低下，通常需要数分钟GPU时间才能生成数秒视频。这种低效性对在需要实时交互的应用（如具身人工智能和虚拟/增强现实）中部署生成式视频构成了关键障碍。本文探索了一种静态场景相机条件视频生成的新策略：利用基于扩散的生成模型生成稀疏关键帧集合，随后通过三维重建与渲染合成完整视频。通过将关键帧提升至三维表征并渲染中间视角，我们的方法在保证几何一致性的同时，将生成成本分摊至数百帧。我们进一步提出一种可预测给定相机轨迹最优关键帧数量的模型，使系统能够自适应分配计算资源。最终方法SRENDER对简单轨迹使用极稀疏关键帧，对复杂相机运动则采用更密集关键帧。该方法在生成20秒视频时，比基于扩散的基线方法提速超过40倍，同时保持高视觉保真度与时间稳定性，为高效可控的视频合成提供了实用路径。",
    "url": "https://huggingface.co/papers/2601.09697",
    "arxiv_url": "https://arxiv.org/abs/2601.09697"
  },
  {
    "title": "Geometric Stability: The Missing Axis of Representations",
    "summary": "Analysis of learned representations has a blind spot: it focuses on similarity, measuring how closely embeddings align with external references, but similarity reveals only what is represented, not whether that structure is robust. We introduce geometric stability, a distinct dimension that quantifies how reliably representational geometry holds under perturbation, and present Shesha, a framework for measuring it. Across 2,463 configurations in seven domains, we show that stability and similarity are empirically uncorrelated (ρapprox 0.01) and mechanistically distinct: similarity metrics collapse after removing the top principal components, while stability retains sensitivity to fine-grained manifold structure. This distinction yields actionable insights: for safety monitoring, stability acts as a functional geometric canary, detecting structural drift nearly 2times more sensitively than CKA while filtering out the non-functional noise that triggers false alarms in rigid distance metrics; for controllability, supervised stability predicts linear steerability (ρ= 0.89-0.96); for model selection, stability dissociates from transferability, revealing a geometric tax that transfer optimization incurs. Beyond machine learning, stability predicts CRISPR perturbation coherence and neural-behavioral coupling. By quantifying how reliably systems maintain structure, geometric stability provides a necessary complement to similarity for auditing representations across biological and computational systems.",
    "translation": "标题：几何稳定性：表征分析中被忽视的维度\n\n摘要：现有学习表征分析方法存在盲区：其聚焦于相似性度量，主要评估嵌入向量与外部参考的对齐程度，但相似性仅能揭示表征内容，无法判断结构是否稳健。本文提出几何稳定性这一全新维度，用于量化表征几何在扰动下的保持可靠性，并构建Shesha测量框架。通过在七个领域的2,463种配置中进行实验，我们发现稳定性与相似性在经验层面无关（ρ≈0.01）且机制相异：移除主要主成分后相似性度量会失效，而稳定性仍能敏感捕捉细粒度流形结构。这种差异产生可操作的洞见：在安全监控方面，稳定性可作为功能性几何预警指标，其检测结构漂移的灵敏度比CKA提高近2倍，同时能过滤刚性距离度量中引发误报的非功能性噪声；在可控性方面，监督稳定性可预测线性可操控性（ρ=0.89-0.96）；在模型选择方面，稳定性与可迁移性解耦，揭示了迁移优化所付出的几何代价。超越机器学习领域，稳定性可预测CRISPR扰动一致性与神经-行为耦合度。通过量化系统维持结构的可靠性，几何稳定性为生物与计算系统的表征审计提供了必要补充，与相似性分析形成完整方法论体系。",
    "url": "https://huggingface.co/papers/2601.09173",
    "arxiv_url": "https://arxiv.org/abs/2601.09173"
  },
  {
    "title": "The AI Hippocampus: How Far are We From Human Memory?",
    "summary": "Memory plays a foundational role in augmenting the reasoning, adaptability, and contextual fidelity of modern Large Language Models and Multi-Modal LLMs. As these models transition from static predictors to interactive systems capable of continual learning and personalized inference, the incorporation of memory mechanisms has emerged as a central theme in their architectural and functional evolution. This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organizing the literature into a cohesive taxonomy comprising implicit, explicit, and agentic memory paradigms. Specifically, the survey delineates three primary memory frameworks. Implicit memory refers to the knowledge embedded within the internal parameters of pre-trained transformers, encompassing their capacity for memorization, associative retrieval, and contextual reasoning. Recent work has explored methods to interpret, manipulate, and reconfigure this latent memory. Explicit memory involves external storage and retrieval components designed to augment model outputs with dynamic, queryable knowledge representations, such as textual corpora, dense vectors, and graph-based structures, thereby enabling scalable and updatable interaction with information sources. Agentic memory introduces persistent, temporally extended memory structures within autonomous agents, facilitating long-term planning, self-consistency, and collaborative behavior in multi-agent systems, with relevance to embodied and interactive AI. Extending beyond text, the survey examines the integration of memory within multi-modal settings, where coherence across vision, language, audio, and action modalities is essential. Key architectural advances, benchmark tasks, and open challenges are discussed, including issues related to memory capacity, alignment, factual consistency, and cross-system interoperability.",
    "translation": "标题：AI海马体：我们距离人类记忆还有多远？\n\n摘要：记忆在增强现代大语言模型与多模态大语言模型的推理能力、适应性及语境保真度方面发挥着基础性作用。随着这些模型从静态预测器转变为能够持续学习和个性化推理的交互系统，记忆机制的整合已成为其架构与功能演进的核心议题。本文对LLMs与MLLMs中的记忆研究进行了全面而结构化的梳理，将现有文献整合为涵盖隐性记忆、显性记忆与智能体记忆范式的统一分类体系。具体而言，本文系统阐述了三类主要记忆框架：隐性记忆指预训练Transformer内部参数所蕴含的知识，包括其记忆存储、关联检索与语境推理能力，近期研究聚焦于对这一潜在记忆的解释、操控与重构方法；显性记忆涉及为增强模型输出而设计的外部存储与检索组件，通过文本语料库、稠密向量及图结构等动态可查询知识表征，实现与信息源的可扩展、可更新交互；智能体记忆在自主智能体中引入具有时间延续性的持久记忆结构，促进多智能体系统中的长期规划、自我一致性与协作行为，对具身交互AI具有重要意义。本文突破文本范畴，进一步探讨了多模态场景下的记忆整合机制，强调视觉、语言、音频与行为模态间的连贯性至关重要。文中系统论述了关键架构进展、基准任务与开放挑战，涵盖记忆容量、对齐机制、事实一致性及跨系统互操作性等核心议题。",
    "url": "https://huggingface.co/papers/2601.09113",
    "arxiv_url": "https://arxiv.org/abs/2601.09113"
  },
  {
    "title": "Flow Equivariant World Models: Memory for Partially Observed Dynamic Environments",
    "summary": "Embodied systems experience the world as 'a symphony of flows': a combination of many continuous streams of sensory input coupled to self-motion, interwoven with the dynamics of external objects. These streams obey smooth, time-parameterized symmetries, which combine through a precisely structured algebra; yet most neural network world models ignore this structure and instead repeatedly re-learn the same transformations from data. In this work, we introduce 'Flow Equivariant World Models', a framework in which both self-motion and external object motion are unified as one-parameter Lie group 'flows'. We leverage this unification to implement group equivariance with respect to these transformations, thereby providing a stable latent world representation over hundreds of timesteps. On both 2D and 3D partially observed video world modeling benchmarks, we demonstrate that Flow Equivariant World Models significantly outperform comparable state-of-the-art diffusion-based and memory-augmented world modeling architectures -- particularly when there are predictable world dynamics outside the agent's current field of view. We show that flow equivariance is particularly beneficial for long rollouts, generalizing far beyond the training horizon. By structuring world model representations with respect to internal and external motion, flow equivariance charts a scalable route to data efficient, symmetry-guided, embodied intelligence. Project link: https://flowequivariantworldmodels.github.io.",
    "translation": "标题：流等变世界模型：部分可观测动态环境中的记忆机制\n\n摘要：具身系统将世界体验为“流动的交响曲”：多种连续感官输入流与自身运动耦合，并与外部物体动力学交织形成的组合。这些数据流遵循平滑的时间参数化对称性，并通过精确结构化的代数进行组合；然而大多数神经网络世界模型忽视了这一结构，转而反复从数据中重新学习相同的变换。本研究提出“流等变世界模型”框架，将自身运动与外部物体运动统一为单参数李群“流”。我们利用这种统一性实现对变换的群等变性，从而在数百个时间步上提供稳定的潜在世界表征。在二维与三维部分可观测视频世界建模基准测试中，我们证明流等变世界模型显著优于当前基于扩散和记忆增强的先进世界建模架构——尤其在智能体当前视野外存在可预测世界动力学时表现突出。研究表明流等变性对长序列推演具有特殊优势，其泛化能力远超训练时域。通过构建与内外运动相关联的世界模型表征，流等变性为数据高效、对称性引导的具身智能开辟了可扩展路径。项目链接：https://flowequivariantworldmodels.github.io。",
    "url": "https://huggingface.co/papers/2601.01075",
    "arxiv_url": "https://arxiv.org/abs/2601.01075"
  },
  {
    "title": "DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing",
    "summary": "Reinforcement learning (RL)-based enhancement of large language models (LLMs) often leads to reduced output diversity, undermining their utility in open-ended tasks like creative writing. Current methods lack explicit mechanisms for guiding diverse exploration and instead prioritize optimization efficiency and performance over diversity. This paper proposes an RL framework structured around a semi-structured long Chain-of-Thought (CoT), in which the generation process is decomposed into explicitly planned intermediate steps. We introduce a Diverse Planning Branching method that strategically introduces divergence at the planning phase based on diversity variation, alongside a group-aware diversity reward to encourage distinct trajectories. Experimental results on creative writing benchmarks demonstrate that our approach significantly improves output diversity without compromising generation quality, consistently outperforming existing baselines.",
    "translation": "标题：DPWriter：基于多样化规划分支的强化学习在创意写作中的应用\n\n摘要：基于强化学习（RL）的大型语言模型（LLMs）增强方法常导致输出多样性降低，削弱了其在创意写作等开放式任务中的实用性。现有方法缺乏引导多样化探索的显式机制，往往优先考虑优化效率和性能而忽视多样性。本文提出一种围绕半结构化长链思维（CoT）构建的强化学习框架，该框架将生成过程分解为显式规划的中间步骤。我们引入了一种多样化规划分支方法，该方法基于多样性变化在规划阶段策略性地引入分叉，并结合群体感知的多样性奖励以鼓励不同的生成轨迹。在创意写作基准测试上的实验结果表明，我们的方法在保持生成质量的同时显著提升了输出多样性， consistently outperforming existing baselines。",
    "url": "https://huggingface.co/papers/2601.09609",
    "arxiv_url": "https://arxiv.org/abs/2601.09609"
  },
  {
    "title": "Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning",
    "summary": "Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning. More recent studies have incorporated multimodal information into the reasoning steps; however, they often follow a single task-specific reasoning pattern, which limits their generalizability across various multimodal tasks. In fact, there are numerous multimodal tasks requiring diverse reasoning skills, such as zooming in on a specific region or marking an object within an image. To address this, we propose unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. We instantiate this paradigm with Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, thereby enabling functional image generation. Additionally, we introduce Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting a promising direction for generative multimodal reasoning.",
    "translation": "标题：Omni-R1：迈向统一生成式多模态推理范式\n\n摘要：多模态大语言模型（MLLMs）在多模态推理领域正取得显著进展。早期方法主要关注纯文本推理。近期研究虽已将多模态信息融入推理步骤，但通常遵循单一任务特定的推理模式，这限制了其在各类多模态任务中的泛化能力。实际上，众多多模态任务需要多样化的推理技能，例如聚焦图像特定区域或在图像中标记对象。为解决这一问题，我们提出统一生成式多模态推理范式，通过在推理过程中生成中间图像来统一多样化的多模态推理能力。我们通过Omni-R1实例化这一范式——该框架采用感知对齐损失与感知奖励的两阶段SFT+RL架构，从而实现功能性图像生成。此外，我们提出Omni-R1-Zero，该方法通过从纯文本推理数据中自举逐步可视化信息，无需依赖多模态标注。实验结果表明，Omni-R1在广泛的多模态任务中实现了统一的生成式推理，而Omni-R1-Zero在整体表现上可与Omni-R1持平甚至更优，这为生成式多模态推理指明了具有前景的发展方向。",
    "url": "https://huggingface.co/papers/2601.09536",
    "arxiv_url": "https://arxiv.org/abs/2601.09536"
  },
  {
    "title": "No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning",
    "summary": "Critique-guided reinforcement learning (RL) has emerged as a powerful paradigm for training LLM agents by augmenting sparse outcome rewards with natural-language feedback. However, current methods often rely on static or offline critic models, which fail to adapt as the policy evolves. In on-policy RL, the agent's error patterns shift over time, causing stationary critics to become stale and providing feedback of diminishing utility. To address this, we introduce ECHO (Evolving Critic for Hindsight-Guided Optimization)}, a framework that jointly optimizes the policy and critic through a synchronized co-evolutionary loop. ECHO utilizes a cascaded rollout mechanism where the critic generates multiple diagnoses for an initial trajectory, followed by policy refinement to enable group-structured advantage estimation. We address the challenge of learning plateaus via a saturation-aware gain shaping objective, which rewards the critic for inducing incremental improvements in high-performing trajectories. By employing dual-track GRPO updates, ECHO ensures the critic's feedback stays synchronized with the evolving policy. Experimental results show that ECHO yields more stable training and higher long-horizon task success across open-world environments.",
    "translation": "标题：告别陈旧反馈：面向开放世界智能体学习的协同演化批评器\n\n摘要：基于批评的强化学习已成为训练大语言模型智能体的重要范式，其通过自然语言反馈增强稀疏结果奖励。然而，现有方法多依赖静态或离线批评器模型，无法随策略演化而自适应调整。在在线策略强化学习中，智能体的错误模式会随时间推移发生变化，导致固定批评器逐渐失效，其反馈效用随之递减。为此，我们提出ECHO（基于后见指导优化的演化批评器）框架，通过同步协同演化循环实现策略与批评器的联合优化。ECHO采用级联式轨迹生成机制：批评器对初始轨迹生成多重诊断，随后通过策略精炼实现群体结构化优势估计。针对学习平台期挑战，我们提出饱和度感知增益重塑目标，使批评器能够通过促进高绩效轨迹的渐进改进获得奖励。通过双轨GRPO更新机制，ECHO确保批评反馈与演化策略保持同步。实验结果表明，ECHO在开放世界环境中能实现更稳定的训练过程，并在长周期任务中取得更高的成功率。",
    "url": "https://huggingface.co/papers/2601.06794",
    "arxiv_url": "https://arxiv.org/abs/2601.06794"
  },
  {
    "title": "SCALER:Synthetic Scalable Adaptive Learning Environment for Reasoning",
    "summary": "Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while preserving strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward sparsity, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.",
    "translation": "标题：SCALER：面向推理的合成可扩展自适应学习环境\n\n摘要：强化学习为提升大语言模型的推理能力提供了系统化方法，但其有效性依赖于能够随模型进化持续提供信息量的训练信号。实践中，当任务难度与模型能力失配，或训练过程被少量重复问题模式主导时，强化学习的进展往往受阻。为协同解决这些问题，我们提出SCALER（面向推理的合成可扩展自适应学习环境），该框架通过自适应环境设计来维持有效的学习信号。SCALER引入可扩展的合成流程，将现实编程问题转化为具有可控难度与无限实例生成能力的可验证推理环境，使得强化学习能够突破有限数据集的限制，同时保持严格的正确定性保证。在此基础上，SCALER进一步采用自适应多环境强化学习策略，动态调整实例难度并筛选活跃环境集合，以追踪模型能力边界并维持分布多样性。这种协同适应机制避免了奖励稀疏性，缓解了对狭窄任务模式的过拟合，并支持训练过程中的持续改进。大量实验表明，SCALER在多种推理基准测试中持续优于基于数据集的强化学习基线，并展现出更稳定、更长周期的训练动态。",
    "url": "https://huggingface.co/papers/2601.04809",
    "arxiv_url": "https://arxiv.org/abs/2601.04809"
  },
  {
    "title": "Focal Guidance: Unlocking Controllability from Semantic-Weak Layers in Video Diffusion Models",
    "summary": "The task of Image-to-Video (I2V) generation aims to synthesize a video from a reference image and a text prompt. This requires diffusion models to reconcile high-frequency visual constraints and low-frequency textual guidance during the denoising process. However, while existing I2V models prioritize visual consistency, how to effectively couple this dual guidance to ensure strong adherence to the text prompt remains underexplored. In this work, we observe that in Diffusion Transformer (DiT)-based I2V models, certain intermediate layers exhibit weak semantic responses (termed Semantic-Weak Layers), as indicated by a measurable drop in text-visual similarity. We attribute this to a phenomenon called Condition Isolation, where attention to visual features becomes partially detached from text guidance and overly relies on learned visual priors. To address this, we propose Focal Guidance (FG), which enhances the controllability from Semantic-Weak Layers. FG comprises two mechanisms: (1) Fine-grained Semantic Guidance (FSG) leverages CLIP to identify key regions in the reference frame and uses them as anchors to guide Semantic-Weak Layers. (2) Attention Cache transfers attention maps from semantically responsive layers to Semantic-Weak Layers, injecting explicit semantic signals and alleviating their over-reliance on the model's learned visual priors, thereby enhancing adherence to textual instructions. To further validate our approach and address the lack of evaluation in this direction, we introduce a benchmark for assessing instruction following in I2V models. On this benchmark, Focal Guidance proves its effectiveness and generalizability, raising the total score on Wan2.1-I2V to 0.7250 (+3.97\\%) and boosting the MMDiT-based HunyuanVideo-I2V to 0.5571 (+7.44\\%).",
    "translation": "标题：焦点引导：从视频扩散模型的语义弱层解锁可控性\n\n摘要：图像到视频（I2V）生成任务旨在根据参考图像和文本提示合成视频。这要求扩散模型在去噪过程中协调高频视觉约束与低频文本引导。然而，尽管现有I2V模型优先考虑视觉一致性，如何有效耦合这种双重引导以确保对文本提示的严格遵循仍缺乏深入探索。本研究观察到，在基于扩散Transformer（DiT）的I2V模型中，某些中间层表现出较弱的语义响应（称为语义弱层），其表现为文本-视觉相似度的可测量下降。我们将此归因于一种称为“条件隔离”的现象，即对视觉特征的注意力部分脱离文本引导，并过度依赖学习到的视觉先验。为解决此问题，我们提出焦点引导（FG）方法，以增强语义弱层的可控性。FG包含两种机制：（1）细粒度语义引导（FSG）利用CLIP识别参考帧中的关键区域，并将其作为锚点引导语义弱层；（2）注意力缓存将语义响应层的注意力图传递至语义弱层，注入显式语义信号，减轻其对模型学习视觉先验的过度依赖，从而提升对文本指令的遵循能力。为进一步验证本方法并弥补该方向评估标准的缺失，我们提出了一个用于评估I2V模型指令遵循能力的基准测试。在该基准上，焦点引导证明了其有效性和泛化能力：将Wan2.1-I2V的总分提升至0.7250（+3.97%），并将基于MMDiT的HunyuanVideo-I2V评分提升至0.5571（+7.44%）。",
    "url": "https://huggingface.co/papers/2601.07287",
    "arxiv_url": "https://arxiv.org/abs/2601.07287"
  },
  {
    "title": "Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing",
    "summary": "Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.",
    "translation": "标题：集群工作负载分配：基于自然语言处理的语义软亲和性\n\n摘要：集群工作负载分配通常需要复杂的配置，存在可用性差距。本文提出一种基于自然语言处理的语义化、意图驱动的集群系统调度范式。该系统通过集成大型语言模型的Kubernetes调度扩展器，解析用于软亲和性偏好的自然语言分配提示注解。我们开发了包含集群状态缓存和意图分析器（使用AWS Bedrock）的原型系统。实证评估表明，在评估基准数据集上，Amazon Nova Pro/Premier和Mistral Pixtral Large等顶级模型实现了较高的LLM解析准确率（子集准确率>95%），显著优于基线引擎。在六种场景下的调度质量测试显示，与标准Kubernetes配置相比，该原型实现了更优或同等的资源安置效果，尤其在复杂场景、量化场景及冲突软偏好处理方面表现突出。结果验证了使用LLM实现可访问调度的可行性，但也揭示了同步LLM延迟等局限性，建议通过异步处理实现生产就绪。本研究证实了语义软亲和性在简化工作负载编排方面的实用价值。",
    "url": "https://huggingface.co/papers/2601.09282",
    "arxiv_url": "https://arxiv.org/abs/2601.09282"
  },
  {
    "title": "sui-1: Grounded and Verifiable Long-Form Summarization",
    "summary": "Large language models frequently generate plausible but unfaithful summaries that users cannot verify against source text, a critical limitation in compliance-sensitive domains such as government and legal analysis. We present sui-1, a 24B parameter model that produces abstractive summaries with inline citations, enabling users to trace each claim to its source sentence. Our synthetic data pipeline combines chain-of-thought prompting with multi-stage verification, generating over 22,000 high-quality training examples across five languages from diverse sources including parliamentary documents, web text, and Wikipedia. Evaluation shows sui-1 significantly outperforms all tested open-weight baselines, including models with 3x more parameters. These results demonstrate that task-specific training substantially outperforms scale alone for citation-grounded summarization. Model weights and an interactive demo are publicly available.",
    "translation": "标题：sui-1：基于引证且可验证的长文本摘要生成模型\n\n摘要：大型语言模型经常生成看似合理但缺乏真实性的摘要，用户无法依据源文本进行验证，这在政府与法律分析等对合规性要求严格的领域中是一个关键局限。本文提出sui-1模型，这是一个拥有240亿参数的模型，能够生成带有文中引证的抽象摘要，使用户能够将每个主张追溯至其源语句。我们的合成数据流程将思维链提示与多阶段验证相结合，从议会文件、网络文本和维基百科等多种来源中，生成了涵盖五种语言的超过22,000个高质量训练样本。评估表明，sui-1模型在性能上显著超越了所有测试的开源基线模型，包括参数量为其三倍的模型。这些结果证明，对于基于引证的摘要生成任务，针对性的训练效果远超单纯扩大模型规模。模型权重及交互演示已公开发布。",
    "url": "https://huggingface.co/papers/2601.08472",
    "arxiv_url": "https://arxiv.org/abs/2601.08472"
  },
  {
    "title": "SampoNLP: A Self-Referential Toolkit for Morphological Analysis of Subword Tokenizers",
    "summary": "The quality of subword tokenization is critical for Large Language Models, yet evaluating tokenizers for morphologically rich Uralic languages is hampered by the lack of clean morpheme lexicons.\n  We introduce SampoNLP, a corpus-free toolkit for morphological lexicon creation using MDL-inspired Self-Referential Atomicity Scoring, which filters composite forms through internal structural cues - suited for low-resource settings.\n  Using the high-purity lexicons generated by SampoNLP for Finnish, Hungarian, and Estonian, we conduct a systematic evaluation of BPE tokenizers across a range of vocabulary sizes (8k-256k). We propose a unified metric, the Integrated Performance Score (IPS), to navigate the trade-off between morpheme coverage and over-splitting. By analyzing the IPS curves, we identify the \"elbow points\" of diminishing returns and provide the first empirically grounded recommendations for optimal vocabulary sizes (k) in these languages. Our study not only offers practical guidance but also quantitatively demonstrates the limitations of standard BPE for highly agglutinative languages. The SampoNLP library and all generated resources are made publicly available: https://github.com/AragonerUA/SampoNLP",
    "translation": "标题：SampoNLP：一种用于子词分词器形态学分析的自参照工具包\n\n摘要：子词分词的质量对大语言模型至关重要，然而对形态丰富的乌拉尔语系语言进行分词器评估，常因缺乏清晰的语素词典而受阻。本文介绍SampoNLP——一种无需语料库的形态学词典构建工具包，其采用受最小描述长度原理启发的自参照原子性评分方法，通过内部结构线索过滤复合形式，适用于低资源场景。利用SampoNLP为芬兰语、匈牙利语和爱沙尼亚语生成的高纯度词典，我们对BPE分词器在不同词汇表规模（8k-256k）下进行了系统评估。我们提出统一指标——综合性能评分（IPS），以权衡语素覆盖度与过度切分问题。通过分析IPS曲线，我们确定了收益递减的“拐点”，并首次为这些语言提供了基于实证的最优词汇表规模建议。本研究不仅提供了实践指导，还定量揭示了标准BPE方法对高度黏着性语言的局限性。SampoNLP工具库及所有生成资源已公开：https://github.com/AragonerUA/SampoNLP",
    "url": "https://huggingface.co/papers/2601.04469",
    "arxiv_url": "https://arxiv.org/abs/2601.04469"
  }
]