[
  {
    "title": "LongCat-Flash-Thinking-2601 Technical Report",
    "summary": "We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.",
    "translation": "标题：LongCat-Flash-Thinking-2601技术报告\n\n摘要：本文介绍LongCat-Flash-Thinking-2601，这是一个拥有5600亿参数的开源专家混合推理模型，具备卓越的智能体推理能力。该模型在广泛的智能体基准测试中实现了开源模型的领先性能，涵盖智能体搜索、智能体工具使用及工具集成推理等领域。除基准测试表现外，该模型在复杂工具交互场景中展现出强大的泛化能力，并在真实世界的噪声环境中保持稳健性能。其先进能力源于统一的训练框架，该框架将领域并行专家训练与后续融合相结合，并实现了从预训练到后训练阶段数据构建、环境配置、算法设计及基础设施的端到端协同优化。特别地，模型在复杂工具使用场景中的强泛化能力得益于我们对环境扩展和原则性任务构建的深入探索。为优化长尾分布、偏态生成和多轮智能体交互，并在涵盖20余个领域的超10000个环境中实现稳定训练，我们系统性地扩展了异步强化学习框架DORA，以支持稳定高效的大规模多环境训练。此外，针对真实世界任务固有的噪声特性，我们系统分析并解构了现实噪声模式，设计了针对性训练流程，将此类不完美因素显式纳入训练过程，从而显著提升了模型在实际应用中的鲁棒性。为进一步增强复杂推理任务性能，我们引入了深度思考模式，通过密集并行思维协同扩展推理深度与宽度，实现了有效的测试时性能扩展。",
    "url": "https://huggingface.co/papers/2601.16725",
    "arxiv_url": "https://arxiv.org/abs/2601.16725"
  },
  {
    "title": "SWE-Pruner: Self-Adaptive Context Pruning for Coding Agents",
    "summary": "LLM agents have demonstrated remarkable capabilities in software development, but their performance is hampered by long interaction contexts, which incur high API costs and latency. While various context compression approaches such as LongLLMLingua have emerged to tackle this challenge, they typically rely on fixed metrics such as PPL, ignoring the task-specific nature of code understanding. As a result, they frequently disrupt syntactic and logical structure and fail to retain critical implementation details. In this paper, we propose SWE-Pruner, a self-adaptive context pruning framework tailored for coding agents. Drawing inspiration from how human programmers \"selectively skim\" source code during development and debugging, SWE-Pruner performs task-aware adaptive pruning for long contexts. Given the current task, the agent formulates an explicit goal (e.g., \"focus on error handling\") as a hint to guide the pruning targets. A lightweight neural skimmer (0.6B parameters) is trained to dynamically select relevant lines from the surrounding context given the goal. Evaluations across four benchmarks and multiple models validate SWE-Pruner's effectiveness in various scenarios, achieving 23-54% token reduction on agent tasks like SWE-Bench Verified and up to 14.84x compression on single-turn tasks like LongCodeQA with minimal performance impact.",
    "translation": "标题：SWE-Pruner：面向代码智能体的自适应上下文剪枝框架\n\n摘要：大语言模型智能体在软件开发中展现出卓越能力，但其性能常受限于冗长的交互上下文，导致高昂的API成本与响应延迟。尽管已有诸如LongLLMLingua等上下文压缩方法应对此挑战，但这些方法通常依赖困惑度等固定指标，忽视了代码理解任务特有的本质，往往破坏代码的语法逻辑结构并丢失关键实现细节。本文提出SWE-Pruner——一个专为代码智能体设计的自适应上下文剪枝框架。该框架借鉴人类程序员在开发调试过程中“选择性浏览”源代码的认知机制，针对长上下文执行任务感知的自适应剪枝。智能体根据当前任务生成明确目标指引（如“聚焦错误处理机制”）作为剪枝导向，通过训练一个轻量级神经浏览模型（0.6B参数）动态筛选与目标相关的上下文代码行。在四个基准测试集和多种模型上的实验表明，SWE-Pruner能在各类场景中保持有效性：在SWE-Bench Verified等智能体任务上实现23-54%的令牌缩减，在LongCodeQA等单轮任务中达到最高14.84倍压缩率，且对性能影响微乎其微。",
    "url": "https://huggingface.co/papers/2601.16746",
    "arxiv_url": "https://arxiv.org/abs/2601.16746"
  },
  {
    "title": "TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers",
    "summary": "Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to \"catastrophic forgetting\" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen \"Left Brain\", which retains robust general visual reasoning, with a trainable \"Right Brain\", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity.",
    "translation": "标题：TwinBrainVLA：通过非对称混合变换器释放通用视觉语言模型在具身任务中的潜力\n\n摘要：标准的视觉-语言-动作模型通常通过显式微调一个单一的视觉语言模型主干来适应机器人控制。然而，这种方法在保持高层通用语义理解与学习低层、细粒度感知运动技能之间产生了关键矛盾，常常导致模型对开放世界能力的“灾难性遗忘”。为解决这一冲突，我们提出了TwinBrainVLA，这是一种新颖的架构，它协调了一个保留通用语义理解的通用视觉语言模型和一个专用于具身本体感知的专用视觉语言模型，以实现联合机器人控制。TwinBrainVLA通过一种新颖的非对称混合变换器机制，将保持强大通用视觉推理能力的冻结“左脑”与专精于具身感知的可训练“右脑”协同工作。该设计使得右脑能够动态地从冻结的左脑查询语义知识，并将其与本体感知状态融合，从而为流匹配动作专家提供丰富的条件信息，以生成精确的连续控制。在SimplerEnv和RoboCasa基准测试上的大量实验表明，与现有先进基线相比，TwinBrainVLA实现了更优的操作性能，同时明确保留了预训练视觉语言模型的全面视觉理解能力，为构建同时具备高层语义理解和低层物理灵巧性的通用机器人提供了一个有前景的方向。",
    "url": "https://huggingface.co/papers/2601.14133",
    "arxiv_url": "https://arxiv.org/abs/2601.14133"
  },
  {
    "title": "VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents",
    "summary": "Modern Vision-Language Models (VLMs) remain poorly characterized in multi-step visual interactions, particularly in how they integrate perception, memory, and action over long horizons. We introduce VisGym, a gymnasium of 17 environments for evaluating and training VLMs. The suite spans symbolic puzzles, real-image understanding, navigation, and manipulation, and provides flexible controls over difficulty, input representation, planning horizon, and feedback. We also provide multi-step solvers that generate structured demonstrations, enabling supervised finetuning. Our evaluations show that all frontier models struggle in interactive settings, achieving low success rates in both the easy (46.6%) and hard (26.0%) configurations. Our experiments reveal notable limitations: models struggle to effectively leverage long context, performing worse with an unbounded history than with truncated windows. Furthermore, we find that several text-based symbolic tasks become substantially harder once rendered visually. However, explicit goal observations, textual feedback, and exploratory demonstrations in partially observable or unknown-dynamics settings for supervised finetuning yield consistent gains, highlighting concrete failure modes and pathways for improving multi-step visual decision-making. Code, data, and models can be found at: https://visgym.github.io/.",
    "translation": "标题：VisGym：面向多模态智能体的多样化、可定制、可扩展环境\n\n摘要：现代视觉-语言模型在多步骤视觉交互中的表现仍缺乏深入刻画，尤其是在其如何整合长时程的感知、记忆与行动方面。本研究提出VisGym，一个包含17种环境的测试平台，用于评估和训练视觉-语言模型。该套件涵盖符号推理、真实图像理解、导航与操作任务，并提供对任务难度、输入表征、规划时域和反馈机制的灵活控制。我们还提供了可生成结构化演示的多步骤求解器，以支持监督式微调。评估结果表明，所有前沿模型在交互式场景中均表现不佳，在简单配置（46.6%）与困难配置（26.0%）下的成功率均较低。实验揭示了若干显著局限：模型难以有效利用长上下文信息，在无限制历史窗口下的表现反而差于截断窗口；同时，多项基于文本的符号任务在转换为视觉呈现后难度显著增加。然而，在部分可观测或动态未知的场景中，通过显式目标观察、文本反馈以及探索性演示进行监督微调，能够带来稳定性能提升，这为改进多步骤视觉决策指明了具体失效模式与优化路径。代码、数据及模型可通过以下链接获取：https://visgym.github.io/。",
    "url": "https://huggingface.co/papers/2601.16973",
    "arxiv_url": "https://arxiv.org/abs/2601.16973"
  },
  {
    "title": "Memory-V2V: Augmenting Video-to-Video Diffusion Models with Memory",
    "summary": "Recent foundational video-to-video diffusion models have achieved impressive results in editing user provided videos by modifying appearance, motion, or camera movement. However, real-world video editing is often an iterative process, where users refine results across multiple rounds of interaction. In this multi-turn setting, current video editors struggle to maintain cross-consistency across sequential edits. In this work, we tackle, for the first time, the problem of cross-consistency in multi-turn video editing and introduce Memory-V2V, a simple, yet effective framework that augments existing video-to-video models with explicit memory. Given an external cache of previously edited videos, Memory-V2V employs accurate retrieval and dynamic tokenization strategies to condition the current editing step on prior results. To further mitigate redundancy and computational overhead, we propose a learnable token compressor within the DiT backbone that compresses redundant conditioning tokens while preserving essential visual cues, achieving an overall speedup of 30%. We validate Memory-V2V on challenging tasks including video novel view synthesis and text-conditioned long video editing. Extensive experiments show that Memory-V2V produces videos that are significantly more cross-consistent with minimal computational overhead, while maintaining or even improving task-specific performance over state-of-the-art baselines. Project page: https://dohunlee1.github.io/MemoryV2V",
    "translation": "标题：Memory-V2V：通过记忆增强视频到视频扩散模型\n\n摘要：近期的基础性视频到视频扩散模型在编辑用户提供的视频方面取得了令人瞩目的成果，能够修改视频的外观、运动或摄像机移动。然而，现实中的视频编辑通常是一个迭代过程，用户需要通过多轮交互来优化结果。在这种多轮编辑场景下，当前的视频编辑工具难以保持连续编辑之间的跨轮次一致性。本研究首次针对多轮视频编辑中的跨轮次一致性问题，提出了Memory-V2V——一个简单而有效的框架，通过显式记忆机制增强现有的视频到视频模型。基于先前已编辑视频的外部缓存，Memory-V2V采用精确检索与动态标记化策略，将历史编辑结果作为当前编辑步骤的条件输入。为进一步减少冗余并降低计算开销，我们在DiT骨干网络中引入了一种可学习的标记压缩器，该压缩器能够在保留关键视觉线索的同时压缩冗余的条件标记，从而实现整体30%的加速效果。我们在视频新视角合成和文本条件长视频编辑等挑战性任务上验证了Memory-V2V的性能。大量实验表明，Memory-V2V能够以最小的计算开销生成具有显著更高跨轮次一致性的视频，同时在特定任务性能上保持甚至超越现有最先进基线模型。项目页面：https://dohunlee1.github.io/MemoryV2V",
    "url": "https://huggingface.co/papers/2601.16296",
    "arxiv_url": "https://arxiv.org/abs/2601.16296"
  },
  {
    "title": "Inference-Time Scaling of Verification: Self-Evolving Deep Research Agents via Test-Time Rubric-Guided Verification",
    "summary": "Recent advances in Deep Research Agents (DRAs) are transforming automated knowledge discovery and problem-solving. While the majority of existing efforts focus on enhancing policy capabilities via post-training, we propose an alternative paradigm: self-evolving the agent's ability by iteratively verifying the policy model's outputs, guided by meticulously crafted rubrics. This approach gives rise to the inference-time scaling of verification, wherein an agent self-improves by evaluating its generated answers to produce iterative feedback and refinements. We derive the rubrics based on an automatically constructed DRA Failure Taxonomy, which systematically classifies agent failures into five major categories and thirteen sub-categories. We present DeepVerifier, a rubrics-based outcome reward verifier that leverages the asymmetry of verification and outperforms vanilla agent-as-judge and LLM judge baselines by 12%-48% in meta-evaluation F1 score. To enable practical self-evolution, DeepVerifier integrates as a plug-and-play module during test-time inference. The verifier produces detailed rubric-based feedback, which is fed back to the agent for iterative bootstrapping, refining responses without additional training. This test-time scaling delivers 8%-11% accuracy gains on challenging subsets of GAIA and XBench-DeepResearch when powered by capable closed-source LLMs. Finally, to support open-source advancement, we release DeepVerifier-4K, a curated supervised fine-tuning dataset of 4,646 high-quality agent steps focused on DRA verification. These examples emphasize reflection and self-critique, enabling open models to develop robust verification capabilities.",
    "translation": "标题：推理时验证的规模化：基于测试时准则引导验证的自演进深度研究智能体\n\n摘要：深度研究智能体（DRAs）的最新进展正在改变自动化知识发现与问题解决的范式。现有研究大多通过训练后优化来提升策略能力，本文提出一种替代范式：通过精心设计的评估准则迭代验证策略模型的输出，从而实现智能体能力的自演进。该方法催生了验证过程的推理时规模化，即智能体通过评估自身生成的答案产生迭代反馈与优化，实现自我改进。我们基于自动构建的DRA失败分类法推导评估准则，该系统将智能体失败系统性地归纳为5个主要类别和13个子类别。我们提出DeepVerifier——一种基于准则的结果奖励验证器，其利用验证过程的不对称性，在元评估F1分数上超越原始智能体即裁判和LLM裁判基线12%-48%。为实现实际自演进，DeepVerifier可作为即插即用模块集成于测试时推理流程。该验证器生成基于准则的详细反馈，反馈至智能体进行迭代自举优化，无需额外训练即可精炼响应。当搭载高性能闭源大语言模型时，这种测试时规模化方法在GAIA和XBench-DeepResearch的挑战性子集上实现了8%-11%的准确率提升。最后，为促进开源生态发展，我们开源DeepVerifier-4K数据集，该监督微调数据集包含4,646个聚焦DRA验证的高质量智能体步骤案例，这些案例强调反思与自我批判能力，助力开源模型发展鲁棒的验证能力。",
    "url": "https://huggingface.co/papers/2601.15808",
    "arxiv_url": "https://arxiv.org/abs/2601.15808"
  },
  {
    "title": "Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow",
    "summary": "Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.",
    "translation": "标题：Jet-RL：通过统一的训练与推演精度流实现基于策略的FP8强化学习\n\n摘要：强化学习（RL）对于提升大语言模型（LLM）的复杂推理能力至关重要。然而，现有的RL训练流程计算效率低且资源消耗大，其中推演阶段占总训练时间的70%以上。量化RL训练，尤其是使用FP8精度，为解决这一瓶颈提供了可行途径。当前普遍采用的策略是在推演阶段使用FP8精度，同时在训练阶段保持BF16精度。本研究首次对FP8 RL训练进行了全面分析，并证明这种广泛使用的“BF16训练 + FP8推演”策略在长序列推演和复杂任务下存在严重的训练不稳定性，并会导致灾难性的精度崩溃。我们的分析表明，这些失败源于该方法的离策略特性，其在训练与推理之间引入了显著的数值不匹配。基于此发现，我们提出了Jet-RL，一个能够实现稳健、稳定RL优化的FP8训练框架。其核心思想是采用统一的FP8精度流同时覆盖训练与推演阶段，从而最大程度减少数值差异，并避免低效的步间校准。大量实验验证了Jet-RL的有效性：我们的方法在推演阶段实现了最高33%的加速，在训练阶段实现了最高41%的加速，相比BF16训练整体端到端加速达16%，同时在所有实验设置下均保持稳定的收敛性，且精度损失可忽略不计。",
    "url": "https://huggingface.co/papers/2601.14243",
    "arxiv_url": "https://arxiv.org/abs/2601.14243"
  },
  {
    "title": "SALAD: Achieve High-Sparsity Attention via Efficient Linear Attention Tuning for Video Diffusion Transformer",
    "summary": "Diffusion Transformers have recently demonstrated remarkable performance in video generation. However, the long input sequences result in high computational latency due to the quadratic complexity of full attention. Various sparse attention mechanisms have been proposed. Training-free sparse attention is constrained by limited sparsity and thus offers modest acceleration, whereas training-based methods can reach much higher sparsity but demand substantial data and computation for training. In this work, we propose SALAD, introducing a lightweight linear attention branch in parallel with the sparse attention. By incorporating an input-dependent gating mechanism to finely balance the two branches, our method attains 90% sparsity and 1.72x inference speedup, while maintaining generation quality comparable to the full attention baseline. Moreover, our finetuning process is highly efficient, requiring only 2,000 video samples and 1,600 training steps with a batch size of 8.",
    "translation": "标题：SALAD：通过高效线性注意力微调实现视频扩散Transformer的高稀疏化注意力机制\n\n摘要：扩散Transformer近期在视频生成领域展现出卓越性能。然而，由于完全注意力机制的二次计算复杂度，长输入序列会导致较高的计算延迟。现有研究提出了多种稀疏注意力机制：免训练的稀疏注意力受限于较低的稀疏度，仅能实现有限的加速效果；而基于训练的方法虽能达到更高稀疏度，却需要大量数据和计算资源进行训练。本研究提出SALAD方法，通过在稀疏注意力旁并行引入轻量级线性注意力分支，并采用输入依赖的门控机制精细平衡两个分支的贡献。该方法在保持生成质量与完全注意力基线相当的前提下，实现了90%的注意力稀疏度和1.72倍的推理加速。此外，我们的微调过程具有高效特性，仅需2,000个视频样本和1,600个训练步数（批次大小为8）即可完成。",
    "url": "https://huggingface.co/papers/2601.16515",
    "arxiv_url": "https://arxiv.org/abs/2601.16515"
  },
  {
    "title": "GameTalk: Training LLMs for Strategic Conversation",
    "summary": "Strategic decision-making in multi-agent settings is a key challenge for large language models (LLMs), particularly when coordination and negotiation must unfold over extended conversations. While recent work has explored the use of LLMs in isolated decision tasks, little attention has been given to optimizing long-term objectives through dialogue. We introduce GameTalk, a framework for training LLMs to make strategic decisions via multi-turn interactions. Unlike prior work that focuses on single-turn objectives or static action prediction, we train LLMs to optimize a global objective across full conversations. We achieve this by adapting fine-tuning methods like GRPO, DPO, and STaR to incorporate reward signals that depend on the entire interaction. We evaluate this approach on a suite of increasingly complex games, designed to stress different aspects of reasoning, coordination, and opponent modeling. Our results show that GameTalk significantly outperforms untrained models, especially under reward shaping, with DPO consistently yielding the strongest gains. These findings position conversational fine-tuning as a promising path for LLMs to reason, negotiate, and act in interactive environments.",
    "translation": "标题：GameTalk：面向战略对话的大语言模型训练框架\n\n摘要：在多智能体环境中进行战略决策是大语言模型面临的核心挑战，尤其在需要通过多轮对话展开协调与谈判的场景中。尽管近期研究已探索大语言模型在独立决策任务中的应用，但如何通过对话优化长期目标的研究仍较为有限。本文提出GameTalk框架，通过多轮交互训练大语言模型进行战略决策。与以往关注单轮目标或静态行为预测的研究不同，我们训练模型在整个对话过程中优化全局目标。通过改进GRPO、DPO和STaR等微调方法，使其能够整合依赖完整交互过程的奖励信号，我们实现了这一目标。在一系列复杂度递增的博弈环境中对该方法进行评估，这些环境专门设计用于检验推理、协调和对手建模等不同维度的能力。实验结果表明，GameTalk显著优于未经训练的基线模型，在奖励塑形条件下表现尤为突出，其中DPO方法持续带来最显著的性能提升。这些发现表明，对话式微调为大语言模型在交互环境中进行推理、谈判与行动提供了可行路径。",
    "url": "https://huggingface.co/papers/2601.16276",
    "arxiv_url": "https://arxiv.org/abs/2601.16276"
  },
  {
    "title": "MeepleLM: A Virtual Playtester Simulating Diverse Subjective Experiences",
    "summary": "Recent advancements have expanded the role of Large Language Models in board games from playing agents to creative co-designers. However, a critical gap remains: current systems lack the capacity to offer constructive critique grounded in the emergent user experience. Bridging this gap is fundamental for harmonizing Human-AI collaboration, as it empowers designers to refine their creations via external perspectives while steering models away from biased or unpredictable outcomes. Automating critique for board games presents two challenges: inferring the latent dynamics connecting rules to gameplay without an explicit engine, and modeling the subjective heterogeneity of diverse player groups. To address these, we curate a dataset of 1,727 structurally corrected rulebooks and 150K reviews selected via quality scoring and facet-aware sampling. We augment this data with Mechanics-Dynamics-Aesthetics (MDA) reasoning to explicitly bridge the causal gap between written rules and player experience. We further distill player personas and introduce MeepleLM, a specialized model that internalizes persona-specific reasoning patterns to accurately simulate the subjective feedback of diverse player archetypes. Experiments demonstrate that MeepleLM significantly outperforms latest commercial models (e.g., GPT-5.1, Gemini3-Pro) in community alignment and critique quality, achieving a 70% preference rate in user studies assessing utility. MeepleLM serves as a reliable virtual playtester for general interactive systems, marking a pivotal step towards audience-aligned, experience-aware Human-AI collaboration.",
    "translation": "标题：MeepleLM：模拟多样化主观体验的虚拟游戏测试员\n\n摘要：近年来，大型语言模型在桌游中的角色已从游戏代理扩展至创意协同设计者。然而，当前系统仍存在一个关键缺陷：缺乏基于涌现用户体验的建构性批判能力。弥补这一缺陷对于协调人机协作至关重要，它使设计者能够借助外部视角完善创作，同时引导模型避免偏见或不可预测的结果。实现桌游批判的自动化面临两大挑战：一是在缺乏显式游戏引擎的情况下，推断连接规则与游戏过程的潜在动态；二是建模多样化玩家群体的主观异质性。为此，我们构建了一个包含1,727份结构校正规则书和15万条通过质量评分与维度感知抽样筛选的评论数据集。我们运用机制-动态-美学（MDA）推理框架增强数据，以显式弥合书面规则与玩家体验之间的因果鸿沟。进一步地，我们提炼玩家角色原型，并提出了MeepleLM——一个内化角色特定推理模式的专用模型，能够精准模拟多样化玩家原型的个性化反馈。实验表明，MeepleLM在社区契合度与批判质量上显著优于最新商业模型（如GPT-5.1、Gemini3-Pro），在评估实用性的用户研究中获得70%的偏好率。MeepleLM可作为通用交互系统的可靠虚拟测试员，标志着面向受众契合、体验感知的人机协作迈出了关键一步。",
    "url": "https://huggingface.co/papers/2601.07251",
    "arxiv_url": "https://arxiv.org/abs/2601.07251"
  },
  {
    "title": "DSGym: A Holistic Framework for Evaluating and Training Data Science Agents",
    "summary": "Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of rigorous data grounding. In particular, we show that a substantial portion of tasks in current benchmarks can be solved without using the actual data. To address these limitations, we introduce DSGym, a standardized framework for evaluating and training data science agents in self-contained execution environments. Unlike static benchmarks, DSGym provides a modular architecture that makes it easy to add tasks, agent scaffolds, and tools, positioning it as a live, extensible testbed. We curate DSGym-Tasks, a holistic task suite that standardizes and refines existing benchmarks via quality and shortcut solvability filtering. We further expand coverage with (1) DSBio: expert-derived bioinformatics tasks grounded in literature and (2) DSPredict: challenging prediction tasks spanning domains such as computer vision, molecular prediction, and single-cell perturbation. Beyond evaluation, DSGym enables agent training via execution-verified data synthesis pipeline. As a case study, we build a 2,000-example training set and trained a 4B model in DSGym that outperforms GPT-4o on standardized analysis benchmarks. Overall, DSGym enables rigorous end-to-end measurement of whether agents can plan, implement, and validate data analyses in realistic scientific context.",
    "translation": "标题：DSGym：一个用于评估与训练数据科学智能体的整体框架\n\n摘要：数据科学智能体有望通过将数据转化为可执行的分析与发现，加速科学发现与洞察生成。然而，现有数据科学基准测试存在不足，主要体现在评估接口碎片化导致跨基准比较困难、任务覆盖范围狭窄以及缺乏严谨的数据基础。我们特别指出，当前基准测试中相当一部分任务无需使用真实数据即可解决。为应对这些局限，本文提出DSGym——一个在自包含执行环境中评估与训练数据科学智能体的标准化框架。与静态基准不同，DSGym采用模块化架构，可便捷地添加任务、智能体框架及工具，使其成为动态可扩展的测试平台。我们构建了DSGym-Tasks整体任务套件，通过质量筛选与捷径可解性过滤对现有基准进行标准化与优化。进一步通过以下方式拓展任务覆盖范围：（1）DSBio：基于文献构建、专家驱动的生物信息学任务；（2）DSPredict：涵盖计算机视觉、分子预测与单细胞扰动等领域的复杂预测任务。除评估功能外，DSGym通过执行验证的数据合成流程支持智能体训练。作为案例研究，我们构建了包含2000个样本的训练集，在DSGym中训练了一个40亿参数模型，该模型在标准化分析基准测试中表现优于GPT-4o。总体而言，DSGym能够对智能体在真实科学场景中规划、实施与验证数据分析的能力进行严谨的端到端评估。",
    "url": "https://huggingface.co/papers/2601.16344",
    "arxiv_url": "https://arxiv.org/abs/2601.16344"
  },
  {
    "title": "Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain",
    "summary": "This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downstream retrieval performance throughout training, revealing that optimal checkpoints achieve best retrieval scores before pre-training loss reaches its minimum. Our encoder models achieve top-3 rankings on the Turkish retrieval leaderboard, with smaller models (155M parameters) achieving comparable performance to larger reference models (307M-567M parameters). Our approach achieves 92.36% production efficiency compared to state-of-the-art models (embeddinggemma-300m: 100.00%, BAAI/bge-m3: 99.54%, newmindai/bge-m3-stsb: 94.38%), ranking fourth overall despite requiring less computational resources. SOTA models rely on multi-stage, computationally intensive training pipelines, making our single-stage pre-training followed by efficient post-training approach a cost-effective alternative; (2)Decoder Model with Continual Pre-training (CPT): Qwen3-1.7B and Qwen3-4B models adapted to Turkish legal domain through controlled curriculum learning. Four-phase CPT with optimal sample ratios enables gradual transition from general language knowledge to specialized legal terminology and long-context reasoning. This approach achieves 36.2% perplexity reduction on Turkish legal text, demonstrating domain adaptation gains.",
    "translation": "标题：Mecellem模型：面向法律领域从头训练与持续预训练的土耳其语模型\n\n摘要：本文提出Mecellem模型框架，该框架通过领域自适应策略开发面向土耳其法律领域的专用语言模型。我们做出两项贡献：（1）从头预训练的编码器模型：基于ModernBERT架构的双向编码器在包含1127亿词符的土耳其语主导语料库上进行预训练。我们实施了检查点选择策略，通过持续评估训练过程中的下游检索性能，发现最优检查点能在预训练损失达到最小值之前取得最佳检索分数。我们的编码器模型在土耳其语检索排行榜中位列前三，其中较小规模模型（1.55亿参数）的性能可与更大规模参考模型（3.07亿-5.67亿参数）相媲美。相较于前沿模型（embeddinggemma-300m：100.00%、BAAI/bge-m3：99.54%、newmindai/bge-m3-stsb：94.38%），我们的方法实现了92.36%的生产效率，在计算资源需求更少的情况下总体排名第四。当前前沿模型依赖多阶段、计算密集的训练流程，而我们采用单阶段预训练结合高效后训练的方法，提供了更具成本效益的替代方案；（2）持续预训练的解码器模型：通过受控课程学习将Qwen3-1.7B和Qwen3-4B模型适配至土耳其法律领域。采用四阶段持续预训练与最优样本配比，实现了从通用语言知识到专业法律术语及长上下文推理的渐进过渡。该方法在土耳其法律文本上实现了36.2%的困惑度降低，充分证明了领域自适应的有效性。",
    "url": "https://huggingface.co/papers/2601.16018",
    "arxiv_url": "https://arxiv.org/abs/2601.16018"
  },
  {
    "title": "Endless Terminals: Scaling RL Environments for Terminal Agents",
    "summary": "Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.",
    "translation": "标题：无尽终端：面向终端智能体的可扩展强化学习环境构建\n\n摘要：环境是自进化智能体的发展瓶颈。现有终端基准测试集为评估而设计，非为训练优化；强化学习需要可扩展的生成流程，而非静态数据集。本文提出“无尽终端”——一个无需人工标注、能自主生成终端任务的全自动流程。该流程包含四个阶段：生成多样化任务描述、构建并验证容器化环境、设计完成度测试、基于可解性进行任务筛选。通过此流程，我们获得了涵盖文件操作、日志管理、数据处理、脚本编写及数据库操作等领域的3255项任务。我们采用标准PPO算法配合二元回合奖励机制进行智能体训练，并采用极简交互循环：无检索机制、多智能体协作或专用工具。尽管设计简洁，在无尽终端上训练的模型仍展现出显著性能提升：在预留开发集上，Llama-3.2-3B模型准确率从4.0%提升至18.2%，Qwen2.5-7B从10.7%提升至53.3%，Qwen3-8B-openthinker-sft从42.6%提升至59.0%。该提升效果可迁移至人工标注基准测试：在TerminalBench 2.0测试中，经无尽终端训练的模型表现全面超越采用复杂智能体框架的对比方案，其中Llama-3.2-3B从0.0%提升至2.2%，Qwen2.5-7B从2.2%提升至3.4%，Qwen3-8B-openthinker-sft从1.1%提升至6.7%。这些结果表明：当环境实现规模化扩展时，简约的强化学习范式即可取得显著成效。",
    "url": "https://huggingface.co/papers/2601.16443",
    "arxiv_url": "https://arxiv.org/abs/2601.16443"
  },
  {
    "title": "ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch",
    "summary": "Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.",
    "translation": "标题：ChartVerse：通过从零开始的可靠程序化合成实现图表推理的规模化\n\n摘要：图表推理是视觉语言模型（VLM）的关键能力。然而，高质量训练数据的缺乏严重阻碍了开源模型的发展。现有数据集面临双重挑战：合成图表往往过于简单且重复，而相关的问答对则容易出现幻觉，缺乏复杂任务所需的推理深度。为弥补这一差距，我们提出了ChartVerse，一个可扩展的框架，旨在从零开始合成复杂图表与可靠的推理数据。（1）针对简单模式的瓶颈，我们首先引入了Rollout后验熵（RPE），这是一种量化图表复杂度的新指标。在RPE的指导下，我们开发了复杂度感知的图表编码器，通过可执行程序自主合成多样化、高复杂度的图表。（2）为确保推理的严谨性，我们开发了基于真实锚点的逆向问答合成方法。与标准生成方式不同，我们采用答案优先的范式：直接从源代码中提取确定性答案，基于这些锚点生成问题，并强制执行严格的一致性验证。为进一步提升难度与推理深度，我们根据模型失败率筛选样本，并提炼出高质量的思维链（CoT）推理数据。我们使用Qwen3-VL-30B-A3B-Thinking作为教师模型，构建了ChartVerse-SFT-600K和ChartVerse-RL-40K数据集。实验结果表明，ChartVerse-8B模型实现了最先进的性能，显著超越了其教师模型，并与更强的Qwen3-VL-32B-Thinking模型相媲美。",
    "url": "https://huggingface.co/papers/2601.13606",
    "arxiv_url": "https://arxiv.org/abs/2601.13606"
  },
  {
    "title": "Knowledge is Not Enough: Injecting RL Skills for Continual Adaptation",
    "summary": "Large Language Models (LLMs) face the \"knowledge cutoff\" challenge, where their frozen parametric memory prevents direct internalization of new information. While Supervised Fine-Tuning (SFT) is commonly used to update model knowledge, it often updates factual content without reliably improving the model's ability to use the newly incorporated information for question answering or decision-making. Reinforcement Learning (RL) is essential for acquiring reasoning skills; however, its high computational cost makes it impractical for efficient online adaptation. We empirically observe that the parameter updates induced by SFT and RL are nearly orthogonal. Based on this observation, we propose Parametric Skill Transfer (PaST), a framework that supports modular skill transfer for efficient and effective knowledge adaptation. By extracting a domain-agnostic Skill Vector from a source domain, we can linearly inject knowledge manipulation skills into a target model after it has undergone lightweight SFT on new data. Experiments on knowledge-incorporation QA (SQuAD, LooGLE) and agentic tool-use benchmarks (ToolBench) demonstrate the effectiveness of our method. On SQuAD, PaST outperforms the state-of-the-art self-editing SFT baseline by up to 9.9 points. PaST further scales to long-context QA on LooGLE with an 8.0-point absolute accuracy gain, and improves zero-shot ToolBench success rates by +10.3 points on average with consistent gains across tool categories, indicating strong scalability and cross-domain transferability of the Skill Vector.",
    "translation": "标题：知识并非万能：注入强化学习技能以实现持续适应\n\n摘要：大型语言模型（LLM）面临“知识截止”挑战，其冻结的参数化记忆阻碍了新信息的直接内化。尽管监督微调（SFT）常用于更新模型知识，但该方法通常仅更新事实性内容，而无法可靠提升模型运用新信息进行问答或决策的能力。强化学习（RL）对获取推理技能至关重要，但其高昂的计算成本使其难以实现高效的在线适应。我们通过实验观察到，SFT与RL引发的参数更新近乎正交。基于此发现，我们提出参数化技能迁移框架（PaST），该框架支持模块化技能迁移，以实现高效且有效的知识适应。通过从源领域提取领域无关的技能向量，我们可以在目标模型对新数据进行轻量级SFT后，线性注入知识操纵技能。在知识融合问答（SQuAD、LooGLE）与智能体工具使用基准测试（ToolBench）上的实验验证了本方法的有效性。在SQuAD数据集上，PaST相较最先进的自我编辑SFT基线最高提升9.9个点。PaST进一步扩展至LooGLE长上下文问答任务，获得8.0个点的绝对准确率提升，并在ToolBench上实现平均+10.3个点的零样本成功率改进，且在不同工具类别中均保持稳定增益，这证明了技能向量具备强大的可扩展性与跨领域迁移能力。",
    "url": "https://huggingface.co/papers/2601.11258",
    "arxiv_url": "https://arxiv.org/abs/2601.11258"
  },
  {
    "title": "VISTA-PATH: An interactive foundation model for pathology image segmentation and quantitative analysis in computational pathology",
    "summary": "Accurate semantic segmentation for histopathology image is crucial for quantitative tissue analysis and downstream clinical modeling. Recent segmentation foundation models have improved generalization through large-scale pretraining, yet remain poorly aligned with pathology because they treat segmentation as a static visual prediction task. Here we present VISTA-PATH, an interactive, class-aware pathology segmentation foundation model designed to resolve heterogeneous structures, incorporate expert feedback, and produce pixel-level segmentation that are directly meaningful for clinical interpretation. VISTA-PATH jointly conditions segmentation on visual context, semantic tissue descriptions, and optional expert-provided spatial prompts, enabling precise multi-class segmentation across heterogeneous pathology images. To support this paradigm, we curate VISTA-PATH Data, a large-scale pathology segmentation corpus comprising over 1.6 million image-mask-text triplets spanning 9 organs and 93 tissue classes. Across extensive held-out and external benchmarks, VISTA-PATH consistently outperforms existing segmentation foundation models. Importantly, VISTA-PATH supports dynamic human-in-the-loop refinement by propagating sparse, patch-level bounding-box annotation feedback into whole-slide segmentation. Finally, we show that the high-fidelity, class-aware segmentation produced by VISTA-PATH is a preferred model for computational pathology. It improve tissue microenvironment analysis through proposed Tumor Interaction Score (TIS), which exhibits strong and significant associations with patient survival. Together, these results establish VISTA-PATH as a foundation model that elevates pathology image segmentation from a static prediction to an interactive and clinically grounded representation for digital pathology. Source code and demo can be found at https://github.com/zhihuanglab/VISTA-PATH.",
    "translation": "标题：VISTA-PATH：一种用于计算病理学中病理图像分割与定量分析的交互式基础模型\n\n摘要：组织病理学图像的精确语义分割对于定量组织分析和下游临床建模至关重要。现有的分割基础模型通过大规模预训练提升了泛化能力，但由于将分割视为静态视觉预测任务，仍难以与病理学需求充分契合。本文提出VISTA-PATH——一种交互式、类别感知的病理分割基础模型，旨在解析异质性组织结构、整合专家反馈，并生成对临床解读具有直接意义的像素级分割结果。该模型通过联合建模视觉上下文、语义组织描述及可选的专家空间提示来实现分割条件化，从而在异质性病理图像中实现精确的多类别分割。为支撑此范式，我们构建了VISTA-PATH数据集，这是一个包含超过160万个图像-掩码-文本三元组的大规模病理分割语料库，涵盖9个器官和93种组织类别。在大量留出测试集和外部基准数据上的实验表明，VISTA-PATH持续优于现有分割基础模型。值得注意的是，该模型支持动态人机协同优化，能够将稀疏的局部边界框标注反馈传播至全玻片分割。最后，我们证明VISTA-PATH生成的高保真、类别感知分割是计算病理学的优选模型：通过提出的肿瘤相互作用评分（TIS）改进组织微环境分析，该评分与患者生存期呈现显著强相关性。综上，这些成果确立了VISTA-PATH作为基础模型的地位，将病理图像分割从静态预测提升为数字病理学中具有交互性和临床依据的表征方法。源代码与演示可通过https://github.com/zhihuanglab/VISTA-PATH获取。",
    "url": "https://huggingface.co/papers/2601.16451",
    "arxiv_url": "https://arxiv.org/abs/2601.16451"
  },
  {
    "title": "Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind",
    "summary": "Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.",
    "translation": "标题：镣铐之舞：基于心智理论的学术反驳策略性说服研究\n\n摘要：尽管人工智能已深度融入研究流程的各个阶段并取得显著进展，学术反驳仍是一个重要且尚未充分探索的挑战。这是因为反驳是在严重信息不对称条件下进行的策略性沟通过程，而非简单的技术辩论。现有方法大多仅模仿表层语言特征，未能把握有效说服所需的核心要素——观点采择能力，因而难以应对这一挑战。本文提出首个基于心智理论的学术反驳框架RebuttalAgent，通过构建\"心智状态建模-策略制定-策略响应生成\"的三阶段流程，将心智理论操作化为可执行的推理机制。为训练该智能体，我们采用新型批判优化方法构建了大规模数据集RebuttalBench。训练过程包含两个阶段：首先通过监督微调使智能体掌握基于心智理论的分析与策略规划能力，随后利用自奖励机制进行强化学习以实现可扩展的自我优化。为建立可靠高效的自动化评估体系，我们进一步开发了专用评估器Rebuttal-RM，该模型基于超过10万条多源反驳数据进行训练，其评分结果与人类偏好的一致性已超越GPT-4.1等强大评估模型。大量实验表明：RebuttalAgent在自动化指标上平均优于基线模型18.3%，同时在自动化评估与人工评估中均超越先进的专有模型。免责声明：生成的反驳内容仅供作者参考启发与辅助草拟，不可替代作者自身的批判性分析与回应。",
    "url": "https://huggingface.co/papers/2601.15715",
    "arxiv_url": "https://arxiv.org/abs/2601.15715"
  },
  {
    "title": "Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization",
    "summary": "Large Language Models (LLMs) are nowadays extensively used for various types of software engineering tasks, primarily code generation. Previous research has shown how suitable prompt engineering could help developers in improving their code generation prompts. However, so far, there do not exist specific guidelines driving developers towards writing suitable prompts for code generation. In this work, we derive and evaluate development-specific prompt optimization guidelines. First, we use an iterative, test-driven approach to automatically refine code generation prompts, and we analyze the outcome of this process to identify prompt improvement items that lead to test passes. We use such elements to elicit 10 guidelines for prompt improvement, related to better specifying I/O, pre-post conditions, providing examples, various types of details, or clarifying ambiguities. We conduct an assessment with 50 practitioners, who report their usage of the elicited prompt improvement patterns, as well as their perceived usefulness, which does not always correspond to the actual usage before knowing our guidelines. Our results lead to implications not only for practitioners and educators, but also for those aimed at creating better LLM-aided software development tools.",
    "translation": "标题：面向代码生成的大语言模型提示指南：一项实证特征研究\n\n摘要：大语言模型（LLMs）当前已广泛应用于各类软件工程任务，其中代码生成是主要应用场景。先前研究表明，恰当的提示工程能够帮助开发者优化代码生成提示。然而，目前尚未形成指导开发者编写有效代码生成提示的专门性指南。本研究提出并评估了一套面向开发场景的提示优化指南。首先，我们采用迭代式、测试驱动的方法自动优化代码生成提示，并通过分析优化过程的结果，识别出能够通过测试的提示改进要素。基于这些要素，我们归纳出10项提示改进指南，涉及输入输出规范、前后置条件说明、示例提供、多维度细节补充以及模糊性澄清等方面。我们邀请了50名从业者进行评估，参与者反馈了他们对所归纳提示改进模式的使用情况及其感知有效性——结果显示，在了解本指南前，实际使用模式与感知有效性并不完全一致。本研究结果不仅对从业者和教育者具有实践意义，也为开发更高效的LLM辅助软件开发工具提供了参考。\n\n请按照以下格式返回：\n标题：面向代码生成的大语言模型提示指南：一项实证特征研究\n摘要：大语言模型（LLMs）当前已广泛应用于各类软件工程任务，其中代码生成是主要应用场景。先前研究表明，恰当的提示工程能够帮助开发者优化代码生成提示。然而，目前尚未形成指导开发者编写有效代码生成提示的专门性指南。本研究提出并评估了一套面向开发场景的提示优化指南。首先，我们采用迭代式、测试驱动的方法自动优化代码生成提示，并通过分析优化过程的结果，识别出能够通过测试的提示改进要素。基于这些要素，我们归纳出10项提示改进指南，涉及输入输出规范、前后置条件说明、示例提供、多维度细节补充以及模糊性澄清等方面。我们邀请了50名从业者进行评估，参与者反馈了他们对所归纳提示改进模式的使用情况及其感知有效性——结果显示，在了解本指南前，实际使用模式与感知有效性并不完全一致。本研究结果不仅对从业者和教育者具有实践意义，也为开发更高效的LLM辅助软件开发工具提供了参考。",
    "url": "https://huggingface.co/papers/2601.13118",
    "arxiv_url": "https://arxiv.org/abs/2601.13118"
  }
]