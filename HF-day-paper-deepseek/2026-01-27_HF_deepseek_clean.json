[
  {
    "title": "Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs",
    "summary": "Data preparation aims to denoise raw datasets, uncover cross-dataset relationships, and extract valuable insights from them, which is essential for a wide range of data-centric applications. Driven by (i) rising demands for application-ready data (e.g., for analytics, visualization, decision-making), (ii) increasingly powerful LLM techniques, and (iii) the emergence of infrastructures that facilitate flexible agent construction (e.g., using Databricks Unity Catalog), LLM-enhanced methods are rapidly becoming a transformative and potentially dominant paradigm for data preparation.\n  By investigating hundreds of recent literature works, this paper presents a systematic review of this evolving landscape, focusing on the use of LLM techniques to prepare data for diverse downstream tasks. First, we characterize the fundamental paradigm shift, from rule-based, model-specific pipelines to prompt-driven, context-aware, and agentic preparation workflows. Next, we introduce a task-centric taxonomy that organizes the field into three major tasks: data cleaning (e.g., standardization, error processing, imputation), data integration (e.g., entity matching, schema matching), and data enrichment (e.g., data annotation, profiling). For each task, we survey representative techniques, and highlight their respective strengths (e.g., improved generalization, semantic understanding) and limitations (e.g., the prohibitive cost of scaling LLMs, persistent hallucinations even in advanced agents, the mismatch between advanced methods and weak evaluation). Moreover, we analyze commonly used datasets and evaluation metrics (the empirical part). Finally, we discuss open research challenges and outline a forward-looking roadmap that emphasizes scalable LLM-data systems, principled designs for reliable agentic workflows, and robust evaluation protocols.",
    "translation": "标题：大语言模型能否清理数据乱局？基于LLM的应用就绪型数据准备技术综述\n\n摘要：数据准备旨在对原始数据集进行去噪、揭示跨数据集关联并从中提取有价值的洞见，这对各类以数据为中心的应用至关重要。在（1）对应用就绪型数据（如用于分析、可视化、决策）的需求日益增长，（2）大语言模型技术能力持续增强，以及（3）支持灵活智能体构建的基础设施（如基于Databricks Unity Catalog）兴起的共同驱动下，基于大语言模型增强的数据准备方法正迅速成为一种变革性且可能占据主导地位的新范式。本文通过系统调研数百篇近期文献，对这一快速发展领域进行了系统性综述，重点关注利用大语言模型技术为多样化下游任务准备数据的方法。首先，我们阐述了该领域从基于规则、模型特定的流水线，向提示驱动、上下文感知且具备自主能力的智能体工作流这一根本性范式转变。接着，我们提出了一个以任务为中心的分类框架，将相关研究归纳为三大核心任务：数据清洗（如标准化、错误处理、缺失值填补）、数据集成（如实体匹配、模式匹配）与数据增强（如数据标注、画像分析）。针对每类任务，我们综述了代表性技术，并着重分析了其优势（如泛化能力提升、语义理解增强）与局限（如大语言模型规模化应用成本高昂、先进智能体中仍存在的幻觉问题、前沿方法与薄弱评估体系间的脱节）。此外，我们系统梳理了常用数据集与评估指标（实证研究部分）。最后，我们探讨了当前开放的研究挑战，并展望了未来发展方向，重点包括可扩展的大语言模型-数据系统、可靠智能体工作流的原则性设计以及鲁棒的评估体系构建。",
    "url": "https://huggingface.co/papers/2601.17058",
    "arxiv_url": "https://arxiv.org/abs/2601.17058"
  },
  {
    "title": "daVinci-Dev: Agent-native Mid-training for Software Engineering",
    "summary": "Recently, the frontier of Large Language Model (LLM) capabilities has shifted from single-turn code generation to agentic software engineering-a paradigm where models autonomously navigate, edit, and test complex repositories. While post-training methods have become the de facto approach for code agents, **agentic mid-training**-mid-training (MT) on large-scale data that mirrors authentic agentic workflows-remains critically underexplored due to substantial resource requirements, despite offering a more scalable path to instilling foundational agentic behaviors than relying solely on expensive reinforcement learning. A central challenge in realizing effective agentic mid-training is the distribution mismatch between static training data and the dynamic, feedback-rich environment of real development. To address this, we present a systematic study of agentic mid-training, establishing both the data synthesis principles and training methodology for effective agent development at scale. Central to our approach is **agent-native data**-supervision comprising two complementary types of trajectories: **contextually-native trajectories** that preserve the complete information flow an agent experiences, offering broad coverage and diversity; and **environmentally-native trajectories** collected from executable repositories where observations stem from actual tool invocations and test executions, providing depth and interaction authenticity. We verify the model's agentic capabilities on `SWE-Bench Verified`. We demonstrate our superiority over the previous open software engineering mid-training recipe `Kimi-Dev` under two post-training settings with an aligned base model and agentic scaffold, while using less than half mid-training tokens (73.1B). Besides relative advantage, our best performing 32B and 72B models achieve **56.1%** and **58.5%** resolution rates, respectively, which are ...",
    "translation": "标题：daVinci-Dev：面向软件工程的智能体原生中期训练\n\n摘要：近期，大语言模型（LLM）能力的前沿已从单轮代码生成转向智能体式软件工程——一种模型能够自主导航、编辑和测试复杂代码仓库的范式。尽管后训练方法已成为代码智能体的事实标准，但**智能体中期训练**——即在大规模数据上进行模拟真实智能体工作流程的中期训练（MT）——尽管比单纯依赖昂贵的强化学习提供了更具可扩展性的路径来培养基础智能体行为，但由于巨大的资源需求，其探索仍严重不足。实现有效智能体中期训练的一个核心挑战在于静态训练数据与真实开发中动态、富含反馈的环境之间的分布不匹配。为解决这一问题，我们提出了对智能体中期训练的系统性研究，建立了大规模有效智能体开发的数据合成原则与训练方法。我们方法的核心是**智能体原生数据**——包含两种互补类型轨迹的监督数据：**上下文原生轨迹**，其保留了智能体所经历的完整信息流，提供了广泛的覆盖面和多样性；以及**环境原生轨迹**，这些轨迹从可执行仓库中收集，其观测源于实际的工具调用和测试执行，提供了深度和交互真实性。我们在 `SWE-Bench Verified` 上验证了模型的智能体能力。在使用相同的基础模型和智能体框架的两种后训练设置下，我们证明了我们的方法优于先前开源的软件工程中期训练方案 `Kimi-Dev`，同时使用了不到一半的中期训练词元（73.1B）。除了相对优势外，我们表现最佳的 32B 和 72B 模型分别实现了 **56.1%** 和 **58.5%** 的问题解决率，这……",
    "url": "https://huggingface.co/papers/2601.18418",
    "arxiv_url": "https://arxiv.org/abs/2601.18418"
  },
  {
    "title": "The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation",
    "summary": "Recent advances in video generation have produced models capable of synthesizing stunning visual content from simple text prompts. However, these models struggle to generate long-form, coherent narratives from high-level concepts like dialogue, revealing a ``semantic gap'' between a creative idea and its cinematic execution. To bridge this gap, we introduce a novel, end-to-end agentic framework for dialogue-to-cinematic-video generation. Central to our framework is ScripterAgent, a model trained to translate coarse dialogue into a fine-grained, executable cinematic script. To enable this, we construct ScriptBench, a new large-scale benchmark with rich multimodal context, annotated via an expert-guided pipeline. The generated script then guides DirectorAgent, which orchestrates state-of-the-art video models using a cross-scene continuous generation strategy to ensure long-horizon coherence. Our comprehensive evaluation, featuring an AI-powered CriticAgent and a new Visual-Script Alignment (VSA) metric, shows our framework significantly improves script faithfulness and temporal fidelity across all tested video models. Furthermore, our analysis uncovers a crucial trade-off in current SOTA models between visual spectacle and strict script adherence, providing valuable insights for the future of automated filmmaking.",
    "translation": "标题：剧本即所需：面向长时域对话到电影视频生成的智能体框架\n\n摘要：近期视频生成技术的进展已能根据简单文本提示合成令人惊叹的视觉内容。然而，这些模型在从对话等高层次概念生成长篇幅、连贯叙事时仍面临挑战，暴露出创意构想与电影化呈现之间的“语义鸿沟”。为弥合这一鸿沟，我们提出了一种新颖的端到端智能体框架，用于实现从对话到电影视频的生成。该框架的核心是剧本生成智能体——一个经过训练、能够将粗略对话转化为细粒度可执行电影剧本的模型。为此，我们构建了ScriptBench——一个通过专家指导流程标注、包含丰富多模态上下文的大规模新基准。生成的剧本随后指导导演智能体，该智能体采用跨场景连续生成策略协调最先进的视频模型，以确保长时域连贯性。我们通过配备AI驱动的评论智能体和新的视觉-剧本对齐指标开展综合评估，结果表明该框架显著提升了所有测试视频模型的剧本忠实度与时间连贯性。此外，我们的分析揭示了当前最先进模型在视觉表现力与严格剧本遵循之间存在关键权衡，这为自动化电影制作的未来发展提供了重要启示。",
    "url": "https://huggingface.co/papers/2601.17737",
    "arxiv_url": "https://arxiv.org/abs/2601.17737"
  },
  {
    "title": "Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility",
    "summary": "While synthetic data has proven effective for improving scientific reasoning in the text domain, multimodal reasoning remains constrained by the difficulty of synthesizing scientifically rigorous images. Existing Text-to-Image (T2I) models often produce outputs that are visually plausible yet scientifically incorrect, resulting in a persistent visual-logic divergence that limits their value for downstream reasoning. Motivated by recent advances in next-generation T2I models, we conduct a systematic study of scientific image synthesis across generation paradigms, evaluation, and downstream use. We analyze both direct pixel-based generation and programmatic synthesis, and propose ImgCoder, a logic-driven framework that follows an explicit \"understand - plan - code\" workflow to improve structural precision. To rigorously assess scientific correctness, we introduce SciGenBench, which evaluates generated images based on information utility and logical validity. Our evaluation reveals systematic failure modes in pixel-based models and highlights a fundamental expressiveness-precision trade-off. Finally, we show that fine-tuning Large Multimodal Models (LMMs) on rigorously verified synthetic scientific images yields consistent reasoning gains, with potential scaling trends analogous to the text domain, validating high-fidelity scientific synthesis as a viable path to unlocking massive multimodal reasoning capabilities.",
    "translation": "标题：科学图像合成：基准测试、方法论与下游应用价值\n\n摘要：尽管合成数据在提升文本领域科学推理能力方面已被证明有效，但多模态推理仍受限于生成科学严谨图像的困难。现有文本到图像（T2I）模型常生成视觉合理但科学错误的输出，导致持续的视觉-逻辑偏差，限制其在下游推理中的价值。基于新一代T2I模型的最新进展，我们对科学图像合成的生成范式、评估方法与下游应用展开系统性研究。我们分析了基于像素的直接生成与程序化合成两种路径，并提出ImgCoder——一个遵循显式“理解-规划-编码”工作流程的逻辑驱动框架，以提升结构精度。为严格评估科学正确性，我们构建了SciGenBench评估基准，从信息效用与逻辑有效性两个维度对生成图像进行量化评估。实验揭示了像素级模型的系统性缺陷，并指出表达能力与精度之间存在根本性权衡。最后，我们证明基于严格验证的合成科学图像对大型多模态模型（LMMs）进行微调，能持续提升其推理性能，其扩展潜力与文本域呈现相似规律，这验证了高保真科学图像合成可作为释放海量多模态推理能力的可行路径。",
    "url": "https://huggingface.co/papers/2601.17027",
    "arxiv_url": "https://arxiv.org/abs/2601.17027"
  },
  {
    "title": "Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers",
    "summary": "The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.",
    "translation": "标题：弹性注意力：面向高效Transformer的测试时自适应稀疏化比率\n\n摘要：标准注意力机制的二次复杂度在长上下文场景下对大型语言模型的可扩展性构成了显著瓶颈。虽然将稀疏注意力与全注意力结合的混合注意力策略提供了可行的解决方案，但这些方法通常采用静态计算比率（即稀疏注意力与全注意力的固定比例），无法在推理阶段适应下游任务对稀疏性敏感度的动态变化。为解决这一问题，我们提出弹性注意力机制，使模型能够根据输入动态调整整体稀疏度。该方法通过在现有预训练模型中集成轻量级注意力路由器来实现，该路由器能够动态地将每个注意力头分配到不同的计算模式。仅需在8张A800 GPU上进行12小时训练，我们的方法即可使模型同时实现强大的性能与高效的推理。在多个主流大型语言模型上进行的三个长上下文基准测试实验证明了本方法的优越性。",
    "url": "https://huggingface.co/papers/2601.17367",
    "arxiv_url": "https://arxiv.org/abs/2601.17367"
  },
  {
    "title": "iFSQ: Improving FSQ for Image Generation with 1 Line of Code",
    "summary": "The field of image generation is currently bifurcated into autoregressive (AR) models operating on discrete tokens and diffusion models utilizing continuous latents. This divide, rooted in the distinction between VQ-VAEs and VAEs, hinders unified modeling and fair benchmarking. Finite Scalar Quantization (FSQ) offers a theoretical bridge, yet vanilla FSQ suffers from a critical flaw: its equal-interval quantization can cause activation collapse. This mismatch forces a trade-off between reconstruction fidelity and information efficiency. In this work, we resolve this dilemma by simply replacing the activation function in original FSQ with a distribution-matching mapping to enforce a uniform prior. Termed iFSQ, this simple strategy requires just one line of code yet mathematically guarantees both optimal bin utilization and reconstruction precision. Leveraging iFSQ as a controlled benchmark, we uncover two key insights: (1) The optimal equilibrium between discrete and continuous representations lies at approximately 4 bits per dimension. (2) Under identical reconstruction constraints, AR models exhibit rapid initial convergence, whereas diffusion models achieve a superior performance ceiling, suggesting that strict sequential ordering may limit the upper bounds of generation quality. Finally, we extend our analysis by adapting Representation Alignment (REPA) to AR models, yielding LlamaGen-REPA. Codes is available at https://github.com/Tencent-Hunyuan/iFSQ",
    "translation": "标题：iFSQ：一行代码改进FSQ以提升图像生成性能\n\n摘要：当前图像生成领域主要分为基于离散标记的自回归模型和利用连续隐变量的扩散模型。这一分野源于VQ-VAE与VAE的根本差异，阻碍了统一建模与公平基准评估。有限标量量化（FSQ）理论提供了桥梁，但原始FSQ存在关键缺陷：其等间隔量化机制可能导致激活崩溃。这种不匹配迫使模型在重建保真度与信息效率之间进行权衡。本研究通过将原始FSQ中的激活函数替换为分布匹配映射以强制均匀先验，从而解决了这一困境。该方法被命名为iFSQ，仅需一行代码即可在数学上同时保证最优的量化区间利用率和重建精度。基于iFSQ构建的受控基准实验揭示了两个关键发现：（1）离散与连续表示之间的最优平衡点约为每维度4比特；（2）在相同重建约束下，自回归模型表现出快速的初始收敛性，而扩散模型则能达到更优的性能上限，这表明严格的序列排序可能限制生成质量的理论边界。最后，我们通过将表示对齐方法（REPA）适配至自回归模型扩展了分析框架，构建出LlamaGen-REPA模型。代码已开源：https://github.com/Tencent-Hunyuan/iFSQ",
    "url": "https://huggingface.co/papers/2601.17124",
    "arxiv_url": "https://arxiv.org/abs/2601.17124"
  },
  {
    "title": "Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability",
    "summary": "Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.",
    "translation": "标题：模型自教自学：在可学习性边缘的推理探索\n\n摘要：模型能否学会突破自身的学习瓶颈？针对大型推理模型的强化学习微调方法在初始成功率较低的数据集上容易陷入停滞，导致训练信号匮乏。本研究探讨一个根本性问题：预训练大语言模型能否利用潜在知识为自身无法解决的问题生成自动化课程？为此，我们设计了SOAR框架：一种通过元强化学习挖掘教学信号的自改进系统。该框架中，教师模型副本为学生模型副本生成合成问题，并根据学生在少量难题子集上的进步获得奖励。SOAR的关键创新在于将课程生成机制锚定于可量化的学生进步，而非依赖内在代理奖励。我们在数学基准测试中最困难的子集（初始成功率0/128）上进行实验，得出三项核心发现：首先，通过激发预训练模型生成有效阶梯问题的潜在能力，可以实现双层元强化学习，从而在稀疏二元奖励条件下开启学习进程；其次，基于实际进步的奖励机制优于先前大语言模型自我对弈中采用的内在奖励方案，能可靠避免后者常见的不稳定性和多样性崩溃问题；最后，对生成问题的分析表明，问题的结构质量与明确性比解答正确性对学习进展更为关键。这些发现表明，生成有效阶梯问题的能力并不以预先具备解决难题的能力为前提，这为无需额外标注数据即可突破推理瓶颈提供了理论可行的路径。",
    "url": "https://huggingface.co/papers/2601.18778",
    "arxiv_url": "https://arxiv.org/abs/2601.18778"
  },
  {
    "title": "Self-Refining Video Sampling",
    "summary": "Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\\% human preference compared to the default sampler and guidance-based sampler.",
    "translation": "标题：自优化视频采样方法\n\n摘要：现代视频生成模型在处理复杂物理动态时仍面临挑战，往往难以实现真实的物理效果。现有方法通常依赖外部验证器或通过增强数据额外训练来解决该问题，这些方法计算成本高昂且在捕捉细粒度运动方面仍存在局限。本研究提出自优化视频采样方法，该简单方法利用在大规模数据集上预训练的视频生成器作为自身的优化器。通过将生成器解释为去噪自编码器，我们能够在推理阶段实现无需外部验证器或额外训练的迭代式内部循环优化。进一步提出基于不确定性的优化策略，该方法依据自一致性原理选择性地优化特定区域，从而避免因过度优化产生的伪影。在先进视频生成模型上的实验表明，该方法在运动连贯性与物理对齐方面取得显著提升，相较于默认采样器及基于引导的采样器，获得超过70%的人类偏好评价。",
    "url": "https://huggingface.co/papers/2601.18577",
    "arxiv_url": "https://arxiv.org/abs/2601.18577"
  },
  {
    "title": "VIBEVOICE-ASR Technical Report",
    "summary": "This report presents VibeVoice-ASR, a general-purpose speech understanding framework built upon VibeVoice, designed to address the persistent challenges of context fragmentation and multi-speaker complexity in long-form audio (e.g., meetings, podcasts) that remain despite recent advancements in short-form speech recognition. Unlike traditional pipelined approaches that rely on audio chunking, VibeVoice-ASRsupports single-pass processing for up to 60 minutes of audio. It unifies Automatic Speech Recognition, Speaker Diarization, and Timestamping into a single end-to-end generation task. In addition, VibeVoice-ASR supports over 50 languages, requires no explicit language setting, and natively handles code-switching within and across utterances. Furthermore, we introduce a prompt-based context injection mechanism that allows users to supply customized conetxt, significantly improving accuracy on domain-specific terminology and polyphonic character disambiguation.",
    "translation": "标题：VIBEVOICE-ASR技术报告\n\n摘要：本报告介绍了VibeVoice-ASR，这是一个基于VibeVoice构建的通用语音理解框架，旨在解决长音频（如会议、播客）中尽管短语音识别技术近期有所进展，但仍持续存在的语境碎片化和多说话人复杂性挑战。与依赖音频分块的传统流水线方法不同，VibeVoice-ASR支持对长达60分钟的音频进行单次处理。它将自动语音识别、说话人日志和时间戳标注统一为单一的端到端生成任务。此外，VibeVoice-ASR支持超过50种语言，无需显式语言设置，并能原生处理语句内及跨语句的语码转换。进一步地，我们引入了一种基于提示的语境注入机制，允许用户提供定制化语境，从而显著提升领域专有术语的识别准确性和多音字消歧能力。",
    "url": "https://huggingface.co/papers/2601.18184",
    "arxiv_url": "https://arxiv.org/abs/2601.18184"
  },
  {
    "title": "DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints",
    "summary": "While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.",
    "translation": "标题：DeepPlanning：具有可验证约束的长程智能体规划基准测试\n\n摘要：尽管智能体评估已转向长程任务，但现有基准仍侧重于局部、步骤层面的推理，而非需要真正规划能力的全局约束优化（如时间和预算限制）。同时，当前基于大语言模型的规划基准未能充分体现现实场景中典型的信息主动获取与细粒度局部约束特性。为此，我们提出DeepPlanning——一个面向实际长程智能体规划的挑战性基准。该基准包含多日旅行规划与多商品购物任务，要求智能体具备主动信息获取、局部约束推理及全局约束优化能力。在DeepPlanning上的评估表明，即使是前沿的智能体大语言模型也难以有效处理此类问题，这凸显了可靠的显式推理模式与并行工具使用对于实现更优效果-效率权衡的重要性。错误分析进一步指出了改进长程规划场景下智能体大语言模型的发展方向。我们已开源相关代码与数据以支持后续研究。",
    "url": "https://huggingface.co/papers/2601.18137",
    "arxiv_url": "https://arxiv.org/abs/2601.18137"
  },
  {
    "title": "CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval",
    "summary": "General-purpose embedding models have demonstrated strong performance in text retrieval but remain suboptimal for table retrieval, where highly structured content leads to semantic compression and query-table mismatch. Recent LLM-based retrieval augmentation methods mitigate this issue by generating synthetic queries, yet they often rely on heuristic partial-table selection and seldom leverage these synthetic queries as supervision to improve the embedding model. We introduce CGPT, a training framework that enhances table retrieval through LLM-generated supervision. CGPT constructs semantically diverse partial tables by clustering table instances using K-means and sampling across clusters to broaden semantic coverage. An LLM then generates synthetic queries for these partial tables, which are used in hard-negative contrastive fine-tuning to refine the embedding model. Experiments across four public benchmarks (MimoTable, OTTQA, FetaQA, and E2E-WTQ) show that CGPT consistently outperforms retrieval baselines, including QGpT, with an average R@1 improvement of 16.54 percent. In a unified multi-domain corpus setting, CGPT further demonstrates strong cross-domain generalization and remains effective even when using smaller LLMs for synthetic query generation. These results indicate that semantically guided partial-table construction, combined with contrastive training from LLM-generated supervision, provides an effective and scalable paradigm for large-scale table retrieval. Our code is available at https://github.com/yumeow0122/CGPT.",
    "translation": "标题：CGPT：基于大语言模型生成监督的聚类引导局部表格检索方法\n\n摘要：通用嵌入模型在文本检索任务中表现出色，但在表格检索场景中仍存在不足，这主要源于高度结构化的内容导致的语义压缩及查询-表格匹配偏差。近期基于大语言模型的检索增强方法通过生成合成查询缓解了这一问题，但这些方法通常依赖启发式的局部表格选择策略，且很少利用合成查询作为监督信号来优化嵌入模型。本文提出CGPT训练框架，通过大语言模型生成的监督信号提升表格检索性能。CGPT首先采用K-means算法对表格实例进行聚类，并通过跨聚类采样构建语义多样化的局部表格集合以拓展语义覆盖范围。随后利用大语言模型为这些局部表格生成合成查询，并基于困难负例对比学习策略对嵌入模型进行微调。在四个公开基准数据集（MimoTable、OTTQA、FetaQA和E2E-WTQ）上的实验表明，CGPT在检索性能上持续优于包括QGpT在内的基线方法，平均R@1指标提升16.54%。在统一多领域语料场景中，CGPT展现出强大的跨领域泛化能力，即使采用较小规模的大语言模型生成合成查询仍保持有效性。这些结果表明：语义引导的局部表格构建策略，结合基于大语言模型生成监督的对比训练，为大规模表格检索提供了高效可扩展的解决方案。代码已开源：https://github.com/yumeow0122/CGPT。",
    "url": "https://huggingface.co/papers/2601.15849",
    "arxiv_url": "https://arxiv.org/abs/2601.15849"
  },
  {
    "title": "STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion",
    "summary": "Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging. Recent methods such as QGpT attempt to enrich table semantics by generating synthetic queries, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query-table alignment. We propose STAR (Semantic Table Representation), a lightweight framework that improves semantic table representation through semantic clustering and weighted fusion. STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table. It then generates cluster-specific synthetic queries to comprehensively cover the table's semantic space. Finally, STAR employs weighted fusion strategies to integrate table and query embeddings, enabling fine-grained semantic alignment. This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations. Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on all datasets, demonstrating the effectiveness of semantic clustering and adaptive weighted fusion for robust table representation. Our code is available at https://github.com/adsl135789/STAR.",
    "translation": "标题：STAR：基于表头感知聚类与自适应加权融合的语义表格表示方法\n\n摘要：表格检索任务旨在根据自然语言查询从大规模语料库中检索最相关的表格。然而，非结构化文本与结构化表格之间的结构与语义差异使得嵌入对齐尤为困难。现有方法如QGpT尝试通过生成合成查询来丰富表格语义，但仍依赖于粗糙的部分表格采样和简单的融合策略，限制了语义多样性并阻碍有效的查询-表格对齐。本文提出STAR（语义表格表示）这一轻量级框架，通过语义聚类与加权融合改进语义表格表示。STAR首先应用表头感知K-means聚类对语义相似的行进行分组，并选取具有代表性的质心实例以构建多样化的部分表格；随后生成针对特定聚类的合成查询，全面覆盖表格的语义空间；最后采用加权融合策略整合表格与查询嵌入，实现细粒度的语义对齐。该设计使STAR能够从结构化与文本化数据源中捕捉互补信息，提升表格表示的表达能力。在五个基准数据集上的实验表明，STAR在所有数据集上的召回率均持续优于QGpT，验证了语义聚类与自适应加权融合对构建鲁棒表格表示的有效性。代码已开源：https://github.com/adsl135789/STAR。",
    "url": "https://huggingface.co/papers/2601.15860",
    "arxiv_url": "https://arxiv.org/abs/2601.15860"
  },
  {
    "title": "Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents",
    "summary": "Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.",
    "translation": "标题：降低泛化税：面向大语言模型智能体的强化学习训练跨域泛化研究\n\n摘要：通用型大语言模型智能体通常在有限环境集合中进行后训练，却需部署至更广泛且未知的领域。本研究针对测试领域未知情境下的智能体后训练挑战展开探讨，重点分析强化学习环境特性与建模选择如何影响跨域性能。首先，我们识别出与跨域泛化能力密切相关的两个环境维度：（一）状态信息丰富度，即智能体需从状态中处理的信息量；（二）规划复杂度，通过基础策略下的目标可达性与轨迹长度进行估算。值得注意的是，领域真实性与文本层面相似性并非主要影响因素；例如，简单的网格世界推箱子游戏在SciWorld中产生的泛化效果甚至优于更接近现实的ALFWorld领域。基于这些发现，我们进一步证明仅提升状态信息丰富度即可有效增强跨域鲁棒性。为此我们提出一种低开销、普适性强的随机化技术：在状态中添加少量与目标无关的干扰特征以增强信息密度，同时保持任务本质不变。除环境特性外，我们还检验了多项建模选择的影响：（a）监督微调预热或中期训练虽能防止强化学习过程中的灾难性遗忘，但会削弱对未包含在中期训练数据混合域中的泛化能力；（b）在强化学习中启用逐步推理机制虽不总能提升域内性能，但对保持泛化能力具有关键作用。",
    "url": "https://huggingface.co/papers/2601.18217",
    "arxiv_url": "https://arxiv.org/abs/2601.18217"
  },
  {
    "title": "AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation",
    "summary": "Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of \"Omni\" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.",
    "translation": "标题：AR-Omni：面向任意模态生成任务的统一自回归模型\n\n摘要：现实世界的感知与交互本质上是多模态的，不仅涉及语言，还包括视觉与语音，这推动了支持多模态输入与输出的“全能型”多模态大语言模型的发展。尽管一系列全能型多模态大语言模型已相继出现，但现有系统大多仍依赖额外的专家组件来实现多模态生成，限制了统一训练与推理的简洁性。自回归建模凭借单一令牌流、单一下一令牌预测目标以及单一解码器，在文本领域是一种优雅且可扩展的基础范式。受此启发，我们提出了AR-Omni——一种在自回归范式下无需任何专家解码器的统一任意模态生成模型。AR-Omni支持自回归文本与图像生成，以及流式语音生成，所有功能均通过单一Transformer解码器实现。我们进一步解决了统一自回归建模中的三个实际问题：通过任务感知的损失重加权应对模态不平衡问题；通过针对图像令牌的轻量级令牌级感知对齐损失提升视觉保真度；通过有限状态解码机制权衡生成稳定性与创造性。实验表明，AR-Omni在三种模态上均实现了高质量的生成效果，同时保持实时性，其语音生成的实时因子达到0.88。",
    "url": "https://huggingface.co/papers/2601.17761",
    "arxiv_url": "https://arxiv.org/abs/2601.17761"
  },
  {
    "title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models",
    "summary": "Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.",
    "translation": "标题：TSRBench：面向通用模型的多任务多模态时间序列推理综合基准\n\n摘要：时间序列数据在现实场景中无处不在，对从能源管理到交通控制等关键应用至关重要。因此，对时间序列进行推理的能力是通用模型解决实际问题的基本技能。然而，现有通用模型基准中明显缺乏对这一维度的评估。为填补这一空白，我们提出了TSRBench——一个全面的多模态基准，旨在全面测试时间序列推理能力。TSRBench具有以下特点：i) 涵盖14个领域的4125个多样化问题，并划分为感知、推理、预测和决策四大维度；ii) 包含四大维度下的15项任务，用于评估核心推理能力（如数值推理）。通过大量实验，我们在TSRBench中评估了30余个领先的专有及开源大语言模型、视觉语言模型和时间序列大语言模型。研究发现：i) 缩放定律在感知与推理任务中成立，但在预测任务中失效；ii) 强大的推理能力不能保证准确的上下文感知预测，表明语义理解与数值预测之间存在脱钩；iii) 尽管文本和视觉形式的时间序列输入具有互补性，当前多模态模型仍未能有效融合两者以实现性能协同提升。TSRBench提供了一个标准化评估平台，不仅揭示了现有挑战，更为推进通用模型发展提供了宝贵见解。代码与数据集已发布于https://tsrbench.github.io/。",
    "url": "https://huggingface.co/papers/2601.18744",
    "arxiv_url": "https://arxiv.org/abs/2601.18744"
  },
  {
    "title": "SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback",
    "summary": "Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.",
    "translation": "标题：SAGE：基于执行反馈的可控智能数据生成框架及其在深度搜索中的应用\n\n摘要：深度搜索智能体旨在回答需要跨多文档推理的复杂问题，能够显著加速信息检索过程。由于探索路径长且复杂，为此类应用收集人工标注的成本极高。本文提出一种智能生成流程，能够针对给定语料库和目标难度级别，自动生成高质量且难度可控的深度搜索问答对。我们的SAGE框架包含两个核心组件：数据生成器负责提出候选问答对，搜索智能体则尝试解答生成的问题并向数据生成器提供执行反馈。两个组件通过多轮交互迭代优化问答对，直至其满足目标难度要求。内在评估表明，SAGE生成的问题需要多样化的推理策略，同时显著提升了生成数据的准确性与难度。外在评估显示，使用本方法生成的合成数据训练深度搜索智能体，在主流深度搜索基准测试中可获得最高23%的相对性能提升。补充实验进一步证明，基于本数据训练的智能体能够在推理阶段从固定语料库检索无缝切换至谷歌搜索，且无需额外训练。",
    "url": "https://huggingface.co/papers/2601.18202",
    "arxiv_url": "https://arxiv.org/abs/2601.18202"
  },
  {
    "title": "Agentic Very Long Video Understanding",
    "summary": "The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks.",
    "translation": "标题：具身智能的超长视频理解\n\n摘要：随着智能眼镜等全天候可穿戴设备推动始终在线个人AI助手的发展，对情境理解提出了更高要求——需要超越短暂孤立事件，涵盖连续、纵向的第一人称视频流。实现这一愿景需在长时域视频理解领域取得突破，要求系统能够解读并回溯跨越数日甚至数周的视觉与听觉信息。现有方法（包括大语言模型与检索增强生成技术）受限于有限的上下文窗口，且缺乏对超长视频流进行组合式多跳推理的能力。本研究通过EGAgent框架应对这些挑战：该增强型具身智能框架以实体场景图为核心，动态表征人物、地点、物体及其随时间演变的关系。系统为规划智能体配备结构化图搜索推理工具及混合视听检索能力，实现精细化、跨模态、时序连贯的推理。在EgoLifeQA和Video-MME（Long）数据集上的实验表明，本方法在复杂纵向视频理解任务中取得突破性成果：EgoLifeQA准确率达57.5%（当前最优），Video-MME（Long）达74.1%（具备竞争优势）。",
    "url": "https://huggingface.co/papers/2601.18157",
    "arxiv_url": "https://arxiv.org/abs/2601.18157"
  },
  {
    "title": "DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal",
    "summary": "Despite the growing adoption of large language models (LLMs) in scientific research workflows, automated support for academic rebuttal, a crucial step in academic communication and peer review, remains largely underexplored. Existing approaches typically rely on off-the-shelf LLMs or simple pipelines, which struggle with long-context understanding and often fail to produce targeted and persuasive responses. In this paper, we propose DRPG, an agentic framework for automatic academic rebuttal generation that operates through four steps: Decompose reviews into atomic concerns, Retrieve relevant evidence from the paper, Plan rebuttal strategies, and Generate responses accordingly. Notably, the Planner in DRPG reaches over 98% accuracy in identifying the most feasible rebuttal direction. Experiments on data from top-tier conferences demonstrate that DRPG significantly outperforms existing rebuttal pipelines and achieves performance beyond the average human level using only an 8B model. Our analysis further demonstrates the effectiveness of the planner design and its value in providing multi-perspective and explainable suggestions. We also showed that DRPG works well in a more complex multi-round setting. These results highlight the effectiveness of DRPG and its potential to provide high-quality rebuttal content and support the scaling of academic discussions. Codes for this work are available at https://github.com/ulab-uiuc/DRPG-RebuttalAgent.",
    "translation": "标题：DRPG（分解、检索、规划、生成）：一种用于学术反驳的智能体框架\n\n摘要：尽管大语言模型在科学研究流程中的应用日益广泛，但针对学术交流与同行评审中关键环节——学术反驳的自动化支持仍鲜有探索。现有方法通常依赖于现成的大语言模型或简单流水线，这些方法在长上下文理解方面存在不足，且往往难以生成具有针对性、说服力的回应。本文提出DRPG框架，该框架通过四个步骤实现自动化学术反驳生成：将审稿意见分解为原子化问题、从论文中检索相关证据、规划反驳策略，并据此生成回应。值得注意的是，DRPG中的规划器在识别最可行反驳方向时准确率超过98%。基于顶级会议数据的实验表明，DRPG显著优于现有反驳生成流程，仅使用80亿参数模型即可达到超越人类平均水平的性能。进一步分析验证了规划器设计的有效性及其在提供多视角、可解释建议方面的价值。实验还证明DRPG在更复杂的多轮交互场景中表现良好。这些结果凸显了DRPG框架在生成高质量反驳内容、支持学术讨论规模化拓展方面的潜力。本工作的代码已公开于：https://github.com/ulab-uiuc/DRPG-RebuttalAgent。",
    "url": "https://huggingface.co/papers/2601.18081",
    "arxiv_url": "https://arxiv.org/abs/2601.18081"
  },
  {
    "title": "IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance",
    "summary": "Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA",
    "translation": "标题：IVRA：基于无训练提示引导的视觉-标记关系优化以提升机器人动作策略\n\n摘要：多数视觉-语言-动作模型将图像块展平为一维标记序列，削弱了精确操作所需的二维空间线索。本文提出IVRA，一种轻量级、无需训练的方法，通过利用模型内置视觉编码器中已有的关联性提示来增强空间理解能力，无需任何外部编码器或重新训练。IVRA选择性地将这些关联信号注入到包含实例级特征的语言模型层中。这种推理阶段的干预能够重新校准视觉-标记的交互关系，在保持所有模型参数固定的同时更好地保留几何结构。我们通过在多种VLA架构（LLaRA、OpenVLA和FLOWER）上应用IVRA，跨越涵盖二维与三维操作的仿真基准测试（VIMA和LIBERO）及多种真实机器人任务，验证了其普适性。在二维VIMA任务中，IVRA在低数据场景下较基线LLaRA平均成功率提升4.2%；在三维LIBERO任务中，对OpenVLA和FLOWER基线模型均带来稳定增益，即使在基线准确率接近饱和时仍能实现提升（从96.3%至97.1%）。所有代码与模型将公开发布，可视化结果请访问：jongwoopark7978.github.io/IVRA",
    "url": "https://huggingface.co/papers/2601.16207",
    "arxiv_url": "https://arxiv.org/abs/2601.16207"
  },
  {
    "title": "End-to-End Joint ASR and Speaker Role Diarization with Child-Adult Interactions",
    "summary": "Accurate transcription and speaker diarization of child-adult spoken interactions are crucial for developmental and clinical research. However, manual annotation is time-consuming and challenging to scale. Existing automated systems typically rely on cascaded speaker diarization and speech recognition pipelines, which can lead to error propagation. This paper presents a unified end-to-end framework that extends the Whisper encoder-decoder architecture to jointly model ASR and child-adult speaker role diarization. The proposed approach integrates: (i) a serialized output training scheme that emits speaker tags and start/end timestamps, (ii) a lightweight frame-level diarization head that enhances speaker-discriminative encoder representations, (iii) diarization-guided silence suppression for improved temporal precision, and (iv) a state-machine-based forced decoding procedure that guarantees structurally valid outputs. Comprehensive evaluations on two datasets demonstrate consistent and substantial improvements over two cascaded baselines, achieving lower multi-talker word error rates and demonstrating competitive diarization accuracy across both Whisper-small and Whisper-large models. These findings highlight the effectiveness and practical utility of the proposed joint modeling framework for generating reliable, speaker-attributed transcripts of child-adult interactions at scale. The code and model weights are publicly available",
    "translation": "标题：儿童-成人互动场景下的端到端联合语音识别与说话人角色分离\n\n摘要：儿童与成人言语互动的准确转写与说话人分离对发展心理学及临床研究至关重要。然而人工标注耗时且难以规模化。现有自动化系统通常采用级联式说话人分离与语音识别流程，易导致误差传递。本文提出一种统一的端到端框架，通过扩展Whisper编码器-解码器架构，实现对语音识别与儿童-成人说话人角色分离的联合建模。该方案整合了以下关键技术：(1) 采用序列化输出训练机制生成说话人标签及起止时间戳；(2) 设计轻量级帧级分离头以增强编码器的说话人区分表征能力；(3) 引入基于分离结果的静音抑制策略以提升时间边界精度；(4) 构建基于状态机的强制解码流程确保输出结构有效性。在两个数据集上的综合评估表明，相比两种级联基线方法，本框架在Whisper-small和Whisper-large模型上均取得稳定且显著的性能提升，实现了更低的多说话人词错误率，并在说话人分离准确率方面展现竞争优势。这些发现证明了所提出的联合建模框架在大规模生成儿童-成人互动的可靠说话人归属转录文本方面的有效性与实用价值。代码及模型权重已公开。",
    "url": "https://huggingface.co/papers/2601.17640",
    "arxiv_url": "https://arxiv.org/abs/2601.17640"
  },
  {
    "title": "SkyReels-V3 Technique Report",
    "summary": "Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized.\n  Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.",
    "translation": "标题：SkyReels-V3 技术报告\n\n摘要：视频生成是构建世界模型的关键基础，其中多模态上下文推理能力是衡量模型性能的核心标准。为此，我们提出了 SkyReels-V3——一个基于扩散 Transformer 统一多模态上下文学习框架的条件视频生成模型。该模型在单一架构中支持三种核心生成范式：参考图像到视频合成、视频到视频扩展以及音频引导视频生成。（1）参考图像到视频模型旨在生成具有强主体身份保持性、时间连贯性与叙事一致性的高保真视频。为增强参考遵循能力与构图稳定性，我们设计了包含跨帧配对、图像编辑与语义重写的综合数据处理流程，有效缓解了复制粘贴伪影问题。训练过程中采用图像-视频混合策略并结合多分辨率联合优化，以提升模型在不同场景下的泛化能力与鲁棒性。（2）视频扩展模型将时空一致性建模与大规模视频理解相结合，既能实现无缝的单镜头延续，也能基于专业影视模式进行智能的多镜头切换。（3）数字人模型通过训练首尾帧插值模式并重构关键帧推理范式，支持分钟级音频条件视频生成，在保障视觉质量的同时优化了音视频同步效果。大量实验评估表明，SkyReels-V3 在视觉质量、指令跟随及特定维度指标等关键度量上达到或接近最优性能，已接近领先的闭源系统水平。项目地址：https://github.com/SkyworkAI/SkyReels-V3。",
    "url": "https://huggingface.co/papers/2601.17323",
    "arxiv_url": "https://arxiv.org/abs/2601.17323"
  },
  {
    "title": "Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts",
    "summary": "Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.",
    "translation": "标题：最小负载专家并行：一种面向不平衡专家混合模型的负载均衡方法\n\n摘要：专家混合模型通常在预训练阶段采用显式负载均衡约束，以确保专家路由在统计上的平衡性。然而我们发现，即使是训练良好的专家混合模型仍会表现出显著的路由不平衡现象。这种行为具有内在合理性——甚至可被视为一种优势——因为不平衡路由能使模型将领域特定知识集中于部分专家内部。专家并行技术旨在通过将专家分布至多个设备来实现专家混合模型的扩展，但其设计隐含了路由平衡的前提假设。在极端不平衡场景下，专家并行可能将不成比例的令牌集中路由至少数专家，导致训练后阶段或推理过程中过载设备出现计算与内存边界失效，而此时显式负载均衡往往难以实施。本文提出最小负载专家并行算法，该创新性专家并行算法能动态地将过载设备上的超额令牌及相关专家参数重路由至利用率不足的设备。该方法在满足内存约束的前提下，确保所有设备在最小集体延迟内完成计算负载。在不同规模模型实验中，相较于标准专家并行技术，最小负载专家并行可实现最高5倍加速比及4倍峰值内存使用降低，其中gpt-oss-120b模型推理速度提升约1.9倍。我们通过系统的理论分析与全面的实证评估（包括消融实验）验证了该方法，揭示了关键性能权衡关系，并建立了面向特定硬件的超参数调优原则框架，为实现最优性能提供理论支撑。",
    "url": "https://huggingface.co/papers/2601.17111",
    "arxiv_url": "https://arxiv.org/abs/2601.17111"
  },
  {
    "title": "One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment",
    "summary": "Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.",
    "translation": "标题：以一适万：基于元奖励建模的个性化大语言模型对齐方法\n\n摘要：大语言模型的对齐旨在使模型输出符合人类偏好，而个性化对齐则进一步使模型适应个体用户需求。这依赖于能够捕捉用户特定偏好并自动提供个性化反馈的奖励模型。然而，开发此类模型面临两大关键挑战：个体用户反馈数据稀缺，以及模型需高效适应未知用户。我们认为，解决这些约束需要实现从“拟合数据以学习用户偏好”到“学习偏好适应过程”的范式转变。为此，我们提出元奖励建模方法，将个性化奖励建模重构为元学习问题。具体而言，我们将每位用户的奖励模型表示为若干基础奖励函数的加权组合，并采用模型无关元学习框架优化这些权重的初始化状态，以支持在有限反馈下的快速适应。为确保鲁棒性，我们引入了鲁棒个性化目标，该目标在元优化过程中更加强调难以学习的用户样本。在个性化偏好数据集上的大量实验表明，该方法能够有效提升少样本个性化性能，增强用户鲁棒性，并持续优于基线模型。",
    "url": "https://huggingface.co/papers/2601.18731",
    "arxiv_url": "https://arxiv.org/abs/2601.18731"
  },
  {
    "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks",
    "summary": "Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.",
    "translation": "标题：云珏智能体技术报告：面向开放任务的完全可复现、零启动原位自进化智能体系统\n\n摘要：传统智能体系统在任务分布持续漂移且外部监督稀缺的开放环境中往往表现不佳。其对静态工具集或离线训练的依赖难以适应动态变化，导致系统能力边界僵化且不可预知。为此，我们提出原位自进化范式。该方法将序列化任务交互视为持续的经验流，使系统能够在缺乏真实标签的情况下，将短期执行反馈提炼为长期可复用的能力。在此框架中，我们将工具进化界定为能力扩展的关键路径，其可提供可验证的二元反馈信号。基于此，我们开发了云珏智能体系统，通过迭代合成、优化和复用工具以应对新兴挑战。为提升进化效率，我们进一步提出并行批量进化策略。在零启动设置下对五个多样化基准任务的实证评估表明，该系统相较于专有基线模型取得显著性能提升。补充性热启动实验进一步验证，系统积累的通用知识可无缝迁移至新领域。最后，我们提出一种监测进化收敛的新指标，其功能类似于传统优化中的训练损失函数。我们已开源代码库、系统轨迹及进化工具，以促进鲁棒性自进化智能研究的后续发展。",
    "url": "https://huggingface.co/papers/2601.18226",
    "arxiv_url": "https://arxiv.org/abs/2601.18226"
  },
  {
    "title": "Masked Depth Modeling for Spatial Perception",
    "summary": "Spatial visual perception is a fundamental requirement in physical-world applications like autonomous driving and robotic manipulation, driven by the need to interact with 3D environments. Capturing pixel-aligned metric depth using RGB-D cameras would be the most viable way, yet it usually faces obstacles posed by hardware limitations and challenging imaging conditions, especially in the presence of specular or texture-less surfaces. In this work, we argue that the inaccuracies from depth sensors can be viewed as \"masked\" signals that inherently reflect underlying geometric ambiguities. Building on this motivation, we present LingBot-Depth, a depth completion model which leverages visual context to refine depth maps through masked depth modeling and incorporates an automated data curation pipeline for scalable training. It is encouraging to see that our model outperforms top-tier RGB-D cameras in terms of both depth precision and pixel coverage. Experimental results on a range of downstream tasks further suggest that LingBot-Depth offers an aligned latent representation across RGB and depth modalities. We release the code, checkpoint, and 3M RGB-depth pairs (including 2M real data and 1M simulated data) to the community of spatial perception.",
    "translation": "标题：基于掩码深度建模的空间感知方法\n\n摘要：在自动驾驶与机器人操控等物理世界应用中，与三维环境交互的需求使得空间视觉感知成为基础性任务。使用RGB-D相机获取像素级对齐的度量深度是最可行的途径，但该方法常受硬件限制与复杂成像条件的制约，尤其在镜面反射或无纹理表面区域更为突出。本研究提出，深度传感器的测量误差可视为反映几何模糊性的\"掩码\"信号。基于此观点，我们提出LingBot-Depth深度补全模型：该模型通过掩码深度建模机制利用视觉上下文优化深度图，并集成自动化数据筛选流程以实现可扩展训练。实验表明，该模型在深度精度与像素覆盖率方面均优于顶级RGB-D相机。多组下游任务实验结果进一步证实，LingBot-Depth能够构建RGB与深度模态间的对齐隐式表征。我们已向空间感知研究社区开源代码、模型检查点及300万组RGB-深度配对数据（含200万真实数据与100万仿真数据）。\n\n请按照以下格式返回：\n标题：基于掩码深度建模的空间感知方法\n摘要：在自动驾驶与机器人操控等物理世界应用中，与三维环境交互的需求使得空间视觉感知成为基础性任务。使用RGB-D相机获取像素级对齐的度量深度是最可行的途径，但该方法常受硬件限制与复杂成像条件的制约，尤其在镜面反射或无纹理表面区域更为突出。本研究提出，深度传感器的测量误差可视为反映几何模糊性的\"掩码\"信号。基于此观点，我们提出LingBot-Depth深度补全模型：该模型通过掩码深度建模机制利用视觉上下文优化深度图，并集成自动化数据筛选流程以实现可扩展训练。实验表明，该模型在深度精度与像素覆盖率方面均优于顶级RGB-D相机。多组下游任务实验结果进一步证实，LingBot-Depth能够构建RGB与深度模态间的对齐隐式表征。我们已向空间感知研究社区开源代码、模型检查点及300万组RGB-深度配对数据（含200万真实数据与100万仿真数据）。",
    "url": "https://huggingface.co/papers/2601.17895",
    "arxiv_url": "https://arxiv.org/abs/2601.17895"
  },
  {
    "title": "A Mechanistic View on Video Generation as World Models: State and Dynamics",
    "summary": "Large-scale video generation models have demonstrated emergent physical coherence, positioning them as potential world models. However, a gap remains between contemporary \"stateless\" video architectures and classic state-centric world model theories. This work bridges this gap by proposing a novel taxonomy centered on two pillars: State Construction and Dynamics Modeling. We categorize state construction into implicit paradigms (context management) and explicit paradigms (latent compression), while dynamics modeling is analyzed through knowledge integration and architectural reformulation. Furthermore, we advocate for a transition in evaluation from visual fidelity to functional benchmarks, testing physical persistence and causal reasoning. We conclude by identifying two critical frontiers: enhancing persistence via data-driven memory and compressed fidelity, and advancing causality through latent factor decoupling and reasoning-prior integration. By addressing these challenges, the field can evolve from generating visually plausible videos to building robust, general-purpose world simulators.",
    "translation": "标题：视频生成作为世界模型的机制视角：状态与动力学\n\n摘要：大规模视频生成模型已展现出涌现的物理一致性，使其成为潜在的世界模型。然而，当前“无状态”的视频架构与经典以状态为中心的世界模型理论之间仍存在差距。本研究通过提出一种以两大支柱为核心的新分类法来弥合这一差距：状态构建与动力学建模。我们将状态构建分为隐式范式（上下文管理）和显式范式（潜在压缩），而动力学建模则通过知识整合与架构重构进行分析。此外，我们主张评估标准应从视觉保真度转向功能基准，以测试物理持久性与因果推理能力。最后，我们指出两个关键前沿方向：通过数据驱动记忆与压缩保真度增强持久性，以及通过潜在因子解耦与推理先验整合推进因果建模。通过应对这些挑战，该领域可从生成视觉合理的视频，发展为构建鲁棒、通用的世界模拟器。",
    "url": "https://huggingface.co/papers/2601.17067",
    "arxiv_url": "https://arxiv.org/abs/2601.17067"
  },
  {
    "title": "Diffusion In Diffusion: Reclaiming Global Coherence in Semi-Autoregressive Diffusion",
    "summary": "One of the most compelling features of global discrete diffusion language models is their global bidirectional contextual capability. However, existing block-based diffusion studies tend to introduce autoregressive priors, which, while offering benefits, can cause models to lose this global coherence at the macro level. To regain global contextual understanding while preserving the advantages of the semi-autoregressive paradigm, we propose Diffusion in Diffusion, a 'draft-then-refine' framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilize snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using only 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.",
    "translation": "标题：扩散中的扩散：在半自回归扩散模型中重获全局连贯性\n\n摘要：全局离散扩散语言模型最引人注目的特征之一是其全局双向上下文建模能力。然而，现有的基于分块的扩散研究往往引入自回归先验，这虽然能带来一定优势，却可能导致模型在宏观层面丧失全局连贯性。为了在保留半自回归范式优点的同时重获全局上下文理解能力，我们提出“扩散中的扩散”——一种“先草拟后精修”的框架，旨在克服分块扩散模型固有的不可逆性与短视问题。该方法首先通过小分块扩散快速生成草稿，随后利用具有更大双向感受野的全局双向扩散对这些草稿进行精细化处理。我们采用快照置信度重掩码技术识别需要修改的关键词元，并应用混合尺度训练来扩展分块扩散模型的全局能力。实验结果表明，我们的方法在OpenWebText数据集上为离散扩散模型设立了新的性能基准。仅使用基线模型26%的微调计算量，我们便将生成困惑度从25.7降至21.9，显著缩小了与自回归模型的性能差距。",
    "url": "https://huggingface.co/papers/2601.13599",
    "arxiv_url": "https://arxiv.org/abs/2601.13599"
  },
  {
    "title": "UI Remix: Supporting UI Design Through Interactive Example Retrieval and Remixing",
    "summary": "Designing user interfaces (UIs) is a critical step when launching products, building portfolios, or personalizing projects, yet end users without design expertise often struggle to articulate their intent and to trust design choices. Existing example-based tools either promote broad exploration, which can cause overwhelm and design drift, or require adapting a single example, risking design fixation. We present UI Remix, an interactive system that supports mobile UI design through an example-driven design workflow. Powered by a multimodal retrieval-augmented generation (MMRAG) model, UI Remix enables iterative search, selection, and adaptation of examples at both the global (whole interface) and local (component) level. To foster trust, it presents source transparency cues such as ratings, download counts, and developer information. In an empirical study with 24 end users, UI Remix significantly improved participants' ability to achieve their design goals, facilitated effective iteration, and encouraged exploration of alternative designs. Participants also reported that source transparency cues enhanced their confidence in adapting examples. Our findings suggest new directions for AI-assisted, example-driven systems that empower end users to design with greater control, trust, and openness to exploration.",
    "translation": "标题：UI Remix：通过交互式示例检索与重组支持用户界面设计\n\n摘要：用户界面（UI）设计是推出产品、构建作品集或个性化项目时的关键步骤，然而不具备设计专业知识的终端用户常常难以准确表达其设计意图，并对设计选择缺乏信心。现有的基于示例的设计工具要么鼓励广泛探索（这可能导致信息过载和设计偏离），要么要求用户仅基于单一示例进行修改（从而带来设计固化的风险）。本文提出UI Remix，这是一个通过示例驱动设计流程支持移动端UI设计的交互式系统。该系统基于多模态检索增强生成（MMRAG）模型，支持在整体界面层面和局部组件层面进行迭代式的示例搜索、选择与适配。为增强用户信任，系统提供了来源透明度提示，如评分、下载量和开发者信息等。一项针对24名终端用户的实证研究表明，UI Remix显著提升了参与者实现设计目标的能力，促进了有效迭代，并鼓励了对替代设计的探索。参与者还反馈，来源透明度提示增强了他们在适配示例时的信心。我们的研究结果为人工智能辅助的示例驱动系统指明了新方向，这类系统能够赋能终端用户，使其在设计过程中拥有更强的控制力、更高的信任度以及更开放的探索心态。",
    "url": "https://huggingface.co/papers/2601.18759",
    "arxiv_url": "https://arxiv.org/abs/2601.18759"
  },
  {
    "title": "PingPong: A Natural Benchmark for Multi-Turn Code-Switching Dialogues",
    "summary": "Code-switching is a widespread practice among the world's multilingual majority, yet few benchmarks accurately reflect its complexity in everyday communication. We present PingPong, a benchmark for natural multi-party code-switching dialogues covering five language-combination variations, some of which are trilingual. Our dataset consists of human-authored conversations among 2 to 4 participants covering authentic, multi-threaded structures where replies frequently reference much earlier points in the dialogue. We demonstrate that our data is significantly more natural and structurally diverse than machine-generated alternatives, offering greater variation in message length, speaker dominance, and reply distance. Based on these dialogues, we define three downstream tasks: Question Answering, Dialogue Summarization, and Topic Classification. Evaluations of several state-of-the-art language models on PingPong reveal that performance remains limited on code-switched inputs, underscoring the urgent need for more robust NLP systems capable of addressing the intricacies of real-world multilingual discourse.",
    "translation": "标题：PingPong：多轮语码转换对话的自然基准数据集\n\n摘要：语码转换是全球多语使用者的普遍现象，但现有基准数据集难以准确反映其在日常交流中的复杂性。本文提出PingPong——一个涵盖五种语言组合变体（部分为三语混合）的自然多方言码转换对话基准数据集。该数据集包含2至4位参与者的人工撰写对话，呈现真实的多线程对话结构，其中应答常指向对话中较早的发言节点。实验证明，相较于机器生成数据，本数据在自然度与结构多样性方面显著提升，在消息长度、说话者主导度及应答距离等维度呈现更丰富的变异特征。基于该对话数据集，我们定义了三个下游任务：问答系统、对话摘要和主题分类。通过对多个前沿语言模型在PingPong上的评估发现，现有模型对语码转换输入的处理能力仍存在局限，这凸显了开发能够应对现实世界多语交际复杂性的鲁棒性自然语言处理系统的迫切需求。",
    "url": "https://huggingface.co/papers/2601.17277",
    "arxiv_url": "https://arxiv.org/abs/2601.17277"
  },
  {
    "title": "Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control",
    "summary": "Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym.",
    "translation": "标题：面向大规模流动控制强化学习算法的即插即用基准测试框架\n\n摘要：强化学习在主动流动控制领域已展现出良好前景，但该领域进展仍难以评估，因为现有研究依赖于异构的观测与执行方案、数值设置及评估标准。当前流动控制基准测试尝试解决这些问题，但严重依赖外部计算流体力学求解器，不具备完全可微性，且对三维与多智能体场景支持有限。为突破这些局限，我们提出了首个独立、完全可微的主动流动控制强化学习基准测试套件FluidGym。该套件完全基于PyTorch构建于GPU加速的PICT求解器之上，在单一Python栈中运行，无需外部计算流体力学软件，并提供标准化评估流程。我们展示了基于PPO与SAC算法的基线实验结果，并将所有仿真环境、数据集及训练模型作为公共资源发布。FluidGym实现了控制方法的系统化比较，为未来基于学习的流动控制研究建立了可扩展的基础平台，项目地址为https://github.com/safe-autonomous-systems/fluidgym。",
    "url": "https://huggingface.co/papers/2601.15015",
    "arxiv_url": "https://arxiv.org/abs/2601.15015"
  },
  {
    "title": "The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning",
    "summary": "As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.",
    "translation": "标题：智能的副作用：多模态大语言模型在多图像推理中的安全风险\n\n摘要：随着多模态大语言模型（MLLMs）在处理复杂多图像指令方面获得更强的推理能力，这一进步可能带来新的安全风险。我们通过引入首个专注于多图像推理安全的基准测试MIR-SafetyBench来研究此问题，该基准包含涵盖9种多图像关系分类的2,676个测试实例。我们对19个MLLMs进行的广泛评估揭示了一个令人担忧的趋势：具备更先进多图像推理能力的模型在MIR-SafetyBench上可能更加脆弱。除了攻击成功率之外，我们发现许多被标记为安全的回应是表面化的，通常源于误解或回避性的、不置可否的答复。我们进一步观察到，不安全的生成内容平均表现出比安全内容更低的注意力熵。这一内部特征表明，模型可能过度专注于任务解决而忽视安全约束，存在潜在风险。我们的代码和数据可在https://github.com/thu-coai/MIR-SafetyBench获取。",
    "url": "https://huggingface.co/papers/2601.14127",
    "arxiv_url": "https://arxiv.org/abs/2601.14127"
  },
  {
    "title": "Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models",
    "summary": "Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off.",
    "translation": "标题：少即是多——直至崩溃：大视觉语言模型中视觉令牌压缩的安全隐患\n\n摘要：视觉令牌压缩技术被广泛采用以提升大视觉语言模型（LVLMs）的推理效率，使其能够部署在对延迟敏感和资源受限的场景中。然而，现有研究主要关注效率与性能，而视觉令牌压缩的安全影响在很大程度上尚未得到探索。本研究首次揭示，视觉令牌压缩会显著降低LVLMs的鲁棒性：在未压缩推理下表现稳健的模型，一旦启用压缩便会变得高度脆弱。这些漏洞具有状态特异性：失效模式仅在压缩设置下出现，并在禁用压缩时完全消失，使其尤其隐蔽且难以诊断。通过分析压缩过程的关键阶段，我们发现令牌重要性排序的不稳定性是导致鲁棒性下降的主要原因。微小且难以察觉的扰动可显著改变令牌排序，导致压缩机制错误地丢弃任务关键信息，最终引发模型失效。基于这一观察，我们提出一种压缩感知攻击方法，以系统性地研究和利用此漏洞。该方法直接针对令牌选择机制，并仅在压缩推理下诱发失效。我们进一步将此方法扩展到更现实的黑盒设置中，提出迁移压缩感知攻击，其中既无法访问目标模型，也无法获取压缩配置信息。我们还评估了潜在的防御措施，发现其仅能提供有限保护。跨模型、数据集和压缩方法的广泛实验表明，视觉令牌压缩显著削弱了模型鲁棒性，揭示了一个先前被忽视的效率与安全之间的权衡关系。",
    "url": "https://huggingface.co/papers/2601.12042",
    "arxiv_url": "https://arxiv.org/abs/2601.12042"
  },
  {
    "title": "MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts",
    "summary": "Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a \"tunnel vision\" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.",
    "translation": "标题：MortalMATH：评估推理目标与紧急情境之间的冲突\n\n摘要：大型语言模型正日益针对深度推理进行优化，将复杂任务的正确执行置于一般性对话之上。我们研究这种对计算能力的关注是否会造成一种“隧道视野”，即在危急情况下忽视安全性。我们提出了MortalMATH基准测试，包含150个场景，其中用户在描述日益危及生命的紧急情况（例如中风症状、自由落体）的同时请求代数帮助。我们发现了一个显著的行为分化：通用模型（如Llama-3.1）能够成功拒绝数学问题以应对危险。相比之下，专用推理模型（如Qwen-3-32b和GPT-5-nano）常常完全忽略紧急情况，在用户描述濒死状态时仍保持超过95%的任务完成率。此外，推理所需的计算时间会引入危险的延迟：在提供任何潜在帮助之前，延迟可能长达15秒。这些结果表明，训练模型不懈追求正确答案，可能会无意中使其丧失安全部署所需的生存本能。",
    "url": "https://huggingface.co/papers/2601.18790",
    "arxiv_url": "https://arxiv.org/abs/2601.18790"
  },
  {
    "title": "HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs",
    "summary": "The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.",
    "translation": "标题：HalluGuard：解析大语言模型中数据驱动与推理驱动幻觉的机制\n\n摘要：大语言模型在医疗、法律及科学发现等高风险领域中的可靠性常因幻觉问题而受到损害。此类错误通常源于两个层面：数据驱动幻觉与推理驱动幻觉。然而，现有检测方法往往仅针对单一来源，且依赖特定任务的启发式规则，限制了其在复杂场景中的泛化能力。为突破这些局限，本文提出“幻觉风险边界”理论框架，将幻觉风险形式化分解为数据驱动与推理驱动两个组成部分，分别对应训练阶段的数据失配与推理阶段的不稳定性，从而为分析幻觉产生与演化机制提供理论依据。基于此框架，我们提出HalluGuard方法——一种基于神经正切核的量化指标，通过利用神经正切核诱导的几何结构及其捕获的表征，实现对数据驱动与推理驱动幻觉的联合检测。我们在10个多样化基准测试集、11个竞争性基线模型及9个主流大语言模型架构上对HalluGuard进行评估，结果表明该方法在检测多形态大语言模型幻觉任务中持续取得最先进的性能表现。",
    "url": "https://huggingface.co/papers/2601.18753",
    "arxiv_url": "https://arxiv.org/abs/2601.18753"
  },
  {
    "title": "RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents",
    "summary": "Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.",
    "translation": "标题：RouteMoA：无需预推理的动态路由提升高效智能体混合框架性能\n\n摘要：智能体混合（MoA）通过分层协作提升大语言模型性能，但其密集拓扑结构会显著增加计算成本与响应延迟。现有方法通常采用大语言模型作为评判器来筛选响应，但仍需所有模型在评判前完成推理，无法有效降低成本。这些方法缺乏明确的模型选择标准，且在处理大规模模型池时面临挑战——完整推理成本高昂，并可能超出上下文长度限制。为此，我们提出RouteMoA，一种融合动态路由机制的高效智能体混合框架。该框架采用轻量级评分器，通过查询内容预测粗粒度性能表现以进行初步筛选，无需执行推理即可将候选模型缩减为高潜力子集。随后，由混合评判器基于现有模型输出，通过轻量级的自评估与交叉评估机制细化评分，实现无需额外推理的后验校正。最后，模型排序机制通过平衡性能、成本与延迟三项指标完成模型选择。实验表明，RouteMoA在不同任务与模型池规模下均优于传统MoA方法，在大规模模型池中可实现89.8%的成本降低与63.6%的延迟缩减。",
    "url": "https://huggingface.co/papers/2601.18130",
    "arxiv_url": "https://arxiv.org/abs/2601.18130"
  },
  {
    "title": "TensorLens: End-to-End Transformer Analysis via High-Order Attention Tensors",
    "summary": "Attention matrices are fundamental to transformer research, supporting a broad range of applications including interpretability, visualization, manipulation, and distillation. Yet, most existing analyses focus on individual attention heads or layers, failing to account for the model's global behavior. While prior efforts have extended attention formulations across multiple heads via averaging and matrix multiplications or incorporated components such as normalization and FFNs, a unified and complete representation that encapsulates all transformer blocks is still lacking. We address this gap by introducing TensorLens, a novel formulation that captures the entire transformer as a single, input-dependent linear operator expressed through a high-order attention-interaction tensor. This tensor jointly encodes attention, FFNs, activations, normalizations, and residual connections, offering a theoretically coherent and expressive linear representation of the model's computation. TensorLens is theoretically grounded and our empirical validation shows that it yields richer representations than previous attention-aggregation methods. Our experiments demonstrate that the attention tensor can serve as a powerful foundation for developing tools aimed at interpretability and model understanding. Our code is attached as a supplementary.",
    "translation": "标题：TensorLens：基于高阶注意力张量的端到端Transformer分析\n\n摘要：注意力矩阵是Transformer研究的核心基础，支撑着包括可解释性、可视化、操控与蒸馏在内的广泛应用。然而，现有分析大多聚焦于单个注意力头或单层结构，未能充分反映模型的全局行为。尽管先前研究已通过平均化、矩阵乘法等方式将注意力计算扩展至多头场景，或纳入归一化、前馈网络等组件，但仍缺乏一个能够完整封装所有Transformer模块的统一表征框架。为此，我们提出TensorLens——一种创新性建模方法，将整个Transformer表征为通过高阶注意力交互张量表达的、依赖输入的单一线性算子。该张量联合编码了注意力机制、前馈网络、激活函数、归一化操作与残差连接，从理论上提供了连贯且富有表现力的模型计算线性表征。TensorLens具备坚实的理论基础，实证研究表明其能比现有注意力聚合方法生成更丰富的表征。实验进一步证明，注意力张量可作为开发可解释性与模型理解工具的强大基础。相关代码已作为补充材料附上。",
    "url": "https://huggingface.co/papers/2601.17958",
    "arxiv_url": "https://arxiv.org/abs/2601.17958"
  },
  {
    "title": "Fast KVzip: Efficient and Accurate LLM Inference with Gated KV Eviction",
    "summary": "Efficient key-value (KV) cache management is crucial for the practical deployment of large language models (LLMs), yet existing compression techniques often incur a trade-off between performance degradation and computational overhead. We propose a novel gating-based KV cache eviction method for frozen-weight LLMs that achieves high compression ratios with negligible computational cost. Our approach introduces lightweight sink-attention gating modules to identify and retain critical KV pairs, and integrates seamlessly into both the prefill and decoding stages. The proposed gate training algorithm relies on forward passes of an LLM, avoiding expensive backpropagation, while achieving strong task generalization through a task-agnostic reconstruction objective. Extensive experiments across the Qwen2.5-1M, Qwen3, and Gemma3 families show that our method maintains near-lossless performance while evicting up to 70% of the KV cache. The results are consistent across a wide range of tasks, including long-context understanding, code comprehension, and mathematical reasoning, demonstrating the generality of our approach.",
    "translation": "标题：Fast KVzip：基于门控KV淘汰机制的高效准确大语言模型推理\n\n摘要：高效的键值（KV）缓存管理对于大语言模型的实际部署至关重要，然而现有压缩技术往往需要在性能损失与计算开销之间进行权衡。本文针对冻结权重的大语言模型，提出一种新颖的基于门控机制的KV缓存淘汰方法，该方法能以可忽略的计算成本实现高压缩比。我们的方法引入轻量化的汇聚注意力门控模块来识别并保留关键KV对，并能无缝集成至预填充和解码阶段。所提出的门控训练算法仅依赖大语言模型的前向传播过程，避免了昂贵的反向传播计算，同时通过任务无关的重建目标实现了强大的任务泛化能力。在Qwen2.5-1M、Qwen3和Gemma3系列模型上的大量实验表明，本方法在淘汰高达70% KV缓存的同时仍能保持近乎无损的性能表现。该结果在长文本理解、代码解析和数学推理等多样化任务中均保持一致性，充分证明了本方法的普适性。",
    "url": "https://huggingface.co/papers/2601.17668",
    "arxiv_url": "https://arxiv.org/abs/2601.17668"
  },
  {
    "title": "Agentic Search in the Wild: Intents and Trajectory Dynamics from 14M+ Real Search Requests",
    "summary": "LLM-powered search agents are increasingly being used for multi-step information seeking tasks, yet the IR community lacks empirical understanding of how agentic search sessions unfold and how retrieved evidence is used. This paper presents a large-scale log analysis of agentic search based on 14.44M search requests (3.97M sessions) collected from DeepResearchGym, i.e. an open-source search API accessed by external agentic clients. We sessionize the logs, assign session-level intents and step-wise query-reformulation labels using LLM-based annotation, and propose Context-driven Term Adoption Rate (CTAR) to quantify whether newly introduced query terms are traceable to previously retrieved evidence. Our analyses reveal distinctive behavioral patterns. First, over 90% of multi-turn sessions contain at most ten steps, and 89% of inter-step intervals fall under one minute. Second, behavior varies by intent. Fact-seeking sessions exhibit high repetition that increases over time, while sessions requiring reasoning sustain broader exploration. Third, agents reuse evidence across steps. On average, 54% of newly introduced query terms appear in the accumulated evidence context, with contributions from earlier steps beyond the most recent retrieval. The findings suggest that agentic search may benefit from repetition-aware early stopping, intent-adaptive retrieval budgets, and explicit cross-step context tracking. We plan to release the anonymized logs to support future research.",
    "translation": "标题：自主搜索实践：基于1400万+真实搜索请求的意图与轨迹动态分析\n\n摘要：基于大语言模型的自主搜索代理正日益应用于多步骤信息检索任务，然而信息检索领域对其会话展开机制与证据利用方式仍缺乏实证认知。本文通过对DeepResearchGym（一个供外部自主客户端访问的开源搜索API）收集的1444万次搜索请求（397万个会话）进行大规模日志分析，系统探究了自主搜索行为特征。我们通过会话化处理日志数据，采用基于大语言模型的标注方法为会话分配意图标签及分步查询重构标签，并提出上下文驱动术语采纳率指标，以量化新引入查询术语与历史检索证据的关联程度。分析揭示了以下关键行为模式：首先，超过90%的多轮会话步数不超过十步，89%的步骤间间隔在一分钟以内；其次，不同意图会话呈现差异化特征——事实查询类会话重复率较高且随时间递增，而需要推理的会话则保持更广泛的探索性；最后，智能体在跨步骤间存在证据复用现象，平均54%的新增查询术语出现在累积证据上下文中，且早期步骤的贡献超越最近检索结果。这些发现表明，自主搜索系统可能受益于重复感知的早停机制、意图自适应的检索资源分配策略以及显式的跨步骤上下文追踪技术。我们计划公开匿名化日志数据以支持后续研究。",
    "url": "https://huggingface.co/papers/2601.17617",
    "arxiv_url": "https://arxiv.org/abs/2601.17617"
  },
  {
    "title": "C-RADIOv4 (Tech Report)",
    "summary": "By leveraging multi-teacher distillation, agglomerative vision backbones provide a unified student model that retains and improves the distinct capabilities of multiple teachers. In this tech report, we describe the most recent release of the C-RADIO family of models, C-RADIOv4, which builds upon AM-RADIO/RADIOv2.5 in design, offering strong improvements on key downstream tasks at the same computational complexity. We release -SO400M (412M params), and -H (631M) model variants, both trained with an updated set of teachers: SigLIP2, DINOv3, and SAM3. In addition to improvements on core metrics and new capabilities from imitating SAM3, the C-RADIOv4 model family further improves any-resolution support, brings back the ViTDet option for drastically enhanced efficiency at high-resolution, and comes with a permissive license.",
    "translation": "标题：C-RADIOv4（技术报告）\n\n摘要：通过利用多教师蒸馏技术，聚合视觉主干网络提供了一个统一的学生模型，该模型保留并提升了多位教师的独特能力。在本技术报告中，我们介绍了C-RADIO模型系列的最新版本C-RADIOv4，其设计基于AM-RADIO/RADIOv2.5，在相同计算复杂度下显著提升了关键下游任务的性能。我们发布了-SO400M（参数4.12亿）和-H（参数6.31亿）两种模型变体，两者均使用更新的教师模型集合进行训练：SigLIP2、DINOv3和SAM3。除了在核心指标上的改进以及通过模仿SAM3获得的新能力外，C-RADIOv4模型系列进一步增强了任意分辨率支持能力，重新引入了ViTDet选项以大幅提升高分辨率下的处理效率，并采用了宽松的许可协议。",
    "url": "https://huggingface.co/papers/2601.17237",
    "arxiv_url": "https://arxiv.org/abs/2601.17237"
  },
  {
    "title": "Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing",
    "summary": "Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.",
    "translation": "标题：Interp3D：面向生成式纹理三维形变的对应感知插值方法\n\n摘要：纹理三维形变旨在生成两个三维资产之间平滑且合理的过渡，同时保持结构连贯性与细粒度外观。这一能力不仅对推动三维生成研究至关重要，也在动画制作、内容编辑与数字创作等实际应用中具有重要价值。现有方法或直接在几何结构上操作，仅能实现纯形状形变而忽略纹理；或将二维插值策略简单扩展至三维，常导致语义模糊、结构错位与纹理模糊等问题。这些挑战凸显了在过渡过程中需同时保持几何一致性、纹理对齐与鲁棒性的必要性。为此，我们提出Interp3D——一种无需训练的新型纹理三维形变框架。该框架利用生成先验，并采用渐进对齐原则，以确保几何保真度与纹理连贯性。Interp3D首先在条件空间进行语义对齐插值，继而通过结构化隐变量引导的结构插值强化结构一致性，最后通过细粒度纹理融合传递外观细节。为进行全面评估，我们构建了专用数据集Interp3DData，其中包含分级难度样本，并从保真度、过渡平滑性与合理性三个维度对生成结果进行评估。定量指标与人工评估均表明，所提方法较以往方法具有显著优势。源代码公开于：https://github.com/xiaolul2/Interp3D。",
    "url": "https://huggingface.co/papers/2601.14103",
    "arxiv_url": "https://arxiv.org/abs/2601.14103"
  }
]