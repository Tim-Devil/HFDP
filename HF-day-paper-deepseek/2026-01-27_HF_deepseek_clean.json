[
  {
    "title": "Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs",
    "summary": "Data preparation aims to denoise raw datasets, uncover cross-dataset relationships, and extract valuable insights from them, which is essential for a wide range of data-centric applications. Driven by (i) rising demands for application-ready data (e.g., for analytics, visualization, decision-making), (ii) increasingly powerful LLM techniques, and (iii) the emergence of infrastructures that facilitate flexible agent construction (e.g., using Databricks Unity Catalog), LLM-enhanced methods are rapidly becoming a transformative and potentially dominant paradigm for data preparation.\n  By investigating hundreds of recent literature works, this paper presents a systematic review of this evolving landscape, focusing on the use of LLM techniques to prepare data for diverse downstream tasks. First, we characterize the fundamental paradigm shift, from rule-based, model-specific pipelines to prompt-driven, context-aware, and agentic preparation workflows. Next, we introduce a task-centric taxonomy that organizes the field into three major tasks: data cleaning (e.g., standardization, error processing, imputation), data integration (e.g., entity matching, schema matching), and data enrichment (e.g., data annotation, profiling). For each task, we survey representative techniques, and highlight their respective strengths (e.g., improved generalization, semantic understanding) and limitations (e.g., the prohibitive cost of scaling LLMs, persistent hallucinations even in advanced agents, the mismatch between advanced methods and weak evaluation). Moreover, we analyze commonly used datasets and evaluation metrics (the empirical part). Finally, we discuss open research challenges and outline a forward-looking roadmap that emphasizes scalable LLM-data systems, principled designs for reliable agentic workflows, and robust evaluation protocols.",
    "translation": "标题：大语言模型能否清理数据乱局？基于LLM的应用就绪型数据准备技术综述\n\n摘要：数据准备旨在对原始数据集进行去噪处理、揭示跨数据集关联并从中提取有价值的洞见，这对各类以数据为中心的应用至关重要。在三大驱动力推动下——（一）对应用就绪型数据（如用于分析、可视化、决策支持）的需求日益增长，（二）大语言模型技术能力持续增强，（三）支持灵活智能体构建的基础设施兴起（例如基于Databricks Unity Catalog的架构）——基于大语言模型增强的数据准备方法正迅速成为该领域的变革性范式，并可能占据主导地位。\n\n本文通过系统调研数百篇近期文献，对这一快速发展领域进行系统性综述，重点关注利用大语言模型技术为多样化下游任务准备数据的方法。首先，我们阐释了从基于规则、模型特定的传统流程，向提示驱动、情境感知、智能体化的工作流程所发生的根本性范式转变。继而提出以任务为中心的分类体系，将本领域划分为三大核心任务：数据清洗（如标准化、错误处理、缺失值填补）、数据集成（如实体匹配、模式匹配）与数据增强（如数据标注、画像分析）。针对每类任务，我们综述了代表性技术，并着重分析其优势（如提升泛化能力、增强语义理解）与局限（如大语言模型扩展的过高成本、先进智能体中仍存在的幻觉问题、前沿方法与薄弱评估体系之间的脱节）。此外，我们系统梳理了常用数据集与评估指标（实证研究部分）。最后，本文探讨了开放研究挑战，并展望了未来发展方向，重点强调可扩展的大语言模型-数据系统、可靠智能体工作流程的规范化设计以及鲁棒的评估框架建设。",
    "url": "https://huggingface.co/papers/2601.17058",
    "arxiv_url": "https://arxiv.org/abs/2601.17058"
  },
  {
    "title": "daVinci-Dev: Agent-native Mid-training for Software Engineering",
    "summary": "Recently, the frontier of Large Language Model (LLM) capabilities has shifted from single-turn code generation to agentic software engineering-a paradigm where models autonomously navigate, edit, and test complex repositories. While post-training methods have become the de facto approach for code agents, **agentic mid-training**-mid-training (MT) on large-scale data that mirrors authentic agentic workflows-remains critically underexplored due to substantial resource requirements, despite offering a more scalable path to instilling foundational agentic behaviors than relying solely on expensive reinforcement learning. A central challenge in realizing effective agentic mid-training is the distribution mismatch between static training data and the dynamic, feedback-rich environment of real development. To address this, we present a systematic study of agentic mid-training, establishing both the data synthesis principles and training methodology for effective agent development at scale. Central to our approach is **agent-native data**-supervision comprising two complementary types of trajectories: **contextually-native trajectories** that preserve the complete information flow an agent experiences, offering broad coverage and diversity; and **environmentally-native trajectories** collected from executable repositories where observations stem from actual tool invocations and test executions, providing depth and interaction authenticity. We verify the model's agentic capabilities on `SWE-Bench Verified`. We demonstrate our superiority over the previous open software engineering mid-training recipe `Kimi-Dev` under two post-training settings with an aligned base model and agentic scaffold, while using less than half mid-training tokens (73.1B). Besides relative advantage, our best performing 32B and 72B models achieve **56.1%** and **58.5%** resolution rates, respectively, which are ...",
    "translation": "标题：daVinci-Dev：面向软件工程的智能体原生中期训练\n\n摘要：近年来，大型语言模型（LLM）能力的前沿已从单轮代码生成转向智能体化软件工程——即模型能够自主导航、编辑和测试复杂代码仓库的范式。尽管后训练方法已成为代码智能体的事实标准，但**智能体中期训练**——在模拟真实智能体工作流程的大规模数据上进行中期训练（MT）——虽比单纯依赖昂贵的强化学习提供了更具扩展性的基础智能体行为培养路径，却因资源需求巨大而仍未得到充分探索。实现有效智能体中期训练的核心挑战在于静态训练数据与真实开发中动态、富含反馈的环境之间的分布不匹配。为解决这一问题，我们对智能体中期训练进行了系统性研究，建立了大规模有效智能体开发的数据合成原则与训练方法。我们方法的核心是**智能体原生数据**——包含两种互补类型轨迹的监督数据：**上下文原生轨迹**，完整保留智能体所经历的信息流，提供广泛的覆盖范围和多样性；以及**环境原生轨迹**，从可执行代码仓库中收集，其观测结果源自实际工具调用和测试执行，提供深度和交互真实性。我们在`SWE-Bench Verified`上验证了模型的智能体能力。在采用对齐基础模型和智能体框架的两种后训练设置下，我们证明了本方法优于先前开放的软件工程中期训练方案`Kimi-Dev`，同时使用了不到一半的中期训练词元（730亿）。除相对优势外，我们表现最佳的320亿和720亿参数模型分别实现了**56.1%**和**58.5%**的问题解决率，这些结果……",
    "url": "https://huggingface.co/papers/2601.18418",
    "arxiv_url": "https://arxiv.org/abs/2601.18418"
  },
  {
    "title": "The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation",
    "summary": "Recent advances in video generation have produced models capable of synthesizing stunning visual content from simple text prompts. However, these models struggle to generate long-form, coherent narratives from high-level concepts like dialogue, revealing a ``semantic gap'' between a creative idea and its cinematic execution. To bridge this gap, we introduce a novel, end-to-end agentic framework for dialogue-to-cinematic-video generation. Central to our framework is ScripterAgent, a model trained to translate coarse dialogue into a fine-grained, executable cinematic script. To enable this, we construct ScriptBench, a new large-scale benchmark with rich multimodal context, annotated via an expert-guided pipeline. The generated script then guides DirectorAgent, which orchestrates state-of-the-art video models using a cross-scene continuous generation strategy to ensure long-horizon coherence. Our comprehensive evaluation, featuring an AI-powered CriticAgent and a new Visual-Script Alignment (VSA) metric, shows our framework significantly improves script faithfulness and temporal fidelity across all tested video models. Furthermore, our analysis uncovers a crucial trade-off in current SOTA models between visual spectacle and strict script adherence, providing valuable insights for the future of automated filmmaking.",
    "translation": "标题：剧本即一切：面向长时程对话-电影视频生成的智能体框架\n\n摘要：近期视频生成技术的进展已能根据简单文本提示合成令人惊叹的视觉内容。然而，现有模型难以从对话等高层次概念中生成长篇幅、连贯的叙事内容，这揭示了创意构想与其影像化呈现之间存在“语义鸿沟”。为弥合这一鸿沟，我们提出了一种新颖的端到端智能体框架，用于实现从对话到电影视频的生成。该框架的核心是剧本生成智能体，该模型经训练可将粗粒度对话转化为细粒度、可执行的电影剧本。为此，我们构建了ScriptBench——一个通过专家指导流程标注、包含丰富多模态上下文的大规模新基准数据集。生成的剧本随后指导导演智能体，该智能体采用跨场景连续生成策略协调多个前沿视频模型，以确保长时程叙事连贯性。我们通过AI驱动的评论智能体及新提出的视觉-剧本对齐指标展开综合评估，结果表明本框架在所有测试视频模型上均显著提升了剧本忠实度与时序保真度。进一步分析揭示了当前先进模型在视觉表现力与严格剧本遵循性之间存在关键权衡，这为自动化电影制作的未来发展提供了重要启示。",
    "url": "https://huggingface.co/papers/2601.17737",
    "arxiv_url": "https://arxiv.org/abs/2601.17737"
  },
  {
    "title": "Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility",
    "summary": "While synthetic data has proven effective for improving scientific reasoning in the text domain, multimodal reasoning remains constrained by the difficulty of synthesizing scientifically rigorous images. Existing Text-to-Image (T2I) models often produce outputs that are visually plausible yet scientifically incorrect, resulting in a persistent visual-logic divergence that limits their value for downstream reasoning. Motivated by recent advances in next-generation T2I models, we conduct a systematic study of scientific image synthesis across generation paradigms, evaluation, and downstream use. We analyze both direct pixel-based generation and programmatic synthesis, and propose ImgCoder, a logic-driven framework that follows an explicit \"understand - plan - code\" workflow to improve structural precision. To rigorously assess scientific correctness, we introduce SciGenBench, which evaluates generated images based on information utility and logical validity. Our evaluation reveals systematic failure modes in pixel-based models and highlights a fundamental expressiveness-precision trade-off. Finally, we show that fine-tuning Large Multimodal Models (LMMs) on rigorously verified synthetic scientific images yields consistent reasoning gains, with potential scaling trends analogous to the text domain, validating high-fidelity scientific synthesis as a viable path to unlocking massive multimodal reasoning capabilities.",
    "translation": "标题：科学图像合成：基准测试、方法论与下游应用价值\n\n摘要：尽管合成数据在提升文本领域科学推理能力方面已被证明有效，但多模态推理仍受限于生成科学严谨图像的困难。现有文本到图像（T2I）模型常生成视觉合理但科学错误的输出，导致持续的视觉-逻辑偏差，限制了下游推理的应用价值。基于新一代T2I模型的最新进展，本研究对科学图像合成的生成范式、评估方法及下游应用进行了系统性探讨。我们分析了基于像素的直接生成与程序化合成两种路径，并提出ImgCoder——一种遵循显式“理解-规划-编码”工作流程的逻辑驱动框架，以提升结构精确性。为严格评估科学正确性，我们构建了SciGenBench基准，从信息效用与逻辑有效性两个维度评估生成图像。实验揭示了基于像素模型的系统性缺陷，并指出表达力与精确度之间存在根本性权衡。最后，我们证明基于严格验证的科学合成图像对大型多模态模型（LMMs）进行微调，能持续提升其推理能力，其扩展潜力与文本域具有相似规律，这验证了高保真科学图像合成可作为释放海量多模态推理能力的可行路径。",
    "url": "https://huggingface.co/papers/2601.17027",
    "arxiv_url": "https://arxiv.org/abs/2601.17027"
  },
  {
    "title": "Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers",
    "summary": "The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.",
    "translation": "标题：弹性注意力：面向高效Transformer的测试时自适应稀疏比率\n\n摘要：标准注意力机制的二次复杂度在长上下文场景下对大型语言模型（LLM）的可扩展性构成了显著瓶颈。尽管在单一模型中结合稀疏注意力与全注意力的混合注意力策略提供了可行解决方案，但这些策略通常采用静态计算比率（即稀疏注意力与全注意力的固定比例），无法在推理过程中适应下游任务对稀疏性的动态敏感度差异。为解决此问题，我们提出弹性注意力机制，使模型能够根据输入动态调整整体稀疏度。该方法通过在现有预训练模型中集成轻量级注意力路由器实现，该路由器能够动态为每个注意力头分配不同的计算模式。仅需在8张A800 GPU上进行12小时训练，我们的方法即可使模型同时实现强劲性能与高效推理。在多个广泛使用的LLM上进行的三个长上下文基准测试实验证明了本方法的优越性。",
    "url": "https://huggingface.co/papers/2601.17367",
    "arxiv_url": "https://arxiv.org/abs/2601.17367"
  },
  {
    "title": "iFSQ: Improving FSQ for Image Generation with 1 Line of Code",
    "summary": "The field of image generation is currently bifurcated into autoregressive (AR) models operating on discrete tokens and diffusion models utilizing continuous latents. This divide, rooted in the distinction between VQ-VAEs and VAEs, hinders unified modeling and fair benchmarking. Finite Scalar Quantization (FSQ) offers a theoretical bridge, yet vanilla FSQ suffers from a critical flaw: its equal-interval quantization can cause activation collapse. This mismatch forces a trade-off between reconstruction fidelity and information efficiency. In this work, we resolve this dilemma by simply replacing the activation function in original FSQ with a distribution-matching mapping to enforce a uniform prior. Termed iFSQ, this simple strategy requires just one line of code yet mathematically guarantees both optimal bin utilization and reconstruction precision. Leveraging iFSQ as a controlled benchmark, we uncover two key insights: (1) The optimal equilibrium between discrete and continuous representations lies at approximately 4 bits per dimension. (2) Under identical reconstruction constraints, AR models exhibit rapid initial convergence, whereas diffusion models achieve a superior performance ceiling, suggesting that strict sequential ordering may limit the upper bounds of generation quality. Finally, we extend our analysis by adapting Representation Alignment (REPA) to AR models, yielding LlamaGen-REPA. Codes is available at https://github.com/Tencent-Hunyuan/iFSQ",
    "translation": "标题：iFSQ：一行代码改进FSQ以提升图像生成性能\n\n摘要：当前图像生成领域主要分为基于离散令牌的自回归模型和利用连续隐变量的扩散模型。这一分野根植于VQ-VAE与VAE的差异，阻碍了统一建模与公平基准评估。有限标量量化（FSQ）提供了理论桥梁，但原始FSQ存在关键缺陷：其等间隔量化机制可能导致激活崩溃。这种不匹配迫使模型在重建保真度与信息效率之间进行权衡。本研究通过将原始FSQ中的激活函数替换为分布匹配映射以强制均匀先验，从而解决了这一困境。该方法被命名为iFSQ，仅需一行代码即可在数学上同时保证最优的量化箱利用率和重建精度。借助iFSQ作为受控基准，我们揭示了两个关键发现：（1）离散与连续表示之间的最优平衡点约为每维度4比特；（2）在相同重建约束下，自回归模型表现出快速的初始收敛性，而扩散模型能达到更优的性能上限，这表明严格的序列排序可能限制生成质量的上界。最后，我们通过将表示对齐方法（REPA）适配至自回归模型扩展了分析，由此构建了LlamaGen-REPA。代码已开源：https://github.com/Tencent-Hunyuan/iFSQ",
    "url": "https://huggingface.co/papers/2601.17124",
    "arxiv_url": "https://arxiv.org/abs/2601.17124"
  },
  {
    "title": "Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability",
    "summary": "Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.",
    "translation": "标题：模型自教：可学习性边缘的推理研究\n\n摘要：模型能否学会突破自身的学习瓶颈？针对大型推理模型的强化学习微调方法在初始成功率较低的数据集上容易陷入停滞，从而缺乏有效的训练信号。我们探究一个根本性问题：预训练大语言模型能否利用潜在知识为自身无法解决的问题生成自动化课程？为此，我们设计了SOAR框架：一种通过元强化学习挖掘教学信号的自改进框架。该框架通过模型教师副本为学生副本生成合成问题，并根据其在困难问题子集上的进步获得奖励。SOAR的关键创新在于将课程设计锚定于可量化的学生进步，而非依赖内在代理奖励。我们在数学基准测试中最困难子集（初始成功率0/128）上的研究揭示了三个核心发现：首先，通过激发预训练模型生成有效阶梯问题的潜在能力，可以实现基于稀疏二元奖励的双层元强化学习；其次，基于实际进步的奖励机制优于现有大语言模型自博弈中的内在奖励方案，能有效避免其常见的不稳定性和多样性崩溃问题；最后，对生成问题的分析表明，问题的结构质量与明确性比答案正确性对学习进程更具决定性。这些发现表明，生成有效阶梯问题的能力并不以预先解决难题的能力为前提，这为无需额外标注数据即可突破推理瓶颈提供了理论路径。\n\n摘要：[中文摘要]",
    "url": "https://huggingface.co/papers/2601.18778",
    "arxiv_url": "https://arxiv.org/abs/2601.18778"
  },
  {
    "title": "Self-Refining Video Sampling",
    "summary": "Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\\% human preference compared to the default sampler and guidance-based sampler.",
    "translation": "标题：自优化视频采样方法\n\n摘要：现代视频生成模型在处理复杂物理动态时仍面临挑战，往往难以实现真实的物理效果。现有方法通常依赖外部验证器或对增强数据进行额外训练来解决这一问题，但这些方法计算成本高昂，且在捕捉细粒度运动方面仍存在局限。本研究提出自优化视频采样方法，该简单方法利用在大规模数据集上预训练的视频生成器作为自身的优化器。通过将生成器解释为去噪自编码器，我们能够在推理阶段实现无需外部验证器或额外训练的迭代式内循环优化。我们进一步提出基于不确定性的优化策略，该策略根据自一致性选择性地优化特定区域，从而避免因过度优化而产生的伪影。在先进视频生成模型上的实验表明，该方法在运动连贯性与物理对齐方面取得显著改进，相较于默认采样器与基于引导的采样器，获得了超过70%的人类偏好度。",
    "url": "https://huggingface.co/papers/2601.18577",
    "arxiv_url": "https://arxiv.org/abs/2601.18577"
  },
  {
    "title": "VIBEVOICE-ASR Technical Report",
    "summary": "This report presents VibeVoice-ASR, a general-purpose speech understanding framework built upon VibeVoice, designed to address the persistent challenges of context fragmentation and multi-speaker complexity in long-form audio (e.g., meetings, podcasts) that remain despite recent advancements in short-form speech recognition. Unlike traditional pipelined approaches that rely on audio chunking, VibeVoice-ASRsupports single-pass processing for up to 60 minutes of audio. It unifies Automatic Speech Recognition, Speaker Diarization, and Timestamping into a single end-to-end generation task. In addition, VibeVoice-ASR supports over 50 languages, requires no explicit language setting, and natively handles code-switching within and across utterances. Furthermore, we introduce a prompt-based context injection mechanism that allows users to supply customized conetxt, significantly improving accuracy on domain-specific terminology and polyphonic character disambiguation.",
    "translation": "标题：VIBEVOICE-ASR技术报告\n\n摘要：本报告介绍了VibeVoice-ASR，这是一个基于VibeVoice构建的通用语音理解框架，旨在解决长音频（如会议、播客）中尽管近期短语音识别技术有所进步，但仍持续存在的上下文碎片化和多说话人复杂性等挑战。与依赖音频分块的传统流水线方法不同，VibeVoice-ASR支持对长达60分钟的音频进行单次处理。它将自动语音识别、说话人日志和时间戳标注统一为单一的端到端生成任务。此外，VibeVoice-ASR支持超过50种语言，无需显式语言设置，并能原生处理话语内及跨话语的语码转换。我们还引入了一种基于提示的上下文注入机制，允许用户提供定制化上下文，从而显著提升领域特定术语和多音字消歧的准确性。",
    "url": "https://huggingface.co/papers/2601.18184",
    "arxiv_url": "https://arxiv.org/abs/2601.18184"
  },
  {
    "title": "DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints",
    "summary": "While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.",
    "translation": "标题：DeepPlanning：基于可验证约束的长周期智能体规划基准测试\n\n摘要：尽管智能体评估已转向长周期任务，但现有基准测试仍侧重于局部、步骤层面的推理，而非需要真正规划能力的全局约束优化（如时间和财务预算）。同时，现有的LLM规划基准未能充分体现现实场景中典型的信息主动获取与细粒度局部约束特性。为此，我们提出DeepPlanning——一个面向实际长周期智能体规划的挑战性基准测试。该基准包含多日旅行规划与多商品购物任务，要求智能体具备主动信息获取、局部约束推理和全局约束优化能力。在DeepPlanning上的评估表明，即使是前沿的智能体LLM也难以有效处理此类问题，这凸显了可靠的显式推理模式与并行工具调用对于实现更优效果-效率权衡的重要性。错误分析进一步指出了改进长周期规划场景下智能体LLM的潜在研究方向。我们将开源代码与数据以支持未来研究。",
    "url": "https://huggingface.co/papers/2601.18137",
    "arxiv_url": "https://arxiv.org/abs/2601.18137"
  },
  {
    "title": "CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval",
    "summary": "General-purpose embedding models have demonstrated strong performance in text retrieval but remain suboptimal for table retrieval, where highly structured content leads to semantic compression and query-table mismatch. Recent LLM-based retrieval augmentation methods mitigate this issue by generating synthetic queries, yet they often rely on heuristic partial-table selection and seldom leverage these synthetic queries as supervision to improve the embedding model. We introduce CGPT, a training framework that enhances table retrieval through LLM-generated supervision. CGPT constructs semantically diverse partial tables by clustering table instances using K-means and sampling across clusters to broaden semantic coverage. An LLM then generates synthetic queries for these partial tables, which are used in hard-negative contrastive fine-tuning to refine the embedding model. Experiments across four public benchmarks (MimoTable, OTTQA, FetaQA, and E2E-WTQ) show that CGPT consistently outperforms retrieval baselines, including QGpT, with an average R@1 improvement of 16.54 percent. In a unified multi-domain corpus setting, CGPT further demonstrates strong cross-domain generalization and remains effective even when using smaller LLMs for synthetic query generation. These results indicate that semantically guided partial-table construction, combined with contrastive training from LLM-generated supervision, provides an effective and scalable paradigm for large-scale table retrieval. Our code is available at https://github.com/yumeow0122/CGPT.",
    "translation": "标题：CGPT：基于聚类引导的部分表格与LLM生成监督的表格检索方法\n\n摘要：通用嵌入模型在文本检索中表现出色，但在表格检索中仍存在不足，高度结构化的内容导致语义压缩和查询-表格匹配偏差。近期基于大语言模型的检索增强方法通过生成合成查询缓解了这一问题，但这些方法通常依赖启发式的部分表格选择策略，且很少利用合成查询作为监督信号来优化嵌入模型。本文提出CGPT训练框架，通过大语言模型生成的监督信号提升表格检索性能。CGPT采用K-means对表格实例进行聚类，并通过跨聚类采样构建语义多样化的部分表格集合以扩展语义覆盖范围。随后利用大语言模型为这些部分表格生成合成查询，通过困难负样本对比微调策略优化嵌入模型。在四个公开基准数据集（MimoTable、OTTQA、FetaQA和E2E-WTQ）上的实验表明，CGPT在检索性能上持续优于包括QGpT在内的基线方法，平均R@1指标提升16.54%。在统一多领域语料场景中，CGPT展现出强大的跨领域泛化能力，即使使用较小规模的大语言模型生成合成查询仍保持有效性。这些结果表明：语义引导的部分表格构建策略，结合大语言模型生成监督的对比训练，为大规模表格检索提供了高效可扩展的解决方案。代码已开源：https://github.com/yumeow0122/CGPT。",
    "url": "https://huggingface.co/papers/2601.15849",
    "arxiv_url": "https://arxiv.org/abs/2601.15849"
  },
  {
    "title": "STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion",
    "summary": "Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging. Recent methods such as QGpT attempt to enrich table semantics by generating synthetic queries, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query-table alignment. We propose STAR (Semantic Table Representation), a lightweight framework that improves semantic table representation through semantic clustering and weighted fusion. STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table. It then generates cluster-specific synthetic queries to comprehensively cover the table's semantic space. Finally, STAR employs weighted fusion strategies to integrate table and query embeddings, enabling fine-grained semantic alignment. This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations. Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on all datasets, demonstrating the effectiveness of semantic clustering and adaptive weighted fusion for robust table representation. Our code is available at https://github.com/adsl135789/STAR.",
    "translation": "标题：STAR：基于表头感知聚类与自适应加权融合的语义表格表示方法\n\n摘要：表格检索任务旨在根据自然语言查询从大规模语料库中检索最相关的表格。然而，非结构化文本与结构化表格之间的结构和语义差异使得嵌入对齐尤为困难。现有方法（如QGpT）尝试通过生成合成查询来丰富表格语义，但仍依赖于粗糙的部分表格采样和简单的融合策略，这限制了语义多样性并阻碍了有效的查询-表格对齐。本文提出STAR（语义表格表示）这一轻量级框架，通过语义聚类与加权融合提升表格语义表示能力。STAR首先采用表头感知的K均值聚类对语义相似的行进行分组，并选取代表性中心实例构建多样化的部分表格；随后生成针对特定聚类的合成查询，以全面覆盖表格的语义空间；最后通过加权融合策略整合表格与查询嵌入，实现细粒度的语义对齐。该设计使STAR能够从结构化与文本化数据源中捕获互补信息，从而提升表格表示的表达能力。在五个基准数据集上的实验表明，STAR在所有数据集上的召回率均持续优于QGpT，验证了语义聚类与自适应加权融合对构建鲁棒表格表示的有效性。代码已开源：https://github.com/adsl135789/STAR。",
    "url": "https://huggingface.co/papers/2601.15860",
    "arxiv_url": "https://arxiv.org/abs/2601.15860"
  },
  {
    "title": "Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents",
    "summary": "Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.",
    "translation": "标题：降低泛化代价：大语言模型智能体强化学习训练的跨领域泛化研究\n\n摘要：通用型大语言模型智能体通常在有限环境集合中进行后训练，却需部署至更广泛、未经见的领域中。本研究探讨了当最终测试领域未知时，智能体后训练所面临的挑战。具体而言，我们分析了强化学习环境特性与建模选择中哪些因素对领域外性能影响最为显著。首先，我们识别出与跨领域泛化强相关的两个环境维度：（一）状态信息丰富度，即智能体从状态中需处理的信息量；（二）规划复杂度，通过基础策略下的目标可达性与轨迹长度进行估算。值得注意的是，领域真实性与文本层面相似性并非主要因素；例如，简单的网格世界领域“推箱子”在SciWorld中产生的泛化能力甚至优于更贴近现实的ALFWorld领域。基于这些发现，我们进一步证明仅提升状态信息丰富度即可有效增强跨领域鲁棒性。我们提出一种低开销且广泛适用的随机化技术：在状态中添加少量与目标无关的干扰特征，在不改变任务本质的前提下增加状态丰富度。除环境侧特性外，我们还检验了多项建模选择：（a）监督微调预热或训练中插入虽能防止强化学习期间的灾难性遗忘，但会削弱对未包含在训练数据混合领域中的泛化能力；（b）在强化学习中启用逐步推理机制，虽不总能提升领域内性能，但对保持泛化能力具有关键作用。",
    "url": "https://huggingface.co/papers/2601.18217",
    "arxiv_url": "https://arxiv.org/abs/2601.18217"
  },
  {
    "title": "AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation",
    "summary": "Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of \"Omni\" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.",
    "translation": "标题：AR-Omni：一种适用于任意模态间生成的统一自回归模型\n\n摘要：现实世界的感知与交互本质上是多模态的，不仅涉及语言，还包括视觉与语音，这推动了支持多模态输入与多模态输出的“全能”多模态大语言模型的发展。尽管一系列全能多模态大语言模型已相继出现，但现有系统大多仍依赖额外的专家组件来实现多模态生成，限制了统一训练与推理的简洁性。自回归建模以其单一令牌流、单一下一令牌目标及单一解码器的特点，在文本领域是一种优雅且可扩展的基础框架。受此启发，我们提出了AR-Omni——一种在自回归范式下无需任何专家解码器的统一任意模态间生成模型。AR-Omni支持自回归文本与图像生成，以及流式语音生成，所有功能均通过单一Transformer解码器实现。我们进一步解决了统一自回归建模中的三个实际问题：通过任务感知的损失重加权应对模态不平衡问题，通过针对图像令牌的轻量级令牌级感知对齐损失提升视觉保真度，以及通过有限状态解码机制平衡稳定性与创造性。实验表明，AR-Omni在三种模态上均实现了高质量生成，同时保持实时性，其语音生成的实时因子达到0.88。",
    "url": "https://huggingface.co/papers/2601.17761",
    "arxiv_url": "https://arxiv.org/abs/2601.17761"
  },
  {
    "title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models",
    "summary": "Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.",
    "translation": "标题：TSRBench：面向通用模型的多任务多模态时间序列推理综合基准\n\n摘要：时间序列数据在现实场景中无处不在，对从能源管理到交通控制等关键应用至关重要。因此，对时间序列进行推理的能力是通用模型解决实际问题的核心技能。然而，现有通用模型基准显著缺乏对这一维度的评估。为填补这一空白，我们提出了TSRBench——一个全面的多模态基准，旨在系统测试时间序列推理的全方位能力。TSRBench具备以下特点：i) 涵盖14个领域的4125个多样化问题，并划分为感知、推理、预测与决策四大核心维度；ii) 通过四大维度下的15项任务评估关键推理能力（如数值推理）。我们通过大量实验，在TSRBench上评估了30余个领先的专有及开源大语言模型、视觉语言模型与时间序列大语言模型。研究发现：i) 缩放定律在感知与推理任务中成立，但在预测任务中失效；ii) 强大的推理能力不能保证准确的上下文感知预测，表明语义理解与数值预测之间存在解耦现象；iii) 尽管文本与视觉两种时间序列表征形式具有输入互补性，当前多模态模型仍未能有效融合二者以实现性能协同提升。TSRBench提供了一个标准化评估平台，不仅揭示了现有挑战，更为推进通用模型发展提供了重要参考。代码与数据集已发布于 https://tsrbench.github.io/。",
    "url": "https://huggingface.co/papers/2601.18744",
    "arxiv_url": "https://arxiv.org/abs/2601.18744"
  },
  {
    "title": "SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback",
    "summary": "Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.",
    "translation": "标题：SAGE：基于执行反馈的可控智能体数据生成方法在深度搜索中的应用\n\n摘要：深度搜索智能体旨在回答需要跨多文档推理的复杂问题，能够显著加速信息检索过程。由于探索路径长且复杂，为此类应用收集人工标注的成本极高。本文提出一种智能体流程，能够针对给定语料库和目标难度级别自动生成高质量、难度可控的深度搜索问答对。我们的SAGE流程包含两个核心组件：数据生成器负责提出问答对，搜索智能体则尝试解答生成的问题并向数据生成器提供执行反馈。两个组件通过多轮交互迭代优化问答对，直至其满足目标难度要求。内在评估表明，SAGE生成的问题需要多样化的推理策略，同时显著提升了生成数据的准确性与难度。外在评估显示，使用我们合成的数据训练深度搜索智能体，在主流深度搜索基准测试中可获得最高23%的相对性能提升。补充实验进一步证明，基于我们数据训练的智能体能够在推理时从固定语料检索无缝适配至谷歌搜索，且无需额外训练。",
    "url": "https://huggingface.co/papers/2601.18202",
    "arxiv_url": "https://arxiv.org/abs/2601.18202"
  },
  {
    "title": "Agentic Very Long Video Understanding",
    "summary": "The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks.",
    "translation": "标题：具身化超长视频理解\n\n摘要：随着智能眼镜等全天候可穿戴设备的普及，始终在线的个人人工智能助手对情境理解提出了更高要求——需要超越短暂、孤立的事件，涵盖连续、纵向的第一人称视频流。实现这一愿景需要长时域视频理解技术的突破，系统必须能够解读并回溯跨越数天甚至数周的视觉与听觉信息。现有方法（包括大语言模型和检索增强生成技术）受限于有限的上下文窗口，且缺乏对超长视频流进行组合式多跳推理的能力。本研究通过EGAgent框架应对这些挑战：该增强型具身化框架以实体场景图为核心，动态表征人物、地点、物体及其随时间演化的关系。我们的系统为规划智能体配备了结构化图搜索推理工具，以及混合视觉-听觉检索能力，从而实现精细化、跨模态且时序连贯的推理。在EgoLifeQA和Video-MME（长时域）数据集上的实验表明，本方法在复杂纵向视频理解任务中取得了EgoLifeQA（57.5%）的最优性能，并在Video-MME（长时域）（74.1%）上达到领先水平。",
    "url": "https://huggingface.co/papers/2601.18157",
    "arxiv_url": "https://arxiv.org/abs/2601.18157"
  },
  {
    "title": "DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal",
    "summary": "Despite the growing adoption of large language models (LLMs) in scientific research workflows, automated support for academic rebuttal, a crucial step in academic communication and peer review, remains largely underexplored. Existing approaches typically rely on off-the-shelf LLMs or simple pipelines, which struggle with long-context understanding and often fail to produce targeted and persuasive responses. In this paper, we propose DRPG, an agentic framework for automatic academic rebuttal generation that operates through four steps: Decompose reviews into atomic concerns, Retrieve relevant evidence from the paper, Plan rebuttal strategies, and Generate responses accordingly. Notably, the Planner in DRPG reaches over 98% accuracy in identifying the most feasible rebuttal direction. Experiments on data from top-tier conferences demonstrate that DRPG significantly outperforms existing rebuttal pipelines and achieves performance beyond the average human level using only an 8B model. Our analysis further demonstrates the effectiveness of the planner design and its value in providing multi-perspective and explainable suggestions. We also showed that DRPG works well in a more complex multi-round setting. These results highlight the effectiveness of DRPG and its potential to provide high-quality rebuttal content and support the scaling of academic discussions. Codes for this work are available at https://github.com/ulab-uiuc/DRPG-RebuttalAgent.",
    "translation": "标题：DRPG（分解、检索、规划、生成）：一种用于学术反驳的智能体框架\n\n摘要：尽管大语言模型在科学研究工作流程中的应用日益广泛，但针对学术交流与同行评审中关键环节——学术反驳的自动化支持仍鲜有深入探索。现有方法通常依赖于现成的大语言模型或简单流水线，这些方法在长上下文理解方面存在不足，且往往难以生成具有针对性、说服力的回应。本文提出DRPG框架，该框架通过四个步骤实现自动化学术反驳生成：将评审意见分解为原子化问题、从论文中检索相关证据、规划反驳策略，并据此生成回应。值得注意的是，DRPG中的规划器在识别最可行反驳方向的任务中准确率超过98%。在顶级会议数据上的实验表明，DRPG显著优于现有反驳生成流程，且仅使用80亿参数模型即可达到超越人类平均水平的性能。我们的分析进一步验证了规划器设计的有效性及其在提供多视角、可解释建议方面的价值。实验还证明DRPG在更复杂的多轮交互场景中表现良好。这些结果凸显了DRPG框架的有效性，及其在生成高质量反驳内容、支持学术讨论规模化拓展方面的潜力。本项目代码已开源：https://github.com/ulab-uiuc/DRPG-RebuttalAgent。",
    "url": "https://huggingface.co/papers/2601.18081",
    "arxiv_url": "https://arxiv.org/abs/2601.18081"
  },
  {
    "title": "IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance",
    "summary": "Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA",
    "translation": "标题：IVRA：基于无训练提示引导的视觉-标记关系优化以提升机器人动作策略\n\n摘要：当前多数视觉-语言-动作模型将图像块展平为一维标记序列，削弱了精确操作所需的二维空间线索。本文提出IVRA，一种轻量级、无需训练的方法，通过利用模型内置视觉编码器中已有的关联提示来增强空间理解能力，无需任何外部编码器或重新训练。IVRA选择性地将这些关联信号注入到包含实例级特征的语言模型层中。这种推理时干预机制在保持所有模型参数固定的同时，重新校准视觉-标记的交互关系，更好地保留几何结构。我们在涵盖二维与三维操作的仿真基准（VIMA和LIBERO）及多种真实机器人任务中，将IVRA应用于不同视觉-语言-动作架构（LLaRA、OpenVLA和FLOWER），验证了其普适性。在二维VIMA任务中，IVRA在低数据场景下较基线LLaRA平均成功率提升4.2%；在三维LIBERO任务中，对OpenVLA和FLOWER基线模型均带来稳定增益，即使在基线准确率接近饱和时仍实现提升（从96.3%至97.1%）。所有代码与模型将公开发布，可视化结果请访问：jongwoopark7978.github.io/IVRA",
    "url": "https://huggingface.co/papers/2601.16207",
    "arxiv_url": "https://arxiv.org/abs/2601.16207"
  },
  {
    "title": "End-to-End Joint ASR and Speaker Role Diarization with Child-Adult Interactions",
    "summary": "Accurate transcription and speaker diarization of child-adult spoken interactions are crucial for developmental and clinical research. However, manual annotation is time-consuming and challenging to scale. Existing automated systems typically rely on cascaded speaker diarization and speech recognition pipelines, which can lead to error propagation. This paper presents a unified end-to-end framework that extends the Whisper encoder-decoder architecture to jointly model ASR and child-adult speaker role diarization. The proposed approach integrates: (i) a serialized output training scheme that emits speaker tags and start/end timestamps, (ii) a lightweight frame-level diarization head that enhances speaker-discriminative encoder representations, (iii) diarization-guided silence suppression for improved temporal precision, and (iv) a state-machine-based forced decoding procedure that guarantees structurally valid outputs. Comprehensive evaluations on two datasets demonstrate consistent and substantial improvements over two cascaded baselines, achieving lower multi-talker word error rates and demonstrating competitive diarization accuracy across both Whisper-small and Whisper-large models. These findings highlight the effectiveness and practical utility of the proposed joint modeling framework for generating reliable, speaker-attributed transcripts of child-adult interactions at scale. The code and model weights are publicly available",
    "translation": "标题：儿童-成人互动场景下的端到端联合语音识别与说话人角色分类\n\n摘要：儿童与成人言语互动的准确转写和说话人分类对发展心理学与临床研究至关重要。然而人工标注耗时费力且难以规模化。现有自动化系统通常采用级联式的说话人分类与语音识别流程，易导致误差传播。本文提出一种统一的端到端框架，通过扩展Whisper编码器-解码器架构，实现语音识别与儿童-成人说话人角色分类的联合建模。该方案整合了四大核心模块：（一）采用序列化输出训练机制，同步生成说话人标签及起止时间戳；（二）设计轻量级帧级分类头，增强编码器表征的说话人区分能力；（三）引入基于分类的静音抑制机制以提升时间边界精度；（四）构建基于状态机的强制解码流程，确保输出结构合法性。在两个数据集上的综合实验表明，相比两种级联基线方法，本框架在Whisper-small与Whisper-large模型上均取得稳定且显著的性能提升：不仅降低了多说话人词错误率，同时保持了具有竞争力的说话人分类准确率。这些发现验证了所提联合建模框架在规模化生成儿童-成人互动场景下说话人归属转录文本方面的有效性与实用价值。相关代码与模型权重已开源发布。",
    "url": "https://huggingface.co/papers/2601.17640",
    "arxiv_url": "https://arxiv.org/abs/2601.17640"
  },
  {
    "title": "SkyReels-V3 Technique Report",
    "summary": "Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized.\n  Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.",
    "translation": "标题：SkyReels-V3 技术报告\n\n摘要：视频生成是构建世界模型的关键基础，而多模态上下文推理能力是衡量其性能的核心标准。为此，我们提出了SkyReels-V3——一个基于扩散Transformer统一多模态上下文学习框架的条件视频生成模型。该模型在单一架构中支持三种核心生成范式：参考图像到视频合成、视频到视频扩展以及音频引导的视频生成。（一）参考图像到视频模型旨在生成具有高度主体身份保持性、时间连贯性和叙事一致性的高保真视频。为增强对参考内容的遵循能力与构图稳定性，我们设计了一套综合数据处理流程，通过跨帧配对、图像编辑和语义重写等技术，有效减少了复制粘贴带来的伪影。训练过程中采用图像-视频混合策略并结合多分辨率联合优化，以提升模型在不同场景下的泛化能力与鲁棒性。（二）视频扩展模型将时空一致性建模与大规模视频理解相结合，既能实现无缝的单镜头延续，也能依据专业影视范式进行智能的多镜头切换。（三）数字人模型通过训练首尾帧插入模式并重构关键帧推理范式，支持分钟级音频条件视频生成，在保障视觉质量的同时优化了音视频同步效果。\n\n综合评估表明，SkyReels-V3在视觉质量、指令跟随及特定维度指标等关键度量上达到或接近业界最优水平，性能可比肩领先的闭源系统。项目地址：https://github.com/SkyworkAI/SkyReels-V3。",
    "url": "https://huggingface.co/papers/2601.17323",
    "arxiv_url": "https://arxiv.org/abs/2601.17323"
  },
  {
    "title": "Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts",
    "summary": "Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.",
    "translation": "标题：最小负载专家并行：一种面向不平衡专家混合模型的负载均衡方法\n\n摘要：专家混合模型通常在预训练阶段采用显式负载均衡约束以确保专家路由的统计平衡。然而，我们发现即使经过充分训练的专家混合模型仍会表现出显著的路由不平衡现象。这种行为具有内在合理性——甚至可视为有益特性——因为不平衡路由能使模型将领域特定知识集中于部分专家内部。专家并行技术旨在通过将专家分布到多个设备上来扩展专家混合模型，但其设计隐含了路由平衡的前提假设。在极端不平衡场景下，专家并行可能将过量令牌集中路由至少数专家，导致训练后阶段或推理过程中过载设备出现计算与内存边界故障，而此时显式负载均衡往往难以实施。本文提出最小负载专家并行算法，该新型专家并行算法能动态将过载设备的超额令牌及相关专家参数重路由至低负载设备，在满足内存约束的前提下确保所有设备在最小集体延迟内完成计算任务。在不同规模模型实验中，该算法相比标准专家并行实现最高5倍加速比和4倍峰值内存使用降低，其中gpt-oss-120b模型推理速度提升约1.9倍。我们通过理论分析与综合实验评估（包括消融研究）验证该方法，揭示了关键性能权衡关系，并建立了面向特定硬件的超参数调优原则框架以实现最优性能。",
    "url": "https://huggingface.co/papers/2601.17111",
    "arxiv_url": "https://arxiv.org/abs/2601.17111"
  },
  {
    "title": "One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment",
    "summary": "Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.",
    "translation": "标题：以一适万：面向个性化大语言模型对齐的元奖励建模\n\n摘要：大语言模型的对齐旨在使其输出符合人类偏好，而个性化对齐则进一步使模型适配于个体用户。这依赖于能够捕捉用户特定偏好并自动提供个性化反馈的奖励模型。然而，开发此类模型面临两大关键挑战：个体用户反馈数据的稀缺性，以及对未见用户进行高效适配的需求。我们认为，解决这些限制需要将范式从拟合数据以学习用户偏好，转变为学习偏好适应的过程。为此，我们提出元奖励建模方法，将个性化奖励建模重新定义为元学习问题。具体而言，我们将每个用户的奖励模型表示为若干基础奖励函数的加权组合，并采用模型无关元学习框架优化这些权重的初始化，以支持在有限反馈下的快速适配。为确保鲁棒性，我们引入了鲁棒个性化目标，该目标在元优化过程中更加强调难以学习的用户。在个性化偏好数据集上进行的大量实验验证了所提方法能够增强少样本个性化性能、提升用户鲁棒性，并持续优于基线模型。",
    "url": "https://huggingface.co/papers/2601.18731",
    "arxiv_url": "https://arxiv.org/abs/2601.18731"
  },
  {
    "title": "Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks",
    "summary": "Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.",
    "translation": "标题：云珏智能体技术报告：面向开放式任务的全可复现、零启动原位自进化智能体系统\n\n摘要：传统智能体系统在任务分布持续漂移且外部监督稀缺的开放式环境中往往表现不佳。其对静态工具集或离线训练的依赖难以适应动态变化，导致系统能力边界僵化且不可知。为解决这一问题，我们提出原位自进化范式。该方法将序列化任务交互视为持续的经验流，使系统能够在缺乏真实标签的情况下，将短期执行反馈提炼为长期可重用的能力。在此框架中，我们识别出工具进化作为能力扩展的关键路径，其可提供可验证的二元反馈信号。基于此框架，我们开发了云珏智能体系统，通过迭代合成、优化和重用工具以应对新兴挑战。为提升进化效率，我们进一步提出并行批量进化策略。在零启动设置下对五个多样化基准的实证评估表明，该系统相较于专有基线模型取得显著性能提升。补充性热启动实验进一步证实，系统积累的通用知识可无缝迁移至新领域。最后，我们提出一种监测进化收敛的新颖指标，其功能类似于传统优化中的训练损失函数。我们已开源代码库、系统轨迹及进化工具，以促进韧性自进化智能领域的后续研究。",
    "url": "https://huggingface.co/papers/2601.18226",
    "arxiv_url": "https://arxiv.org/abs/2601.18226"
  },
  {
    "title": "Masked Depth Modeling for Spatial Perception",
    "summary": "Spatial visual perception is a fundamental requirement in physical-world applications like autonomous driving and robotic manipulation, driven by the need to interact with 3D environments. Capturing pixel-aligned metric depth using RGB-D cameras would be the most viable way, yet it usually faces obstacles posed by hardware limitations and challenging imaging conditions, especially in the presence of specular or texture-less surfaces. In this work, we argue that the inaccuracies from depth sensors can be viewed as \"masked\" signals that inherently reflect underlying geometric ambiguities. Building on this motivation, we present LingBot-Depth, a depth completion model which leverages visual context to refine depth maps through masked depth modeling and incorporates an automated data curation pipeline for scalable training. It is encouraging to see that our model outperforms top-tier RGB-D cameras in terms of both depth precision and pixel coverage. Experimental results on a range of downstream tasks further suggest that LingBot-Depth offers an aligned latent representation across RGB and depth modalities. We release the code, checkpoint, and 3M RGB-depth pairs (including 2M real data and 1M simulated data) to the community of spatial perception.",
    "translation": "标题：面向空间感知的掩蔽深度建模\n\n摘要：在与三维环境交互的需求驱动下，空间视觉感知已成为自动驾驶、机器人操控等物理世界应用的基础能力。使用RGB-D相机获取像素对齐的度量深度本是最可行的方案，但该方法常受硬件限制与复杂成像条件（特别是镜面或弱纹理表面）的制约。本研究提出：深度传感器的测量误差可被视为反映底层几何模糊性的“掩蔽”信号。基于此观点，我们提出LingBot-Depth深度补全模型，该模型通过掩蔽深度建模机制利用视觉上下文优化深度图，并集成自动化数据筛选流程以实现可扩展训练。实验表明，该模型在深度精度与像素覆盖率方面均优于顶级RGB-D相机。在多项下游任务中的实验结果进一步证明，LingBot-Depth能够为RGB与深度模态提供对齐的潜在表征。我们已向空间感知研究社区开源代码、模型检查点及300万组RGB-深度配对数据（含200万真实数据与100万仿真数据）。",
    "url": "https://huggingface.co/papers/2601.17895",
    "arxiv_url": "https://arxiv.org/abs/2601.17895"
  },
  {
    "title": "A Mechanistic View on Video Generation as World Models: State and Dynamics",
    "summary": "Large-scale video generation models have demonstrated emergent physical coherence, positioning them as potential world models. However, a gap remains between contemporary \"stateless\" video architectures and classic state-centric world model theories. This work bridges this gap by proposing a novel taxonomy centered on two pillars: State Construction and Dynamics Modeling. We categorize state construction into implicit paradigms (context management) and explicit paradigms (latent compression), while dynamics modeling is analyzed through knowledge integration and architectural reformulation. Furthermore, we advocate for a transition in evaluation from visual fidelity to functional benchmarks, testing physical persistence and causal reasoning. We conclude by identifying two critical frontiers: enhancing persistence via data-driven memory and compressed fidelity, and advancing causality through latent factor decoupling and reasoning-prior integration. By addressing these challenges, the field can evolve from generating visually plausible videos to building robust, general-purpose world simulators.",
    "translation": "标题：视频生成作为世界模型的机制视角：状态与动态\n\n摘要：大规模视频生成模型已展现出涌现的物理一致性，使其具备成为潜在世界模型的可能。然而，当前“无状态”的视频架构与经典以状态为中心的世界模型理论之间仍存在差距。本研究通过提出一个以两大支柱为核心的新分类体系来弥合这一差距：状态构建与动态建模。我们将状态构建分为隐式范式（上下文管理）与显式范式（潜在压缩），同时通过知识整合与架构重构来分析动态建模。此外，我们主张评估标准应从视觉保真度转向功能基准测试，以检验物理持久性与因果推理能力。最后，我们指出两个关键前沿方向：通过数据驱动的记忆与压缩保真度提升持久性，以及通过潜在因子解耦与推理先验整合推进因果建模。通过应对这些挑战，该领域有望从生成视觉合理的视频，演进为构建鲁棒、通用的世界模拟器。",
    "url": "https://huggingface.co/papers/2601.17067",
    "arxiv_url": "https://arxiv.org/abs/2601.17067"
  },
  {
    "title": "Diffusion In Diffusion: Reclaiming Global Coherence in Semi-Autoregressive Diffusion",
    "summary": "One of the most compelling features of global discrete diffusion language models is their global bidirectional contextual capability. However, existing block-based diffusion studies tend to introduce autoregressive priors, which, while offering benefits, can cause models to lose this global coherence at the macro level. To regain global contextual understanding while preserving the advantages of the semi-autoregressive paradigm, we propose Diffusion in Diffusion, a 'draft-then-refine' framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilize snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using only 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.",
    "translation": "标题：扩散中的扩散：在半自回归扩散模型中重获全局连贯性\n\n摘要：全局离散扩散语言模型最引人注目的特征之一是其全局双向上下文建模能力。然而，现有的基于分块的扩散研究往往引入自回归先验，这虽然带来一定优势，却可能导致模型在宏观层面丧失全局连贯性。为了在保留半自回归范式优点的同时恢复全局上下文理解能力，我们提出“扩散中的扩散”——一种“先草拟后精修”的框架，旨在克服分块扩散模型固有的不可逆性与短视性问题。该方法首先通过小分块扩散快速生成文本草稿，随后利用具有更大双向感受野的全局双向扩散对这些草稿进行精细化重构。我们采用置信度快照重掩码技术识别需要修改的关键词元，并运用混合尺度训练拓展分块扩散模型的全局建模能力。实验结果表明，我们的方法在OpenWebText数据集上为离散扩散模型设立了新的性能基准：仅使用基线模型26%的微调计算量，便将生成困惑度从25.7降至21.9，显著缩小了与自回归模型的性能差距。",
    "url": "https://huggingface.co/papers/2601.13599",
    "arxiv_url": "https://arxiv.org/abs/2601.13599"
  },
  {
    "title": "UI Remix: Supporting UI Design Through Interactive Example Retrieval and Remixing",
    "summary": "Designing user interfaces (UIs) is a critical step when launching products, building portfolios, or personalizing projects, yet end users without design expertise often struggle to articulate their intent and to trust design choices. Existing example-based tools either promote broad exploration, which can cause overwhelm and design drift, or require adapting a single example, risking design fixation. We present UI Remix, an interactive system that supports mobile UI design through an example-driven design workflow. Powered by a multimodal retrieval-augmented generation (MMRAG) model, UI Remix enables iterative search, selection, and adaptation of examples at both the global (whole interface) and local (component) level. To foster trust, it presents source transparency cues such as ratings, download counts, and developer information. In an empirical study with 24 end users, UI Remix significantly improved participants' ability to achieve their design goals, facilitated effective iteration, and encouraged exploration of alternative designs. Participants also reported that source transparency cues enhanced their confidence in adapting examples. Our findings suggest new directions for AI-assisted, example-driven systems that empower end users to design with greater control, trust, and openness to exploration.",
    "translation": "标题：UI Remix：通过交互式案例检索与重组支持用户界面设计\n\n摘要：用户界面（UI）设计是发布产品、构建作品集或个性化项目中的关键步骤，然而不具备设计专业知识的终端用户往往难以清晰表达其设计意图，并对自身的设计选择缺乏信心。现有的基于案例的设计工具要么鼓励广泛探索（可能导致信息过载与设计方向偏离），要么要求用户仅基于单一案例进行修改（存在设计固化的风险）。本文提出UI Remix，一个通过案例驱动的工作流程来支持移动端UI设计的交互式系统。该系统基于多模态检索增强生成（MMRAG）模型，支持用户在整体界面（全局）和界面组件（局部）两个层面上进行迭代式的案例搜索、选择与适配。为增强用户信任，系统提供了来源透明度提示，如评分、下载量和开发者信息等。一项针对24名终端用户的实证研究表明，UI Remix显著提升了参与者实现其设计目标的能力，促进了有效的设计迭代，并鼓励了对替代设计的探索。参与者还反馈，来源透明度提示增强了他们在适配案例时的信心。我们的研究结果为人工智能辅助的案例驱动系统指明了新的方向，这类系统能够赋能终端用户，使其在设计过程中拥有更强的控制力、更高的信任度以及更开放的探索心态。",
    "url": "https://huggingface.co/papers/2601.18759",
    "arxiv_url": "https://arxiv.org/abs/2601.18759"
  },
  {
    "title": "PingPong: A Natural Benchmark for Multi-Turn Code-Switching Dialogues",
    "summary": "Code-switching is a widespread practice among the world's multilingual majority, yet few benchmarks accurately reflect its complexity in everyday communication. We present PingPong, a benchmark for natural multi-party code-switching dialogues covering five language-combination variations, some of which are trilingual. Our dataset consists of human-authored conversations among 2 to 4 participants covering authentic, multi-threaded structures where replies frequently reference much earlier points in the dialogue. We demonstrate that our data is significantly more natural and structurally diverse than machine-generated alternatives, offering greater variation in message length, speaker dominance, and reply distance. Based on these dialogues, we define three downstream tasks: Question Answering, Dialogue Summarization, and Topic Classification. Evaluations of several state-of-the-art language models on PingPong reveal that performance remains limited on code-switched inputs, underscoring the urgent need for more robust NLP systems capable of addressing the intricacies of real-world multilingual discourse.",
    "translation": "标题：PingPong：多轮语码转换对话的自然基准测试集\n\n摘要：语码转换是全球多语使用者的普遍现象，但现有基准测试集鲜能准确反映其在日常交流中的复杂性。本文提出PingPong——一个涵盖五种语言组合变体（部分为三语混合）的自然多方言码转换对话基准测试集。该数据集由2至4名参与者进行人工撰写的对话构成，呈现真实的多线程对话结构，其中应答内容常指向对话中较早的节点。我们证明该数据在信息长度、说话者主导性和应答距离等方面，比机器生成数据具有更强的自然性与结构多样性，且对话线索更复杂。基于这些对话，我们定义了三个下游任务：问答系统、对话摘要和主题分类。通过在PingPong上对多种前沿语言模型进行评估，我们发现现有模型对语码转换输入的处理能力仍显不足，这凸显了亟需开发能够应对现实世界多语交流复杂性的更强健自然语言处理系统。",
    "url": "https://huggingface.co/papers/2601.17277",
    "arxiv_url": "https://arxiv.org/abs/2601.17277"
  },
  {
    "title": "Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control",
    "summary": "Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym.",
    "translation": "标题：强化学习算法在大规模流动控制中的即插即用基准测试框架\n\n摘要：强化学习在主动流动控制领域已展现出良好前景，但该领域进展仍难以评估，因为现有研究依赖于异构的观测与执行方案、数值设置及评估协议。当前AFC基准测试虽试图解决这些问题，但严重依赖外部计算流体动力学求解器，不具备完全可微性，且对三维与多智能体场景支持有限。为突破这些限制，我们提出首个独立、完全可微的AFC强化学习基准测试套件FluidGym。该框架完全基于PyTorch构建于GPU加速的PICT求解器之上，在单一Python环境中运行，无需外部CFD软件，并提供标准化评估协议。我们展示了PPO与SAC算法的基线测试结果，并将所有仿真环境、数据集及训练模型作为公共资源发布。FluidGym实现了控制方法的系统性比较，为基于学习的流动控制研究建立了可扩展的基础平台，项目地址：https://github.com/safe-autonomous-systems/fluidgym。",
    "url": "https://huggingface.co/papers/2601.15015",
    "arxiv_url": "https://arxiv.org/abs/2601.15015"
  },
  {
    "title": "The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning",
    "summary": "As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.",
    "translation": "标题：智能的副作用：多模态大语言模型在多图像推理中的安全风险\n\n摘要：随着多模态大语言模型（MLLMs）在处理复杂多图像指令方面获得更强的推理能力，这一进步可能带来新的安全风险。我们通过引入首个专注于多图像推理安全的基准测试MIR-SafetyBench来研究此问题，该基准包含涵盖9种多图像关系分类的2,676个实例。我们对19个MLLMs进行的广泛评估揭示了一个令人担忧的趋势：具有更先进多图像推理能力的模型在MIR-SafetyBench上可能更加脆弱。除了攻击成功率之外，我们发现许多被标记为安全的回应是表面化的，通常源于误解或回避性的、不置可否的答复。我们进一步观察到，不安全的生成结果平均表现出比安全结果更低的注意力熵。这一内部特征表明，模型可能过度专注于任务解决而忽视安全约束，存在潜在风险。我们的代码和数据可在https://github.com/thu-coai/MIR-SafetyBench获取。",
    "url": "https://huggingface.co/papers/2601.14127",
    "arxiv_url": "https://arxiv.org/abs/2601.14127"
  },
  {
    "title": "Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models",
    "summary": "Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off.",
    "translation": "标题：少即是多——直至崩溃：大视觉语言模型中视觉令牌压缩的安全隐患\n\n摘要：视觉令牌压缩技术被广泛采用以提升大视觉语言模型（LVLMs）的推理效率，使其能够部署在延迟敏感和资源受限的场景中。然而，现有研究主要关注效率与性能，而视觉令牌压缩的安全影响在很大程度上尚未得到探索。本研究首次揭示，视觉令牌压缩会显著降低LVLMs的鲁棒性：在未压缩推理下表现稳健的模型，一旦启用压缩便会变得高度脆弱。这些漏洞具有状态特异性：故障模式仅在压缩设置下出现，并在禁用压缩时完全消失，这使得它们尤为隐蔽且难以诊断。通过分析压缩过程的关键阶段，我们发现令牌重要性排序的不稳定性是导致鲁棒性下降的主要原因。微小且难以察觉的扰动即可显著改变令牌排序，导致压缩机制错误地丢弃任务关键信息，最终引发模型故障。基于这一观察，我们提出了一种压缩感知攻击（CAA）来系统性地研究和利用此漏洞。CAA直接针对令牌选择机制，并仅在压缩推理下诱发故障。我们进一步将此方法扩展到更现实的“黑盒”场景，提出了迁移CAA，其中既无法访问目标模型，也无法获知其压缩配置。我们还评估了潜在的防御措施，发现其提供的保护作用有限。跨模型、数据集和压缩方法的广泛实验表明，视觉令牌压缩显著削弱了模型的鲁棒性，揭示了一个先前被忽视的效率与安全之间的权衡关系。",
    "url": "https://huggingface.co/papers/2601.12042",
    "arxiv_url": "https://arxiv.org/abs/2601.12042"
  },
  {
    "title": "MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts",
    "summary": "Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a \"tunnel vision\" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.",
    "translation": "标题：MortalMATH：评估推理目标与紧急情境之间的冲突\n\n摘要：大型语言模型正日益针对深度推理进行优化，其优先考虑复杂任务的正确执行，而非一般性对话。本研究探讨这种对计算能力的侧重是否会造成一种“隧道视野”，即在危急情况下忽视安全性。我们提出了MortalMATH基准测试，包含150个场景，其中用户在描述日益危及生命的紧急情况（例如中风症状、自由落体）的同时请求代数帮助。我们发现模型行为存在显著分化：通用模型（如Llama-3.1）能够成功拒绝数学请求以应对危险。相比之下，专用推理模型（如Qwen-3-32b和GPT-5-nano）常常完全忽略紧急情况，在用户描述濒死状态时仍保持超过95%的任务完成率。此外，推理所需的计算时间会引入危险的延迟：在提供任何潜在帮助前可能长达15秒。这些结果表明，训练模型不懈追求正确答案可能会无意中使其丧失安全部署所需的生存本能。",
    "url": "https://huggingface.co/papers/2601.18790",
    "arxiv_url": "https://arxiv.org/abs/2601.18790"
  },
  {
    "title": "HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs",
    "summary": "The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.",
    "translation": "标题：HalluGuard：解析大语言模型中数据驱动与推理驱动幻觉的生成机制\n\n摘要：大语言模型在医疗、法律与科学发现等高风险领域中的可靠性常因幻觉问题而受到损害。此类错误通常源于两类成因：数据驱动幻觉与推理驱动幻觉。然而，现有检测方法往往仅针对单一成因，且依赖特定任务的启发式规则，难以推广至复杂场景。为突破这些局限，我们提出“幻觉风险边界”理论框架，将幻觉风险形式化分解为数据驱动与推理驱动两个组成部分，分别对应训练阶段的数据失配与推理阶段的不稳定性，从而为系统分析幻觉的生成与演化机制奠定理论基础。基于此框架，我们进一步提出HalluGuard检测方法，通过构建基于神经正切核的量化指标，利用其诱导的几何结构与表征信息，实现对数据驱动与推理驱动幻觉的联合识别。我们在10个多样化基准测试集、11个竞争性基线方法与9个主流大语言模型架构上对HalluGuard进行评估，结果表明该方法在检测多种形式的大语言模型幻觉任务中均能取得最先进的性能表现。",
    "url": "https://huggingface.co/papers/2601.18753",
    "arxiv_url": "https://arxiv.org/abs/2601.18753"
  },
  {
    "title": "RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents",
    "summary": "Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.",
    "translation": "标题：RouteMoA：无需预推理的动态路由机制提升高效智能体混合架构性能\n\n摘要：智能体混合架构通过分层协作提升大语言模型性能，但其密集拓扑结构会增加计算成本与延迟。现有方法采用大语言模型作为评判器对响应进行筛选，但仍需所有模型在评判前完成推理，未能有效降低成本。这些方法缺乏模型选择标准，且难以应对大规模模型池场景——完整推理成本高昂并可能超出上下文长度限制。为此，我们提出RouteMoA，一种融合动态路由机制的高效智能体混合框架。该框架采用轻量化评分器，通过查询语句预测粗粒度性能指标进行初始筛选，在无需推理的情况下将候选模型缩减为高潜力子集。随后通过混合评判器基于现有模型输出进行轻量级自评估与交叉评估，实现无需额外推理的后验校正。最终通过平衡性能、成本与延迟的模型排序机制完成模型选择。实验表明，RouteMoA在不同任务与模型池规模下均优于传统智能体混合架构，在大规模模型池中可降低89.8%的成本并减少63.6%的延迟。",
    "url": "https://huggingface.co/papers/2601.18130",
    "arxiv_url": "https://arxiv.org/abs/2601.18130"
  },
  {
    "title": "TensorLens: End-to-End Transformer Analysis via High-Order Attention Tensors",
    "summary": "Attention matrices are fundamental to transformer research, supporting a broad range of applications including interpretability, visualization, manipulation, and distillation. Yet, most existing analyses focus on individual attention heads or layers, failing to account for the model's global behavior. While prior efforts have extended attention formulations across multiple heads via averaging and matrix multiplications or incorporated components such as normalization and FFNs, a unified and complete representation that encapsulates all transformer blocks is still lacking. We address this gap by introducing TensorLens, a novel formulation that captures the entire transformer as a single, input-dependent linear operator expressed through a high-order attention-interaction tensor. This tensor jointly encodes attention, FFNs, activations, normalizations, and residual connections, offering a theoretically coherent and expressive linear representation of the model's computation. TensorLens is theoretically grounded and our empirical validation shows that it yields richer representations than previous attention-aggregation methods. Our experiments demonstrate that the attention tensor can serve as a powerful foundation for developing tools aimed at interpretability and model understanding. Our code is attached as a supplementary.",
    "translation": "标题：TensorLens：基于高阶注意力张量的端到端Transformer分析\n\n摘要：注意力矩阵是Transformer研究的核心基础，支撑着包括可解释性、可视化、操控与蒸馏在内的广泛应用。然而，现有分析大多聚焦于单个注意力头或单层结构，未能充分考虑模型的全局行为。尽管先前研究已通过平均化、矩阵乘法等方式扩展了跨多头注意力的计算形式，或引入了归一化与前馈网络等组件，但仍缺乏一个能够完整封装所有Transformer模块的统一表征框架。为此，我们提出TensorLens这一创新性方法，通过构建高阶注意力交互张量，将整个Transformer模型表达为单一且依赖于输入的线性算子。该张量联合编码了注意力机制、前馈网络、激活函数、归一化操作与残差连接，从理论上提供了连贯且富有表现力的模型计算线性表征。TensorLens具有坚实的理论基础，实证研究表明其能生成比以往注意力聚合方法更丰富的表征。实验进一步证明，注意力张量可作为开发可解释性与模型理解工具的强大基础。相关代码已作为补充材料附上。",
    "url": "https://huggingface.co/papers/2601.17958",
    "arxiv_url": "https://arxiv.org/abs/2601.17958"
  },
  {
    "title": "Fast KVzip: Efficient and Accurate LLM Inference with Gated KV Eviction",
    "summary": "Efficient key-value (KV) cache management is crucial for the practical deployment of large language models (LLMs), yet existing compression techniques often incur a trade-off between performance degradation and computational overhead. We propose a novel gating-based KV cache eviction method for frozen-weight LLMs that achieves high compression ratios with negligible computational cost. Our approach introduces lightweight sink-attention gating modules to identify and retain critical KV pairs, and integrates seamlessly into both the prefill and decoding stages. The proposed gate training algorithm relies on forward passes of an LLM, avoiding expensive backpropagation, while achieving strong task generalization through a task-agnostic reconstruction objective. Extensive experiments across the Qwen2.5-1M, Qwen3, and Gemma3 families show that our method maintains near-lossless performance while evicting up to 70% of the KV cache. The results are consistent across a wide range of tasks, including long-context understanding, code comprehension, and mathematical reasoning, demonstrating the generality of our approach.",
    "translation": "标题：Fast KVzip：基于门控KV淘汰的高效准确大语言模型推理\n\n摘要：高效的键值（KV）缓存管理对于大语言模型的实际部署至关重要，然而现有的压缩技术往往需要在性能损失与计算开销之间进行权衡。本文针对权重冻结的大语言模型，提出一种新颖的基于门控机制的KV缓存淘汰方法，该方法能以可忽略的计算成本实现高压缩率。我们的方法引入了轻量级的汇聚注意力门控模块，用于识别并保留关键的KV对，并可无缝集成到预填充和解码两个阶段。所提出的门控训练算法仅依赖大语言模型的前向传播，避免了昂贵的反向传播过程，同时通过任务无关的重建目标实现了强大的任务泛化能力。在Qwen2.5-1M、Qwen3和Gemma3系列模型上的大量实验表明，本方法在淘汰高达70% KV缓存的同时，仍能保持近乎无损的性能。该结果在长文本理解、代码解析和数学推理等多种任务中均表现一致，充分证明了本方法的普适性。",
    "url": "https://huggingface.co/papers/2601.17668",
    "arxiv_url": "https://arxiv.org/abs/2601.17668"
  },
  {
    "title": "Agentic Search in the Wild: Intents and Trajectory Dynamics from 14M+ Real Search Requests",
    "summary": "LLM-powered search agents are increasingly being used for multi-step information seeking tasks, yet the IR community lacks empirical understanding of how agentic search sessions unfold and how retrieved evidence is used. This paper presents a large-scale log analysis of agentic search based on 14.44M search requests (3.97M sessions) collected from DeepResearchGym, i.e. an open-source search API accessed by external agentic clients. We sessionize the logs, assign session-level intents and step-wise query-reformulation labels using LLM-based annotation, and propose Context-driven Term Adoption Rate (CTAR) to quantify whether newly introduced query terms are traceable to previously retrieved evidence. Our analyses reveal distinctive behavioral patterns. First, over 90% of multi-turn sessions contain at most ten steps, and 89% of inter-step intervals fall under one minute. Second, behavior varies by intent. Fact-seeking sessions exhibit high repetition that increases over time, while sessions requiring reasoning sustain broader exploration. Third, agents reuse evidence across steps. On average, 54% of newly introduced query terms appear in the accumulated evidence context, with contributions from earlier steps beyond the most recent retrieval. The findings suggest that agentic search may benefit from repetition-aware early stopping, intent-adaptive retrieval budgets, and explicit cross-step context tracking. We plan to release the anonymized logs to support future research.",
    "translation": "标题：自主搜索在真实场景中的表现：基于1400万+真实搜索请求的意图与轨迹动态分析\n\n摘要：基于大语言模型的搜索智能体正日益广泛地应用于多步骤信息检索任务，然而信息检索领域对于自主搜索会话的实际展开方式及检索证据的运用机制仍缺乏实证理解。本文通过对DeepResearchGym（一个供外部自主客户端访问的开源搜索API）收集的1444万次搜索请求（397万个会话）进行大规模日志分析，系统探究了自主搜索行为。我们通过会话划分、基于大语言模型的会话级意图标注与分步查询重构标签分类，并提出上下文驱动术语采纳率指标，用以量化新引入查询术语是否可追溯至先前检索证据。分析揭示了以下显著行为模式：首先，超过90%的多轮会话包含不超过十个步骤，89%的步骤间间隔在一分钟以内；其次，不同意图会话呈现差异化特征——事实查询会话表现出随时间增强的高重复性，而需要推理的会话则持续保持更广泛的探索行为；第三，智能体在跨步骤间复用检索证据，平均54%的新引入查询术语出现在累积证据上下文中，且早期步骤的贡献超越最近一次检索结果。这些发现表明，自主搜索系统可能受益于重复感知的早停机制、意图自适应的检索资源分配以及显式的跨步骤上下文追踪。我们计划公开匿名化日志数据以支持后续研究。",
    "url": "https://huggingface.co/papers/2601.17617",
    "arxiv_url": "https://arxiv.org/abs/2601.17617"
  },
  {
    "title": "C-RADIOv4 (Tech Report)",
    "summary": "By leveraging multi-teacher distillation, agglomerative vision backbones provide a unified student model that retains and improves the distinct capabilities of multiple teachers. In this tech report, we describe the most recent release of the C-RADIO family of models, C-RADIOv4, which builds upon AM-RADIO/RADIOv2.5 in design, offering strong improvements on key downstream tasks at the same computational complexity. We release -SO400M (412M params), and -H (631M) model variants, both trained with an updated set of teachers: SigLIP2, DINOv3, and SAM3. In addition to improvements on core metrics and new capabilities from imitating SAM3, the C-RADIOv4 model family further improves any-resolution support, brings back the ViTDet option for drastically enhanced efficiency at high-resolution, and comes with a permissive license.",
    "translation": "标题：C-RADIOv4（技术报告）\n\n摘要：通过利用多教师蒸馏技术，聚合视觉骨干网络提供了一个统一的学生模型，该模型保留并提升了多位教师网络的独特能力。在本技术报告中，我们介绍了C-RADIO模型系列的最新版本C-RADIOv4。该版本基于AM-RADIO/RADIOv2.5的设计框架，在保持相同计算复杂度的前提下，显著提升了关键下游任务的性能。我们发布了-SO400M（参数4.12亿）和-H（参数6.31亿）两种模型变体，二者均采用更新的教师模型集合（SigLIP2、DINOv3和SAM3）进行训练。除了在核心指标上的提升以及通过模仿SAM3获得的新能力外，C-RADIOv4模型系列进一步增强了任意分辨率支持能力，重新引入了ViTDet选项以大幅提升高分辨率下的处理效率，并采用了宽松的开源许可协议。",
    "url": "https://huggingface.co/papers/2601.17237",
    "arxiv_url": "https://arxiv.org/abs/2601.17237"
  },
  {
    "title": "Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing",
    "summary": "Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.",
    "translation": "标题：Interp3D：基于对应关系的生成式纹理三维变形插值方法\n\n摘要：纹理三维变形旨在生成两个三维资产之间平滑且合理的过渡，同时保持结构连贯性与细粒度外观。该能力不仅对推动三维生成研究至关重要，也在动画制作、模型编辑及数字内容创作等实际应用中具有关键价值。现有方法或仅直接在几何结构上操作，局限于仅形状变形而忽略纹理；或将二维插值策略简单扩展至三维，常导致语义模糊、结构错位及纹理模糊等问题。这些挑战凸显了在过渡过程中同时保持几何一致性、纹理对齐与鲁棒性的必要性。为此，我们提出Interp3D——一种无需训练的新型纹理三维变形框架。该方法利用生成先验，并采用渐进对齐原则，以确保几何保真度与纹理连贯性。Interp3D从条件空间的语义对齐插值出发，通过结构化潜在表示引导的结构插值强化结构一致性，最终借助细粒度纹理融合实现外观细节迁移。为进行全面评估，我们构建了专用数据集Interp3DData，其包含多级难度样本，并从保真度、过渡平滑性与合理性三个维度对生成结果进行评估。定量指标与人工评估均表明，所提方法较现有技术具有显著优势。源代码公开于：https://github.com/xiaolul2/Interp3D。",
    "url": "https://huggingface.co/papers/2601.14103",
    "arxiv_url": "https://arxiv.org/abs/2601.14103"
  }
]