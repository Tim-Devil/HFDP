[
  {
    "title": "Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting",
    "summary": "Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as \"Confident Conflicts\" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.",
    "translation": "标题：熵自适应微调：解决置信冲突以缓解遗忘\n\n摘要：监督微调是领域适应的标准范式，但其常伴随灾难性遗忘的代价。与之形成鲜明对比的是，在线策略强化学习能有效保留模型的通用能力。我们深入探究这一差异，发现其根源在于根本性的分布差异：强化学习与模型内部信念保持一致，而监督微调则强制模型拟合外部监督信号。这种不匹配常表现为“置信冲突”标记——这些标记具有低概率但低熵的特征。在此类情况下，模型对其自身预测高度确信，却被强制学习相悖的真实标注，从而引发破坏性的梯度更新。为解决该问题，我们提出熵自适应微调方法。与仅依赖预测概率的方法不同，该方法利用标记层级的熵作为门控机制，以区分认知不确定性与知识冲突。这使得模型能够从不确定样本中学习，同时抑制冲突数据产生的梯度。我们在数学、医疗和智能体领域对千问及GLM系列模型（参数量覆盖40亿至320亿）开展的广泛实验验证了我们的假设。熵自适应微调在保持与标准监督微调相当的下游性能的同时，显著缓解了通用能力的退化。\n\n请按照以下格式返回：\n标题：[中文标题]\n摘要：[中文摘要]",
    "url": "https://huggingface.co/papers/2601.02151",
    "arxiv_url": "https://arxiv.org/abs/2601.02151"
  },
  {
    "title": "Evolving Programmatic Skill Networks",
    "summary": "We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\\footnote{We plan to open-source the code.",
    "translation": "标题：演化式程序化技能网络\n\n摘要：本研究探讨在开放式具身环境中智能体的持续技能获取问题，其需构建、优化并复用不断扩展的可执行技能库。我们提出程序化技能网络（PSN）框架，该框架将技能定义为可执行的符号化程序，形成通过经验演化的组合式网络。PSN通过大语言模型实例化三个核心机制：（1）基于结构化故障定位的REFLECT机制，用于技能组合的精准问题定位；（2）采用成熟度感知更新门控的渐进式优化策略，在稳定可靠技能的同时保持对不确定技能的适应性；（3）基于回滚验证的规范化结构重构机制，保障网络结构的紧凑性。研究进一步揭示PSN的学习动态与神经网络训练存在结构相似性。在MineDojo和Crafter环境中的实验表明，该系统在开放式任务分布中展现出鲁棒的技能复用能力、快速适应能力及强大的泛化性能。\\footnote{我们计划开源相关代码。}",
    "url": "https://huggingface.co/papers/2601.03509",
    "arxiv_url": "https://arxiv.org/abs/2601.03509"
  },
  {
    "title": "Atlas: Orchestrating Heterogeneous Models and Tools for Multi-Domain Complex Reasoning",
    "summary": "The integration of large language models (LLMs) with external tools has significantly expanded the capabilities of AI agents. However, as the diversity of both LLMs and tools increases, selecting the optimal model-tool combination becomes a high-dimensional optimization challenge. Existing approaches often rely on a single model or fixed tool-calling logic, failing to exploit the performance variations across heterogeneous model-tool pairs. In this paper, we present ATLAS (Adaptive Tool-LLM Alignment and Synergistic Invocation), a dual-path framework for dynamic tool usage in cross-domain complex reasoning. ATLAS operates via a dual-path approach: (1) training-free cluster-based routing that exploits empirical priors for domain-specific alignment, and (2) RL-based multi-step routing that explores autonomous trajectories for out-of-distribution generalization. Extensive experiments across 15 benchmarks demonstrate that our method outperforms closed-source models like GPT-4o, surpassing existing routing methods on both in-distribution (+10.1%) and out-of-distribution (+13.1%) tasks. Furthermore, our framework shows significant gains in visual reasoning by orchestrating specialized multi-modal tools.",
    "translation": "标题：Atlas：面向多领域复杂推理的异构模型与工具协同编排框架\n\n摘要：大型语言模型（LLM）与外部工具的融合显著扩展了智能代理的能力。然而，随着模型与工具多样性的增加，选择最优的模型-工具组合已成为一个高维优化难题。现有方法通常依赖单一模型或固定的工具调用逻辑，未能充分利用异构模型-工具组合间的性能差异。本文提出ATLAS（自适应工具-模型对齐与协同调用框架），一种面向跨领域复杂推理的动态工具调用双路径框架。ATLAS通过双路径机制运行：（1）基于无训练聚类路由，利用经验先验实现领域自适应对齐；（2）基于强化学习的多步路由，通过自主轨迹探索实现分布外泛化。在15个基准测试上的大量实验表明，本方法在分布内任务（+10.1%）和分布外任务（+13.1%）上均超越GPT-4o等闭源模型，并显著优于现有路由方法。此外，通过协同编排专用多模态工具，本框架在视觉推理任务中展现出显著性能提升。",
    "url": "https://huggingface.co/papers/2601.03872",
    "arxiv_url": "https://arxiv.org/abs/2601.03872"
  },
  {
    "title": "Benchmark^2: Systematic Evaluation of LLM Benchmarks",
    "summary": "The rapid proliferation of benchmarks for evaluating large language models (LLMs) has created an urgent need for systematic methods to assess benchmark quality itself. We propose Benchmark^2, a comprehensive framework comprising three complementary metrics: (1) Cross-Benchmark Ranking Consistency, measuring whether a benchmark produces model rankings aligned with peer benchmarks; (2) Discriminability Score, quantifying a benchmark's ability to differentiate between models; and (3) Capability Alignment Deviation, identifying problematic instances where stronger models fail but weaker models succeed within the same model family. We conduct extensive experiments across 15 benchmarks spanning mathematics, reasoning, and knowledge domains, evaluating 11 LLMs across four model families. Our analysis reveals significant quality variations among existing benchmarks and demonstrates that selective benchmark construction based on our metrics can achieve comparable evaluation performance with substantially reduced test sets.",
    "translation": "标题：Benchmark^2：大语言模型基准测试的系统性评估\n\n摘要：用于评估大语言模型的基准测试数量激增，亟需系统性的方法来评估基准测试本身的质量。我们提出了Benchmark^2，这是一个包含三个互补指标的综合性框架：（1）跨基准排名一致性，用于衡量一个基准测试产生的模型排名是否与其他同类基准测试的结果一致；（2）区分度评分，用于量化基准测试区分不同模型的能力；（3）能力对齐偏差，用于识别同一模型系列中更强模型失败而更弱模型却成功的异常测试实例。我们在涵盖数学、推理和知识领域的15个基准测试上进行了广泛实验，评估了来自四个模型系列的11个大语言模型。我们的分析揭示了现有基准测试之间存在显著的质量差异，并证明基于我们提出的指标进行选择性基准构建，能够在使用大幅缩减的测试集的情况下，获得可比较的评估性能。",
    "url": "https://huggingface.co/papers/2601.03986",
    "arxiv_url": "https://arxiv.org/abs/2601.03986"
  },
  {
    "title": "ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition",
    "summary": "Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimating return over investment (ROI), and allocating computation strategically. We propose ROI-Reasoning, a two-stage framework that endows LLMs with intrinsic, budget-aware rationality. In the first stage, Meta-Cognitive Fine-Tuning teaches models to predict reasoning cost and expected utility before generation, enabling explicit solve-or-skip decisions. Next, Rationality-Aware Reinforcement Learning optimizes sequential decision making under a hard token budget, allowing models to learn long-horizon allocation strategies. Across budgeted mathematical reasoning benchmarks, ROI-Reasoning consistently improves overall score while substantially reducing regret under tight computation budgets.",
    "translation": "标题：ROI推理：基于预计算元认知的推理理性优化\n\n摘要：大型语言模型在充足计算资源支持下可实现强大的推理性能，但其本身无法预知任务所需计算量。本研究针对严格全局令牌约束下的多任务推理场景，将其形式化为有序随机多选择背包问题。该视角揭示出元认知需求——需要预判任务难度、评估投资回报率并策略性分配计算资源。我们提出ROI推理框架，通过两阶段训练赋予大型语言模型内在的预算感知理性能力。第一阶段通过元认知微调使模型在生成前预测推理成本与期望效用，实现显式的\"求解-跳过\"决策机制。第二阶段采用理性感知强化学习，在硬性令牌预算约束下优化序列决策，使模型掌握长时程资源分配策略。在多个预算约束数学推理基准测试中，ROI推理框架在严格计算预算下持续提升总体得分，同时显著降低决策遗憾度。",
    "url": "https://huggingface.co/papers/2601.03822",
    "arxiv_url": "https://arxiv.org/abs/2601.03822"
  },
  {
    "title": "Klear: Unified Multi-Task Audio-Video Joint Generation",
    "summary": "Audio-video joint generation has progressed rapidly, yet substantial challenges still remain. Non-commercial approaches still suffer audio-visual asynchrony, poor lip-speech alignment, and unimodal degradation, which can be stemmed from weak audio-visual correspondence modeling, limited generalization, and scarce high-quality dense-caption data. To address these issues, we introduce Klear and delve into three axes--model architecture, training strategy, and data curation. Architecturally, we adopt a single-tower design with unified DiT blocks and an Omni-Full Attention mechanism, achieving tight audio-visual alignment and strong scalability. Training-wise, we adopt a progressive multitask regime--random modality masking to joint optimization across tasks, and a multistage curriculum, yielding robust representations, strengthening A-V aligned world knowledge, and preventing unimodal collapse. For datasets, we present the first large-scale audio-video dataset with dense captions, and introduce a novel automated data-construction pipeline which annotates and filters millions of diverse, high-quality, strictly aligned audio-video-caption triplets. Building on this, Klear scales to large datasets, delivering high-fidelity, semantically and temporally aligned, instruction-following generation in both joint and unimodal settings while generalizing robustly to out-of-distribution scenarios. Across tasks, it substantially outperforms prior methods by a large margin and achieves performance comparable to Veo 3, offering a unified, scalable path toward next-generation audio-video synthesis.",
    "translation": "标题：Klear：统一多任务音视频联合生成\n\n摘要：音视频联合生成技术发展迅速，但仍面临重大挑战。非商业化方法仍存在音视频异步、唇语-语音对齐不佳及单模态退化等问题，其根源在于音视频对应关系建模薄弱、泛化能力有限以及高质量密集标注数据稀缺。为解决这些问题，我们提出Klear系统，并从三个维度展开研究——模型架构、训练策略与数据构建。在架构层面，我们采用统一DiT模块的单塔式设计及全向全局注意力机制，实现了紧密的音视频对齐与强大的可扩展性。在训练策略上，我们采用渐进式多任务范式——通过随机模态掩码实现跨任务联合优化，结合多阶段课程学习，从而获得鲁棒的表示、强化音视频对齐的世界知识并防止单模态崩溃。数据方面，我们构建了首个大规模带密集标注的音视频数据集，并提出创新的自动化数据构建流程，可标注并筛选数百万条多样化、高质量、严格对齐的音视频-文本三元组。基于此，Klear能够扩展至大规模数据集，在联合生成与单模态生成场景中均能实现高保真度、语义与时序对齐的指令跟随生成，并对分布外场景展现出强大的泛化能力。在多项任务评估中，本方法显著超越现有技术，达到与Veo 3相当的性能，为下一代音视频合成提供了统一且可扩展的技术路径。",
    "url": "https://huggingface.co/papers/2601.04151",
    "arxiv_url": "https://arxiv.org/abs/2601.04151"
  },
  {
    "title": "Choreographing a World of Dynamic Objects",
    "summary": "Dynamic objects in our physical 4D (3D + time) world are constantly evolving, deforming, and interacting with other objects, leading to diverse 4D scene dynamics. In this paper, we present a universal generative pipeline, CHORD, for CHOReographing Dynamic objects and scenes and synthesizing this type of phenomena. Traditional rule-based graphics pipelines to create these dynamics are based on category-specific heuristics, yet are labor-intensive and not scalable. Recent learning-based methods typically demand large-scale datasets, which may not cover all object categories in interest. Our approach instead inherits the universality from the video generative models by proposing a distillation-based pipeline to extract the rich Lagrangian motion information hidden in the Eulerian representations of 2D videos. Our method is universal, versatile, and category-agnostic. We demonstrate its effectiveness by conducting experiments to generate a diverse range of multi-body 4D dynamics, show its advantage compared to existing methods, and demonstrate its applicability in generating robotics manipulation policies. Project page: https://yanzhelyu.github.io/chord",
    "translation": "标题：动态物体世界的编排\n\n摘要：在我们所处的物理四维（三维空间+时间）世界中，动态物体持续演化、形变并与其他物体相互作用，形成了多样化的四维场景动态。本文提出了一种通用生成框架CHORD，用于编排动态物体与场景并合成此类现象。传统基于规则的图形学流程虽能创建此类动态，但依赖于特定类别的启发式方法，不仅耗时费力且难以扩展。近期基于学习的方法通常需要大规模数据集，而这些数据集可能无法覆盖所有目标物体类别。我们的方法通过提出一种基于蒸馏的流程，从二维视频的欧拉表示中提取隐藏的丰富拉格朗日运动信息，从而继承了视频生成模型的普适性。本方法具有通用性、多功能性且不依赖特定类别。我们通过生成多样化多体四维动态的实验验证了其有效性，展示了相较于现有方法的优势，并证明了其在生成机器人操作策略中的适用性。项目页面：https://yanzhelyu.github.io/chord",
    "url": "https://huggingface.co/papers/2601.04194",
    "arxiv_url": "https://arxiv.org/abs/2601.04194"
  },
  {
    "title": "Agentic Rubrics as Contextual Verifiers for SWE Agents",
    "summary": "Verification is critical for improving agents: it provides the reward signal for Reinforcement Learning and enables inference-time gains through Test-Time Scaling (TTS). Despite its importance, verification in software engineering (SWE) agent settings often relies on code execution, which can be difficult to scale due to environment setup overhead. Scalable alternatives such as patch classifiers and heuristic methods exist, but they are less grounded in codebase context and harder to interpret. To this end, we explore Agentic Rubrics: an expert agent interacts with the repository to create a context-grounded rubric checklist, and candidate patches are then scored against it without requiring test execution. On SWE-Bench Verified under parallel TTS evaluation, Agentic Rubrics achieve a score of 54.2% on Qwen3-Coder-30B-A3B and 40.6% on Qwen3-32B, with at least a +3.5 percentage-point gain over the strongest baseline in our comparison set. We further analyze rubric behavior, showing that rubric scores are consistent with ground-truth tests while also flagging issues that tests do not capture. Our ablations show that agentic context gathering is essential for producing codebase-specific, unambiguous criteria. Together, these results suggest that Agentic Rubrics provide an efficient, scalable, and granular verification signal for SWE agents.",
    "translation": "标题：作为软件工程智能体情境验证器的能动性评估准则\n\n摘要：验证对于改进智能体至关重要：它为强化学习提供奖励信号，并通过测试时扩展技术实现推理阶段的性能提升。尽管验证在软件工程智能体场景中具有重要意义，当前方法仍主要依赖代码执行，而环境配置开销使得该方法难以扩展。虽然存在补丁分类器和启发式方法等可扩展替代方案，但这些方法往往缺乏代码库情境支撑且可解释性较弱。为此，我们提出“能动性评估准则”方法：专家智能体通过交互式分析代码仓库，生成基于具体情境的评估清单，随后在不执行测试的情况下依据该清单对候选补丁进行评分。在并行测试时扩展评估框架下的SWE-Bench Verified基准测试中，该方法在Qwen3-Coder-30B-A3B模型上获得54.2%的得分，在Qwen3-32B模型上获得40.6%的得分，较对比组中最强基线模型提升至少3.5个百分点。我们进一步分析评估准则的行为特征，证明其评分结果与真实测试结果具有一致性，同时能识别传统测试未能捕捉的问题。消融实验表明，智能体驱动的情境收集机制对于生成针对特定代码库的明确评估标准具有关键作用。综合而言，这些结果表明能动性评估准则能为软件工程智能体提供高效、可扩展且精细化的验证信号。",
    "url": "https://huggingface.co/papers/2601.04171",
    "arxiv_url": "https://arxiv.org/abs/2601.04171"
  },
  {
    "title": "MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics",
    "summary": "Molecular dynamics (MD) simulations are essential for understanding atomic-scale behaviors in materials science, yet writing LAMMPS scripts remains highly specialized and time-consuming tasks. Although LLMs show promise in code generation and domain-specific question answering, their performance in MD scenarios is limited by scarce domain data, the high deployment cost of state-of-the-art LLMs, and low code executability. Building upon our prior MDAgent, we present MDAgent2, the first end-to-end framework capable of performing both knowledge Q&A and code generation within the MD domain. We construct a domain-specific data-construction pipeline that yields three high-quality datasets spanning MD knowledge, question answering, and code generation. Based on these datasets, we adopt a three stage post-training strategy--continued pre-training (CPT), supervised fine-tuning (SFT), and reinforcement learning (RL)--to train two domain-adapted models, MD-Instruct and MD-Code. Furthermore, we introduce MD-GRPO, a closed-loop RL method that leverages simulation outcomes as reward signals and recycles low-reward trajectories for continual refinement. We further build MDAgent2-RUNTIME, a deployable multi-agent system that integrates code generation, execution, evaluation, and self-correction. Together with MD-EvalBench proposed in this work, the first benchmark for LAMMPS code generation and question answering, our models and system achieve performance surpassing several strong baselines.This work systematically demonstrates the adaptability and generalization capability of large language models in industrial simulation tasks, laying a methodological foundation for automatic code generation in AI for Science and industrial-scale simulations. URL: https://github.com/FredericVAN/PKU_MDAgent2",
    "translation": "标题：MDAgent2：面向分子动力学代码生成与知识问答的大语言模型\n\n摘要：分子动力学模拟在材料科学的原子尺度行为研究中具有关键作用，但编写LAMMPS脚本仍是高度专业化且耗时的工作。尽管大语言模型在代码生成和领域特定问答任务中展现出潜力，但其在分子动力学场景中的应用仍受限于领域数据稀缺、前沿大语言模型部署成本高昂以及代码可执行率低等问题。基于我们先前开发的MDAgent，本文提出MDAgent2——首个能够在分子动力学领域同时实现知识问答与代码生成的端到端框架。我们构建了领域专用的数据生成流程，产出涵盖分子动力学知识、问答与代码生成的三类高质量数据集。基于这些数据集，我们采用三阶段训练策略（持续预训练、监督微调与强化学习）训练出两个领域适应模型：MD-Instruct与MD-Code。此外，我们提出MD-GRPO强化学习方法，通过模拟结果作为奖励信号，并循环利用低奖励轨迹实现持续优化。我们进一步开发了可部署的多智能体系统MDAgent2-RUNTIME，集成代码生成、执行、评估与自我修正功能。结合本文提出的首个LAMMPS代码生成与问答评估基准MD-EvalBench，我们的模型与系统在多项指标上超越现有基线方法。本工作系统论证了大语言模型在工业仿真任务中的适应性与泛化能力，为“AI for Science”及工业级模拟的自动化代码生成奠定了方法论基础。项目地址：https://github.com/FredericVAN/PKU_MDAgent2",
    "url": "https://huggingface.co/papers/2601.02075",
    "arxiv_url": "https://arxiv.org/abs/2601.02075"
  },
  {
    "title": "E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models",
    "summary": "Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.",
    "translation": "标题：E-GRPO：高熵步长驱动流模型的有效强化学习\n\n摘要：近期强化学习技术提升了流匹配模型在人类偏好对齐任务中的表现。虽然随机采样能够探索去噪方向，但现有在多步去噪过程中进行优化的方法常面临奖励信号稀疏且模糊的问题。我们观察到，高熵步长能够实现更高效、更有效的探索，而低熵步长则会导致生成轨迹缺乏区分度。为此，我们提出E-GRPO，一种基于熵感知的分组相对策略优化方法，旨在提高随机微分方程采样步长的熵值。由于随机微分方程的积分过程会因多步随机性而产生模糊的奖励信号，我们特别将连续的低熵步长合并为一个高熵步长用于随机微分方程采样，而对其他步长采用常微分方程采样。在此基础上，我们引入了多步分组归一化优势函数，该函数在共享同一合并去噪步长的样本组内计算组间相对优势。在不同奖励设置下的实验结果验证了我们方法的有效性。",
    "url": "https://huggingface.co/papers/2601.00423",
    "arxiv_url": "https://arxiv.org/abs/2601.00423"
  },
  {
    "title": "EpiQAL: Benchmarking Large Language Models in Epidemiological Question Answering for Enhanced Alignment and Reasoning",
    "summary": "Reliable epidemiological reasoning requires synthesizing study evidence to infer disease burden, transmission dynamics, and intervention effects at the population level. Existing medical question answering benchmarks primarily emphasize clinical knowledge or patient-level reasoning, yet few systematically evaluate evidence-grounded epidemiological inference. We present EpiQAL, the first diagnostic benchmark for epidemiological question answering across diverse diseases, comprising three subsets built from open-access literature. The subsets respectively evaluate text-grounded factual recall, multi-step inference linking document evidence with epidemiological principles, and conclusion reconstruction with the Discussion section withheld. Construction combines expert-designed taxonomy guidance, multi-model verification, and retrieval-based difficulty control. Experiments on ten open models reveal that current LLMs show limited performance on epidemiological reasoning, with multi-step inference posing the greatest challenge. Model rankings shift across subsets, and scale alone does not predict success. Chain-of-Thought prompting benefits multi-step inference but yields mixed results elsewhere. EpiQAL provides fine-grained diagnostic signals for evidence grounding, inferential reasoning, and conclusion reconstruction.",
    "translation": "标题：EpiQAL：面向增强对齐与推理能力的流行病学问答大语言模型评测基准\n\n摘要：可靠的流行病学推理需要综合研究证据，以推断人群层面的疾病负担、传播动态和干预效果。现有的医学问答评测基准主要侧重于临床知识或患者层面的推理，但鲜有系统评估基于证据的流行病学推断能力。本研究提出EpiQAL——首个涵盖多种疾病的流行病学问答诊断性评测基准，该基准包含基于开放获取文献构建的三个子集。这些子集分别评估基于文本的事实召回能力、连接文献证据与流行病学原理的多步推理能力，以及隐藏讨论部分情况下的结论重构能力。基准构建过程融合了专家设计的分类学指导、多模型验证和基于检索的难度控制。对十个开源模型的实验表明，当前大语言模型在流行病学推理任务上表现有限，其中多步推理任务挑战最大。模型在不同子集上的排名存在波动，且仅靠模型规模无法预测其表现。思维链提示策略对多步推理任务有所助益，但在其他任务中效果参差不齐。EpiQAL为证据锚定、推断推理和结论重构能力提供了细粒度的诊断信号。",
    "url": "https://huggingface.co/papers/2601.03471",
    "arxiv_url": "https://arxiv.org/abs/2601.03471"
  },
  {
    "title": "RedBench: A Universal Dataset for Comprehensive Red Teaming of Large Language Models",
    "summary": "As large language models (LLMs) become integral to safety-critical applications, ensuring their robustness against adversarial prompts is paramount. However, existing red teaming datasets suffer from inconsistent risk categorizations, limited domain coverage, and outdated evaluations, hindering systematic vulnerability assessments. To address these challenges, we introduce RedBench, a universal dataset aggregating 37 benchmark datasets from leading conferences and repositories, comprising 29,362 samples across attack and refusal prompts. RedBench employs a standardized taxonomy with 22 risk categories and 19 domains, enabling consistent and comprehensive evaluations of LLM vulnerabilities. We provide a detailed analysis of existing datasets, establish baselines for modern LLMs, and open-source the dataset and evaluation code. Our contributions facilitate robust comparisons, foster future research, and promote the development of secure and reliable LLMs for real-world deployment. Code: https://github.com/knoveleng/redeval",
    "translation": "标题：RedBench：面向大型语言模型全面红队测试的通用数据集\n\n摘要：随着大型语言模型（LLM）在安全关键型应用中的普及，确保其对抗性提示的鲁棒性至关重要。然而，现有红队测试数据集存在风险分类不一致、领域覆盖有限及评估方法过时等问题，阻碍了系统化的漏洞评估。为应对这些挑战，我们提出了RedBench——一个聚合了来自顶级学术会议与开源仓库的37个基准数据集的通用数据集，共包含29,362个涵盖攻击性提示与拒绝性提示的样本。RedBench采用包含22个风险类别和19个领域的标准化分类体系，能够对LLM漏洞进行一致且全面的评估。我们系统分析了现有数据集，为现代LLM建立了性能基线，并开源了数据集与评估代码。本研究的贡献在于：推动鲁棒性比较研究，促进未来安全评估工作的发展，并为实际场景中安全可靠LLM的部署提供支持。代码地址：https://github.com/knoveleng/redeval",
    "url": "https://huggingface.co/papers/2601.03699",
    "arxiv_url": "https://arxiv.org/abs/2601.03699"
  },
  {
    "title": "Why LLMs Aren't Scientists Yet: Lessons from Four Autonomous Research Attempts",
    "summary": "We report a case study of four end-to-end attempts to autonomously generate ML research papers using a pipeline of six LLM agents mapped to stages of the scientific workflow. Of these four, three attempts failed during implementation or evaluation. One completed the pipeline and was accepted to Agents4Science 2025, an experimental inaugural venue that required AI systems as first authors, passing both human and multi-AI review. From these attempts, we document six recurring failure modes: bias toward training data defaults, implementation drift under execution pressure, memory and context degradation across long-horizon tasks, overexcitement that declares success despite obvious failures, insufficient domain intelligence, and weak scientific taste in experimental design. We conclude by discussing four design principles for more robust AI-scientist systems, implications for autonomous scientific discovery, and we release all prompts, artifacts, and outputs at https://github.com/Lossfunk/ai-scientist-artefacts-v1",
    "translation": "标题：为何大语言模型尚未成为科学家：从四次自主研究尝试中汲取的教训\n\n摘要：本文报告了一项案例研究，通过构建由六个大语言模型智能体组成的流程，对应科学工作流程的不同阶段，进行了四次端到端的自主生成机器学习研究论文的尝试。在这四次尝试中，三次在实施或评估阶段失败。其中一次成功完成了全流程，其成果被要求以人工智能系统为第一作者的实验性首届会议Agents4Science 2025接收，并同时通过了人类评审与多智能体评审。基于这些尝试，我们记录了六种反复出现的失败模式：倾向于训练数据默认设定、执行压力下的实施偏移、长周期任务中的记忆与上下文退化、面对明显失败仍过度兴奋地宣布成功、领域智能不足，以及实验设计中的科学品味薄弱。最后，我们讨论了构建更稳健的AI-科学家系统的四项设计原则，分析了其对自主科学发现的意义，并公开了所有提示词、过程产物及输出结果，详见 https://github.com/Lossfunk/ai-scientist-artefacts-v1。",
    "url": "https://huggingface.co/papers/2601.03315",
    "arxiv_url": "https://arxiv.org/abs/2601.03315"
  },
  {
    "title": "ThinkRL-Edit: Thinking in Reinforcement Learning for Reasoning-Centric Image Editing",
    "summary": "Instruction-driven image editing with unified multimodal generative models has advanced rapidly, yet their underlying visual reasoning remains limited, leading to suboptimal performance on reasoning-centric edits. Reinforcement learning (RL) has been investigated for improving the quality of image editing, but it faces three key challenges: (1) limited reasoning exploration confined to denoising stochasticity, (2) biased reward fusion, and (3) unstable VLM-based instruction rewards. In this work, we propose ThinkRL-Edit, a reasoning-centric RL framework that decouples visual reasoning from image synthesis and expands reasoning exploration beyond denoising. To the end, we introduce Chain-of-Thought (CoT)-based reasoning sampling with planning and reflection stages prior to generation in online sampling, compelling the model to explore multiple semantic hypotheses and validate their plausibility before committing to a visual outcome. To avoid the failures of weighted aggregation, we propose an unbiased chain preference grouping strategy across multiple reward dimensions. Moreover, we replace interval-based VLM scores with a binary checklist, yielding more precise, lower-variance, and interpretable rewards for complex reasoning. Experiments show our method significantly outperforms prior work on reasoning-centric image editing, producing instruction-faithful, visually coherent, and semantically grounded edits.",
    "translation": "标题：ThinkRL-Edit：基于强化学习思维推理的图像编辑方法\n\n摘要：基于统一多模态生成模型的指令驱动图像编辑技术发展迅速，但其底层的视觉推理能力仍然有限，导致在以推理为核心的编辑任务中表现欠佳。强化学习已被探索用于提升图像编辑质量，但面临三个关键挑战：(1) 受限于去噪随机性的推理探索空间不足，(2) 存在偏置的奖励融合机制，以及(3) 基于视觉语言模型的指令奖励不稳定。本研究提出ThinkRL-Edit——一个以推理为核心的强化学习框架，该框架将视觉推理与图像合成解耦，并将推理探索拓展至去噪过程之外。为此，我们引入基于思维链的推理采样机制，在在线采样的生成阶段前设置规划与反思环节，迫使模型在确定视觉输出前探索多种语义假设并验证其合理性。为避免加权聚合的失效问题，我们提出跨多奖励维度的无偏链式偏好分组策略。此外，我们将基于区间的视觉语言模型评分替换为二元检查表，从而为复杂推理任务提供更精确、低方差且可解释的奖励机制。实验表明，本方法在以推理为核心的图像编辑任务上显著优于现有技术，能够生成符合指令要求、视觉连贯且语义可靠的编辑结果。",
    "url": "https://huggingface.co/papers/2601.03467",
    "arxiv_url": "https://arxiv.org/abs/2601.03467"
  },
  {
    "title": "Enhancing Linguistic Competence of Language Models through Pre-training with Language Learning Tasks",
    "summary": "Language models (LMs) are pre-trained on raw text datasets to generate text sequences token-by-token. While this approach facilitates the learning of world knowledge and reasoning, it does not explicitly optimize for linguistic competence. To bridge this gap, we propose L2T, a pre-training framework integrating Language Learning Tasks alongside standard next-token prediction. Inspired by human language acquisition, L2T transforms raw text into structured input-output pairs to provide explicit linguistic stimulation. Pre-training LMs on a mixture of raw text and L2T data not only improves overall performance on linguistic competence benchmarks but accelerates its acquisition, while maintaining competitive performance on general reasoning tasks.",
    "translation": "标题：通过语言学习任务预训练增强语言模型的语言能力\n\n摘要：语言模型通常在原始文本数据集上进行预训练，以逐词生成文本序列。虽然这种方法有助于学习世界知识和推理能力，但并未明确优化语言能力。为弥补这一差距，我们提出L2T预训练框架，将语言学习任务与标准的下一个词预测相结合。受人类语言习得过程启发，L2T将原始文本转化为结构化输入-输出对，以提供明确的语言刺激。在原始文本与L2T数据的混合数据集上预训练语言模型，不仅能提升语言能力基准测试的整体表现、加速语言能力习得，同时能在通用推理任务中保持竞争优势。",
    "url": "https://huggingface.co/papers/2601.03448",
    "arxiv_url": "https://arxiv.org/abs/2601.03448"
  },
  {
    "title": "Pearmut: Human Evaluation of Translation Made Trivial",
    "summary": "Human evaluation is the gold standard for multilingual NLP, but is often skipped in practice and substituted with automatic metrics, because it is notoriously complex and slow to set up with existing tools with substantial engineering and operational overhead. We introduce Pearmut, a lightweight yet feature-rich platform that makes end-to-end human evaluation as easy to run as automatic evaluation. Pearmut removes common entry barriers and provides support for evaluating multilingual tasks, with a particular focus on machine translation. The platform implements standard evaluation protocols, including DA, ESA, or MQM, but is also extensible to allow prototyping new protocols. It features document-level context, absolute and contrastive evaluation, attention checks, ESAAI pre-annotations and both static and active learning-based assignment strategies. Pearmut enables reliable human evaluation to become a practical, routine component of model development and diagnosis rather than an occasional effort.",
    "translation": "标题：Pearmut：轻松实现翻译的人工评估\n\n摘要：人工评估是多语言自然语言处理领域的黄金标准，但在实践中常因现有工具设置复杂、耗时且需大量工程与运维投入而被自动指标替代。我们推出Pearmut——一个轻量级但功能丰富的平台，使端到端人工评估能像自动评估一样简便运行。该平台消除了常见的入门障碍，支持多语言任务评估，尤其专注于机器翻译领域。Pearmut实现了包括直接评估、错误标注评估、多维质量度量在内的标准评估协议，同时具备可扩展性以支持新协议的原型设计。其核心功能涵盖文档级上下文评估、绝对与对比评估、注意力检查、基于ESAAI的预标注，以及静态与主动学习驱动的任务分配策略。通过Pearmut，可靠的人工评估得以成为模型开发与诊断中实用且常规的组成部分，而非偶然性工作。",
    "url": "https://huggingface.co/papers/2601.02933",
    "arxiv_url": "https://arxiv.org/abs/2601.02933"
  },
  {
    "title": "Gen3R: 3D Scene Generation Meets Feed-Forward Reconstruction",
    "summary": "We present Gen3R, a method that bridges the strong priors of foundational reconstruction models and video diffusion models for scene-level 3D generation. We repurpose the VGGT reconstruction model to produce geometric latents by training an adapter on its tokens, which are regularized to align with the appearance latents of pre-trained video diffusion models. By jointly generating these disentangled yet aligned latents, Gen3R produces both RGB videos and corresponding 3D geometry, including camera poses, depth maps, and global point clouds. Experiments demonstrate that our approach achieves state-of-the-art results in single- and multi-image conditioned 3D scene generation. Additionally, our method can enhance the robustness of reconstruction by leveraging generative priors, demonstrating the mutual benefit of tightly coupling reconstruction and generative models.",
    "translation": "标题：Gen3R：三维场景生成与前馈式重建的融合\n\n摘要：本文提出Gen3R方法，该方法通过桥接基础重建模型与视频扩散模型的强先验知识，实现场景级三维生成。我们重新利用VGGT重建模型，通过在其特征标记上训练适配器来生成几何隐变量，并对其进行正则化以与预训练视频扩散模型的外观隐变量对齐。通过联合生成这些解耦但对齐的隐变量，Gen3R能够同时生成RGB视频及对应的三维几何信息（包括相机位姿、深度图和全局点云）。实验表明，我们的方法在单图像与多图像条件化三维场景生成任务中均达到了最先进的性能。此外，本方法能够通过利用生成先验增强重建的鲁棒性，证明了重建模型与生成模型的紧密耦合具有相互促进的效益。",
    "url": "https://huggingface.co/papers/2601.04090",
    "arxiv_url": "https://arxiv.org/abs/2601.04090"
  },
  {
    "title": "ResTok: Learning Hierarchical Residuals in 1D Visual Tokenizers for Autoregressive Image Generation",
    "summary": "Existing 1D visual tokenizers for autoregressive (AR) generation largely follow the design principles of language modeling, as they are built directly upon transformers whose priors originate in language, yielding single-hierarchy latent tokens and treating visual data as flat sequential token streams. However, this language-like formulation overlooks key properties of vision, particularly the hierarchical and residual network designs that have long been essential for convergence and efficiency in visual models. To bring \"vision\" back to vision, we propose the Residual Tokenizer (ResTok), a 1D visual tokenizer that builds hierarchical residuals for both image tokens and latent tokens. The hierarchical representations obtained through progressively merging enable cross-level feature fusion at each layer, substantially enhancing representational capacity. Meanwhile, the semantic residuals between hierarchies prevent information overlap, yielding more concentrated latent distributions that are easier for AR modeling. Cross-level bindings consequently emerge without any explicit constraints. To accelerate the generation process, we further introduce a hierarchical AR generator that substantially reduces sampling steps by predicting an entire level of latent tokens at once rather than generating them strictly token-by-token. Extensive experiments demonstrate that restoring hierarchical residual priors in visual tokenization significantly improves AR image generation, achieving a gFID of 2.34 on ImageNet-256 with only 9 sampling steps. Code is available at https://github.com/Kwai-Kolors/ResTok.",
    "translation": "标题：ResTok：面向自回归图像生成的一维视觉分词器层次残差学习\n\n摘要：现有用于自回归生成的一维视觉分词器主要遵循语言建模的设计原则，因其直接基于先验源自语言领域的Transformer构建，仅生成单层次潜在标记并将视觉数据视为扁平化的序列标记流。然而，这种类语言范式忽视了视觉任务的关键特性，尤其是长期以来对视觉模型收敛性与效率至关重要的层次化结构与残差网络设计。为使视觉任务回归其本质，我们提出残差分词器（ResTok），这是一种通过构建图像标记与潜在标记双重层次残差的一维视觉分词器。通过渐进式融合获得的层次化表征可在每一层实现跨层级特征融合，显著提升表征能力。同时，层次间的语义残差可避免信息重叠，形成更集中的潜在分布，从而更易于自回归建模。跨层级绑定关系由此自然涌现而无需显式约束。为加速生成过程，我们进一步提出层次化自回归生成器，通过一次性预测整层潜在标记而非严格逐标记生成，大幅减少采样步骤。大量实验表明，在视觉分词中恢复层次残差先验能显著提升自回归图像生成质量，在ImageNet-256数据集上仅需9步采样即可达到2.34的gFID指标。代码已开源：https://github.com/Kwai-Kolors/ResTok。",
    "url": "https://huggingface.co/papers/2601.03955",
    "arxiv_url": "https://arxiv.org/abs/2601.03955"
  },
  {
    "title": "MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents",
    "summary": "Memory-Augmented Generation (MAG) extends Large Language Models with external memory to support long-context reasoning, but existing approaches largely rely on semantic similarity over monolithic memory stores, entangling temporal, causal, and entity information. This design limits interpretability and alignment between query intent and retrieved evidence, leading to suboptimal reasoning accuracy. In this paper, we propose MAGMA, a multi-graph agentic memory architecture that represents each memory item across orthogonal semantic, temporal, causal, and entity graphs. MAGMA formulates retrieval as policy-guided traversal over these relational views, enabling query-adaptive selection and structured context construction. By decoupling memory representation from retrieval logic, MAGMA provides transparent reasoning paths and fine-grained control over retrieval. Experiments on LoCoMo and LongMemEval demonstrate that MAGMA consistently outperforms state-of-the-art agentic memory systems in long-horizon reasoning tasks.",
    "translation": "标题：MAGMA：基于多图架构的智能体记忆系统\n\n摘要：记忆增强生成技术通过为大型语言模型引入外部记忆机制来支持长上下文推理，但现有方法主要依赖单一记忆存储的语义相似性检索，导致时间、因果与实体信息相互耦合。这种设计限制了查询意图与检索证据之间的可解释性与对齐度，进而影响推理准确性。本文提出MAGMA——一种基于多图结构的智能体记忆架构，该架构将每个记忆单元映射至正交的语义图、时间图、因果图与实体图中。MAGMA将检索过程定义为基于策略的多图遍历机制，实现查询自适应的记忆选择与结构化上下文构建。通过解耦记忆表征与检索逻辑，MAGMA提供了透明的推理路径与细粒度检索控制。在LoCoMo与LongMemEval基准上的实验表明，MAGMA在长程推理任务中持续优于当前最先进的智能体记忆系统。",
    "url": "https://huggingface.co/papers/2601.03236",
    "arxiv_url": "https://arxiv.org/abs/2601.03236"
  },
  {
    "title": "RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization",
    "summary": "We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.",
    "translation": "标题：RGS-SLAM：基于单次密集初始化的鲁棒高斯溅射SLAM系统\n\n摘要：本文提出RGS-SLAM，一种鲁棒的高斯溅射SLAM框架。该框架采用免训练的对应关系-高斯初始化方法，取代了GS-SLAM中依赖残差驱动的致密化阶段。不同于传统方法通过残差揭示缺失几何结构来逐步添加高斯元素，RGS-SLAM通过对经置信感知内点分类器优化的DINOv3描述符所生成的密集多视角对应关系进行单次三角测量，在优化前即可生成分布均匀且具有结构感知能力的高斯种子。这种初始化策略显著提升了早期建图的稳定性，并使收敛速度加快约20%，在纹理丰富和结构复杂的场景中实现了更高的渲染保真度，同时完全兼容现有GS-SLAM流程。在TUM RGB-D和Replica数据集上的评估表明，相较于当前最先进的高斯溅射与点云SLAM系统，RGS-SLAM在定位与重建精度方面达到竞争性乃至更优的性能，同时保持高达925 FPS的实时建图能力。",
    "url": "https://huggingface.co/papers/2601.00705",
    "arxiv_url": "https://arxiv.org/abs/2601.00705"
  }
]