[
  {
    "title": "Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization",
    "summary": "The image geolocalization task aims to predict the location where an image was taken anywhere on Earth using visual clues. Existing large vision-language model (LVLM) approaches leverage world knowledge, chain-of-thought reasoning, and agentic capabilities, but overlook a common strategy used by humans -- using maps. In this work, we first equip the model Thinking with Map ability and formulate it as an agent-in-the-map loop. We develop a two-stage optimization scheme for it, including agentic reinforcement learning (RL) followed by parallel test-time scaling (TTS). The RL strengthens the agentic capability of model to improve sampling efficiency, and the parallel TTS enables the model to explore multiple candidate paths before making the final prediction, which is crucial for geolocalization. To evaluate our method on up-to-date and in-the-wild images, we further present MAPBench, a comprehensive geolocalization training and evaluation benchmark composed entirely of real-world images. Experimental results show that our method outperforms existing open- and closed-source models on most metrics, specifically improving Acc@500m from 8.0\\% to 22.1\\% compared to Gemini-3-Pro with Google Search/Map grounded mode.",
    "translation": "标题：基于地图的思考：用于地理定位的强化并行地图增强智能体\n\n摘要：图像地理定位任务旨在利用视觉线索预测图像在地球上任意位置的拍摄地点。现有的大型视觉语言模型方法虽然利用了世界知识、思维链推理和智能体能力，但忽视了人类常用的一种策略——使用地图。在本研究中，我们首先赋予模型“基于地图思考”的能力，并将其构建为地图内智能体循环框架。为此，我们开发了一种两阶段优化方案，包括智能体强化学习阶段和并行测试时扩展阶段。强化学习增强了模型的智能体能力以提高采样效率，而并行测试时扩展使模型能够在最终预测前探索多条候选路径，这对地理定位至关重要。为了在最新真实场景图像上评估我们的方法，我们进一步提出了MAPBench——一个完全由真实世界图像构成的综合性地理定位训练与评估基准。实验结果表明，我们的方法在多数指标上优于现有开源和闭源模型，特别是在与具备谷歌搜索/地图增强模式的Gemini-3-Pro对比时，将Acc@500m指标从8.0%提升至22.1%。",
    "url": "https://huggingface.co/papers/2601.05432",
    "arxiv_url": "https://arxiv.org/abs/2601.05432"
  },
  {
    "title": "MMFormalizer: Multimodal Autoformalization in the Wild",
    "summary": "Autoformalization, which translates natural language mathematics into formal statements to enable machine reasoning, faces fundamental challenges in the wild due to the multimodal nature of the physical world, where physics requires inferring hidden constraints (e.g., mass or energy) from visual elements. To address this, we propose MMFormalizer, which extends autoformalization beyond text by integrating adaptive grounding with entities from real-world mathematical and physical domains. MMFormalizer recursively constructs formal propositions from perceptually grounded primitives through recursive grounding and axiom composition, with adaptive recursive termination ensuring that every abstraction is supported by visual evidence and anchored in dimensional or axiomatic grounding. We evaluate MMFormalizer on a new benchmark, PhyX-AF, comprising 115 curated samples from MathVerse, PhyX, Synthetic Geometry, and Analytic Geometry, covering diverse multimodal autoformalization tasks. Results show that frontier models such as GPT-5 and Gemini-3-Pro achieve the highest compile and semantic accuracy, with GPT-5 excelling in physical reasoning, while geometry remains the most challenging domain. Overall, MMFormalizer provides a scalable framework for unified multimodal autoformalization, bridging perception and formal reasoning. To the best of our knowledge, this is the first multimodal autoformalization method capable of handling classical mechanics (derived from the Hamiltonian), as well as relativity, quantum mechanics, and thermodynamics. More details are available on our project page: MMFormalizer.github.io",
    "translation": "标题：MMFormalizer：面向真实场景的多模态自动形式化方法\n\n摘要：自动形式化旨在将自然语言描述的数学内容转化为形式化语句以支持机器推理，但在真实物理世界中面临根本性挑战——物理问题常需从视觉元素推断隐藏约束（如质量或能量），这体现了问题的多模态本质。为此，我们提出MMFormalizer，通过将自适应实体锚定与真实世界的数学及物理领域实体相结合，将自动形式化的范畴从纯文本扩展至多模态场景。该系统通过递归锚定与公理组合，从感知锚定的基本单元递归构建形式化命题，其自适应递归终止机制确保每个抽象概念均获得视觉证据支持，并锚定于维度或公理基础之上。我们在新构建的基准测试集PhyX-AF上评估MMFormalizer，该数据集包含从MathVerse、PhyX、合成几何与解析几何中精选的115个样本，涵盖多样化的多模态自动形式化任务。实验结果表明，GPT-5与Gemini-3-Pro等前沿模型在编译准确率与语义准确率上表现最佳，其中GPT-5在物理推理任务中尤为突出，而几何领域仍是当前最具挑战性的方向。总体而言，MMFormalizer为统一的多模态自动形式化提供了可扩展框架，有效连接了感知与形式化推理。据我们所知，这是首个能够处理经典力学（源自哈密顿量体系）、相对论、量子力学及热力学的多模态自动形式化方法。更多细节详见项目页面：MMFormalizer.github.io",
    "url": "https://huggingface.co/papers/2601.03017",
    "arxiv_url": "https://arxiv.org/abs/2601.03017"
  },
  {
    "title": "CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature",
    "summary": "A photorealistic and controllable 3D caricaturization framework for faces is introduced. We start with an intrinsic Gaussian curvature-based surface exaggeration technique, which, when coupled with texture, tends to produce over-smoothed renders. To address this, we resort to 3D Gaussian Splatting (3DGS), which has recently been shown to produce realistic free-viewpoint avatars. Given a multiview sequence, we extract a FLAME mesh, solve a curvature-weighted Poisson equation, and obtain its exaggerated form. However, directly deforming the Gaussians yields poor results, necessitating the synthesis of pseudo-ground-truth caricature images by warping each frame to its exaggerated 2D representation using local affine transformations. We then devise a training scheme that alternates real and synthesized supervision, enabling a single Gaussian collection to represent both natural and exaggerated avatars. This scheme improves fidelity, supports local edits, and allows continuous control over the intensity of the caricature. In order to achieve real-time deformations, an efficient interpolation between the original and exaggerated surfaces is introduced. We further analyze and show that it has a bounded deviation from closed-form solutions. In both quantitative and qualitative evaluations, our results outperform prior work, delivering photorealistic, geometry-controlled caricature avatars.",
    "translation": "标题：CaricatureGS：基于高斯曲率的三维高斯泼溅人脸夸张化方法\n\n摘要：本文提出了一种兼具照片级真实感与可控性的三维人脸夸张化框架。我们首先采用基于本征高斯曲率的表面夸张技术，但发现其与纹理结合时易产生过度平滑的渲染效果。为解决此问题，我们引入近期被证实能生成逼真自由视角虚拟形象的三维高斯泼溅技术。基于多视角图像序列，我们提取FLAME网格模型，求解曲率加权泊松方程，获得其夸张化形态。然而直接对高斯分布进行形变会导致效果不佳，因此我们通过局部仿射变换将每帧图像扭曲至其对应的二维夸张表征，合成了伪真实夸张图像。随后设计了一种交替使用真实数据与合成数据监督的训练方案，使单一高斯集合能够同时表征自然与夸张形态的虚拟形象。该方案提升了保真度，支持局部编辑，并允许对夸张强度进行连续控制。为实现实时形变，我们引入了原始表面与夸张表面之间的高效插值方法，并通过分析证明该方法与闭式解存在有界偏差。在定量与定性评估中，本方法均优于现有工作，能够生成具有照片级真实感且几何可控的夸张虚拟形象。",
    "url": "https://huggingface.co/papers/2601.03319",
    "arxiv_url": "https://arxiv.org/abs/2601.03319"
  },
  {
    "title": "The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning",
    "summary": "Large language models (LLMs) often fail to learn effective long chain-of-thought (Long CoT) reasoning from human or non-Long-CoT LLMs imitation. To understand this, we propose that effective and learnable Long CoT trajectories feature stable molecular-like structures in unified view, which are formed by three interaction types: Deep-Reasoning (covalent-like), Self-Reflection (hydrogen-bond-like), and Self-Exploration (van der Waals-like). Analysis of distilled trajectories reveals these structures emerge from Long CoT fine-tuning, not keyword imitation. We introduce Effective Semantic Isomers and show that only bonds promoting fast entropy convergence support stable Long CoT learning, while structural competition impairs training. Drawing on these findings, we present Mole-Syn, a distribution-transfer-graph method that guides synthesis of effective Long CoT structures, boosting performance and RL stability across benchmarks.",
    "translation": "标题：思维分子结构：长链推理拓扑映射研究\n\n摘要：大语言模型在模仿人类或非长链推理模型时，常难以习得有效的长链推理能力。为探究此问题，本研究提出可学习的长链推理轨迹在统一视域下具有稳定的类分子结构，该结构由三种相互作用构成：深度推理（类共价键作用）、自我反思（类氢键作用）与自我探索（类范德华作用）。对蒸馏轨迹的分析表明，此类结构源于长链推理微调过程，而非关键词模仿。我们提出\"有效语义异构体\"概念，证明仅促进熵快速收敛的键合作用能支撑稳定的长链推理学习，而结构竞争会损害训练效果。基于这些发现，我们开发了Mole-Syn方法——一种基于分布转移图的引导合成技术，可有效构建长链推理结构，在多项基准测试中显著提升模型性能与强化学习稳定性。",
    "url": "https://huggingface.co/papers/2601.06002",
    "arxiv_url": "https://arxiv.org/abs/2601.06002"
  },
  {
    "title": "Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards",
    "summary": "Reinforcement learning (RL) has emerged as a critical technique for enhancing LLM-based deep search agents. However, existing approaches primarily rely on binary outcome rewards, which fail to capture the comprehensiveness and factuality of agents' reasoning process, and often lead to undesirable behaviors such as shortcut exploitation and hallucinations. To address these limitations, we propose Citation-aware Rubric Rewards (CaRR), a fine-grained reward framework for deep search agents that emphasizes reasoning comprehensiveness, factual grounding, and evidence connectivity. CaRR decomposes complex questions into verifiable single-hop rubrics and requires agents to satisfy these rubrics by explicitly identifying hidden entities, supporting them with correct citations, and constructing complete evidence chains that link to the predicted answer. We further introduce Citation-aware Group Relative Policy Optimization (C-GRPO), which combines CaRR and outcome rewards for training robust deep search agents. Experiments show that C-GRPO consistently outperforms standard outcome-based RL baselines across multiple deep search benchmarks. Our analysis also validates that C-GRPO effectively discourages shortcut exploitation, promotes comprehensive, evidence-grounded reasoning, and exhibits strong generalization to open-ended deep research tasks. Our code and data are available at https://github.com/THUDM/CaRR.",
    "translation": "标题：证据链构建：基于引证感知评分奖励的深度搜索智能体鲁棒强化学习\n\n摘要：强化学习已成为提升基于大语言模型的深度搜索智能体性能的关键技术。然而，现有方法主要依赖二元结果奖励，无法有效评估智能体推理过程的全面性与事实依据，常导致捷径利用和事实幻觉等不良行为。为突破这些局限，我们提出引证感知评分奖励框架——一种面向深度搜索智能体的细粒度奖励机制，强调推理的全面性、事实依据性和证据连贯性。该框架将复杂问题分解为可验证的单步评分项，要求智能体通过显式识别隐含实体、提供准确引证支撑，并构建连接预测答案的完整证据链来满足这些评分标准。我们进一步提出引证感知分组相对策略优化算法，该算法融合引证感知评分奖励与结果奖励，用于训练鲁棒的深度搜索智能体。实验表明，在多个深度搜索基准测试中，该算法均稳定优于基于标准结果奖励的强化学习基线方法。分析结果验证了该算法能有效抑制捷径利用行为，促进全面且基于证据的推理过程，并在开放式深度研究任务中展现出强大的泛化能力。相关代码与数据已公开于https://github.com/THUDM/CaRR。",
    "url": "https://huggingface.co/papers/2601.06021",
    "arxiv_url": "https://arxiv.org/abs/2601.06021"
  },
  {
    "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis",
    "summary": "Large language models (LLMs) are expected to be trained to act as agents in various real-world environments, but this process relies on rich and varied tool-interaction sandboxes. However, access to real systems is often restricted; LLM-simulated environments are prone to hallucinations and inconsistencies; and manually built sandboxes are hard to scale. In this paper, we propose EnvScaler, an automated framework for scalable tool-interaction environments via programmatic synthesis. EnvScaler comprises two components. First, SkelBuilder constructs diverse environment skeletons through topic mining, logic modeling, and quality evaluation. Then, ScenGenerator generates multiple task scenarios and rule-based trajectory validation functions for each environment. With EnvScaler, we synthesize 191 environments and about 7K scenarios, and apply them to Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) for Qwen3 series models. Results on three benchmarks show that EnvScaler significantly improves LLMs' ability to solve tasks in complex environments involving multi-turn, multi-tool interactions. We release our code and data at https://github.com/RUC-NLPIR/EnvScaler.",
    "translation": "标题：EnvScaler：基于程序化合成的LLM智能体工具交互环境扩展框架\n\n摘要：大语言模型（LLM）被期望训练为能够在各类现实环境中作为智能体执行任务，但这一过程依赖于丰富多样的工具交互沙箱环境。然而，真实系统的访问往往受限；LLM模拟的环境容易产生幻觉与不一致性；而人工构建的沙箱则难以扩展。本文提出EnvScaler，一种通过程序化合成实现可扩展工具交互环境的自动化框架。EnvScaler包含两个核心组件：首先，SkelBuilder通过主题挖掘、逻辑建模与质量评估构建多样化的环境骨架；随后，ScenGenerator为每个环境生成多任务场景及基于规则的轨迹验证函数。借助EnvScaler，我们合成了191个环境及约7,000个场景，并将其应用于Qwen3系列模型的监督微调（SFT）与强化学习（RL）训练。在三个基准测试上的实验结果表明，EnvScaler显著提升了LLM在涉及多轮次、多工具交互的复杂环境中解决任务的能力。代码与数据已开源：https://github.com/RUC-NLPIR/EnvScaler。",
    "url": "https://huggingface.co/papers/2601.05808",
    "arxiv_url": "https://arxiv.org/abs/2601.05808"
  },
  {
    "title": "Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking",
    "summary": "In this report, we introduce the Qwen3-VL-Embedding and Qwen3-VL-Reranker model series, the latest extensions of the Qwen family built on the Qwen3-VL foundation model. Together, they provide an end-to-end pipeline for high-precision multimodal search by mapping diverse modalities, including text, images, document images, and video, into a unified representation space. The Qwen3-VL-Embedding model employs a multi-stage training paradigm, progressing from large-scale contrastive pre-training to reranking model distillation, to generate semantically rich high-dimensional vectors. It supports Matryoshka Representation Learning, enabling flexible embedding dimensions, and handles inputs up to 32k tokens. Complementing this, Qwen3-VL-Reranker performs fine-grained relevance estimation for query-document pairs using a cross-encoder architecture with cross-attention mechanisms. Both model series inherit the multilingual capabilities of Qwen3-VL, supporting more than 30 languages, and are released in 2B and 8B parameter sizes to accommodate diverse deployment requirements. Empirical evaluations demonstrate that the Qwen3-VL-Embedding series achieves state-of-the-art results across diverse multimodal embedding evaluation benchmarks. Specifically, Qwen3-VL-Embedding-8B attains an overall score of 77.8 on MMEB-V2, ranking first among all models (as of January 8, 2025). This report presents the architecture, training methodology, and practical capabilities of the series, demonstrating their effectiveness on various multimodal retrieval tasks, including image-text retrieval, visual question answering, and video-text matching.",
    "translation": "标题：Qwen3-VL-Embedding 与 Qwen3-VL-Reranker：一种用于前沿多模态检索与排序的统一框架\n\n摘要：本报告介绍了 Qwen3-VL-Embedding 与 Qwen3-VL-Reranker 模型系列，它们是基于 Qwen3-VL 基础模型构建的 Qwen 家族最新扩展。二者共同提供了一个端到端的高精度多模态搜索流程，通过将文本、图像、文档图像及视频等多种模态映射到一个统一的表示空间中实现。Qwen3-VL-Embedding 模型采用多阶段训练范式，从大规模对比预训练逐步推进到重排序模型蒸馏，以生成语义丰富的高维向量。该模型支持嵌套表示学习，可实现灵活的嵌入维度，并能处理长达 32k 词元的输入。作为补充，Qwen3-VL-Reranker 采用具有交叉注意力机制的交叉编码器架构，对查询-文档对进行细粒度相关性估计。两个模型系列均继承了 Qwen3-VL 的多语言能力，支持超过 30 种语言，并以 2B 和 8B 参数规模发布，以适应多样化的部署需求。实证评估表明，Qwen3-VL-Embedding 系列在多种多模态嵌入评估基准上均取得了领先性能。具体而言，Qwen3-VL-Embedding-8B 在 MMEB-V2 基准上获得 77.8 的综合得分，在所有模型中位列第一（截至 2025 年 1 月 8 日）。本报告详细阐述了该系列的架构设计、训练方法及实际能力，并展示了其在图像-文本检索、视觉问答、视频-文本匹配等多种多模态检索任务上的有效性。",
    "url": "https://huggingface.co/papers/2601.04720",
    "arxiv_url": "https://arxiv.org/abs/2601.04720"
  },
  {
    "title": "Can We Predict Before Executing Machine Learning Agents?",
    "summary": "Autonomous machine learning agents have revolutionized scientific discovery, yet they remain constrained by a Generate-Execute-Feedback paradigm. Previous approaches suffer from a severe Execution Bottleneck, as hypothesis evaluation relies strictly on expensive physical execution. To bypass these physical constraints, we internalize execution priors to substitute costly runtime checks with instantaneous predictive reasoning, drawing inspiration from World Models. In this work, we formalize the task of Data-centric Solution Preference and construct a comprehensive corpus of 18,438 pairwise comparisons. We demonstrate that LLMs exhibit significant predictive capabilities when primed with a Verified Data Analysis Report, achieving 61.5% accuracy and robust confidence calibration. Finally, we instantiate this framework in FOREAGENT, an agent that employs a Predict-then-Verify loop, achieving a 6x acceleration in convergence while surpassing execution-based baselines by +6%. Our code and dataset will be publicly available soon at https://github.com/zjunlp/predict-before-execute.",
    "translation": "标题：能否在执行前预测机器学习智能体的行为？\n\n摘要：自主机器学习智能体已彻底改变科学发现范式，但其仍受限于“生成-执行-反馈”的传统框架。现有方法因严格依赖高成本的物理执行来验证假设，面临严重的“执行瓶颈”问题。受世界模型启发，本研究通过内化执行先验知识，以即时预测推理替代昂贵的运行时验证，从而突破物理约束。我们在此工作中形式化定义了“数据驱动的解决方案偏好”任务，并构建了包含18,438组对比对的完整语料库。实验表明，大语言模型在获得“已验证数据分析报告”的提示后展现出显著的预测能力，准确率达61.5%且置信度校准稳健。最终，我们将该框架实例化为FOREAGENT智能体，采用“预测-验证”循环机制，在收敛速度提升6倍的同时，其性能超越基于执行的基线方法6%。代码与数据集将于近期在https://github.com/zjunlp/predict-before-execute公开。",
    "url": "https://huggingface.co/papers/2601.05930",
    "arxiv_url": "https://arxiv.org/abs/2601.05930"
  },
  {
    "title": "AgentOCR: Reimagining Agent History via Optical Self-Compression",
    "summary": "Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual cache, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\\% of text-based agent performance while substantially reducing token consumption (>50\\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-compression.",
    "translation": "标题：AgentOCR：通过光学自压缩重构智能体历史\n\n摘要：大型语言模型的最新进展使得基于多轮交互轨迹进行强化学习的智能体系统成为可能，但实际部署受限于快速增长的文本历史记录，这些记录会大幅增加令牌开销和内存占用。本文提出AgentOCR框架，该框架通过将累积的观察-行动历史表示为紧凑的渲染图像，利用视觉令牌更高的信息密度。为实现多轮交互的可扩展性，AgentOCR提出分段光学缓存机制。该机制通过将历史分解为可哈希的片段并维护视觉缓存，消除了冗余的重复渲染。除固定渲染外，AgentOCR引入智能体自压缩机制，使智能体主动输出压缩率，并通过压缩感知奖励进行训练，从而自适应地平衡任务成功率与令牌效率。我们在ALFWorld和基于搜索的问答等具有挑战性的智能体基准测试上进行了广泛实验。结果显示，AgentOCR在显著降低令牌消耗（>50%）的同时，保持了基于文本的智能体95%以上的性能，实现了稳定的令牌与内存效率。进一步分析验证了分段光学缓存带来20倍的渲染加速效果，以及自压缩机制有效的策略平衡能力。",
    "url": "https://huggingface.co/papers/2601.04786",
    "arxiv_url": "https://arxiv.org/abs/2601.04786"
  },
  {
    "title": "An Empirical Study on Preference Tuning Generalization and Diversity Under Domain Shift",
    "summary": "Preference tuning aligns pretrained language models to human judgments of quality, helpfulness, or safety by optimizing over explicit preference signals rather than likelihood alone. Prior work has shown that preference-tuning degrades performance and reduces helpfulness when evaluated outside the training domain. However, the extent to which adaptation strategies mitigate this domain shift remains unexplored. We address this challenge by conducting a comprehensive and systematic study of alignment generalization under domain shift. We compare five popular alignment objectives and various adaptation strategies from source to target, including target-domain supervised fine-tuning and pseudo-labeling, across summarization and question-answering helpfulness tasks. Our findings reveal systematic differences in generalization across alignment objectives under domain shift. We show that adaptation strategies based on pseudo-labeling can substantially reduce domain-shift degradation",
    "translation": "标题：领域偏移下偏好调优泛化性与多样性的实证研究\n\n摘要：偏好调优通过优化显式偏好信号（而非仅依赖似然性），使预训练语言模型与人类在质量、实用性或安全性方面的判断标准对齐。已有研究表明，当在训练领域外进行评估时，偏好调优会降低模型性能并削弱其实用性。然而，适应性策略在多大程度上能够缓解这种领域偏移的影响尚未得到充分探索。为应对这一挑战，本研究对领域偏移下的对齐泛化问题进行了全面系统的考察。我们在文本摘要和问答实用性任务中，比较了五种主流对齐目标以及从源领域到目标领域的多种适应性策略（包括目标领域监督微调与伪标注方法）。研究结果表明，不同对齐目标在领域偏移下的泛化表现存在系统性差异。我们进一步证明，基于伪标注的适应性策略能够显著减轻领域偏移导致的性能退化。",
    "url": "https://huggingface.co/papers/2601.05882",
    "arxiv_url": "https://arxiv.org/abs/2601.05882"
  },
  {
    "title": "VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction",
    "summary": "Recent advances in video generation have been dominated by diffusion and flow-matching models, which produce high-quality results but remain computationally intensive and difficult to scale. In this work, we introduce VideoAR, the first large-scale Visual Autoregressive (VAR) framework for video generation that combines multi-scale next-frame prediction with autoregressive modeling. VideoAR disentangles spatial and temporal dependencies by integrating intra-frame VAR modeling with causal next-frame prediction, supported by a 3D multi-scale tokenizer that efficiently encodes spatio-temporal dynamics. To improve long-term consistency, we propose Multi-scale Temporal RoPE, Cross-Frame Error Correction, and Random Frame Mask, which collectively mitigate error propagation and stabilize temporal coherence. Our multi-stage pretraining pipeline progressively aligns spatial and temporal learning across increasing resolutions and durations. Empirically, VideoAR achieves new state-of-the-art results among autoregressive models, improving FVD on UCF-101 from 99.5 to 88.6 while reducing inference steps by over 10x, and reaching a VBench score of 81.74-competitive with diffusion-based models an order of magnitude larger. These results demonstrate that VideoAR narrows the performance gap between autoregressive and diffusion paradigms, offering a scalable, efficient, and temporally consistent foundation for future video generation research.",
    "translation": "标题：VideoAR：基于下一帧与尺度预测的自回归视频生成模型\n\n摘要：当前视频生成领域的研究进展主要由扩散模型和流匹配模型主导，这些模型虽能生成高质量结果，但计算成本高昂且难以扩展。本研究提出VideoAR，首个结合多尺度下一帧预测与自回归建模的大规模视觉自回归视频生成框架。VideoAR通过将帧内自回归建模与因果性下一帧预测相结合，并辅以能高效编码时空动态的三维多尺度分词器，实现了空间与时间依赖关系的解耦。为提升长时一致性，我们提出了多尺度时序旋转位置编码、跨帧误差校正和随机帧掩码技术，共同抑制误差传播并增强时序连贯性。我们的多阶段预训练流程通过逐步提升分辨率和时长，实现了空间与时间学习的渐进对齐。实验表明，VideoAR在自回归模型中取得了最先进的性能：在UCF-101数据集上将FVD指标从99.5提升至88.6，同时减少超过10倍的推理步数，并获得81.74的VBench评分——该成绩可与规模大一个数量级的扩散模型相媲美。这些结果证明VideoAR显著缩小了自回归范式与扩散范式之间的性能差距，为未来视频生成研究提供了可扩展、高效且时序一致的基础框架。",
    "url": "https://huggingface.co/papers/2601.05966",
    "arxiv_url": "https://arxiv.org/abs/2601.05966"
  },
  {
    "title": "Illusions of Confidence? Diagnosing LLM Truthfulness via Neighborhood Consistency",
    "summary": "As Large Language Models (LLMs) are increasingly deployed in real-world settings, correctness alone is insufficient. Reliable deployment requires maintaining truthful beliefs under contextual perturbations. Existing evaluations largely rely on point-wise confidence like Self-Consistency, which can mask brittle belief. We show that even facts answered with perfect self-consistency can rapidly collapse under mild contextual interference. To address this gap, we propose Neighbor-Consistency Belief (NCB), a structural measure of belief robustness that evaluates response coherence across a conceptual neighborhood. To validate the efficiency of NCB, we introduce a new cognitive stress-testing protocol that probes outputs stability under contextual interference. Experiments across multiple LLMs show that the performance of high-NCB data is relatively more resistant to interference. Finally, we present Structure-Aware Training (SAT), which optimizes context-invariant belief structure and reduces long-tail knowledge brittleness by approximately 30%. Code will be available at https://github.com/zjunlp/belief.",
    "translation": "标题：自信的幻觉？通过邻域一致性诊断大语言模型的真实性\n\n摘要：随着大语言模型在现实场景中的部署日益广泛，仅关注回答正确性已显不足。可靠的部署要求模型在上下文扰动下保持真实的信念。现有评估主要依赖点状置信度指标（如自一致性），这可能掩盖信念的脆弱性。研究表明，即使是具有完美自一致性的回答事实，在轻微上下文干扰下也可能迅速崩溃。为弥补这一缺陷，我们提出邻域一致性信念——一种评估概念邻域内响应连贯性的信念稳健性结构化度量方法。为验证该方法的有效性，我们设计了新的认知压力测试协议，用于探测上下文干扰下的输出稳定性。在多类大语言模型上的实验表明，具有高邻域一致性信念的数据在抗干扰性方面表现更为稳健。最后，我们提出结构感知训练方法，通过优化上下文不变的信念结构，将长尾知识的脆弱性降低约30%。代码发布于https://github.com/zjunlp/belief。",
    "url": "https://huggingface.co/papers/2601.05905",
    "arxiv_url": "https://arxiv.org/abs/2601.05905"
  },
  {
    "title": "Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals",
    "summary": "Recent advancements in video generation have enabled the development of ``world models'' capable of simulating potential futures for robotics and planning. However, specifying precise goals for these models remains a challenge; text instructions are often too abstract to capture physical nuances, while target images are frequently infeasible to specify for dynamic tasks. To address this, we introduce Goal Force, a novel framework that allows users to define goals via explicit force vectors and intermediate dynamics, mirroring how humans conceptualize physical tasks. We train a video generation model on a curated dataset of synthetic causal primitives-such as elastic collisions and falling dominos-teaching it to propagate forces through time and space. Despite being trained on simple physics data, our model exhibits remarkable zero-shot generalization to complex, real-world scenarios, including tool manipulation and multi-object causal chains. Our results suggest that by grounding video generation in fundamental physical interactions, models can emerge as implicit neural physics simulators, enabling precise, physics-aware planning without reliance on external engines. We release all datasets, code, model weights, and interactive video demos at our project page.",
    "translation": "标题：目标力：教授视频模型实现物理条件化目标\n\n摘要：视频生成领域的最新进展使得能够开发出可为机器人技术和规划任务模拟潜在未来的“世界模型”。然而，为这些模型指定精确目标仍具挑战性：文本指令通常过于抽象而难以捕捉物理细节，而目标图像对于动态任务往往难以指定。为此，我们提出“目标力”这一新颖框架，允许用户通过明确的力向量和中间动力学过程来定义目标，从而模拟人类对物理任务的思维模式。我们在精心构建的合成因果基元数据集（如弹性碰撞和多米诺骨牌倾倒）上训练视频生成模型，使其学会在时空维度上传递力的作用。尽管仅基于简单物理数据进行训练，我们的模型在复杂现实场景（包括工具操控和多物体因果链）中展现出卓越的零样本泛化能力。研究结果表明，通过将视频生成建立在基础物理交互之上，模型能够演化为隐式神经物理模拟器，实现无需依赖外部引擎的精确物理感知规划。相关数据集、代码、模型权重及交互式视频演示已发布于项目页面。\n\n摘要：[中文摘要]",
    "url": "https://huggingface.co/papers/2601.05848",
    "arxiv_url": "https://arxiv.org/abs/2601.05848"
  },
  {
    "title": "BizFinBench.v2: A Unified Dual-Mode Bilingual Benchmark for Expert-Level Financial Capability Alignment",
    "summary": "Large language models have undergone rapid evolution, emerging as a pivotal technology for intelligence in financial operations. However, existing benchmarks are often constrained by pitfalls such as reliance on simulated or general-purpose samples and a focus on singular, offline static scenarios. Consequently, they fail to align with the requirements for authenticity and real-time responsiveness in financial services, leading to a significant discrepancy between benchmark performance and actual operational efficacy. To address this, we introduce BizFinBench.v2, the first large-scale evaluation benchmark grounded in authentic business data from both Chinese and U.S. equity markets, integrating online assessment. We performed clustering analysis on authentic user queries from financial platforms, resulting in eight fundamental tasks and two online tasks across four core business scenarios, totaling 29,578 expert-level Q&A pairs. Experimental results demonstrate that ChatGPT-5 achieves a prominent 61.5% accuracy in main tasks, though a substantial gap relative to financial experts persists; in online tasks, DeepSeek-R1 outperforms all other commercial LLMs. Error analysis further identifies the specific capability deficiencies of existing models within practical financial business contexts. BizFinBench.v2 transcends the limitations of current benchmarks, achieving a business-level deconstruction of LLM financial capabilities and providing a precise basis for evaluating efficacy in the widespread deployment of LLMs within the financial domain. The data and code are available at https://github.com/HiThink-Research/BizFinBench.v2.",
    "translation": "标题：BizFinBench.v2：一个面向专家级金融能力对齐的统一双模式双语基准\n\n摘要：大语言模型经历了快速演进，已成为金融运营智能化的关键技术。然而，现有基准常受限于依赖模拟或通用样本、聚焦单一离线静态场景等缺陷，导致其无法契合金融服务对真实性与实时响应的要求，造成基准表现与实际运营效能间的显著差距。为此，我们推出BizFinBench.v2，这是首个基于中美股市真实业务数据并融合在线评估的大规模评测基准。通过对金融平台真实用户查询进行聚类分析，我们在四大核心业务场景下构建了八项基础任务与两项在线任务，共计29,578组专家级问答对。实验结果显示，ChatGPT-5在主任务中取得61.5%的突出准确率，但与金融专家仍存在明显差距；在线任务中DeepSeek-R1的表现优于所有其他商用大语言模型。错误分析进一步揭示了现有模型在真实金融业务场景中的具体能力缺陷。BizFinBench.v2突破了当前基准的局限性，实现了对大语言模型金融能力的业务级解构，为评估大语言模型在金融领域广泛部署的效能提供了精准依据。数据与代码已公开于https://github.com/HiThink-Research/BizFinBench.v2。",
    "url": "https://huggingface.co/papers/2601.06401",
    "arxiv_url": "https://arxiv.org/abs/2601.06401"
  },
  {
    "title": "Orient Anything V2: Unifying Orientation and Rotation Understanding",
    "summary": "This work presents Orient Anything V2, an enhanced foundation model for unified understanding of object 3D orientation and rotation from single or paired images. Building upon Orient Anything V1, which defines orientation via a single unique front face, V2 extends this capability to handle objects with diverse rotational symmetries and directly estimate relative rotations. These improvements are enabled by four key innovations: 1) Scalable 3D assets synthesized by generative models, ensuring broad category coverage and balanced data distribution; 2) An efficient, model-in-the-loop annotation system that robustly identifies 0 to N valid front faces for each object; 3) A symmetry-aware, periodic distribution fitting objective that captures all plausible front-facing orientations, effectively modeling object rotational symmetry; 4) A multi-frame architecture that directly predicts relative object rotations. Extensive experiments show that Orient Anything V2 achieves state-of-the-art zero-shot performance on orientation estimation, 6DoF pose estimation, and object symmetry recognition across 11 widely used benchmarks. The model demonstrates strong generalization, significantly broadening the applicability of orientation estimation in diverse downstream tasks.",
    "translation": "标题：Orient Anything V2：统一朝向与旋转理解\n\n摘要：本研究提出Orient Anything V2，这是一个增强型基础模型，用于从单张或成对图像中统一理解物体的三维朝向与旋转。该模型在Orient Anything V1（通过单一独特正面定义朝向）的基础上进行扩展，能够处理具有不同旋转对称性的物体，并直接估计相对旋转。这些改进得益于四项关键创新：1）通过生成模型合成可扩展的三维资产，确保广泛的类别覆盖与均衡的数据分布；2）一种高效的模型在环标注系统，能够鲁棒地识别每个物体0到N个有效正面；3）一种对称感知的周期性分布拟合目标，可捕捉所有可能的正面朝向，有效建模物体的旋转对称性；4）一种直接预测物体相对旋转的多帧架构。大量实验表明，Orient Anything V2在11个广泛使用的基准测试中，于朝向估计、六自由度姿态估计和物体对称性识别任务上均实现了零样本性能的领先水平。该模型展现出强大的泛化能力，显著拓宽了朝向估计在多种下游任务中的适用性。",
    "url": "https://huggingface.co/papers/2601.05573",
    "arxiv_url": "https://arxiv.org/abs/2601.05573"
  },
  {
    "title": "Same Claim, Different Judgment: Benchmarking Scenario-Induced Bias in Multilingual Financial Misinformation Detection",
    "summary": "Large language models (LLMs) have been widely applied across various domains of finance. Since their training data are largely derived from human-authored corpora, LLMs may inherit a range of human biases. Behavioral biases can lead to instability and uncertainty in decision-making, particularly when processing financial information. However, existing research on LLM bias has mainly focused on direct questioning or simplified, general-purpose settings, with limited consideration of the complex real-world financial environments and high-risk, context-sensitive, multilingual financial misinformation detection tasks (\\mfmd). In this work, we propose \\mfmdscen, a comprehensive benchmark for evaluating behavioral biases of LLMs in \\mfmd across diverse economic scenarios. In collaboration with financial experts, we construct three types of complex financial scenarios: (i) role- and personality-based, (ii) role- and region-based, and (iii) role-based scenarios incorporating ethnicity and religious beliefs. We further develop a multilingual financial misinformation dataset covering English, Chinese, Greek, and Bengali. By integrating these scenarios with misinformation claims, \\mfmdscen enables a systematic evaluation of 22 mainstream LLMs. Our findings reveal that pronounced behavioral biases persist across both commercial and open-source models. This project will be available at https://github.com/lzw108/FMD.",
    "translation": "标题：同一论断，不同判断：多语言金融虚假信息检测中情境诱导偏见的基准研究\n\n摘要：大语言模型已广泛应用于金融领域的各个方面。由于训练数据主要来源于人类撰写的语料库，大语言模型可能继承一系列人类偏见。行为偏见可能导致决策的不稳定性和不确定性，尤其是在处理金融信息时。然而，现有关于大语言模型偏见的研究主要集中于直接提问或简化的通用场景，对复杂的现实金融环境以及高风险、情境敏感的多语言金融虚假信息检测任务的考量有限。本研究提出MFMDScen——一个用于评估大语言模型在多语言金融虚假信息检测任务中跨不同经济场景行为偏见的综合基准。通过与金融专家合作，我们构建了三类复杂金融场景：（1）基于角色与人格特质的场景；（2）基于角色与地域背景的场景；（3）融合族群与宗教信仰的角色场景。我们进一步开发了涵盖英语、中文、希腊语和孟加拉语的多语言金融虚假信息数据集。通过将这些场景与虚假信息论断相结合，MFMDScen实现了对22个主流大语言模型的系统性评估。研究结果表明，显著的行为偏见在商业模型和开源模型中持续存在。本项目资源发布于https://github.com/lzw108/FMD。",
    "url": "https://huggingface.co/papers/2601.05403",
    "arxiv_url": "https://arxiv.org/abs/2601.05403"
  },
  {
    "title": "AnyDepth: Depth Estimation Made Easy",
    "summary": "Monocular depth estimation aims to recover the depth information of 3D scenes from 2D images. Recent work has made significant progress, but its reliance on large-scale datasets and complex decoders has limited its efficiency and generalization ability. In this paper, we propose a lightweight and data-centric framework for zero-shot monocular depth estimation. We first adopt DINOv3 as the visual encoder to obtain high-quality dense features. Secondly, to address the inherent drawbacks of the complex structure of the DPT, we design the Simple Depth Transformer (SDT), a compact transformer-based decoder. Compared to the DPT, it uses a single-path feature fusion and upsampling process to reduce the computational overhead of cross-scale feature fusion, achieving higher accuracy while reducing the number of parameters by approximately 85%-89%. Furthermore, we propose a quality-based filtering strategy to filter out harmful samples, thereby reducing dataset size while improving overall training quality. Extensive experiments on five benchmarks demonstrate that our framework surpasses the DPT in accuracy. This work highlights the importance of balancing model design and data quality for achieving efficient and generalizable zero-shot depth estimation. Code: https://github.com/AIGeeksGroup/AnyDepth. Website: https://aigeeksgroup.github.io/AnyDepth.",
    "translation": "标题：AnyDepth：简化深度估计\n\n摘要：单目深度估计旨在从二维图像中恢复三维场景的深度信息。近期研究虽取得显著进展，但其对大规模数据集和复杂解码器的依赖限制了效率与泛化能力。本文提出一种轻量级且以数据为中心的零样本单目深度估计框架。首先采用DINOv3作为视觉编码器以获取高质量密集特征；其次，针对DPT结构复杂性的固有缺陷，设计了基于紧凑Transformer架构的简易深度变换解码器（SDT）。相较于DPT，该解码器采用单路径特征融合与上采样流程，显著降低了跨尺度特征融合的计算开销，在减少约85%-89%参数量的同时实现了更高精度。此外，提出基于质量的数据筛选策略，通过滤除低质量样本在缩减数据集规模的同时提升整体训练质量。在五个基准数据集上的大量实验表明，本框架在精度上超越DPT。本研究凸显了平衡模型设计与数据质量对于实现高效可泛化零样本深度估计的重要性。代码：https://github.com/AIGeeksGroup/AnyDepth。项目网站：https://aigeeksgroup.github.io/AnyDepth。",
    "url": "https://huggingface.co/papers/2601.02760",
    "arxiv_url": "https://arxiv.org/abs/2601.02760"
  },
  {
    "title": "SmartSearch: Process Reward-Guided Query Refinement for Search Agents",
    "summary": "Large language model (LLM)-based search agents have proven promising for addressing knowledge-intensive problems by incorporating information retrieval capabilities. Existing works largely focus on optimizing the reasoning paradigms of search agents, yet the quality of intermediate search queries during reasoning remains overlooked. As a result, the generated queries often remain inaccurate, leading to unexpected retrieval results and ultimately limiting search agents' overall effectiveness. To mitigate this issue, we introduce SmartSearch, a framework built upon two key mechanisms: (1) Process rewards, which provide fine-grained supervision for the quality of each intermediate search query through Dual-Level Credit Assessment. (2) Query refinement, which promotes the optimization of query generation by selectively refining low-quality search queries and regenerating subsequent search rounds based on these refinements. To enable the search agent to progressively internalize the ability to improve query quality under the guidance of process rewards, we design a three-stage curriculum learning framework. This framework guides the agent through a progression from imitation, to alignment, and ultimately to generalization. Experimental results show that SmartSearch consistently surpasses existing baselines, and additional quantitative analyses further confirm its significant gains in both search efficiency and query quality. The code is available at https://github.com/MYVAE/SmartSearch.",
    "translation": "标题：SmartSearch：面向搜索代理的过程奖励引导式查询优化框架\n\n摘要：基于大语言模型的搜索代理通过整合信息检索能力，在解决知识密集型问题方面展现出巨大潜力。现有研究主要聚焦于优化搜索代理的推理范式，但推理过程中中间搜索查询的质量问题尚未得到充分重视。这导致生成的查询往往不够精确，进而引发非预期的检索结果，最终制约搜索代理的整体效能。为缓解这一问题，我们提出SmartSearch框架，其核心机制包括：（1）过程奖励机制：通过双层级信用评估对每个中间搜索查询的质量提供细粒度监督；（2）查询优化机制：通过选择性优化低质量搜索查询，并基于优化结果重新生成后续搜索轮次，从而提升查询生成质量。为使搜索代理能够在过程奖励引导下逐步内化查询质量改进能力，我们设计了三阶段课程学习框架，引导代理依次经历模仿、对齐与泛化三个阶段。实验结果表明，SmartSearch在各项基准测试中均优于现有基线方法，定量分析进一步验证了其在搜索效率与查询质量方面的显著提升。代码已开源：https://github.com/MYVAE/SmartSearch。",
    "url": "https://huggingface.co/papers/2601.04888",
    "arxiv_url": "https://arxiv.org/abs/2601.04888"
  },
  {
    "title": "Over-Searching in Search-Augmented Large Language Models",
    "summary": "Search-augmented large language models (LLMs) excel at knowledge-intensive tasks by integrating external retrieval. However, they often over-search -- unnecessarily invoking search tool even when it does not improve response quality, which leads to computational inefficiency and hallucinations by incorporating irrelevant context. In this work, we conduct a systematic evaluation of over-searching across multiple dimensions, including query types, model categories, retrieval conditions, and multi-turn conversations. Our finding shows: (i) search generally improves answer accuracy on answerable queries but harms abstention on unanswerable ones; (ii) over-searching is more pronounced in complex reasoning models and deep research systems, is exacerbated by noisy retrieval, and compounds across turns in multi-turn conversations; and (iii) the composition of retrieved evidence is crucial, as the presence of negative evidence improves abstention. To quantify over-searching, we introduce Tokens Per Correctness (TPC), an evaluation metric that captures the performance-cost trade-off for search-augmented LLMs. Lastly, we investigate mitigation approaches at both the query and retrieval levels and release the OverSearchQA to foster continued research into efficient search-augmented LLMs.",
    "translation": "标题：检索增强大语言模型中的过度搜索现象研究\n\n摘要：检索增强大语言模型通过整合外部检索机制，在知识密集型任务中表现卓越。然而，这类模型常出现过度搜索现象——即使检索无助于提升回答质量，仍不必要地调用搜索工具，这不仅导致计算效率低下，还可能因引入无关上下文而产生事实幻觉。本研究从查询类型、模型类别、检索条件及多轮对话等多个维度系统评估了过度搜索现象。研究发现：（1）检索通常能提升可回答查询的答案准确率，但会削弱模型对不可回答问题的拒答能力；（2）过度搜索现象在复杂推理模型和深度研究系统中更为显著，其程度受噪声检索影响而加剧，并在多轮对话中随轮次增加而累积；（3）检索证据的构成至关重要，负面证据的存在能有效提升模型的拒答能力。为量化过度搜索，本文提出\"单位正确性所需标记数\"评估指标，用以衡量检索增强大语言模型的性能-成本权衡关系。最后，我们探索了查询层面与检索层面的缓解策略，并发布OverSearchQA数据集以推动高效检索增强大语言模型的持续研究。",
    "url": "https://huggingface.co/papers/2601.05503",
    "arxiv_url": "https://arxiv.org/abs/2601.05503"
  },
  {
    "title": "DR-LoRA: Dynamic Rank LoRA for Mixture-of-Experts Adaptation",
    "summary": "Mixture-of-Experts (MoE) has become a prominent paradigm for scaling Large Language Models (LLMs). Parameter-efficient fine-tuning (PEFT), such as LoRA, is widely adopted to adapt pretrained MoE LLMs to downstream tasks. However, existing approaches assign identical LoRA ranks to all experts, overlooking the intrinsic functional specialization within MoE LLMs. This uniform allocation leads to resource mismatch, task-relevant experts are under-provisioned while less relevant ones receive redundant parameters. We propose a Dynamic Rank LoRA framework named DR-LoRA, which dynamically grows expert LoRA ranks during fine-tuning based on task-specific demands. DR-LoRA employs an Expert Saliency Scoring mechanism that integrates expert routing frequency and LoRA rank importance to quantify each expert's demand for additional capacity. Experts with higher saliency scores are prioritized for rank expansion, enabling the automatic formation of a heterogeneous rank distribution tailored to the target task. Experiments on multiple benchmarks demonstrate that DR-LoRA consistently outperforms standard LoRA and static allocation strategies under the same parameter budget, achieving superior task performance with more efficient parameter utilization.",
    "translation": "标题：DR-LoRA：面向专家混合模型适配的动态秩LoRA方法\n\n摘要：专家混合模型已成为扩展大语言模型的主流范式。参数高效微调技术（如LoRA）被广泛用于将预训练的MoE大语言模型适配至下游任务。然而，现有方法为所有专家分配相同的LoRA秩，忽视了MoE大语言模型内在的功能专化特性。这种均匀分配导致资源错配：任务相关专家参数配置不足，而相关性较低的专家却获得冗余参数。本文提出动态秩LoRA框架DR-LoRA，该框架能根据任务特定需求在微调过程中动态调整专家LoRA秩。DR-LoRA采用专家显著性评分机制，综合专家路由频率与LoRA秩重要性来量化各专家对额外容量的需求。具有较高显著性评分的专家将优先进行秩扩展，从而自动形成适应目标任务的异构秩分布。在多基准测试上的实验表明，在相同参数预算下，DR-LoRA始终优于标准LoRA及静态分配策略，通过更高效的参数利用实现了更优越的任务性能。",
    "url": "https://huggingface.co/papers/2601.04823",
    "arxiv_url": "https://arxiv.org/abs/2601.04823"
  },
  {
    "title": "Memory Matters More: Event-Centric Memory as a Logic Map for Agent Searching and Reasoning",
    "summary": "Large language models (LLMs) are increasingly deployed as intelligent agents that reason, plan, and interact with their environments. To effectively scale to long-horizon scenarios, a key capability for such agents is a memory mechanism that can retain, organize, and retrieve past experiences to support downstream decision-making. However, most existing approaches organize and store memories in a flat manner and rely on simple similarity-based retrieval techniques. Even when structured memory is introduced, existing methods often struggle to explicitly capture the logical relationships among experiences or memory units. Moreover, memory access is largely detached from the constructed structure and still depends on shallow semantic retrieval, preventing agents from reasoning logically over long-horizon dependencies. In this work, we propose CompassMem, an event-centric memory framework inspired by Event Segmentation Theory. CompassMem organizes memory as an Event Graph by incrementally segmenting experiences into events and linking them through explicit logical relations. This graph serves as a logic map, enabling agents to perform structured and goal-directed navigation over memory beyond superficial retrieval, progressively gathering valuable memories to support long-horizon reasoning. Experiments on LoCoMo and NarrativeQA demonstrate that CompassMem consistently improves both retrieval and reasoning performance across multiple backbone models.",
    "translation": "标题：记忆至关重要：以事件为中心的记忆作为智能体搜索与推理的逻辑图谱\n\n摘要：大型语言模型正日益被部署为能够推理、规划并与环境交互的智能体。为有效适应长周期任务场景，此类智能体的关键能力在于具备一种能够保存、组织并检索过往经验以支持下游决策的记忆机制。然而，现有方法大多以扁平化方式组织存储记忆，并依赖简单的基于相似度的检索技术。即使引入结构化记忆，现有方法仍难以显式捕捉经验或记忆单元间的逻辑关联。此外，记忆访问过程往往与已构建的结构脱节，仍依赖于浅层语义检索，导致智能体无法对长周期依赖关系进行逻辑推理。本研究提出CompassMem——一个受事件分割理论启发的、以事件为中心的记忆框架。该框架通过将经验渐进分割为事件并以显式逻辑关系进行连接，将记忆组织为事件图谱。该图谱作为逻辑导航地图，使智能体能够超越表层检索，在记忆空间中进行结构化、目标导向的导航，逐步汇聚有价值记忆以支持长周期推理。在LoCoMo与NarrativeQA数据集上的实验表明，CompassMem在多种骨干模型中均能持续提升检索与推理性能。",
    "url": "https://huggingface.co/papers/2601.04726",
    "arxiv_url": "https://arxiv.org/abs/2601.04726"
  },
  {
    "title": "GenCtrl -- A Formal Controllability Toolkit for Generative Models",
    "summary": "As generative models become ubiquitous, there is a critical need for fine-grained control over the generation process. Yet, while controlled generation methods from prompting to fine-tuning proliferate, a fundamental question remains unanswered: are these models truly controllable in the first place? In this work, we provide a theoretical framework to formally answer this question. Framing human-model interaction as a control process, we propose a novel algorithm to estimate the controllable sets of models in a dialogue setting. Notably, we provide formal guarantees on the estimation error as a function of sample complexity: we derive probably-approximately correct bounds for controllable set estimates that are distribution-free, employ no assumptions except for output boundedness, and work for any black-box nonlinear control system (i.e., any generative model). We empirically demonstrate the theoretical framework on different tasks in controlling dialogue processes, for both language models and text-to-image generation. Our results show that model controllability is surprisingly fragile and highly dependent on the experimental setting. This highlights the need for rigorous controllability analysis, shifting the focus from simply attempting control to first understanding its fundamental limits.",
    "translation": "标题：GenCtrl——生成模型的形式化可控性工具包\n\n摘要：随着生成模型日益普及，对生成过程进行细粒度控制的需求变得至关重要。然而，尽管从提示工程到微调的各种受控生成方法不断涌现，一个根本性问题仍未得到解答：这些模型本身是否真正可控？本研究提出了一个理论框架来形式化地回答这一问题。通过将人机交互建模为控制过程，我们提出了一种新颖算法，用于在对话场景中估计模型的可控集合。值得注意的是，我们基于样本复杂度给出了估计误差的形式化保证：我们推导出可控集合估计的概率近似正确边界，这些边界具有分布无关性，除输出有界性外无需任何假设，且适用于任何黑盒非线性控制系统（即任意生成模型）。我们在对话过程控制的不同任务上对理论框架进行了实证验证，涵盖语言模型和文本到图像生成场景。实验结果表明，模型可控性具有出人意料的脆弱性，且高度依赖实验设置。这凸显了进行严格可控性分析的必要性，应将研究重点从单纯尝试控制转向首先理解其根本性局限。\n\n---\n**改写说明**：\n- 对专业术语和学术表述做了准确且符合惯例的翻译\n- 保持原文逻辑和学术严谨性，语句通顺并符合中文表达习惯\n- 规范处理长句和被动语态，确保摘要整体流畅和正式\n\n如果您需要更简洁或侧重某一方面的译法，我可以继续为您优化调整。",
    "url": "https://huggingface.co/papers/2601.05637",
    "arxiv_url": "https://arxiv.org/abs/2601.05637"
  },
  {
    "title": "TCAndon-Router: Adaptive Reasoning Router for Multi-Agent Collaboration",
    "summary": "Multi-Agent Systems(MAS) have become a powerful paradigm for building high performance intelligent applications. Within these systems, the router responsible for determining which expert agents should handle a given query plays a crucial role in overall performance. Existing routing strategies generally fall into two categories: performance routing, which balances latency and cost across models of different sizes, and task routing, which assigns queries to domain-specific experts to improve accuracy. In real-world enterprise applications, task routing is more suitable; however, most existing approaches rely on static single-label decisions, which introduce two major limitations: (i) difficulty in seamlessly integrating new agents as business domains expand, and (ii) routing conflicts caused by overlapping agent capabilities, ultimately degrading accuracy and robustness.To address these challenges, we propose TCAndon-Router(TCAR): an adaptive reasoning router for multi-agent collaboration. Unlike traditional routers, TCAR supports dynamic agent onboarding and first generates a natural-language reasoning chain before predicting a set of candidate agents capable of handling the query. In addition, we design a collaborative execution pipeline in which selected agents independently produce responses, which are then aggregated and refined into a single high-quality response by a dedicated Refining Agent.Experiments on public datasets and real enterprise data demonstrate that TCAR significantly improves routing accuracy, reduces routing conflicts, and remains robust in ambiguous scenarios. We have released TCAR at https://huggingface.co/tencent/TCAndon-Router to support future research on explainable and collaborative multi-agent routing.",
    "translation": "标题：TCAndon-Router：面向多智能体协作的自适应推理路由机制\n\n摘要：多智能体系统已成为构建高性能智能应用的重要范式。在这些系统中，负责决定由哪些专家智能体处理给定查询的路由机制对整体性能起着关键作用。现有的路由策略主要分为两类：性能路由（通过在不同规模的模型间平衡延迟与成本）和任务路由（将查询分配给特定领域的专家以提高准确性）。在实际企业应用中，任务路由更为适用；然而，现有方法大多依赖静态的单标签决策机制，这带来了两大局限：（一）难以在业务领域扩展时无缝集成新的智能体；（二）因智能体能力重叠导致的路由冲突，最终降低了系统的准确性与鲁棒性。为应对这些挑战，本文提出TCAndon-Router（TCAR）：一种面向多智能体协作的自适应推理路由机制。与传统路由机制不同，TCAR支持动态接入智能体，并首先生成自然语言推理链，再预测能够处理查询的候选智能体集合。此外，我们设计了协作执行流程：被选中的智能体独立生成响应，随后由专用的优化智能体进行聚合与精炼，最终形成单一高质量响应。在公开数据集和企业实际数据上的实验表明，TCAR显著提升了路由准确性，减少了路由冲突，并在模糊场景中保持鲁棒性。我们已在https://huggingface.co/tencent/TCAndon-Router发布TCAR，以支持未来可解释与协作式多智能体路由的相关研究。",
    "url": "https://huggingface.co/papers/2601.04544",
    "arxiv_url": "https://arxiv.org/abs/2601.04544"
  },
  {
    "title": "Distilling Feedback into Memory-as-a-Tool",
    "summary": "We propose a framework that amortizes the cost of inference-time reasoning by converting transient critiques into retrievable guidelines, through a file-based memory system and agent-controlled tool calls. We evaluate this method on the Rubric Feedback Bench, a novel dataset for rubric-based learning. Experiments demonstrate that our augmented LLMs rapidly match the performance of test-time refinement pipelines while drastically reducing inference cost.",
    "translation": "标题：将反馈提炼为记忆即工具\n\n摘要：本文提出一种框架，通过基于文件的记忆系统与智能体控制的工具调用，将瞬时性批判转化为可检索的指导原则，从而分摊推理时逻辑分析的计算成本。我们在Rubric Feedback Bench（一种基于评分标准学习的新型数据集）上对该方法进行评估。实验表明，增强后的大型语言模型能快速达到测试时优化流程的性能水平，同时显著降低推理成本。",
    "url": "https://huggingface.co/papers/2601.05960",
    "arxiv_url": "https://arxiv.org/abs/2601.05960"
  },
  {
    "title": "TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents",
    "summary": "Recent breakthroughs in Large Language Models (LLMs) have positioned them as a promising paradigm for agents, with long-term planning and decision-making emerging as core general-purpose capabilities for adapting to diverse scenarios and tasks. Real-time strategy (RTS) games serve as an ideal testbed for evaluating these two capabilities, as their inherent gameplay requires both macro-level strategic planning and micro-level tactical adaptation and action execution. Existing RTS game-based environments either suffer from relatively high computational demands or lack support for textual observations, which has constrained the use of RTS games for LLM evaluation. Motivated by this, we present TowerMind, a novel environment grounded in the tower defense (TD) subgenre of RTS games. TowerMind preserves the key evaluation strengths of RTS games for assessing LLMs, while featuring low computational demands and a multimodal observation space, including pixel-based, textual, and structured game-state representations. In addition, TowerMind supports the evaluation of model hallucination and provides a high degree of customizability. We design five benchmark levels to evaluate several widely used LLMs under different multimodal input settings. The results reveal a clear performance gap between LLMs and human experts across both capability and hallucination dimensions. The experiments further highlight key limitations in LLM behavior, such as inadequate planning validation, a lack of multifinality in decision-making, and inefficient action use. We also evaluate two classic reinforcement learning algorithms: Ape-X DQN and PPO. By offering a lightweight and multimodal design, TowerMind complements the existing RTS game-based environment landscape and introduces a new benchmark for the AI agent field. The source code is publicly available on GitHub(https://github.com/tb6147877/TowerMind).",
    "translation": "标题：TowerMind：面向大语言模型智能体的塔防游戏学习环境与基准测试平台\n\n摘要：大语言模型（LLMs）近期取得的突破性进展，使其成为构建智能体的潜力范式，其中长期规划与决策能力正逐渐成为适应多样化场景与任务的核心通用能力。实时策略（RTS）游戏是评估这两项能力的理想测试平台，因其固有的游戏机制要求同时具备宏观层面的战略规划能力与微观层面的战术适应及动作执行能力。然而，现有的基于RTS游戏的环境往往存在计算需求较高或缺乏文本观察支持的问题，这限制了大语言模型在RTS游戏评估中的应用。为此，我们提出了TowerMind——一个基于RTS游戏子类塔防（TD）游戏的新型环境。TowerMind保留了RTS游戏评估大语言模型的关键优势，同时具备低计算需求和多模态观察空间，包括基于像素的图像、文本描述以及结构化游戏状态表示。此外，TowerMind支持模型幻觉评估，并提供了高度的可定制性。我们设计了五个基准关卡，用于评估多种广泛使用的大语言模型在不同多模态输入设置下的表现。实验结果显示，大语言模型在能力与幻觉维度上均与人类专家存在明显的性能差距。实验进一步揭示了大语言模型行为的关键局限，例如规划验证不足、决策缺乏多终局性以及动作使用效率低下。我们还评估了两种经典强化学习算法：Ape-X DQN和PPO。通过提供轻量级、多模态的设计，TowerMind补充了现有基于RTS游戏的环境体系，并为人工智能智能体领域引入了新的基准测试标准。项目源代码已在GitHub（https://github.com/tb6147877/TowerMind）上公开。",
    "url": "https://huggingface.co/papers/2601.05899",
    "arxiv_url": "https://arxiv.org/abs/2601.05899"
  },
  {
    "title": "Router-Suggest: Dynamic Routing for Multimodal Auto-Completion in Visually-Grounded Dialogs",
    "summary": "Real-time multimodal auto-completion is essential for digital assistants, chatbots, design tools, and healthcare consultations, where user inputs rely on shared visual context. We introduce Multimodal Auto-Completion (MAC), a task that predicts upcoming characters in live chats using partially typed text and visual cues. Unlike traditional text-only auto-completion (TAC), MAC grounds predictions in multimodal context to better capture user intent. To enable this task, we adapt MMDialog and ImageChat to create benchmark datasets. We evaluate leading vision-language models (VLMs) against strong textual baselines, highlighting trade-offs in accuracy and efficiency. We present Router-Suggest, a router framework that dynamically selects between textual models and VLMs based on dialog context, along with a lightweight variant for resource-constrained environments. Router-Suggest achieves a 2.3x to 10x speedup over the best-performing VLM. A user study shows that VLMs significantly excel over textual models on user satisfaction, notably saving user typing effort and improving the quality of completions in multi-turn conversations. These findings underscore the need for multimodal context in auto-completions, leading to smarter, user-aware assistants.",
    "translation": "标题：Router-Suggest：视觉对话中多模态自动补全的动态路由方法\n\n摘要：实时多模态自动补全对于数字助手、聊天机器人、设计工具及医疗咨询等依赖共享视觉情境的用户输入场景至关重要。本文提出多模态自动补全任务，该任务基于部分已输入文本及视觉线索实时预测对话中的后续字符。与传统纯文本自动补全不同，多模态自动补全将预测建立在多模态语境中，从而更精准捕捉用户意图。为支持该任务研究，我们基于MMDialog与ImageChat构建了基准数据集。通过将前沿视觉语言模型与强文本基线模型进行对比评估，本文揭示了模型在准确性与效率间的权衡关系。我们提出Router-Suggest路由框架，该框架可根据对话语境动态选择文本模型或视觉语言模型，并设计了适用于资源受限环境的轻量化变体。实验表明，Router-Suggest较性能最优的视觉语言模型实现了2.3倍至10倍的加速效果。用户研究证实，在多轮对话场景中，视觉语言模型在用户满意度方面显著优于文本模型，特别是在节省用户输入成本与提升补全质量方面表现突出。这些发现强调了多模态语境在自动补全系统中的必要性，为构建更智能、更具用户感知能力的辅助系统提供了新方向。",
    "url": "https://huggingface.co/papers/2601.05851",
    "arxiv_url": "https://arxiv.org/abs/2601.05851"
  },
  {
    "title": "ViTNT-FIQA: Training-Free Face Image Quality Assessment with Vision Transformers",
    "summary": "Face Image Quality Assessment (FIQA) is essential for reliable face recognition systems. Current approaches primarily exploit only final-layer representations, while training-free methods require multiple forward passes or backpropagation. We propose ViTNT-FIQA, a training-free approach that measures the stability of patch embedding evolution across intermediate Vision Transformer (ViT) blocks. We demonstrate that high-quality face images exhibit stable feature refinement trajectories across blocks, while degraded images show erratic transformations. Our method computes Euclidean distances between L2-normalized patch embeddings from consecutive transformer blocks and aggregates them into image-level quality scores. We empirically validate this correlation on a quality-labeled synthetic dataset with controlled degradation levels. Unlike existing training-free approaches, ViTNT-FIQA requires only a single forward pass without backpropagation or architectural modifications. Through extensive evaluation on eight benchmarks (LFW, AgeDB-30, CFP-FP, CALFW, Adience, CPLFW, XQLFW, IJB-C), we show that ViTNT-FIQA achieves competitive performance with state-of-the-art methods while maintaining computational efficiency and immediate applicability to any pre-trained ViT-based face recognition model.",
    "translation": "标题：ViTNT-FIQA：基于视觉Transformer的无训练人脸图像质量评估方法\n\n摘要：人脸图像质量评估（FIQA）对于构建可靠的人脸识别系统至关重要。现有方法主要仅利用最终层的特征表示，而无训练方法通常需要多次前向传播或反向传播过程。本文提出ViTNT-FIQA，一种无需训练的方法，通过度量中间层视觉Transformer（ViT）模块间图像块嵌入演化的稳定性来评估质量。我们发现高质量人脸图像在跨模块间呈现稳定的特征优化轨迹，而质量退化图像则表现出不稳定的特征变换。该方法通过计算连续Transformer模块间L2归一化图像块嵌入的欧氏距离，并将其聚合为图像级质量分数。我们在具有可控退化等级的质量标注合成数据集上实证验证了这种相关性。与现有无训练方法不同，ViTNT-FIQA仅需单次前向传播，无需反向传播或模型结构修改。通过在八个基准数据集（LFW、AgeDB-30、CFP-FP、CALFW、Adience、CPLFW、XQLFW、IJB-C）上的广泛实验表明，ViTNT-FIQA在保持计算效率、可直接应用于任何预训练ViT人脸识别模型的同时，达到了与最先进方法相竞争的性能水平。",
    "url": "https://huggingface.co/papers/2601.05741",
    "arxiv_url": "https://arxiv.org/abs/2601.05741"
  },
  {
    "title": "IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck",
    "summary": "Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) for Large Language Model (LLM) reasoning have been hindered by a persistent challenge: exploration collapse. The semantic homogeneity of random rollouts often traps models in narrow, over-optimized behaviors. While existing methods leverage policy entropy to encourage exploration, they face inherent limitations. Global entropy regularization is susceptible to reward hacking, which can induce meaningless verbosity, whereas local token-selective updates struggle with the strong inductive bias of pre-trained models. To address this, we propose Latent Policy Optimization via Iterative Information Bottleneck (IIB-LPO), a novel approach that shifts exploration from statistical perturbation of token distributions to topological branching of reasoning trajectories. IIB-LPO triggers latent branching at high-entropy states to diversify reasoning paths and employs the Information Bottleneck principle both as a trajectory filter and a self-reward mechanism, ensuring concise and informative exploration. Empirical results across four mathematical reasoning benchmarks demonstrate that IIB-LPO achieves state-of-the-art performance, surpassing prior methods by margins of up to 5.3% in accuracy and 7.4% in diversity metrics.",
    "translation": "标题：IIB-LPO：基于迭代信息瓶颈的潜在策略优化\n\n摘要：近期，面向大语言模型推理的可验证奖励强化学习虽取得进展，却始终受限于一个持续存在的挑战：探索坍缩。随机推演的语义同质性常使模型陷入狭窄且过度优化的行为模式。现有方法虽利用策略熵鼓励探索，却存在固有局限：全局熵正则化易受奖励黑客攻击，可能导致无意义的冗长输出；而局部基于令牌的选择性更新则受预训练模型强归纳偏置的制约。为此，我们提出基于迭代信息瓶颈的潜在策略优化方法，该创新方法将探索机制从令牌分布的统计扰动转向推理轨迹的拓扑分岔。IIB-LPO在高熵状态触发潜在分岔以多样化推理路径，并运用信息瓶颈原理同时作为轨迹过滤器与自奖励机制，确保探索过程既简洁又信息丰富。在四个数学推理基准测试上的实证结果表明，IIB-LPO实现了最先进的性能，在准确率上超越现有方法最高达5.3%，在多样性指标上提升最高达7.4%。",
    "url": "https://huggingface.co/papers/2601.05870",
    "arxiv_url": "https://arxiv.org/abs/2601.05870"
  },
  {
    "title": "Afri-MCQA: Multimodal Cultural Question Answering for African Languages",
    "summary": "Africa is home to over one-third of the world's languages, yet remains underrepresented in AI research. We introduce Afri-MCQA, the first Multilingual Cultural Question-Answering benchmark covering 7.5k Q&A pairs across 15 African languages from 12 countries. The benchmark offers parallel English-African language Q&A pairs across text and speech modalities and was entirely created by native speakers. Benchmarking large language models (LLMs) on Afri-MCQA shows that open-weight models perform poorly across evaluated cultures, with near-zero accuracy on open-ended VQA when queried in native language or speech. To evaluate linguistic competence, we include control experiments meant to assess this specific aspect separate from cultural knowledge, and we observe significant performance gaps between native languages and English for both text and speech. These findings underscore the need for speech-first approaches, culturally grounded pretraining, and cross-lingual cultural transfer. To support more inclusive multimodal AI development in African languages, we release our Afri-MCQA under academic license or CC BY-NC 4.0 on HuggingFace (https://huggingface.co/datasets/Atnafu/Afri-MCQA)",
    "translation": "标题：Afri-MCQA：面向非洲语言的多模态文化问答基准\n\n摘要：非洲拥有全球超过三分之一的语言，但在人工智能研究中仍处于代表性不足的状态。本文提出Afri-MCQA，这是首个覆盖12个国家、15种非洲语言、包含7.5万组问答对的多语言文化问答基准。该基准提供文本与语音模态的英语-非洲语言平行问答对，所有数据均由母语者创建。基于Afri-MCQA对大语言模型（LLMs）的评估表明，开源模型在各类文化场景中表现欠佳，当以母语或语音形式进行开放式视觉问答时，准确率接近零。为评估语言能力，我们设计了控制实验以区分文化知识与语言能力的影响，观察到模型在非洲母语与英语的文本及语音任务上均存在显著性能差距。这些发现凸显了发展语音优先方法、文化导向预训练以及跨语言文化迁移的必要性。为支持更具包容性的非洲语言多模态人工智能发展，我们已在HuggingFace平台（https://huggingface.co/datasets/Atnafu/Afri-MCQA）以学术许可协议或CC BY-NC 4.0协议开源Afri-MCQA数据集。",
    "url": "https://huggingface.co/papers/2601.05699",
    "arxiv_url": "https://arxiv.org/abs/2601.05699"
  },
  {
    "title": "The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models",
    "summary": "Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\\ cautious) influence behavior across models and medical tasks. We assess performance on clinical triage and patient-safety tasks using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior. We find systematic, context-dependent, and non-monotonic effects: Medical personas improve performance in critical care tasks, yielding gains of up to sim+20% in accuracy and calibration, but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity and sensitivity, but it's highly model-dependent. While aggregated LLM-judge rankings favor medical over non-medical personas in safety-critical cases, we found that human clinicians show moderate agreement on safety compliance (average Cohen's κ= 0.43) but indicate a low confidence in 95.9\\% of their responses on reasoning quality. Our work shows that personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise. The code is available at https://github.com/rsinghlab/Persona\\_Paradox.",
    "translation": "标题：角色悖论：医学角色作为临床语言模型中的行为先验\n\n摘要：角色调节可视为大型语言模型（LLM）的一种行为先验，通常被认为能以单调方式赋予专业能力并提升安全性。然而，其对高风险临床决策的影响仍缺乏深入探究。本研究系统评估了临床LLM中基于角色的控制机制，通过考察专业角色（如急诊科医师、护士）与交互风格（果敢型vs.谨慎型）如何影响不同模型在医疗任务中的行为表现。我们采用多维评估方法，从任务准确性、校准度和安全相关风险行为三个维度，对临床分诊与患者安全任务进行性能评估。研究发现存在系统性、情境依赖且非单调的影响效应：医学角色能提升危重症护理任务的表现，使准确性与校准度最高提升约20%，但在初级诊疗场景中却会导致相当程度的性能下降。交互风格虽能调节风险倾向与敏感度，但其效果高度依赖模型特性。尽管在安全关键案例中，聚合的LLM评估结果倾向于医学角色优于非医学角色，但人类临床医生在安全合规性方面仅呈现中等一致性（平均科恩κ系数=0.43），且对其推理质量的回答表现出极低置信度（95.9%的回应缺乏把握）。本研究揭示：角色作为行为先验会引发情境依赖的权衡效应，而非安全性与专业能力的可靠保证。代码已发布于https://github.com/rsinghlab/Persona_Paradox。",
    "url": "https://huggingface.co/papers/2601.05376",
    "arxiv_url": "https://arxiv.org/abs/2601.05376"
  },
  {
    "title": "Legal Alignment for Safe and Ethical AI",
    "summary": "Alignment of artificial intelligence (AI) encompasses the normative problem of specifying how AI systems should act and the technical problem of ensuring AI systems comply with those specifications. To date, AI alignment has generally overlooked an important source of knowledge and practice for grappling with these problems: law. In this paper, we aim to fill this gap by exploring how legal rules, principles, and methods can be leveraged to address problems of alignment and inform the design of AI systems that operate safely and ethically. This emerging field -- legal alignment -- focuses on three research directions: (1) designing AI systems to comply with the content of legal rules developed through legitimate institutions and processes, (2) adapting methods from legal interpretation to guide how AI systems reason and make decisions, and (3) harnessing legal concepts as a structural blueprint for confronting challenges of reliability, trust, and cooperation in AI systems. These research directions present new conceptual, empirical, and institutional questions, which include examining the specific set of laws that particular AI systems should follow, creating evaluations to assess their legal compliance in real-world settings, and developing governance frameworks to support the implementation of legal alignment in practice. Tackling these questions requires expertise across law, computer science, and other disciplines, offering these communities the opportunity to collaborate in designing AI for the better.",
    "translation": "标题：面向安全与伦理人工智能的法律对齐\n\n摘要：人工智能对齐包含两大核心问题：一是规范性问题，即明确人工智能系统应如何行动；二是技术性问题，即确保人工智能系统符合这些规范。迄今为止，人工智能对齐研究普遍忽视了一个应对这些问题的重要知识来源与实践领域：法律。本文旨在填补这一空白，探讨如何运用法律规则、原则及方法来应对对齐问题，并为设计安全、合乎伦理的人工智能系统提供理论依据。这一新兴领域——法律对齐——聚焦三个研究方向：（1）设计符合合法制度与程序所制定之法律规则内容的人工智能系统；（2）借鉴法律解释方法以指导人工智能系统的推理与决策过程；（3）运用法律概念作为应对人工智能系统可靠性、信任与合作挑战的结构性蓝图。这些研究方向衍生出新的概念性、实证性与制度性问题，包括探究特定人工智能系统应遵循的具体法律体系、建立评估机制以检验其在真实场景中的合规性，以及构建支持法律对齐实践实施的治理框架。解决这些问题需要融合法学、计算机科学等多学科专业知识，为相关领域学者提供了协同设计更优人工智能系统的合作契机。",
    "url": "https://huggingface.co/papers/2601.04175",
    "arxiv_url": "https://arxiv.org/abs/2601.04175"
  }
]